[{"title":"游戏大神 John Carmarck 的编程学习建议","date":"2022-01-26T23:41:20.000Z","path":"2022/01/26/adivces-from-john-camark.html","text":"John Carmark 是游戏编程祖师爷级别的人物，id Software的创始人之一。代表作有《德军总部3D》（Wolfenstein 3D）、《毁灭战士》（Doom）和《雷神之锤》（Quake）等等，这些游戏和它们的后续版本都获取了巨大的成功。 《Doom 启示录》这本书可以说是很多游戏创作者的启蒙书。 他更是创造了游戏编程和图形学中的一些经典技术，比如他在 Doom上第一次使用了二叉树分割技术，表面缓存技术则在 Quake 中第一次出现。 前段时间看到个说法： 衡量一职业是否越老越吃香，就看能不能在前面加上德高望重四字。例如：德高望重的医生，德高望重的老师，德高望重的鉴定师…… 我想 John Carmark 是不是可以配得上这四个字？但是总感觉哪里不对，原来是年纪，其实 John Carmark 今年不过才 51 岁。 就是这样的大神，仍然对编程保持着好奇心和学习的心态，从他的 Twitter @ID_AA_Carmack 可以偶尔看到一些关于编程学习的心得和体会。 比如前几年他对函数式编程感兴趣了，所以做了一个 Scheme 脚本语言来进行 VR 开发。 他提倡的学习方式是实际动手去做一些小东西，这两年他在学一些 AI 相关的东西 : My advice to people wanting to get into game programming has been to write small games completely from scratch while also working on commercial game mods and with unity or unreal. I’m following that myself for AI — I have some C++ backprop-from-scratch projects while also learning python / pytorch / jupyter and experimenting with pretrained models. I had to give myself a bit of a kick to not dwell too much in the lowest levels, but now I am enjoying the new world quite a bit. You can do a remarkable amount with very little code, but when I actually write a loop in python because I don’t know the correct way to do something with tensor ops I get reminded just how slow python is relative to C++. Carmark 甚至还会使用这种静修式的方式来找回编程的乐趣，完整地花费一周时间来自己实现神经网络的小项目，顺便玩一些自己用得比较少的工具: I’m not a Unix geek. I get around ok, but I am most comfortable developing in Visual Studio on Windows. I thought a week of full immersion work in the old school Unix style would be interesting, even if it meant working at a slower pace. It was sort of an adventure in retro computing — this was fvwm and vi. Not vim, actual BSD vi.…..Maybe next time I do this I will try to go full emacs, another major culture that I don’t have much exposure to. 你看，当一个喜欢编程的程序员财富自由了之后，最有乐趣的事还是编程。 那大佬对学习编程有什么建议么？ 简而言之还是那句话：多看，多写！ 2005 年有个 14 岁的小朋友发邮件问 John Carmak 如何学习编程，他当年给了一个回复，2018 年的时候又被翻出来，虽然十多年过去了，技术变得越来越复杂，但是这仍然是学习编程的好建议： John Carmack on Twitter: “This is still generally good advice.” / Twitter When I started, computers couldn’t do much more than simple arithmetic and if statements – my first computer had 4k of memory. How I learned probably isn’t very relevant, because there are so much better resources available today. Don’t expect it to be easy, you will have to work at it. Get a few more books from the library that cover beginning programming to go with the ones you have – sometimes a different author explaining the same thing will help a concept click. Go through all of them at least twice. Try to do every problem and exercise, don’t just read them and think you get it. Lots of people that want to program will talk a lot about programming, but not actually write that many programs. You should write hundreds of programs If you want to get good at something you need to focus on it, which means choosing to exclude some other things from your life. Keep a little journal of what you are working on each day, you may find that you aren’t applying yourself all that hard. Learn something new every single day. Avoid “cookbook programming”, where you copy and paste bits of code that you have found to make something work. Make sure you fully understand what everything it actually doing, and that you are comfortable applying the techniques in other situations. It isn’t a bad idea to start in an environment that give you more exciting feedback, like visual basic, flash, or javascript, but you should try and “find the excitement” in even the most simple data processing tasks. There are layers and layers of things going on in just compiling and running the simplest program that are worth investigating. Pay attention in school to the math classes. It is more important to be able to do basic algebra and trigonometry extremely well than to sort of get by in higher math classes. You should be able to ace all the tests and teach other people if you truly have a complete understanding of the subjects. John Carmack","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"}]},{"title":"培养习惯，程序员学英语没那么难","date":"2022-01-24T13:30:47.000Z","path":"2022/01/24/learn-english-as-programmer.html","text":"接着上一篇，我们谈谈程序员如何能从各个维度来提高自己的英语能力。 首先声明，我自己的英语水平也没那么好，技术类的阅读没有问题，自己还在提高英语写作和口语，我的目标是在专业方向上完全无障碍的英语表达。 这是我自己日常工作生活中总结出来的一些小经验吧，每个人的学习习惯不同，这些仅作参考。 PS：等我开始写这篇的时候，我发现有的事情不能写，比如怎么科学上网之类的 ，那么我们假设这个你已经搞定了🤣 阅读作为 IT 从业人员，我们日常生活中其实会接触很多英文内容，书籍、文档、参考资料等等。如果一个英文不够好的人会优先选择中文内容。 如果你想提高自己的英文能力，就得改变这个默认倾向。否则这就是一个怪圈，你一直看中文的就不可能打破这个循环。 首先，编程的时候参考文档换成优先看英文版本，比如假设你是前端开发，平时需要看 vue 文档，那就换成英文的，而且英文的内容更及时更新。 我建议默认也把操作系统的语言设置为英文的，这样很多软件默认语言也自动成为英文。 关闭浏览器的自动翻译功能，因为这会干扰阅读，也会让你放弃掉自己先阅读英文的机会。 在浏览英文网页的时候，可以使用一些辅助查询插件，比如我用的这个 Chrome 插件 Saladict 沙拉查词 就提供各种辅助查询，也可以把自己不认识的生词保存在线上以便以后回顾。 在用互联网上搜索的时候，也尽量换成使用英文关键词。如果能用 Google 最好，不能的话换成 Bing 、DuckDuckGo 搜英文也比百度好很多。 除了文档，另一个不错的英语阅读来源是 Medium.com，这上面除了技术类的文章也有很多其他方向上的内容，这些文章并不是很长，而且排版都非常好，容易让人沉下心来阅读。欢迎关注我的账号：Medium 👻 如果是在校学生，你也许需要看很多计算机相关的书籍，如果能看英文原版的最好。不要恐惧去拿起整本的英文书，因为只要坚持读完第一本，后面自然就会读起来越来越快。 我在学校的时候借过《Introduction to Algorithms》和 《Structure and Interpretation of Computer Programs》。 学校图书馆的英文书相对更容易借到，因为看的人少很多，从书本的新旧程度看这些书基本没人借过。所以，选择少有人走的路，有时候反而更轻松。 还有不少其他计算机的经典书籍，我认为计算机相关专业的最好在学校阶段看一遍，比如： The Pragmatic Programmer: From Journeyman to Master The C Programming Language The UNIX Programming Environment The Art of Unix Programming Clean Code Refactoring: Improving the Design of Existing Code Computer Systems: A Programmer’s Perspective Code Complete Programming Pearls 这些书中的任何两本认真看完，技术类的阅读不成问题了。 写作英语写作更难一些，因为相对来说如果不是在外企工作，使用英文写作的场景会少很多。 很多时候越是难的事才越有价值，我在之前公司工作的时候需要写英文的技术文档，懂技术的英文不好，懂英文的技术不好，所以把这两种稀缺能力叠加一起就很好地提高自己的价值。 我们也可以刻意地改变一些习惯培养技术写作，比如使用英文来写 Readme 和代码中的注释，使用英文来写平时的记录和博客之类的。 建立一个自己的英文 Blog 是非常好的方式，我在自己的英文站点 http://coderscat.com 上总共写了 150 多篇技术相关的英语文章，有的是平时工作中的一些记录，有的是解题报告，有的是刻意练习写作的。 在写的过程中需要反馈才能提高，因为有很多中式表达如果没有人指出来自己是意识不到的。 为了得到一些反馈，反馈也会激励我们继续写下去，所以我们需要把自己的内容让更多人看到。 在 StackOverflow, Quora 上回答问题是锻炼写作能力的好平台。我有段时间就经常在 Quora 上回答问题，因为这里有很多英语母语者在浏览。如果他们发现问题可能会乐于帮我指出来。 我有时候会把文章同步到 dev.to，比如我这篇文章曾经是 dev.to 上的爆款：How To Learn Data Structures And Algorithms 后来我把自己写的文章同步到 Medium.com 上，然后投稿到一些大的技术类专栏，比如 Better Programming，Level Up Coding。 为什么要投稿呢，因为可以来判断自己是否写得足够好，而且像 Better Programming 这样对质量要求比较高的专栏，他们能看出我不是英语母语者，但是如果我的内容还不错，也会让自己的编辑去帮我润色，这就是最好的得到反馈的机会。 专业的编辑会从标题的选取、排版、英语写作的用法等等角度去改进文章。我在这个过程中就学会了很多东西。 在 Medium 写作的另一好处是可以赚钱，可以参考一下我写的这篇：How I Wrote a $500 Article in My First 3 Months on Medium，文中提到的那篇文章一直都还有阅读，后来累计了 1300 $。 在 Medium 上写作赚钱的红利期也过了，除了我上面的那篇爆款，我其他写的文章如果专栏接收大概也只是在 500 元左右的收益。 关于如何建一个盈利的英文站以及如何通过英文写作赚钱，这是另一个比较大的话题，这些也以后再分享 🙌 沟通听力和口语这是两项英语沟通的必备技能，最好在学校阶段就注重这方面的培养，因为工作之后时间和精力都会少很多。 如果是锻炼听力，轻松的办法是看美剧，比如 Friends 系列。我现在用得更多的是听 Podcast 、看 Youtube 之类的。这里推荐两个 IT 类的 Podcast： Behind the Tech Podcast with Kevin Scott - Microsoft 微软 CTO 关于科技方面的播客。 Hanselminutes Technology Podcast Scott Hanselman 在 Youtube 上也很活跃，技术介绍通俗易懂。 在口语这块，我自己在学校阶段没刻意提高，所以虽然阅读、写作相对好些，口语一直都一般。 如果有练习口语的环境，逼得你日常就用英语交流，这就会提高很快。2013 年我在硅谷待过一段时间，每天至少会和印度同事交流一下，感受是听力好了很多。 然而后面脱离了那个环境就又退化了。我两年前曾经付费使用过 Cambly 来练习口语，每天花 30 分钟和英语母语者聊天，自我感觉提高了一些，其实主要是克服了那种不敢说的恐惧。我的发音不太准，以后再花时间改进。 工作后的人大多没有很多时间来学习英语，我见过同事花了 2 万多去报名培训班，上了几次后之后就坚持不了的。提高英语能力不是一朝一夕的事情，没什么捷径，每天花 20 分钟专门阅读，20 分钟锻炼口语或者写作就是很好的习惯。 如果你想不知不觉地提高自己的英语，好好培养一些习惯，然后一直坚持就够了。如果要刻意提高，在校的学生可以尝试先把四六级过了，然后如果有时间和精力去考雅思托福之类的。 以上就是我自己的一些经验之谈。道理很简单：不管是读写听说，多用英语，用得多了日积月累就会提高，摸索出一些适合自己的习惯才能持久。","tags":[{"name":"英语","slug":"英语","permalink":"http://catcoding.me/tags/%E8%8B%B1%E8%AF%AD/"},{"name":"自我成长","slug":"自我成长","permalink":"http://catcoding.me/tags/%E8%87%AA%E6%88%91%E6%88%90%E9%95%BF/"}]},{"title":"世界很大，一定要学好英语","date":"2022-01-18T00:10:31.000Z","path":"2022/01/18/learn-english-for-big-world.html","text":"今天再分享一下自己作为程序员学习英语的一些经验，我计划分几篇写成一个系列。 首先我们谈谈作为程序员，我们为什么要学好英语。英语对程序员的重要性主要体现在以下几个方面： 更好的输入毋庸置疑，英语已经是世界上科技和学术交流的通用语言，这是我们无法改变的事实，而且可以预见我们有生之年仍然是这样。在 IT 领域更是这样，这个世界上最新的、最全的、最好的编程学习资料大多是英文的。 比如我前几天介绍的 Crafting Interpreters 这本书，如果等到国内翻译出来说不定几年都过去了。而且国内很多技术书的翻译质量很差，因为翻译的收入并不高，有能力把技术翻译做好的人，大多不愿意投入时间到这上面。 我知道一些出版社找的是国内高校的老师，然后让一些实验室的几个研究生来翻译，这些研究生因为缺乏从业经验，翻译出来的东西质量低下。有的经典技术书籍被翻译成烂的中文版，让人痛心。 比如《人月神话》中文版里有一句话是 “大拇指的规则就是 …..”，你看的时候会不会困惑不已，大拇指规则是什么？ 如果你去看英文版本，其实这句是: The rule of thumb，其实是指”经验法则”。 其实不止是英文资料的问题，很多软件的中文告示也是不够准确的，甚至有的计算机术语是没有公认得中文翻译的。 比如编译器 Gcc 的一个中文警告： 提领类型双关的指针将破坏强重叠规则. 这到底写个啥？但如果你去看英文，就容易理解得多： warning: dereferencing type-punned pointer will break strict-aliasing rules 如果我们一直用这些学习资料，容易被误导、浪费自己的时间，更是可能是达到一定瓶颈无法提高自己，所以直接看原版的英文书收益更多。比如我就基本没买计算机的书了，我用公司的 OReilly 账号，基本能看所有好的原版计算机书籍： 更广的交流如果你在 Github 上做开源，免不了和其他国家程序员沟通。要在一个顶级的开源项目做贡献，一个 Pull Request 来来回回几十个讨论也是很正常的。 能否在英语世界中传播对于一个开源项目至关重要。 Ruby 创始人松本行弘 1995 年开始创建 Ruby，前面好几年其实 Ruby 大多是在日本圈子里用用，可以看看 Ruby 的早期版本里很多注释都是日文的。一直到 2005 年 Rails 发布，出现了很多英文的 Rails 书籍和介绍，Ruby 才开始风靡全球。 那些做出著名开源项目的国人中，英语交流肯定是没有任何问题的，例如 OpenResty 作者章亦春，Vue 创始人尤雨溪等。反观国内某些大厂的某些开源项目，例如腾讯的 polarismesh/polaris，这文档、代码注释都是只有中文，这如何能在世界范围内流行开了呢。 有的国内开发者编程中的变量名用拼音，可以想象如果一个开发者写的代码是： def denglu(yonghu): ... 这代码只有中国人有可能读懂，那如何让中国之外的开发者协作？ 同样的原因，我认为中文编程可能为英语不好的初学者稍微拉低一下学习门槛，除此之外毫无益处。 更多机会国内年轻人多，2021 年应届生加上海归总人数达到 900 万。 而其他行业相对不好找工作、工资低，导致很多人转向 IT 行业，结果就是国内 IT 职位内卷得要命。 另一方面，现在因为疫情、贸易战等原因，世界各国的人员流动减缓，但是线上协作更多了。疫情加速了全球数字化进程，其实各个国家都很缺软件工程师。 所以如果你想做这行但又不想内卷，就别一直盯着国内大厂，多看看外面的机会，比如国内外企，远程职位，或者其他国家的职位。 德国就为工程师提供欧盟蓝卡，比如《精通正则表达式》的译者余晟就在德国生活得很舒服啊。 当然是否出国定居涉及到很多因素，如果不出国也可以试着找国内的外企，比如微软在国内大量招聘(找我内推)，还有 Paypal、AMD、NVIDIA、Amazon、Hulu 等等。有人会说外企在国内正在衰退啊，我的理解是传统外企确实岗位少了很多，而 IT 类的外企还是有很多职位在招人，只是对比 BAT 招聘名额少很多，所以显得没有多少存在感。 应聘这些职位对英语有一定要求，但这个要求其实又没有你想象的那么高，通常只要能达到日常交流水平就可以了，因为编程工作中的交流相对来说是比较简单的。 这篇已经比较长了，后一篇再接着谈作为工程师如何提高英语能力。我的经验是不用专门为了提高英语而刻意去学，更多是日常工作学习中做一些习惯上的改变，达到日渐提高英语的目的。 待续。","tags":[{"name":"英语","slug":"英语","permalink":"http://catcoding.me/tags/%E8%8B%B1%E8%AF%AD/"},{"name":"自我成长","slug":"自我成长","permalink":"http://catcoding.me/tags/%E8%87%AA%E6%88%91%E6%88%90%E9%95%BF/"}]},{"title":"国内远程 IT 职位","date":"2022-01-15T00:09:24.000Z","path":"2022/01/15/remote-jobs-in-cn.html","text":"我最近在做一个提供国内远程职位的公司列表，可能对你有帮助。 可以看出这些公司通常不是那些行业巨头，反而是一些小而美的创业公司。他们能提供的薪资也许比不上 996 的大公司，但是也不会那么卷和累，而且如果远程工作你可以居住在二三线城市，这样也能做到一定程度兼顾家庭。 所以我认为这是逃离内卷的一种方式。 为什么说愿意让员工远程的公司通常不那么卷？ 因为远程职位通常要求员工的自驱力比较强，并且公司相信员工能够按约定交付，所以也不太关心你什么时候上下班，每天工作多少时间。对员工信任的公司，不会内卷。 这些公司提供的职位大多是偏技术的，毕竟编程的工作是比较适合远程的。如果你有感兴趣的职位，可以找我内推，也许我认识这里面的一些朋友。另外，微软也支持远程，如果远程时间小于 50% 经理批准就可以，如果全职远程必须部门大老板批准(我也看到有人在全职远程了)。感兴趣的也可以让我内推。 这个列表的链接是：chenyukang/remote-jobs-cn (github.com)。 公众号重新编辑不便，所以如果后续有新增我会更新到 Github 上。 平凯星辰 | PingCAP 职位： Careers | PingCAP 行业：分布式数据库 技术：Golang, Rust, 前端，数据库，DevOps，运维 PingCAP 的 5 年远程办公实践 - 知乎 (zhihu.com) 涛思数据 | TDengine 职位： 招贤纳士 | 涛思数据 (taosdata.com) 行业：时序数据库 技术：C/C++, 前端 关于 | 涛思数据 (taosdata.com) 开源 —— “这是最好的时代，这是最坏的时代”｜陶建辉 MegaEase 职位：Hiring@MegaEase.com 行业： 云原生开源软件、微服务开发框架、中间件等 技术：Golang, C/C++ MegaEase的远程工作文化 | 酷 壳 - CoolShell 秘猿科技 | cryptape 职位：cryptape 行业：区块链 技术：Rust，C/C++ 等 秘猿科技 招聘区块链开发工程师/Rust 开发工程师/全栈开发 FydeOS - 面向未来的操作系统 职位：操作系统底层工程师、Android 底层工程师、C/C++ 底层软件工程师、前端 行业：操作系统 [北京/武汉/深圳/远程] FydeOS - V2EX VMware 职位：数据库内核开发 行业： 虚拟化 技术：C, k8s 、网络、存储、虚拟化 [北京][955]VMware 招聘 Greenplum 数据库内核开发 - V2EX RustDesk 职位：Contact (rustdesk.com) 行业：远程桌面 技术：Rust 、Flutter 、React/Javascript RustDesk招聘远程 - Rust语言中文社区 (rustcc.cn) Databend 职位：数据库内核、Cloud 平台开发工程师、社区运营 行业：开源云原生数仓库 技术：Rust Databend 招聘中，期待你能全职加入开源项目 - Rust语言中文社区 (rustcc.cn) 极狐 (GitLab) 职位：Ruby 测试/研发/全栈工程师等多个职位 行业：开源代码托管 极狐 (GitLab) 招聘 Ruby 测试/研发/全栈工程师等多个职位 · Ruby China (ruby-china.org) Logseq 职位：开发工程师 行业：笔记软件 技术： Clojure(Script) 职位不多，也许招满了。Logseq 远程招聘一位开发工程师 [40k ~ 65k] - V2EX","tags":[{"name":"工作，远程","slug":"工作，远程","permalink":"http://catcoding.me/tags/%E5%B7%A5%E4%BD%9C%EF%BC%8C%E8%BF%9C%E7%A8%8B/"}]},{"title":"大家都在用我的代码，所以我就该富有吗？","date":"2022-01-12T20:11:48.000Z","path":"2022/01/12/fakerjs-is-deleted.html","text":"这些天因为 faker.js 开源作者 Marak 删除代码事件让开源出圈了，好多非 IT 的自媒体都跟风写上了。我花了些时间查找资料，也说说自己的理解。 首先我们回顾一下整个事件： 8 年前 Marak 的 JavaScript 库 Faker.js 完成 1.0.0 版本，该库可以制造非常多不同类型的假数据，用于开发调试。使用的是 MIT License ，这个 License 简而言之你可以随意用我的代码，但是风险你自己承担，我也不会收费。 Marak 曾在2020年10月25日的时候在推特发帖声称自己在公寓火灾中丢失了所有东西，几乎无家可归，在申请外界支援，从回复上看很多人已经伸出了援手。 2020 年底开始，Marak 一直在寻求一些方式来通过 Faker.js 赚钱，众筹或者寻求大公司赞助，甚至是希望被收购。这过程中收到了一些拒绝。 从2021 年左右开始，Marak 开始关注币圈了，说要卖掉房子来投资 NFT。可以看出这时候他应该从火灾的窘境中脱离了？ 也许是因为通过 faker.js 筹钱不顺，前几天 Marak 强制把代码仓库清空，并写上了句关于 Aaron Swartz 的话。 Aaron Swartz 被称为互联网之子，作为开放获取运动的长期支持者，因为大规模系统性地下载JSTOR上的学术期刊]而被判非法入侵罪，他拒绝认罪并随后自杀。Aaron Swartz 倡导的开发和平等的互联网思想深深的影响了一代 IT 从业人员，使得越来越多人愿意将自己的软件授权、技术书籍、平台信息选择对外开放。 所以 Marak 的做法也许在拷问，这个世界怎么了，我们分享精神得不到应该得到的回报？ 如果作者不想再继续维护开源软件，通常的做法是不做更新、或者转移项目所有权给其他人。但是 Marak 的做法是清空代码库，这导致一大波公司不能使用。最后，作者还因为向自己开源项目提交恶意代码，使得 GitHub 账户被暂停使用，从而在技术圈引发热议。 这里我再加一些具体的细节。这个库虽然有用，但是并不是什么高深技术。即使没有他这个东西，一个资深的前端程序员完全可以自己搞出来一个。在开源的世界一个东西流行，其实有很多因素，可能出现的时机对了，当然也可能确实有些独特好用的地方。这样功能的一个库，往往只要一个火了，其使用量就会很大，排第二的可能就没多少人知道了。 另外作者来开始的时候，也是不知道这东西这么多人用的，选择的 License 就很随意，要是选择 GPL 在道义上就没问题。所以十年后，用的人多了的情况下，他就形成了这样一种心理：世界上这么多人用我的代码，但我却这么穷，这不公平。 大家都用我的代码，所以我就该富有吗？ 理论上确实是如此，你创造了一个大家都在用的东西，理应收到物质上的回馈。但现实中就很复杂，你这东西如果从开始就说要收费，可能根本没这么多人用。所以这就是一个鸡生蛋还是蛋生鸡的问题，而且这库也不是一个必需品，事实上这是开发过程中的辅助库，基本不会发布到生产环境，替换起来又没到伤筋动骨的程度。 所以 Marak 在尝试通过这个库来赚钱的时候会很困难。即使这样，faker.js 并不是没融到钱，只是可能没达到最近玩币圈的 Marak 的胃口。参考faker.js - Open Collective ： 真正能赚钱的通常不是基础库，而是直接面向用户的成品，比如 Obsidian 这个产品，我作为愿意付费，但是我没捐赠给他用的那些开源库。而给基础开源库捐赠的企业太少了，参考之前的 OpenSSL 事件。 个人为什么开源实际上，能通过开源软件直接赚钱的个人开发者少之又少。如果这样，作为个人开发者，为什么我们要开源？ 开源运动始于早期黑客的反抗精神和分享精神，Unix 不是闭源么，所以早期黑客把代码印成书来分发，这是一种对商业软件的反抗。随着互联网和 Linux 的发展，开源已成为软件开发的常态，甚至是开发者的自豪。可以说开源和 Wikipedia 是目前人类两项最大的集体智慧活动，无数人在无偿地、自愿地付出时间和精力去做共享。 大多开源是为了交流和单纯的分享，想给其他人看看怎么样，也许社区会有反馈，也去其他人可以帮忙完善一部分等等。 另一部分原因是为了名声，如果一个开源作品得到很多关注，可以给自己增光不少。如果一个开源项目被大公司用了，通常会怎样？作者会把大公司的名称列到 README 的用户列表中。开发者可能内心会希望大公司多少能捐赠些，但其实大公司白嫖也能给项目带来曝光度和知名度。 公司为什么要开源公司是否开源是个很复杂的问题。很多公司开源是为了形成社区和生态，比如 VSCode，要是不开放源肯定没有现在的几乎垄断的态势。比如 TiDB、TDEngine ，他们巴不得各位来学习、研究他们的代码，这样会渐渐形成开发生态。用户一看关注度这么高，用的信心也增强了。但你说这源码都给用户了，该怎么挣钱啊。事实上他们总会有付费的功能不会在社区版本，然后用户中只要有一小部分能赚钱就可以了。 我理解这是行业发展到一定程度必然出现的结果，就是先让大家用起来，然后再通过技术支持和付费功能收费。开源软件的商业化也不好走，比如 Docker 影响力这么大的开源项目也难以找到合适的盈利模式。 开源是否拉低了行业门槛半佛仙人提到其他行业的聪明人，比如律师、医生都在提高行业门槛，为什么 IT 行业的傻傻程序员在免费分享，降低行业门槛？ 现实确实如此，现在学习编程的资料多如牛毛、唾手可得，任何想学编程的都可以面对电脑开始学。开源的、可复用的代码太多，任何人稍微学学可能就能弄出一个产品。比如搭网站，在二十年前可能需要一个专业的程序员，耗费好几天才可以搞定。现在既然有了这么多代码可以参考，这么多现有的框架可以用，可能一个学了一个月的初级程序员花上一天就能搞定。 那这到底是门槛低了还是生产率提高了？ 我认为都有。但我不认为这是这个行业内卷的原因，内卷化的本质是生存与发展问题，国内很多人涌进来学 IT 本身因为这个行业相对好找工作、工资高点。开源提高了程序员生产力，同时也加速了各行各业的数字化进程，蛋糕越来越大了。中国 IT 行业内卷是因为年轻人多，而公司做的都是业务型工作多，导致老人容易被新人替代。你看腐朽的资本主义国家，IT 行业还是处于极度缺人状态，行业从业人员也不用 996。 有人说：开源软件是程序员的自媒体。 我觉得这种说法很恰当，作为开发者你可以开个自媒体，也可以不跟这个风气。现状是有小部分人因为自媒体富了起来，绝大部分在用爱发电。 假如，作为一个自媒体的作者，我一直说我的东西是免费的，结果 10 年后进入币圈觉得自己穷，高呼你们这些粉丝和读者都是白嫖党，看了我的文章的都该给我钱，没多少人给钱我就把老文章给删了。 这，就很诡异！ 所以我觉得这事件的结论是：币圈容易让人黑化。","tags":[{"name":"技术，开源","slug":"技术，开源","permalink":"http://catcoding.me/tags/%E6%8A%80%E6%9C%AF%EF%BC%8C%E5%BC%80%E6%BA%90/"}]},{"title":"花 10 年写一本编程语言实现的书","date":"2022-01-12T00:10:31.000Z","path":"2022/01/12/a-book-on-programming-language.html","text":"Robert Nystrom 是一位拥有 20 年工作经验的软件工程师，之前在 EA 做了 9 年多，2010 年入职 Google ，目前工作在 Dart 项目。 2009 年开始写一本设计模式方面的书，叫 Game Programming Patterns，写到一半发现自己对编程语言实现很感兴趣。强忍着兴奋继续写第一本，直到 2014 年第一本书完成.。这本书收获很高的评价，建议想学习设计模式的同学看看这本书，电子版本的完全公开。 而后就开始了第二本关于编程语言实现的书，断断续续写了这么多年，直到 2020 年完成了：Crafting Interpreters，整个过程居然花费了接近 10 年时间。 在这篇 Crafting “Crafting Interpreters” 中，作者详细记录了完成这本书的过程。反正我看完后很震惊，一本技术书籍可以按照这种制作工艺和水准，最后的成书是我见过的质量最高的技术书籍，而且成书和代码可以完全免费阅读！ 其实写技术书是投入产出比很低的事情，只有纯粹的热情才能让一个人花这么多年去写这种书。为了完成这本书，作者看了这么多关于语言实现的书： 里面的插图是自己手画的，配文是手写的 ，完成之后再通过扫描机扫描成电子版本： 所有想深入学习编程的人都应该去理解一个编程语言是如何实现的，因为： 克服对语言的恐惧，解释器、编译器不过是另外一个程序。我们可以自己去实现一些常见的语法和特性，编程语言对我们是可以改变和理解的工具，而不是黑盒。 这是一个绝佳的提升编程技能的方式。 工作中会接触到各种小语言和 DSL (Domain-specific language)，parser 或者编译相关的技能可能会有用。 我大学本科的时候挂了一门课叫做形式语言和自动机，这门课当然是对 Parser 很重要的，但是我觉得枯燥之极，我记得需要手画状态机。 后来我工作之后，找了一些具体的代码来看，才能理解状态机这些东西如何应用在实际中。所以，我认为在学习编程中最重要的还是读代码和写代码。我通过读 Essentials of programming languages 学到了很多编程语言相关的东西，在这里面可以实现好多小解释器。 理解编程语言的过程中，Parser 只是其中第一步，而且也是不重要的一步。Parser 如何做已经有了很成熟和规范的做法，一门编程语言更重要的是语法、语义和实现。编译部分又涉及到更多底层和高深的东西，现在 LLVM 是常用的编译后端。所以要理解一门编程语言的实现，一个小语言的解释器就是很好的方向。 在这本书里，作者详细讲解了一个解释器的两遍实现，第一遍用 Java 实现，注重主要概念和原理；第二遍用 C 实现，bytecode、VM 、GC，注重优化和底层实现。 这些主题对于非编译器从业人员来说已经足够了。编程语言的实现比很多日常项目难，但这值得一个想更深入学习编程的人锻炼： 长跑运动员有时在脚踝上绑上重物，或者在空气稀薄的高海拔地区进行训练。然后卸下包袱时，相对轻松的四肢和富含氧气的空气使它们跑得更远更快。 另外这本书中有一些英语俚语，不过不会对阅读造成干扰。相比较 EOPL，我更推荐这本书来学习编程语言原理，因为 EOPL 偏函数式一些，相对更小众。","tags":[{"name":"技术","slug":"技术","permalink":"http://catcoding.me/tags/%E6%8A%80%E6%9C%AF/"},{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"}]},{"title":"深刻启发我的 3 篇文章","date":"2022-01-10T22:07:55.000Z","path":"2022/01/10/share-3-articles.html","text":"这些年读过很多的文章，绝大部分看了就忘记了，其中这三篇对我启发很大，这里分享给大家。 十年学会编程 Teach Yourself Programming in Ten Years 十年学会编程 这篇文章是 Peter Norvig 发表于二十年前。现在和二十年前都一样，很多人学习编程都会浮躁，渴望 21 天甚至是 7 天 就能学会编程，这篇文章很好的解释了为什么不行。甚至是，初学者理解的编程和一个高手理解的编程可能都不是一回事。 对我的启发是，永远不要妄想有什么捷径，不要浮躁，编程不是一门科学，更像是一种技艺，如同绘画、音乐一样的技能，只有通过长时间的砺练才会有所成。 另外不要拘泥于单一技术，因为技术可能会过时，这样年纪越大越容易被淘汰。需要不断加基础知识和核心能力，因为技术原理相通，无论适应学习新技术、还是发挥经验优势，都是比年轻人强很多的。 学习编程这么多年后，反而更加觉得自己渺小和无知，看着那些后浪做出的漂亮东西有时候会感叹，这十年可荒废了不少，想再上一台阶再花十年吧。 Learn in Public Learn In Public 当众学习 - 最快的学习方式 我之前写了 10 来年的博客，但我基本是当作自己的一个私人记录在写，我甚至不希望身边的朋友、同事发现我写的东西，因为我会觉得不舒服，后来我才知道这其实就是冒名顶替综合症。我的域名也丢了两次，所以最终导致我写的东西除了自己看没有什么很多人看过。 这会有什么问题？ 其实也没什么大问题，只是我丧失了很多提高自己的机会。 写出来的东西并没有其他人看，就相当于我只是在消费，实际并没有产出。因为没有得到太多的反馈、激励，即使我写了 10 年，这也是断断续续写的，兴致来了写上一篇，通常每年十篇左右，这样没有形成习作的习惯。而且我丧失了让其他人纠正我，以及从其他人学习的机会。 我认为 Learn In Public 是费曼学习法的加强版，能在公共场合传授我们所学，这是更高的标准。 具体执行起来可能是在 Github 上通过做贡献，或者是建立一个持久的开源的知识库，或者去做公开的技术分享等等。长久来说，人们会注意到真正的学习者和生产者，然后会向其提供帮助或者寻求帮助，这个过程就能产生价值。 我正在实践这个理念，比如我正在写的这个公众号，我想让自己变得更自信和开放，推广自己的想法，让自己成为生产者，同时还能和更多人交流。 别让自己“墙”了自己 别让自己“墙”了自己 CoolShell 上有很多不错的文章，其中这篇我会时不时再看。 偏见和不开放，对一个人的限制是真正有毁灭性的。 持有强烈偏见是技术人员经常会出现的问题，大概是因为我们在编程的时候其实是在构建一个简单的世界，所以自认为一切都可控，自己擅长的就是最好的。 比如有的人认为 C++ 是最强的，所以鄙视其他语言；比如我之前认为 Emacs 是最好的，所以排斥一些现代先进的编辑器；比如自认为是后端开发，所以前端的东西不想碰。行业里这样的偏见到处可见，能形成各种鄙视链。这种不开放的心态就是作茧自缚。 这篇文章还谈了很多其他的方面： 站在更高维度上思考和学习 整天在焦虑那些低维度的事（比如自己的薪水、工作的地点、稳不稳定、有没有户口……），只会让你变得越来越平庸，只要你站在更高的维度（比如： 眼界有没有扩大、可能性是不是更多、竞争力是不是更强、能不能解决更大更难的问题、能创造多大的价值……），时间会让你明白那些低维度的东西全都不是事儿。 技术学习上也一样，站在学习编程语法特性的维度和站在学习编程范式、设计模式的维度是两种完全不一样的学习方式。 扩大眼界 英文语言能力对你能不能融入世界是起决定性的作用，所以我也还在提高英语写作和口语。","tags":[{"name":"写作，个人成长","slug":"写作，个人成长","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C%EF%BC%8C%E4%B8%AA%E4%BA%BA%E6%88%90%E9%95%BF/"}]},{"title":"35 岁，我用这三种方法克服焦虑","date":"2022-01-07T00:10:33.000Z","path":"2022/01/07/how-to-beat-anxiety.html","text":"去年我刚好满 35 岁。 我 2011 年研究生毕业后参加工作，一直工作在 IT 领域，这些年发展也算比较顺利。毕业后我待了一个创业团队三年，后面六年一直待在深圳一个独角兽企业。这十年算是赶上了行业红利和房产红利，经济上没什么大的压力。 但是在 2019 年开始我开始焦虑。 主要压力来自家庭，亲人查出严重疾病，幸好手术后渐渐恢复。另一方面压力来自工作，因为在同一公司工作六年后我感觉到了瓶颈，对自己的工作内容也提不起兴趣。还有一方面来自自己的身体，因为经常晚上睡不好觉导致出了一些肠胃方面的慢性疾病。有段时间我不敢去医院检查，因为怕是什么绝症之类的。后来鼓起勇气去做了比较彻底的检查，医生说这病只能慢慢养，心情要放松才行。 总之，人生进入后半场不如意十之八九，家庭、工作、健康，突然各方面都需要应对，而精力又大不如前。 经过一年多的调整，我感觉现在基本摆脱了焦虑，自认为算是迈过了这道坎。总的来说我用了三种方法： 做让自己进入心流的事 换工作和城市 找到自己的长期驱动力，做 PlanB 分别再详细阐述一下。 当一个人焦虑的时候，就很容易东想西想、瞻前顾后，这样会加重精神内耗，反过来加重焦虑。如何避免自己想得太多从而进入恶性循环？ 一个好办法是让自己进去心流状态，尝试找自己感兴趣的、喜欢做的事情，留出较长一段时间来做。这就好像是躲避，但是是一种安全的躲避方式。 我喜欢编程，有段时间我就也没想到写哪方面的代码，就在 LeetCode 上刷题。后来有一段时间很热衷于玩乐高，所以买了一些夜深人静的时候自己玩。后来我又觉得写作能让自己进去心流，所以那段时间我每天写一篇技术类的英文文章，然后发布到 Medium 上。我发现这样也能赚一些钱，所以就动机更大，投入了更多时间在这上面。兴趣和爱好可以让自己从工作、生活中暂时逃离，可以让人应对心理、精神上的疲劳。 2020 年中，因为一次偶然的面试，我拿了一个苏州某著名外企的 Offer。然后大概经过了一个多月的考虑，我决定举家从深圳搬迁到苏州。这需要很大的勇气，我甚至让女儿来抽签决定是否离开已经定居的深圳。最终做出换城市和工作的决定还是因为我想多一些不同的体验和尝试。就像是优化算法进入了一个局部最优解，我需要趁还不那么老的时候去做一个更大的改变。 在苏州待了一年之后，我有些庆幸自己当时做了那个决定。人焦虑很多时候是因为所处的环境。苏州整个城市都是有一种养老的气质，稍晚点街上就没什么人，路上没什么车，完全没有奋斗的氛围。 如果要在一个公司长待，那么公司企业文化是否和自己贴合特别重要。外企工作节奏和氛围轻松多了，我工作上时间投入少很多，基本是上午十点上班晚上六点下班。更重要的是成熟的公司管理方式反而更简单些，上班做事下班闪人。 人到中年有时候得把工作别看得太重，这需要做取舍。在纪伯伦的《先知》中谈论到工作时写道： 所有知识都是无用的，除非有了工作，所有工作都是空洞的，除非有了爱； 毕竟工作也还是为了家。工作相对轻松了，我可以每天晚上回家吃饭，陪女儿玩耍，看书，给她洗漱哄她睡觉。这些陪伴对她的成长很重要，从长远来看这也许比赚钱还重要。在陪小孩的过程中，自己也像是在重新过一个童年，玩积木和拼图都很有趣。 另外苏州的风景和天气都很不错，所以这一年我经常周末开车出去逛，太湖、阳澄湖、古镇等等，风景好的地方太多了。当一个人整个心态慢下来，漫步在风景优美的自然环境里，就会觉得人间美好，我没心情焦虑了。肠胃方面的问题也渐渐地就没什么症状了。 说了这么多，有的人可能就说这不就是躺平么？ 我认为不是。我是在调整工作和生活，更好地应对衰老这个自然规律。职场上的中年危机，本质上就是一种对不确定性的恐惧和焦虑。 如果是作为工薪阶层，年纪大了还一直还是只盯着职位和工资看，难免为失望，因为命运掌握在公司手里就会有不确定性。 即使到了 35 岁，后面的路还有很长，不要自己局限在公司和职场上。作为个体来说，我认为需要花时间思考自己的后路，如何能不断保持自己能力的提高，如何能不依赖公司或者机构创造自己的价值，如何找到自己的内在驱动力，如何做复利和时间的朋友。 这需要不断尝试，找到自己的激情所在，并且需要保持一种开放，终生学习成长的心态。比如我通过摸索，现在能通过写作赚钱，这一年我花了更多时间在开源上，对技术反而有了更大的兴趣，也能通过做开源软件赚钱。即使这两样加起来目前都不足以养活家庭，但是这是我自己的兴趣和爱好。 最坏的情况下我失业了，我还可以用此谋生，而且我相信如果投入更多时间，这两块都能做得更好。总之，PlanB 能让人自信和安宁，只要还在学习和进步就不算躺平。 经过了这个焦虑的阶段，回忆起来那种焦虑会让人更深入的认识自己。经过毕业后这么些年，我们也许还不是很确定自己所求，但肯定知道哪些是自己不要的。在某个阶段必须做取舍，就需要不断问自己想要的生活和人生是什么样的，想清楚之后去做决定然后执行，焦虑就少了。 如果按照中国平均寿命 70 多岁来算，35 岁刚好是一个分界点，在人生四季中算是进入秋季。前段时间在东太湖生态公园看到一排排的红杉树，觉得特别美。 正如人生的每一个年龄段自有其痛苦和动人之处。努力学会适应和享受，就能克服中年危机。","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"}]},{"title":"那些年，我们终将碰上的 Bug","date":"2022-01-05T15:12:02.000Z","path":"2022/01/05/those-bugs-will-always-happen.html","text":"2022 年的新年钟声刚敲响，时钟从 2021 年 12 月 31 日跳转到 2022 年 1 月 1 日，微软 Exchange 准时给大家带来了第一个世界范围内的 Bug。人们写好的新年祝福等邮件，突然发不出去了！大量用户在 Reddit 、Twitter 上亮出新年第一骂。 那些正准备休假的倒霉的 IT 管理员，被紧急电话呼进公司，排查后发现邮件队列卡住了，日志里显示的是： 随后微软官方确认了这个 Bug。 这些错误是由 Microsoft Exchange Server 检查 FIP-FS 防病毒扫描引擎的版本，并试图将日期存储在带符号的 int32 变量中引起的。 在这个变量中使用了 yymmddHHMM 这种格式的约定，我们知道 int32 能表示的最大值是 2,147,483,647，但是到了 2020.01.01 这个值将是 2,201,010,001，所以就溢出了！ 这是一个典型的类似千年虫 问题，即由于时间的数据格式不对导致溢出或者日期逻辑错误，进而导致大量软件出现 Bug。千年虫的问题很多是因为很多老程序使用了两位来表示年份，比如 99 代表 1999 年，那 2000 年只能用 00 来表示了，但是 00 在程序里本意指的是 1900。 可能现在的新生代程序员会感叹，这些老古董为什么会犯这样低级的错误？ 这就牵扯到一些更复杂的问题： 一个是约定习俗，1931 年后很多人在写年份的时候，自然就开始用两位来代表年份，因为 1931 年后年和日已经不重合了，例如写成 35 ，任何人看了都是理解为 1935 年。 另一个原因是内存曾经又贵又稀缺，早期核心内存的价格是每比特 1 美元，老一辈程序员在写代码的时候都是按 bit 抠的。 前美联储主席 Alan Greenspan 曾经也写过程序： 我是造成这个问题的罪魁祸首之一。我曾在20世纪60年代和70年代编写过这些程序，我为自己能够在程序中挤出一些空格元素而感到自豪，因为我不需要在年份前加上一个19。 在当时，这是非常重要的。在我们开始编写程序之前，我们曾经花了很多时间进行各种数学练习，这样它们就可以很清楚地根据空间和容量的使用进行划分。 我们从来没有想到，这些项目会持续几年以上。 “过早优化是万恶之源”，高老头真是诚不我欺： 这种类型的 Bug 是可以预测的，比如千年虫问题，其实在 1985 年左右就已经有计算机专家发现了。问题是代码已经写好并且运行了，甚至因为早期的系统和软件通用性不高，有很多固化在芯片内部的程序，所以要解决也是大费周折。而且日期的问题与各个地方的不同习俗也有关系，比如台湾某些程序在 2011 年出现了日期溢出问题，大家考虑一下为什么😉？ 总而言之，这些 Bug 就很神奇，我们知道在某些年份这类 Bug 必然会发生，但是我们无法完全消除，我们可以简称为 那些年，我们终将碰上的 Bug。 我们可以列举一下今后会碰到 Bug 的重要年份： GPS 星期技术归零GPS(全球定位系统) 广播时采用周计数(WN) + 周内时(TOW)的方式组合发布，早期的 GPS 采用 10bits 存储 WN，所以当计数达到 1024 时会翻转为 0。因此每 1024 周(也就是 19.6年) 会轮回一次。 最近几年发生是 1999，2019，下一次预计就是 2038 年。 2019 年的这次看起来没有发生特别严重的事故，霍尼韦尔的飞行管理和导航软件因为没有及时打上补丁导致航班延误。一些 2012 年之前生产的 iPhone 和 iPad 可能因此连不上网络。 为了解决这一问题，现代化的 GPS 导航消息使用 13 位字段，该字段重复周期变成了 8,192 周（157岁），也就是说会直到 2137 年附近才清零。 Unix 系统 time 溢出 2038 年将是软件历史上史诗级别的灾难年。 因为 Unix 系统最初实现的时候采用的是有符号整数 int 来保存时间，而时间系统是由 Epoch 开始计算起，单位为秒，Epoch 则是指定为 1970 年 1 月 1 日凌晨 00:00:00，格林威治时间。 很多古老的 UNIX 系统都是用 32 位元来记录时间，正值表示为 1970 以后，负值则表示 1970 年以前。也就是说最大为 0xFFFFFFFF 的一半，除以一天 86400 秒的话，就是 68 年。1970 年往后延 68 年刚好是 2038 年。 2038 年问题比 2000 的千年虫问题更麻烦。虽然目前很多 OS 和硬件已经升级到 64 位系统，32 位的嵌入式系统仍然大量运行。另外因为这涉及到系统层面的改动，如果我们直接修改 time_t 的定义，则会出现兼容性问题。 乐观情况，在还剩下不到 20 年的时间里，这些 32 位的系统逐渐被 64 位替换掉，这样就不会出现大问题。有可能导致严重问题的是那些无法升级的嵌入式系统，运行这些系统的设备寿命通常比较长，例如交通系统、汽车的稳定控制系统等。 2106 年很多文件格式、通讯协议采用的是类似 Unix 的日期格式，差别是把时间存储在无符号 32 bit 整数里。按照这个范围计算，日期将在 2106 年溢出。 4501 年Microsoft Outlook 使用 4501 年 1 月 1 日作为“none”或“empty”的占位符，不知道那天会出现什么神奇的 Bug，反正我们已经不在了。 这种类型的 Bug 其实还有很多，时间和日期是程序和系统中非常重要的一个概念，在分布式系统中时间也很容易造成 Bug。我们作为程序员在写代码的时候，尽量眼光放远一点，多想想自己的程序一千年以后还在跑🤣，这样大概就没这类问题了。 不过一千年后还在运行的代码，得多伟大。这时候我脑海里回想起来那首歌： 别等到 一千年以后所有人都遗忘了我那时红色黄昏的沙漠能有谁 解开缠绕千年的寂寞","tags":[{"name":"技术，写作","slug":"技术，写作","permalink":"http://catcoding.me/tags/%E6%8A%80%E6%9C%AF%EF%BC%8C%E5%86%99%E4%BD%9C/"}]},{"title":"什么是 Web3","date":"2022-01-03T10:30:46.000Z","path":"2022/01/03/what-is-web3.html","text":"2021 年 Web3 彻底火了，突然感觉很多人都在讨论，这看起来是在一个大的变革前夕。Web3 被路透社评为今年的科技热词之一，然而马斯克和一些科技大佬直呼没见过 Web3 这东西。 我花时间来理解了一下这个东西，从非技术角度探讨一下。。 对于 Web 1.0 和 2.0 的区分，业界似乎是达成了比较一致的共识，但是对 Web3 这个术语其实是有些困惑的，我来解释一下。 Web 1.0 时代 年份： 1991 - 2004 在这个时代，作为互联网的普通用户，我们主要是从互联网获取信息和内容。内容是由那些互联网门户，例如搜狐、网易、新浪、腾讯等四大门户网站。这个时代的最大赢家是 Yahoo！这是一种单向的信息分享，信息提供商提供新闻、咨询等，我们上网读取。 这个阶段社交网络还没有真正成型，大多是还是以企业以及组织机构为主的门户网站。本质上就是单向的信息分享——我通过网络查看我需要的资料。 活化石一样的互联网公司——Yahoo！是这个时期的大赢家。国内比较有代表性的是搜狐、网易、新浪、腾讯为代表的四大门户。 Web 2.0 时代 年份：2004 - 2020 大概从 03 年开始，O’Reilly Media 的副总裁戴尔·杜赫蒂（Dale Dougherty）首先提出 Web2.0 这个词，随后 Web2.0 的浪潮席卷全球。 Facebook 于 2004 年创办，而后成为社交网络巨头。可以说社交网络定义了 Web 2.0，移动设备比如手机联入互联网，极大地加速了 Web 2.0 的发展。 在 2. 0 时代，互联网就把人与内容的关系变成了人与人的关系。在短短十年的时间里，Web2.0 完全重新定义了市场营销和业务运营。Web2.0 包含大量目前我们熟悉的产品和服务，例如RSS、博客、播客、维基、P2P下载、SNS、社区、分享服务等等。 互联网用户也参与了生产内容，比如你上网发表个博客，发一个照片，发个餐厅的评论等等，大量的数据从普通用户那里产生。 人对于互联网的影响力与日俱增，以往网站给用户投喂信息的时代已经过去。有影响的网红只需要发一个视频就可以让一个餐馆排满长队，也可以用一句话让一家网店差评如潮。公众号、微博等本质上是把个体做成了品牌。 在 Web 2.0 时代，少数超级强大的公司拥有的封闭式平台上进行大量的通信和商业，全球的谷歌，Facebook，亚马逊，国内的腾讯，新浪微博等。 Web 3.0 时代 年份：2021 ~ …. 有的狂热的支持者可能只认可 Web3 这种说法，但是业界目前有的人用 Web 3.0 ，有的人用 Web3，并且他们讨论的可能不是一个东西。Web3 看起来就是一个箩筐，大家都在往里面扔不同的东西，其定义还在不断地改变。里面保罗万象，有物联网、人工智能、区块链等等。我从一些资料梳理了一下，总结发现 Web3 主要是指下面这两个： 语义互联网以 2014 年为分割点，之前大家在讨论 Web 3.0 的时候，更多的是在讨论语义互联网(Semantic Web)。语义互联网的概念是 W3C 发起的，目标是改善互联网现状。通过给万维网上的文档（如: HTML文档）添加能够被计算机所理解的语义元数据，使得人们能够更方便快捷地找到网络信息。这些元数据描述语言包括 RDF/RDFS 等。 但这条路其实发展缓慢，或者其实基于关键词的搜索满足了绝大部分场景。有的公司使用自然语言处理(Natural Language Process) 继续在朝着让机器理解内容的方向前进。在知识理解这块我觉得 WolframAlpha 让人耳目一新，WolframAlpha 对自然语言的识别和逻辑感觉比较强大，这更像知识引擎 。 去中心化2009 年比特币发明，其底层技术区块链于2014年开始越来越热。以太坊(Ethereum) 联合创始人 Gavin Wood 于 2014 年重新定义了 Web 3.0。 在新的概念中，Web3 的特点是去中心化。这也等于要革这些中心化巨头的命，师出有名很重要，Web 3.0 可是个好名称，用来营销再适合不过了。 区块链信徒相信未来互联网是一个运行在“区块链”技术上面的“去中心化”的互联网。在这种模式下，用户将拥有平台和应用程序的所有权。一些爱好者还将游戏、元世界、增强现实和虚拟现实与 Web3 联系在一起，因为一些虚拟世界依赖于基于区块链的数字资产。 为什么要去中心化？这得从中心化的弊端开始讨论。所谓中心，即在一个体系中，如果一个节点要和另外的节点产生关联，都要通过特定的一个节点，这个特定的节点就是一个中心。比如阿里的淘宝，我要买东西需要在淘宝下单，然后付钱，对方发货我确认后，对方在淘宝收钱。对于交易来说，淘宝就是一个中心。同理，银行、微信、微博、Facebook 都是中心。 中心化的弊端是风险和隐私。 中心拥有所有用户的数据，可以操纵用户的情况下是非常危险的，比如 Facebook 可以通过给不同政见的人群推送不同类型的广告，这样可以用来引导选民。川普那么多粉丝，Twitter 说杀就杀，这就是平台的权力。再比如我们的隐私被电商收集，大数据杀熟成为常规操作。我们的交易产生的数据被第三方平台无偿利用，我们却得不到任何报酬，它往往涉及用户的隐私。如果管理不当，也极易造成隐私的泄露。 在 Web3 里，用户不仅是创造内容，还需要拥有自己的数据。 目前已经出现了一批去中心化的应用，DApp 是 D+App，D 为英文单词 Decentralization 的首字母，中文翻译为去中心化，即 DApp 为去中心化应用。DApp 是在区块链公链上开发并结合智能合约，其数据加密后存储在区块链，难以篡改。从现在有的运行模式看，DApp 更像是众筹模式。先有发起人写好白皮书明确了共识机制和 Token(通证) 分配与激励，以包括智能合约等区块链技术开发好应用，其中持有 Token 的用户都是股东，持有的 Token 也可以在支持的交易所交易。 前段时间出现了一个典型的案例，一个区块链爱好者在网上发起来了一个通过区块链筹款来竞拍美国宪法的古董品，最终竟然筹集 4700 万美元。虽然最终没有竞拍成功，但是依然创造了历史，证明基于区块链的集资是可行的。 目前这些 DApp 都还比较小众，比如下面这些区中心化的应用，你用过多少？ 我看了看其中的这个 Brave 浏览器，它在用户安全和隐私上做了很多优化，特别是去掉了一些可以追踪用户的功能。代码全部开源，同样使用 Chrome 的内核，支持跨平台使用，它是基于区块链技术的无广告纯净Web浏览器。 Brave 利用区块链技术集成 Token BAT 来让用户可以直接支持投给自己喜欢的文章，视频等创造者。并且用户也可以通过自身加入区块链为基础的数字广告平台，通过推广而获得奖励。这大概就是用户 own 的意思吧。 虽然目前区块链除了比特币之类的数字货币外，并没有出现另一个现象级应用，资本还是在不断投入到这些初创公司中。如果一个投资公司在某些区块链应用中占大部分股份，那这本质上还是一个中心化的实体。这也是为什么 Twitter 的创始人多西吐槽说，投资机构拥有这些 Web3。 我不知道 Web3 到底是真的未来互联网方向，还是一个泡沫似的营销术语。但我认为去中心化的大势是好的，去中心化的互联网一个更能促进人与人平等、人与 Web 相处更友好的互联网.","tags":[{"name":"Web","slug":"Web","permalink":"http://catcoding.me/tags/Web/"},{"name":"互联网","slug":"互联网","permalink":"http://catcoding.me/tags/%E4%BA%92%E8%81%94%E7%BD%91/"}]},{"title":"我欣赏的英文技术站","date":"2021-12-28T10:32:58.000Z","path":"2021/12/28/best-english-tech-sites.html","text":"做技术这么多年，我订阅了很多英文技术站点。这里介绍一些我认为非常值得关注、学习的技术站点。 我推荐的标准是： 持续多年更新 质量非常高，或者某些文章深刻地启发了我 后面我会长期更新这个列表： Joel on Software Essays (paulgraham.com) 有太多经典的技术文章。分别有中文的《Joel谈软件》和 《黑客与画家》。 Eli Bendersky’s website (thegreenplace.net) 这个博客已经有十多年了。我记得最初搜索到这个站点是自己在 2008 年做SICP的习题时，我发现这里有几乎 SICP 所有的习题答案，附带自己详细的解释。 难能可贵的是，作者 Eli Bendersky 一直坚持记录自己技术上的心得，这个博客持续在更新。而且他写的内容质量都非常高，既有理论又有实践和代码。例如他写的 Raft 系列： Implementing Raft: Part 0 - Introduction，简直就是技术写作的典范。 Flavio Copes 这个博客是一个意大利开发者维护的，内容偏向于前端和 Web 开发之类的。我欣赏这个站点是因为他在几年内几乎做到了每天都日更写博客。有时候我想写又懒癌发作的时候，就会想到这位作者。他写的东西也许并不高深，但对很多人来说有用。我之前用 SEO 工具看过这个网站的数据，Google 给他带来的自然流量非常高。 Every developer should have a blog. Here’s why, and how to stick with it I wrote 1 blog post every day for 2 years. Here’s 5 things I learned about SEO Julia Evans (jvns.ca) 这个博客也是持续更新了近 10 年，涉及的领域及其广泛。这个作者深刻启发了我的观点是，通过搞懂内部原理来学习编程：Get better at programming by learning how things work。 当然还有很多其他类的技术类文章如：Diving into concurrency: trying out mutexes and atomics 而且作者做了很多技术相关的电子书，用漫画的方式讲解技术，图文并茂：wizard zines journal.stuffwithstuff.com 花 6 年时间，用工匠精神写一本编程语言实现的书是怎样一种体验？Crafting “Crafting Interpreters” 在这里所有的图片都是用手画出来的，字体、颜色、对齐等，所有这些细节几乎都做到完美，最终成书可以称之为艺术品。一个技术书籍竟然能做到如此优美！ swyx’s site 主要内容涉及开发、个人成长等。其中 Learn In Public (swyx.io) 这个概念对我有很大触动，这个博客还有很多 podcast 。","tags":[{"name":"编程","slug":"编程","permalink":"http://catcoding.me/tags/%E7%BC%96%E7%A8%8B/"}]},{"title":"百度是如何死掉的","date":"2021-12-27T07:02:34.000Z","path":"2021/12/27/baidu-die-for-reason.html","text":"“百度已死” 几年前就已经被广泛讨论过，好像现在大家都不怎么讨论了。即使百度仍是最大的中文搜索引擎，但已沦为互联网度量单位，短短数年间的变化不由让人惋惜。 今天让我重新思考这个问题的是两件小事。 事件一：我有一个英文小站点，断断续续写了一些技术类的文章。这一年来已经有一些稳定的流量，大部分都是从Google 来的自然流量。我曾经学了点 Amazon 推广的东西，当时把几篇文章的链接换成了亚马逊的推广链接，然后现在隔段时间就能从亚马逊收到一笔小钱，平均每个月大概 10 来块美金吧。 这个数额很小，但是这种模式确实就是很多小网站的盈利模式。这是已经被验证可行的创造被动收入的可靠方式，有的站点能做到几万美金一个月。 事件二：我老婆想找一个房屋出租合同模板，结果她在百度上花了十来分钟，我看她已经开始在注册某下载网站的账号，她说要下载就得付费。我大为震惊！这个年代这种免费中文信息居然如此难以获取。然后我打开 Google 输入关键词立马解决。 从这两件小事上，我分别从内容创作者、互联网普通用户两个角色体验到了百度为什么会死。 百度这些年来渐渐的沦为互联网公司的度量单位，一个原因是没有拿到移动互联网的门票，另一个更根本的原因就是丢掉了信任，甚至是作恶太多。其结果不只是一个公司发展不好，甚至可以说是阻碍了中文信息的分享，并且让很多初创企业无法生存。 不知道大家有没有体会，现在互联网上的免费的、好的中文信息越来越少。曾经流行过一段时间独立站点，但是你看现在活下来的，还在好好创作内容的中小站点还有多少？ 但是英文就完全不同，我们可以通过 Google 搜索到的很多结果来自中小站点，而且内容质量很高。 因为用户相信在 Google 上能找到可靠的、高质量的内容，内容创作者相信高质量的内容可以通过 Google 吸引到用户，有流量就可以通过各种方式来变现。所以创作者就会不断创造高质量的内容，争取能做到 Google 的搜索排名靠前。还衍生了 SEO (Search Engine Optimization ) 这样的行业，有提供咨询和服务的，有提供工具的，有提供数据的等等。这样就形成了一个正向闭环。这种的商业模式对于用户、创作者、Google 三方有益的。可以说 Google 通过搜索打造了一个超级印钞机。 但是百度选择另外一条路，因为过于短视，竭泽而渔去做竞价排名，最终破坏了这种用户、内容创作者对百度的信任。反正写得好也没流量，结果就是整个开放的互联网上，中文的高质量内容越来越少。而一些高质量的站点，比如 CoolShell 从来不期望百度能带流量，而且做了anti-baidu 插件来提醒读者不要使用百度。用户搜索行为被分流到了各个垂直领域的 App。这些 App 很多都是对搜索引擎是封闭的，比如微信公众号，整个就是一个大的封闭生态，这样百度可以使用的信息也越来越少。 2010 年的时候，我的一个师兄在成都创业，做的是房产相关的网站。我当时快毕业了，跟着在里面实习打杂。我印象比较深的一点是，我隔壁座位的师兄时不时叹息：百度账号上的钱又快没了。实际上我们的业务都还没跑上正轨，但是百度已经开始收割了。很多人可能没开过做过初创公司，不信你可以试试，以公司的名义上线一个网站，要不了几个礼拜百度的销售会联系过来，问你要不要充钱。那你说我们可以不充钱啊，不充的结果就是几乎没有任何自然增长的机会 。 一个公平有效的互联网搜索引擎，应当会给这些中小企业生存机会，而不是一味的凭借自己手握流量来抢夺和豪取，吃自己的饭让别人没饭可吃。理想情况下，如果一个初创企业或个人能够提供好的信息和服务，那就应该被人们搜索到，然后逐渐成长起来。比如 Flavio Copes，这是一个意大利开发者的个人站点，写的东西简单明了，Google 每天给他带来几万的自然流量，这样他可以开始自己卖电子书，逐渐摸索出了自己的业务。 当一个公司掌握了流量分发大权时，有太多的手段可以立马来钱，所以抵抗这种诱惑需要克制和智慧。 在 Google 2004 年首次公开募股的招股说明书中，包含了这几个字：“不作恶，我们坚信，从长远来看，即使我们放弃一些短期收益，作为股东，以及在其他方面，作为一家为世界做好事的公司，我们也会得到更好的服务“。 很遗憾，百度在我看来就是在作恶。从我上面的第二个例子可以看出百度已经把免费的信息拿来换钱了，其他的恶还有把卖百度贴吧，百度全家桶等等，罄竹难书。 我想如果没有百度也许我们会有一个更好的中文互联网环境。 除了百度的一些核心高管，外界估计无法知晓为什么百度这么多年都坚持做竞价排名。也许这东西就像是毒品一般，用上了之后就在资本的压力下再也无法回头。百度这些年来转头做 AI，作为普通用户我也是不抱任何期待。魏则西事件后大众对百度口诛笔伐，但是现在还是原来那个卵样。你要是想在百度上查个什么病，看几页搜索结果就会觉得自己命不久矣。 所以，百度的产品能绕开就建议不用，少给自己添麻烦。","tags":[{"name":"胡写","slug":"胡写","permalink":"http://catcoding.me/tags/%E8%83%A1%E5%86%99/"}]},{"title":"编译 WebAssembly 模块","date":"2021-12-16T07:02:23.000Z","path":"2021/12/16/compiling-to-wasm.html","text":"最近一年经常接触了 WebAssembly , 我把一些老的 C/C++ 代码通过 emcc 编译为 wasm 模块，也可以把 Rust 代码编译为 wasm。 这里做一个简单的总结，以及我在编译过程中碰到的问题。 WebAssembly 的优势 WebAsembly 定义了一个可移植、体积小、加载快的二进制格式作为编译结果。通过充分发挥通用硬件的能力（包括移动设备以及物联网），使其在大多数平台上能达到原生的执行效率。借助 wasi，WebAssembly 还可能运行在服务端。WebAssembly 的目标包括： 现有的 Web 平台完美结合并在其中运行： 维护无版本、特性可测试、向后兼容的 Web 演变过程； 和 JavaScript 执行在相同的语意环境中； 允许和 JavaScript 相互的同步调用； 严格遵守同源策略以及浏览器安全策略； 和 JavaScript 一样，可以访问相同的 Web API 去调用浏览器的功能；以及 定义一个可与二进制格式相互转化的人类可编辑的文本格式，并且支持查看源码的功能。 被设计为也可以支持非浏览器嵌入的运行形式，这样就可能在某些场景下替代 Docker。 C/C++ =&gt; wasm首先需要安装 Emscripten SDK:https://emscripten.org/docs/getting_started/downloads.html 移植一个 C/C++ 项目到 WebAssembly , 最简单的办法是把类似 gcc 命令换成 emcc，难点在于动态链接的第三方库，我们需要改成静态链接。一些常用的库已经被移植了，例如libc, libc++ and SDL，这些我们不需要手动处理。不在 emcc 预装里的库，我们只需要在编译的过程中加一些额外的参数，例如我下面这个项目就用到了 PNG，JPEG 这些库： emcc -c dbgutil.c -o dbgutil.oemcc -c qrtest.c -o qrtest.oemcc -c decode.c -o decode.oemcc -c identify.c -o identify.oemcc -c quirc.c -o quirc.oemcc -c version_db.c -o version_db.oemcc -g -Oz --llvm-lto 1 -s STANDALONE_WASM *.o -o qrtest.wasm -lm -s USE_LIBJPEG -s USE_LIBPNG 另外 emcc 编译出来的 wasm 模块默认只能做纯计算，没有网络、系统文件等。如果有系统调用则需要运行在浏览器中，用浏览器的接口来模拟某些 C 函数调用，例如 C 语言中的系统调用 time 在 emcc 中被替成为了 JavaScript 代码： clock: function() &#123; if (_clock.start === undefined) _clock.start = Date.now(); return ((Date.now() - _clock.start) * (&#123;&#123;&#123; cDefine(&#x27;CLOCKS_PER_SEC&#x27;) &#125;&#125;&#125; / 1000))|0; &#125; Rust =&gt; wasmRust 是对 WebAssembly 支持得特别好的编程语言。我们可以使用 wasm-pack，或者安装 target: rustup target add wasm32-wasi 然后在编译命令后面加参数：cargo build --target wasm32-wasi 系统函数同样是个问题，有的第三方库可能会支持 wasm 格式，例如 getrandom - Rust (docs.rs)。 参考Main — Emscripten 3.0.1-git (dev) documentationWASM Tutorial (marcoselvatici.github.io)Introduction - Rust and WebAssembly (rustwasm.github.io)","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"WebAssembly","slug":"WebAssembly","permalink":"http://catcoding.me/tags/WebAssembly/"}]},{"title":"为什么要开源","date":"2021-12-14T07:02:45.000Z","path":"2021/12/14/why-open-source.html","text":"这篇源于知乎上的一个问题：为什么程序员们愿意在 GitHub 上开源自己的成果给别人免费使用和学习？ 最近越发觉得，分享越多就会有更多的可能性，这里谈谈自己这些年的收获和想法。 我 2010 年开始在 Github 上分享自己的代码。在 push 代码之前我根本没想过为什么，只是因我当时学了 Git，而且又觉得 Github 很方便，可以用来备份自己的代码。 而后我就参加工作了，在工作之余我还会写一些感兴趣的代码分享到 Github，没事也经常在上面瞎逛，找一些自己感兴趣的资料和代码来学习。没想到这么多年下来，在 Github 上玩开源已经成为自己的一种习惯、爱好和生活方式。 最近一年工作轻松些了，所以有更多时间投入在这上面 (忽略最近两个月的大量提交数据，因为有个自动脚本每天在同步笔记 😁) 自我提高我建议任何在学编程、想提高开发技能的人参与到开源中来。 现在的软件开发已经过了刀耕火种，徒手编码的年代。很多开发需要复用大量已有的库和工具，大型软件开发是一种社会化的、集体性的智慧活动。在 Github 上分享代码，给其他开源项目做贡献，是最好的、最直接的方式来练习这种编程能力、协作能力和复用已有代码的能力。在 Github 上混久了，就形成一种自然而然做贡献的习惯，在这里我们不只是使用者，也可以是贡献者，例如： 我想学学 WebAssembly，所以找来一个Runtime wasmerio/wasmer 实现看看，顺便修复一些自己发现的问题]。 我在使用这个 Obsidian 补全插件碰到些缺陷，提了个 PR 修一下然后和作者讨论一下怎么更完善。 在使用 Rust 开发的时候，我看到了一些重复的警告，在 Github 上一搜索发现别人也碰到过，所以我花了一些时间提 PR 修复。 我想看看 container 是怎么实现的，所以找来开源代码 containers/youki 来学习，然后顺便修复自己发现的问题，后来还成了 maintainer。 在开发中，使用者和贡献者是完全不同的态度，使用者在碰到问题的时候可能会放弃掉，而贡献者会去尝试发现原因、找到解决办法，在这个过程中我们可以学到很多。而且为开源做贡献属于 Working in Public，也是 Learn in Public。Working in Public 的好处在于我们做的贡献可以算作能力的证明，参考刘未鹏十年前的怎样花两年时间去面试一个人, Github 主页是最直观的开发人员简历。这些年我换工作就碰到过认可我开源贡献的公司，面试的时候就不考八股的问题了。 创造价值实际上绝大多数代码不值钱。纯代码不值钱，业务才能赚钱，所以代码得运行起来、或者是交流起来。如果我分享出来的代码对别人有用，就能产生价值，能产生价值就附带可以赚钱。 举个例子，我在自己看书《Enssential of Programming Language》的时候，一边学习一边把课后习题用代码实现了：my solutions to EOPL3 。 这个代码如果一直留在我硬盘的某个角落，估计就是分文不值，我总不能把它当作传家宝留给我的后代。但是开源之后居然每年都会收到一些邮件咨询这方面的问题。因为这本书是国外一些大学的教材，他们学编程语言相关的课程就需要做这些编程题，还有一些项目之类的，有的同学就付费让我咨询。所以有的时候赚钱是结果的副产物。 更多可能前段时间我看到 React 核心开发 Dan Abramov 的十年总结 My Decade in Review — Overreacted, Dan Abramov 在几年里就从一个 17 岁的编程小白成为行业大牛。从总结里面看好多关键节点都是因为开源和分享，开源让一个人能成长如此快。 当然每个人的故事都是独一无二无法复制的。我想分享一下自己的小例子，在学习数据结构和算法时我实现了一个生成迷宫程序，还写了一些 A* 路径规划算法相关的文章。后来上海大学有个搞生物的教授看到我的文章，问我能不能帮他们看个程序，他们需要在多个节点里计算 k-th shortest 路径。我花了一些业余时间帮他们把核心算法用 C 实现了，他们后来把文章发表了出来，还把我的名字署上了。 我可从来没想过自己会发表一篇分子生物类的文章。最近我也开始另一种副业，在 Github 上收费帮有的公司做开源。这些就是分享的奇妙之处，我不知道自己的分享什么时候就帮助了别人，同时创造了更多的可能性。 无数人的分享让开源改变了整个软件行业，这些如今牛逼的开源项目都是从最开始一个小的分享举动开始的，Linus 在分享自己的小 Kernel 时估计未曾想过整个 IT 行业被自己改变了，尤大在分享自己的前端成果时也未料到 Vue 会被这么多企业使用。 最后，特别推荐这两期播客 : 和 Vue.js 的创造者尤雨溪聊开源软件 跟 Anthony Fu 聊聊全职开源和他的故事 这些开发者已经实现了全职做开源这种工作形态。另外现在国内开始出现了一波用开源软件赚钱的公司，比如 PingCap，TDengine 等。我认为这是个很好的趋势，让我们这些本身喜欢写代码的除了 996 之外有了更多选择。 这是开发人员最好的时代了，一起学习和贡献吧。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"OpenSource","slug":"OpenSource","permalink":"http://catcoding.me/tags/OpenSource/"}]},{"title":"为什么印度人占领了硅谷","date":"2021-12-12T07:02:34.000Z","path":"2021/12/12/why-indian-lead-silicon-valley.html","text":"前段时间 Twitter 也换了 CEO，还是一个印度裔。目前，硅谷的很多大的 IT 公司 CEO 位置都被印度裔占了，包括 Google，Microsoft，IBM，Adobe, Palo Alto Network , VMWare 等等，如今硅谷的印度裔高管已经数不过来了。这种现象逐渐成为西方媒体也在讨论的 The Indian CEO Phenomenon。 从我个人的经历来说，我毕业后所工作的第一家公司(模式是国内研发美国销售)，在创业六年后被印度人的公司收购了。我目前所在的公司也是印度裔 CEO，工作中接触不少印度同事。 对于这个现象，有时候会和身边的朋友同事交流。综合下来，我认为主要原因有这些： 能力很多印度裔技术人员早年都在印度上完大学。因为印度有种姓制度，社会阶层明显。能在印度上大学的大多家庭条件和阶层都不错。我 2015 年在硅谷出差时，有段时间经常蹭印度同事的车，所以我们会聊一些日常。他吐槽说跑到美国后更累了，因为在印度家里有好几个佣人，过得可是饭来张口的生活😃。 印度的 STEM 氛围比较重，工程师算得上是一个受人尊重的职位。看过《三傻大闹宝莱坞》的可能对此有些印象。从目前印度高考情况来看，理工科是最热门的、入学门槛最高的学科。像印度理工学院这种顶尖学校，入学难度堪比麻省理工。印度好的理工学校，很多学生毕业后就去美国继续上学、工作。 所以，我们看到的去美国的印度工程师，其实也和中国类似，经过了好几轮教育体制的筛选，智力、学习能力大多都是不输中国人的。 在人数众多的 IT 公司中，领导岗位犹如部队的率领，也许枪法不是最好的，更重要的是能带队伍，做正确决策等综合能力。印度是一个非常注重商业管理教育的国家，很多印度人出于职业发展上的考虑，喜欢上商业类的双学位课程，或者像 MBA 这类的项目。 技术能力对于做 Leader 岗位来说，只是其中一个维度。当大部分都是技术上出众的时候，那么同时具备商业嗅觉、宏观判断力的人就容易突出。Google CEO 的 Sundar Pichai ，当年作为 PM 领导了 Google Chrome ，Google Drive 等明星产品。 沟通在公司能踏实做事固然很重要，但如果要走向管理岗，不太会表达就是个大问题。 在 IT 行业工作的印度程序员，基本都能很流利地用英语表达。日常搜索中我们经常碰到的 geekforgeeks 这种网站都是印度人做的。 很多印度人说出来的口语口音很重（部分阶层更高的印度人从小接受英语教育，所以口音更纯正一些）。典型的印度口音就像是这个视频 里一样。但是这不是一个大问题，欧洲的、俄罗斯的、世界各地的非英语母语国家的人说英语都是由口音的。对于母语是英语的听众来说，有口音大多不影响理解。就像是国内北京人来听带山东、湖南口音的普通话，这完全是没有什么障碍的。在英语这块，中国的技术人员很多是应试教育的受害者，高考后荒废几年，英语日常沟通交流并不顺畅。这种现象在我这种 80 后的年龄段中还比较突出。公司最近有一些毕业生入职，总体感觉 90、00 后相对来说口语会好很多。 文化InfoQ 曾有一篇文章对比了华人与印度裔的领导力：华人是典型的技术型领导者，主张内心修为，务实低调，倾向于个人奋斗，喜欢在技术方向上深钻；印度裔则是典型的商业型领导者，他们更关注传递价值观，注重培养沟通能力、管理能力、影响力及对商业的理解，这更贴近西方文化中领导力的内涵。 通常中国人相对内敛，表达方式含蓄，东西方这种表达方式上的偏差会在职场上造成巨大影响。所以实际上，韩国、日本能在欧美企业中做到顶尖的也相对较少。 东方文化中推崇“凡事不做出头鸟”，中国人工程师大多比含蓄和谦虚，自己做了 120 分可能才敢说出 100 分。中国传统文化中，我们推崇那种扫地僧，默默地做技术大牛，在技艺上做到顶尖，而在很多公司决策上、公共事务上成为”沉默的大多数“。这对于美国人是比较陌生的，美国人沟通倾向于直接明、强势自信的。在印度被英国统治多年，印度人的思想、文化、体质几乎都彻底被西方化，所以自然容易同美国人打交道。I 文化差异的另一方面是团结。传说“公司来了一个印度人，过段时间就是一群”。硅谷的印度人对自己族裔相互提携，非常抱团，部分原因是因为印度的种姓制度，同阶层和种姓的群体容易相互帮助。而华人圈曾经流行过一句话：“一个中国人是条龙，一群中国人是条虫” ，辛辣地批评了中国人的劣根性。北京大学著名学者钱理群先生说：今天大学所培养的，不过是一群精致的“利己主义者”。 在美国工作了三十年的前老板跟我提到过，华人里面其实暗地里相互的较劲很多，特别是同级别之间。文人相轻自古以来都有，千军万马独木桥走过的做题家，在狭窄的职场上容易引起竞争。攀比、嫉妒等会造成很大内耗，最终影响华人整体发展。 国情中国和印度两国的巨大国情差异也是一个原因，这导致了两国留在美国发展的人的追求就不同。 近二十年来，因为中国人口基数红利，中国基础设施的完善，互联网对中国各个行业的渗透，国内 IT 行业迅速崛起。机会和资本都不缺，这些年来对于顶尖人才的待遇不输美国，职场天花板更高。在美国的中国技术人员大都犹豫过是否回国。现实也是，很多优秀的、有大抱负的中国人放弃了在美国职场闯荡的路径，选择回国创业或加入国内大公司。另外我发现很多程序员出去是为了逃避内卷，或者是为了孩子教育，他们追求的是工作之余“种竹浇花酿酒”。 对于印度人而言，在一个好的理工学校毕业，然后去美国赚钱、发展，这是非常理想的，几乎是唯一好的出路。因为印度本土发展落后太多，生活形态和质量也差很多。选择少反而成了优势，留下来扎根的人，自然有些渐渐就爬上去了。 以上纯是些个人感受和理解，或许和实际情况存在一些偏差。 其实我们也没必要过于纠结在这点上。总体而言，我认为这些年来中国在 IT 领域取得了全球最快的发展速度，我们有自己的成功 IT 企业，也有很华人创办了成功的创业公司，例如 Zoom、Notion 等等。 但这事也值得大家思考，职场发展其实不管哪个国家都有一些共性的东西。多向别人学习，发觉自己的不足，这样才能成长和进步。共勉！","tags":[{"name":"瞎写","slug":"瞎写","permalink":"http://catcoding.me/tags/%E7%9E%8E%E5%86%99/"}]},{"title":"什么是好的技术面试","date":"2021-12-08T09:11:49.000Z","path":"2021/12/08/the-good-tech-interview.html","text":"今天正好看到两个技术面试相关的分享。结合自己这十年来的面试或者被面试经历，谈谈自己的想法。 难得的面试分享首先我们来看看 ReactJs 核心开发 Dan Abramov 的面试视频。这不算是正式的面试，是一个 Youtube 主播和 Dan 进行的模拟面试。Coding Interview with Dan Abramov - YouTube 这个面试将近持续了一个小时，但是主要是后面的那个算法题耗费时间，前面几个问题都是很八股的前端面试题： let 和 const 区别 什么时候使用 redux dangerouslySetInnerHTML 是什么，该怎么用 把一个 div 居中 把一个 binaryTree 镜像翻转 Bonus Q: 一个找兔子的算法题，兔子出现在数组的某个位置，但是每次可以跳向相邻的位置，用最快的办法找到兔子的位置。 这里面有意思的点是： Ben: There is a library called ‘redux’ Dan: “Hmmmm heard about it” Redux 最初版本是 Dan 2015 年发布的…….. 面试官小哥羞涩地笑了 🤣 然后，把 div 居中算是前端中的经典梗了，Dan 花了好一会时间在面试官的提示下才把一个 div 居中。如果对方不是 React 核心开发，手熟的前端可能就会开始鄙视这位“初级前端”了。这让我这种一直觉得 css 很难的前端学习者觉得信心大增。 反转二叉树问题 Dan 很快就答出来了，但是从面试过程中可以看到他对怎么尽量少代码 swap 两个变量还想了一会儿。我后来看他的十年总结的博文中，职业生涯初期的一次面试也提到了这个点: At one point I freaked out and panicked because I couldn’t write three lines of code that swap two items in an array. I asked Jing to look away for a few seconds. She said “I know you can swap two items”, and that gave me the confidence to finish the answer and make it through the interview. I probably didn’t pass with flying colors, but I got the offer. 最后一个算法题比较新颖，这不算红黑树式的八股算法题，倒像是一个 IQ 测试题目。可以看出 dan 也很少碰这类算法题。他花费了近半个小时在面试官的提示下，按照自己的直觉一步一步推出了答案。但是他最后写的代码是有点小问题的(没有用 2 来递增 index)，面试者看他思路是对的也没有指出来了。这里可以看到，其实结果可能并不重要，而是在解决这问题中所展现出来的思维方式方法很重要。 除去 Bonus Question，可以说这轮面试的题目大多比较常规，难度小于很多国内外大厂的面试。Dan 作为前端大咖，愿意参加这样的直播分享很难得。我感觉看到的是一个真实的工程师，在未做过八股训练下的真实表现。 这是今晚看到的另外一个面试分享， 经历了人生体验最棒的一次面试 · Issue #228 · yihong0618/gitblog (github.com)： 我觉得比较难得的是第一面面试官的面试方式，选择一个面试者的开源项目，然后提一个小需求让他实现。这得很花面试官的心思和时间，也确实能很好地考察应聘者的编程能力和工程能力。国内这种认真面试的公司太少太少，而且一线大厂几乎不可能出现这种面试方式。 我的一些经历在我十年的职业生涯中，经历过多次技术面试，作为应聘者被面试或者面试他人。 我经历过的最差的面试体验是在 2014 年。面试官没怎么看我的简历，首先让我挑两个主题，然后我能看到他在屏幕前点了点鼠标，从题库中挑选了几个题甩给我。这种感觉就是高中时候的考试体验，我需要在纸上写程序和公式。面试官全程严肃无表情，即使我主动需求交流也无果。这次面试可以说是深深地伤害了我，并给了我很大的心理阴影，导致我后来面试就会忍不住祈祷千万别再碰到这类面试官。 一些小而美的技术公司倒是更尊重应聘者。前两年我参加过一个新加坡小外企的招聘。首先第一轮面试是双方自我介绍，对方会和我聊他们公司的主要业务和技术栈，以及目前这个岗位的工作内容和职责，确定我感兴趣之后才会约第一轮技术面试。第一轮面试就是一个小的项目，需求都写清楚，但其中也留了一下自由发挥的空间。我一周的时间来完成，然后把代码发过去。第二轮技术面试首先是从那个小项目聊，为什么这么写等等，然后会引出一些技术问题，但是会从深度和广度不断地追问下去。这就有些像是平时工作中，两个同事探讨问题的状态。 算法有什么用面试的难点在于，很难在短时间内了解这个人的全部技能和特点。这些包括编程能力，工程能力，技术视野，沟通能力，应对挑战的能力等。 刘未鹏曾经在怎样花两年时间去面试一个人中提到，用 Github 和书单的方法来面试。这当然是一个不错的面试方法。而大公司采用比较标准的面试，主要是为了节省时间。因为应聘者多，面试的场次多，不可能让面试官在工作之余花大时间主动了解应聘者，通常情况是面试官在面试之前匆匆扫上一眼简历。而且八股文式的面试很容易让面试官得出结论，即使这个结论包含了不少偶然性因素。 面试造火箭，入职后拧螺丝是行业常态。这也说明，我们工作中极少极少去碰这些基础算法类的东西。工作久了，我能看到很多面试官拿出一个公司的面试题，在不看答案的情况下自己也做不出来。 算法又是很多程序员所惧怕和不擅长的部分。Programming Pearls(《编程珠玑》)一书的作者 Jon Bentley 曾经说过：“90%的程序员无法正确实现二分查找算法...”。2014 年我在广州参加一个技术聚会上，因为一个一时兴起的赌局验证过这点。当时我们那个会议室 20 多个程序员，其中有工作多年的，也有刚毕业没多久的，能在规定时间写出一个无 bug 的二分查找的确实寥寥无几。 那面试出这种题目有何意义？ 算法当然对程序员很重要，特别是某些特定的领域，比如图形学、机器学习、高性能计算等等。另外如果一个程序员啃过算法这个硬骨头后，会觉得学其他都不算太难。在学习编程阶段，大量地实现数据结构和算法就是一种很好的提高编程能力的方法。我在学校最后一年刷了 POJ 500 道算法题，自我感觉编程能力大幅提高。 但我认为面试中的算法题可以当作一个下限标准，使用相对基础的、简单的编程题，会有助于筛选出编程能力不适合的应聘者。另外来自实际工作中的一些算法问题也是很好的面试题，比如上次我碰到的输入自动补全算法。这种问题没有唯一解，而且也很容易理解实现，通常有一定编程经验的程序员都可以实现出自己的版本。 对于绝大部分岗位来说，算法题测试不适合当作上限标准，因为专门训练过的应聘者和没训练过的差别太大。较难的、八股式的算法题对于初步筛选不太有用。一个应聘者如果能很快答这种题，可能是他刷 LeetCode 比较多，或者是刚好之前碰到过这个题。对于资深的应聘者，往往只能通过以往的项目来考察深度和广度。我认为深度比广度重要，因为如果一个人能把某个领域做得很深，如果他花时间换个领域很可能会做得好，反之则不然。 总而言之，很多大公司的面试看起来八股，也有一定道理。作为应聘者，专门针对这类面试做一些针对性训练结果就会好很多。 我认为好的技术面试有如下特点： 对应聘者尊重、真诚，面试是一种平等的沟通和交流 拒绝八股，更多考察实际解决问题的能力","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"面试","slug":"面试","permalink":"http://catcoding.me/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"Obsidian 插件开发","date":"2021-12-02T07:17:37.000Z","path":"2021/12/02/obsidian-plugin-dev.html","text":"昨天花了点时间下学习 Obsidian 的插件开发。我想了一下目前自己有点不爽的是图片插入的时候，图片的名称中间有空格，这虽然也不是什么大问题，只是在 Linux 环境下显示的时候看起来特别别扭。而且这看起来也是一个很好的入门小插件，可以接触 Obsidian 里面的文件管理和编辑操作，我需要把图片在文件系统里的名称改掉，也要修改 markdown 里的路径。 所有代码都在这里了： chenyukang/obsidian-rename-image (github.com)。 开发步骤 从 plugin sample repo 克隆一个仓库 修改其中的 manifest.json 文件，其中 plugin id 是最重要的。 修改主文件 main.ts，使用 npm install 安装依赖库 使用命令 npm run dev 编译出 main.js 在 Obsidian 的 vault 目录 .obsidian/plugins/ 创建一个插件名称的文件夹，拷贝 manifest.json 和 main.js 到该目录，有的插件可能还有 style.css 等文件。 在 settings 页面加载插件 在开发过程中，可以通过 Ctrl-Shift-i 来打开调试页面，在代码中加入调试信息。 API 相关在插件项目里执行了 npm install 之后，文件 node_modules/obsidian/obsidian.d.ts 就是 Obsidian 的 API ，里面有很详细的注释。 作为补充可以看看 Obsidian API - Liam Cain。API 分为这几个主要部分。 其中文件编辑部分使用了这个CodeMirror。 其他之前有那么一会我会想，Obsidian 这样一个软件为什么不开源？如果开源我们是不是可以做更多的自由探索。通过折腾插件这么一段体验，我认为不开源问题也不大，其实通过插件我们其实可以在插件里面跑任何自己的代码。这里面的可扩展性对于绝大部分用户来说绰绰有余。 一个技巧是多看看已有的插件是如何实现的。打开 Settings 页面的 community plugins，选择某个感兴趣的插件看看里面的代码： Obsidian 模块化做得很好，而且 API 的粒度很细。在 VsCode 中写 TypeScript 插件体验比在 Emacs 中写 elisp 开发插件好很多，并且 JavaScript 的相关文档可太丰富了。 所以，真没必要抱着上古时代的软件不放 😁","tags":[{"name":"工具","slug":"工具","permalink":"http://catcoding.me/tags/%E5%B7%A5%E5%85%B7/"},{"name":"obsidian","slug":"obsidian","permalink":"http://catcoding.me/tags/obsidian/"},{"name":"TypeScript","slug":"TypeScript","permalink":"http://catcoding.me/tags/TypeScript/"}]},{"title":"Sidecar 架构模式","date":"2021-12-01T07:17:38.000Z","path":"2021/12/01/sidecar-design-pattern.html","text":"如果你最近看一些容器相关的技术文章，可能会看到这个技术名词：Sidecar 模式。中文译名为：挎斗模式。这个名字为直译，挎斗就是这样的一种摩托车： 如果理解了这种模式，就会明白这个名字其实取得特别好。Sidecar 模式就是指在原来的业务逻辑上再新加一个抽象层。这种模式很好的印证了那个计算机的名言： “计算机科学领域的任何问题都可以通过增加一个简介的中间层来解决。” “Any problem in computer science can be solved by another layer of indirection.” 如果一个抽象层不够，那来两个。这种模式也不是近些年新发明的，我们可以理解 Nginx 的反向代理其实也算一种 sidecar 模式，应用前面的 Nginx 可以实现一些常用的流量功能、鉴权、静态文件访问等基础功能。只是近些年，随着微服务和容器化在实践中越来越多，这种模式的使用范围也更广、粒度更细了。在非容器的环境下，一个 Nginx 可能会服务多个物理机(或者虚拟机)，在容器环境下我们可以单独起 Nginx 容器来服务单个应用。 场景在微服务架构中，如果应用多了就会形成一些共有的需求。特别是流量控制方面，包括限流、流量分发和监控、灰度等等。通常我们对一类需求可以实现一个抽象层，然后在这个抽象层上实现具体的业务逻辑。比如很多公司都有服务网关，然后使用各种语言的 SDK 来集成到应用中。 这是通常我们会选择的一种方式，这过程中会有这样的一些问题需要考虑： SDK 的维护成本是很高 SDK 集成到代码中，其中一个组件发生故障就可能会影响到其他组件，SDK 和应用程序之间是保持着相互依赖的关系的。 在应用层和基础服务没有解耦的情况下，我们对基础服务做改动会增加很多风险和复杂度。例如，我之前所在的部门整个电商的应用做灰度改造，所有应用都需要做对应的改动。 sidecar 架构那我们是否可以提供一个统一的抽象层来做这些基础的重复工作？将基础服务抽象、解耦到应用层都感知不到的程度？ 这是现在的趋势，特别是现在很多架构都跑在容器这样的环境了，统一的抽象层能大大减少架构上的复杂度。 sidecar 模式在不改变主应用的情况下，会起来一个辅助应用，来辅助主应用做一些基础性的甚至是额外的工作。这个 sidecar 通常是和主应用部署在一起，所以在同样的运行环境下。这其中还有一些性能上的考虑，sidecar 如果和主程序网络通信上有延迟就会造成性能问题。例如在 K8s 下一个 pod 里的所有子应用共享一个 sidecar 服务。 这个辅助应用不一定属于应用程序的一部分，而只是与应用相连接。这就像是挎斗摩托车，每个摩托车都有自己独立的辅助部分，它随着主应用启动或停止。因为 sidecar 其实是一个独立的服务，我们可以在上面做很多东西，例如 sidecar 之间相互通信、或者通过统一的节点控制 sidecar ，从而达到 Service Mesh。 这样的好处在于： 应用层和基础服务层解耦 基础服务统一维护，SDK 统一集成，减少复杂度，减少应用服务中的重复部分 可以在不改变原有应用的情况下，为应用扩展新的功能 案例分析我们可以来看看业界典型的使用 sidecar 模式的框架。 DAPRDapr: Distributed Application Runtime 是微软开源的一套分布式程序开发框架，其目标是：“Build distributed applications with any language, any framework, run anywhere”。既然任何编程语言，任何框架都要支持，sidercar 是一个必然的选择。DAPR 把很多常见的分布式程序的公共组件抽象出来成为’building blocks’，然后通过 gRPC 或者 HTTP 统一出接口。应用程序通过 sidecar 来访问。 这样多了一层抽象之后，即使是某个 Component 做了一些改变，应用层也是无感知的。除了在容器化的环境下运行，用户也可以在非容器化环境以 sidecar 模式启动任何应用，例如我们启动一个图片接口服务 image-api-service，该服务会监听端口 8080，而 sidecar 会通过 3500 端口来代理该服务接受请求： dapr run --app-id image-api \\ --app-protocol http \\ --app-port 8080 \\ --dapr-http-port 3500 \\ --components-path ../config \\ --log-level debug \\ ./image-api-service 其他服务组件可以通过 sidecar 去请求该服务： // Dapr api format: http://localhost:&lt;daprPort&gt;/v1.0/invoke/&lt;appId&gt;/method/&lt;method-uri = &quot;http://localhost:3500/v1.0/invoke/image-api/method/api/image&quot;req, err := http.NewRequest(&quot;POST&quot;, uri, bytes.NewBuffer(image)) lstioIstio 服务网格 是一个开源的服务网格，提供了统一的方式来实现连接、监控、负载均衡等公共服务和流量管理。单个服务的所有传入和传出网络流量均通过 Sidecar 代理，完成微服务之间的流量管理、遥测数据收集以及策略的执行等。 在 lstio 中，我们需要了解 Data Plane 和 Control Plane 两个概念—— Data Plane 的作用是处理网格内服务间的通信，并完成服务发现、负载均衡、流量管理、健康检查等功能；数据平面的作用是处理网格内服务之间的通信，并负责实现服务发现、负载平衡、流量管理、健康检查等功能； Control Plane 的作用是管理和配置 Sidecar 来执行策略并收集遥测 lstio 中使用了 Lyft 开源的 Envoy 来做流量代理，Envoy 和应用程序一起在一个独立的进程中运行，应用与 localhost 收发信息，对网络的拓扑结构无感知。 其他考虑 更适合在容器化的环境使用 简单系统就没有必要使用这种重型武器了 哪些部分可以放到 sidercar 里面需要慎重考虑","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"架构","slug":"架构","permalink":"http://catcoding.me/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"在 Github Action 使用 Git","date":"2021-11-30T07:17:46.000Z","path":"2021/11/30/using-git-in-github-action.html","text":"最近我把自己的一些自动化脚本移到了 Github Action。因为考虑到 Github Action 有下面几个优势： 自动化脚本是代码的一部分 (Infrastructure as Code)，而不是限定在某个服务器上。这样长久来说更为通用，如果我迁移到其他服务器根本不用做什么修改，因为我们在写 Github Action 的脚本的时候就不假定在哪台服务器上运行。 配置更为方便，想要修改一下只需要提交配置文件就可以了，不用登录到服务器上。 基于以上几点考虑，我花了一些时间来把之前的一些 Ruby、Shell 脚本变成 Github Action 配置。有的脚本做的事情是定时拉去某个 repo，如果有改动则会根据规则生成新的内容，然后自动提交到远程仓库。所以我需要在 Github Action 中使用 Git 提交数据。要达到这个目的得在 Github 中配置 Git 的权限和账户信息。有以下两种方式： 使用 Github Access token首先需要在 Settings 页面生成一个 Access Token. 然后添加到要配置 Github Action 的仓库的 Settings 页面中，假设我的 token 取名为PAT，在 Action 中我们可以通过 secrets.PAT 获取和使用该 Token。 jobs: sync-to-sites: runs-on: ubuntu-latest steps: - name: Git Clone and Global Config run: | # Git setup export GITHUB_USER=yukang echo &quot;GITHUB_USER=$GITHUB_USER&quot; &gt;&gt; $GITHUB_ENV echo &quot;GITHUB_TOKEN=$&#123;&#123; secrets.PAT &#125;&#125;&quot; &gt;&gt; $GITHUB_ENV git config --global user.email &quot;moorekang@gmail.com&quot; git config --global user.name $GITHUB_USER 然后通过如下方式 clone 要修改的 repo 到跑 action 的服务器目录上。 - name: checkout blog uses: actions/checkout@master with: repository: chenyukang/blog-source token: $&#123;&#123; secrets.PAT &#125;&#125; path: blog-source 这种通过 Access Token 的方式 clone repo，用的是 HTTPS 的方式。通过 git remote -v 查看可以看到 remote 的地址。 使用 SSH另外一种方式是通过 ssh key。我们首先在任何一个服务器生成一个 ssh key，把这个 ssh 的 public key 加入到 Github settings 里。 ssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot; 然后把私钥拷贝到要配置 Action 的 repo 的 secrets 里。 通过如下方式在 action 中配置 ssh： - name: Install SSH Key uses: shimataro/ssh-key-action@v2 with: key: $&#123;&#123; secrets.SSH_KEY &#125;&#125; known_hosts: &#x27;just-a-placeholder&#x27; 这样之后就可以在 Action 的后续步骤中像在本地一样使用 SSH 的方式来 clone repo 和提交代码了。通过 ssh key 的方式我们也可以在 Github Action 中通过远程的方式来在其他服务器上执行命令，这对于要部署到服务器上的脚本来说是非常有用。 具体可以参考这篇文章： Deploying to a server via SSH and Rsync in a Github Action | Zell Liew (zellwk.com)","tags":[{"name":"工具，Github","slug":"工具，Github","permalink":"http://catcoding.me/tags/%E5%B7%A5%E5%85%B7%EF%BC%8CGithub/"}]},{"title":"自动补全算法","date":"2021-11-29T08:34:43.000Z","path":"2021/11/29/input-complement-algorithm.html","text":"周末在和一个日本小伙一直讨论一个 Obsidian 的 补全插件，经过一个周末的努力，最终这个插件完善了不少。我主要想用这个插件来补全英文输入，这个插件目前没有自带的词典。我在互联网上搜索了一圈，最终在 Github 上找了这个 Google 10000 English，也就是最长使用的搜索单词。 实际上，前 7000 个英语单词覆盖了日常的 90% 使用场景。 中文输入首先我碰到的问题是，输入中文的时候插件也在补全英文。然后我提了第一个 issue。作者很快就回复了，给了我一个开发版本尝试，很完美的修复了这个问题。然后在使用过程中发现另一个小问题，比如我的字典里面有 apple，但是如果我是在句子头部输入 Ap ，这个单词并没有出现在补全列表。我们当然可以把字典的单词都进行首字母大写的处理，但是这就会让字典翻倍。 我看了看源码，果然如自己猜想的那样，匹配的时候没有考虑首字母大写的问题。我花了一些时间做了一个 PR：fix issue #30, take care of uppercase 。 性能优化在我做上个修复的时候，也顺便修复了一个性能上的问题，看这个补全插件的核心算法如下： function suggestWords(words: Word[], query: string, max: number): Word[] &#123; return Array.from(words) .filter((x) =&gt; x.value !== query) .map((x) =&gt; &#123; if (caseIncludesWithoutSpace(x.value, query)) &#123; return &#123; word: x, value: x.value, alias: false &#125;; &#125; const matchedAlias = x.aliases?.find((a) =&gt; caseIncludesWithoutSpace(a, query) ); if (matchedAlias) &#123; return &#123; word: x, value: matchedAlias, alias: true &#125;; &#125; return &#123; word: x, alias: false &#125;; &#125;) .filter((x) =&gt; x.value !== undefined) .sort((a, b) =&gt; &#123; const aliasP = (Number(a.alias) - Number(b.alias)) * 10000; const startP = (Number(lowerStartsWith(b.value!, query)) - Number(lowerStartsWith(a.value!, query))) * 1000; const lengthP = a.value!.length - b.value!.length; return aliasP + startP + lengthP; &#125;) .map((x) =&gt; x.word) .slice(0, max);&#125; 在这个函数中如果词典列表很长，这里的 filter, map, filter 会遍历列表三次，是很耗时的操作。我把第一个 filter 干掉了。然后在匹配逻辑里面增加了首字母大写的相关的 处理。除了自定义的单词词典，这里补全的候选词来源包括当前文件内容、Obsidian 的内部链接。而链接需要进行部分匹配进行补全。 后续在使用过程中我又觉得补全有些慢，甚至会影响输入的体验，在 Obsidian 里面通过 Ctrl+Shift+I 可以打开调试面板，我们可以看到补全的耗时： 这里的主要问题还是因为每次输入一个字母，算法都在遍历单词列表两边。优化思路有两条： 使用类似桶排序的思路，把单词按照首字母进行分割，分成 26 个子列表，这样查找的时候就先根据首字母找到子列表，然后进行遍历搜索。 使用类似 Trie Tree 的数据结构进行前缀匹配。 后来那个作者按照第一种思路进行了 优化，很快将补全时间优化到了 0~5 ms。果然粗暴的算法其实很多时候就够了。 中文分词在日常使用过程中，我又发现了还存在这个 问题。如果我尝试去修改中文句子的某个部分，这个插件会补全当前句子，就像这样：这当然是完全没有意义的。我看了一下代码发现是没有进行中文分词，所以现在的补全把这个中文句子当作一个连续的字符串在补全。 我自己尝试这想做一个 PR，但是没找到合适的中文分割 JavaScript 库。Obsidian 不能使用 Node 的库（移动端方面的考虑），所以也就不能使用这个 NodeJieba。虽然还没完成这个分词功能，不过我也在这个过程中学着写了点 TypeScript。 一些感想这个看似简单的功能，如果要做到日常可用其实有很多细节需要完善。这个算法问题看起来不难，很适合用来进行面试，因为这是日常中很常见的一个需求场景，而且优化这个算法思路也可以很开放。 TypeScript 真强，虽然我只是简单用了一下，一些常见的 JavaScript 错误比如 enum 忘记补全之类的问题都能找出来。Electron 真猛，VSCode、Obsidian、Slack 这类工具都是 Electron 开发的。 开源软件的好处在于很多代码的作者对自己的成果有一种成就感，所以会想办法来完善，而用户也可以帮着来想办法。在这个过程中，不仅可以让其他人受益，自己也得到了一些学习和提高😘。","tags":[{"name":"Tools","slug":"Tools","permalink":"http://catcoding.me/tags/Tools/"},{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Obsidian","slug":"Obsidian","permalink":"http://catcoding.me/tags/Obsidian/"}]},{"title":"打造自己的工具 - Obweb","date":"2021-11-28T07:00:04.000Z","path":"2021/11/28/intro-to-obweb.html","text":"在文章我的知识管理工具和经验中我介绍了自己开发的 Obsidian 配合 Web 应用 obweb。 下面详细介绍一下自己对每个功能的使用场景，以及其中的一点技术细节。后端使用 Rust 开发的，因为后端逻辑并不复杂，所以使用什么语言区别不大。我最近在练手 Rust，所以就用了 Warp 这个框架来实现。 我是一个前端新手，顺便借这个项目在学习一些 JavaScript 和 Svelte 相关的技能。第一次实现的时候是纯 HTML 加 JQuery，后来又加上了 Svelte 。Svelte 这个前端框架对新手来说也不难，我是边看教程边照着做的。 Obweb 是一个典型的前后端分离的 Web 应用，没什么技术上的难度。可忽略我直男的 UI 设计(貌似根本无设计😂)，我们着重看看我日常用的这些功能。 记录想法这是我做 Obweb 的初衷，我想在手机端把一些想法和灵感记录下来。之前一直使用 [[flomo]] 这款应用，这个应用功能很少，就是让你打开迅速记录自己所想，使用标签来把这些想法串联起立。随着我使用 Obsidian 的时间越来越多，我就想把这些数据同步到自己的 Obsidian 中。 于是就开始用自己蹩脚的前端能力搞了这么一个界面。 这个界面很简单，就是一个输入框，可以加入标签或者 Link。但是这里面隐藏了一些逻辑： 如果 Link 为空，这个记录则为一个每日的想法，会追加在每天的 Daily 文件后 如果 Link 是 Todo，则会在我的 Todo.md 在文件头部增加一个记录。 如果 Link 是一个其他的文件名，如果数据中没有这个文件则会创建，否则就会在现有的文件后追加这条记录。这种使用场景是我在手机上看 Kindle，有的摘抄就会记录下来，最终每一本书阅读后摘抄就会在一个文件里面。这也是为什么这个 Link 除非手动清除，否则会一直记录在 localStorage 里面。因为一段时间内我看的都是一本书。如果要清除缓存则可以使用 Reset 按钮。 可以在想法中加上图片，但是限制只能加一张。因为我习惯了使用这个记录页面之后，我也想在 PC 端使用。因此增加了从剪切板中存储图片的功能，以方便我在 PC 端想同步一些内容到手机上以备后续查看。 每日回顾想法中记录的内容，可以使用 Day 来回顾，目前只有按照日期每日来回地切换。如果要大量地查阅内容我肯定使用 PC 端。这里也可以进行一些轻度编辑。 搜索和编辑我在手机端使用场景主要记录想法，但也有一定的查阅需求。比如我在外面办事可能需要看公司的保险需要哪些材料，这些我都会截图或者记录下来。所以，搜索是刚需。 目前搜索使用的就是粗暴的关键词匹配，我感觉已经够用了。后续可能可以增加分词等复杂一些的逻辑。作为程序员，文件中的代码高亮肯定是需要支持的，使用 highlight.js 就好了。 TodoTodo 也是一个 Markdown 格式的文件，而且这个文件只有记录了创建这个 todo 项的时间。我养成习惯每天早上都会看一看然后选择一些 todo 干掉。虽然目前很简陋，看起来就像是一个备忘录而已。对我来说也是足够了，我没有很多细小的事情需要赶 deadline。 RSS 阅读我已经有一段时间没有使用 RSS 阅读器了，其中一个原因是我没找到合适的安卓客户端。可能 IOS 上能找到一些精美的 RSS 阅读器。越来越多的人对 RSS 阅读不感兴趣了，国内的很多人使用公众号或，知乎，或者很多空闲时间用来看抖音。国外很多人继续使用 Newsletter 的形式来订阅，内容创作者也喜欢让你通过邮件订阅，因为邮件订阅是一种双向的关系，他也可以通过邮件联系你，这样后续就可以推广产品之类的。所以说 RSS 是反商业的模式，通过 Feed 订阅似乎成为怀旧行为。 互联网上还是有很多独立博客，他们不是为了商业利益，纯粹是为了自己的爱好和分享精神，坚持写一些高质量的内容。在没找到合适的工具的情况下，我自己实现了一个简单的 RSS 爬虫和这个 RSS 阅读界面。爬虫部署在我的服务器上，每隔几十分钟就会遍历我的订阅列表，抓取内容推送到 Github 私人仓库。服务端的爬虫使用的数据库是 SQLite 来存储文章的其他一些元数据。 有的作者 RSS feed 里面只提供摘要。为了营造沉入式的阅读感受，我尝试把文章的内容都抓取过来，包括图片也会拷贝一份到我自己的服务器上。这样每一篇文章打开都是全文，而不是摘要。 我最近发现一个新的使用场景，这种里面带有 Podcast 的语音内容，在开车时候打开听很方便。 后续改进因为现在使用 RSS 阅读的时间越来越多了，后面可能会继续优化 RSS 阅读的一些细节。另外前端代码现在比较乱，后面会继续学习一些前端技能，把代码优化得更优雅简洁。","tags":[{"name":"工具，Obweb","slug":"工具，Obweb","permalink":"http://catcoding.me/tags/%E5%B7%A5%E5%85%B7%EF%BC%8CObweb/"}]},{"title":"我的知识管理工具和经验","date":"2021-11-23T00:21:58.000Z","path":"2021/11/23/my-notes-taking-tools-and-experience.html","text":"知识管理是近些年出来的逼格称呼，通俗点说就是写笔记或者写作，讲究一点可以说成“打造第二大脑”，英文中可以诗意地称之为 “Digital Garden”。看看，同样一个事怎么说出来格局完全不同了。 近两年笔记软件这个领域出现了两个很重要的创新： 一个是双向链接，开山鼻祖是 Roam Research ，一个是一切皆对象和可无限嵌套的设计，也就是 Notion。 因为这两个大方向上的微创新，现在笔记类软件和系统百发齐放，这是真是最好的时代了。 作为程序员我分享一下自己在这类工具上的使用经验、感受以及建议。 大概十多年前，还在学校的时候，博客文化刚兴起，所以很多记录类的东西我都写在博客里了。那些常见的博客系统我基本都用过，后来很多都倒闭了。当然 Wordpress 现在在非程序员中都非常流行。 后来很长一段时间我都是用 Evernote ，国内版本叫做印象笔记。用的人多了各种周边的工具也非常多，比如浏览器插件之类的。这类笔记软件也非常多。 三四年后我又渐渐不使用印象笔记了，因为我用了很多年 Emacs，所以偶然尝试了 org-mode。这东西结合 GTD 可玩的方式可太多了。 org-mode 日程管理，日志，文档都在本地，一切都是纯文本的 org 格式，我通过 Github 来做数据存储。一切都是文本并且本地化就可以自动化，我可以自己写一些脚本，自己定义各种模板等等。虽然是纯文本的格式，我也可以很方便地到导出成 PDF , 甚至是做演示。很多人是为了使用 org-mode 才一直用 Emacs，我也曾经认为自己找到了以后一直用的记录工具和方式。 在这段时间，我养成的一个很好的习惯是使用 Github 来存储自己的数据。Github 已经成为最基础的互联网设施，我信任这个平台胜过其他服务。Joe Armstrong 在去世前一年，把自己的文章迁移到 Github，感兴趣的可以看看这篇不错的文章 People Die, but Long Live GitHub。 后来，我因为换工作的原因不怎么使用 Emacs了。最近一年工作内容变了，自己日常开发和业务时间使用 Windows 更多。业余时间基本是用的 WSL ，配合 VsCode 日常开发体验很棒。 而 Emacs 在 Windows 上使用体验很不好，我也没找到合适的移动端解决方案。虽然最近 WSL 也支持 Linux Gui 了，但我已经懒得折腾，因为我已经离不开 VS Code 。 我需要重新找一个笔记类工具，我的需求是： 本地存储文件 足够的自定义 支持 Markdown 支持双向链接 这个需求其实满足了绝大部分程序员用户，一个文件夹加 Typora 估计都差不多了，但是我觉得双链这个设计确实有一些价值，所以也变成刚需了。 在摸索的过程中我试过 Notion，Wolai，Logseq，Obsidian。 Notion 确实有耳目一新的感觉，而且 UI 的审美很好，用户做出来的笔记可以很美观整洁。而内嵌 Database 可以打造出来很多好玩的东西，甚至可以用来做站点。缺点是服务器在国外，不太稳定。 Wolai 提供 Notion 类似的块编辑以及大部分功能，而且很早就有双链接，服务器在国内所以速度上也很快。版本更新很快，有很多针对中文用户的细节优化。如果不想折腾用 Wolai 也挺好的。Wolai 和 Notion 是比较重的工具，已经超过了通常我们理解的笔记管理软件的范畴。 Logseq 是 Roam Research 的模仿品，但是提供本地存储的方式，也有桌面版软件。很多人赞赏 Roam Research ，不过我没有觉得这种方式完全适合我。 Roam Research 的正常方式是每天都在日志页面记录，然后写的过程中加上适合的链接，这样你的文档渐渐构成一个网络。如果你日常中经常用到的概念，自然就会经常被链接，那么就会是网络中的一个密集点。所以即使你不建文件目录，这种文档之间的关系也会自然而然形成，并且比目录这种单线的关系更符合直觉。 最终我一直保持使用的是 Obsidian。Obsidian 支持本地存储数据的方式（也可选择付费远程同步）。我使用一个 Git 的插件自动同步到 Github。Obsidian 的客户端做得如此出色，而且扩张性极好，已经形成很成熟的插件生态。这是我的记录汇成的网状。 在使用 Obsidian 一段时间后我又体验了 Flomo，这是一个不错的软件让我们迅速把日常的想法记录下来。我想如果 Flomo 的数据能够同步到 Obsidian 就好了。 看了一下 Flomo 的接口，我觉得干脆还不如自己动手重新实现来练练手。我就动手自己实现了一个 Web 单页应用 obweb，然后部署在自己的服务器上。这个应用提供一个简单的页面来记录日常的想法，文字或者图片都能迅速提交。数据提交后同步到 GitHub。这个 SPA 页面可以内嵌在微信浏览器，所以使用体验和一个小程序差不多。 而后我又增加了搜索的接口，这样我所有 Obsidian 的数据都可以在手机端检索和查看，而且我也能做一些简单的编辑。实际使用下来这真的比一个独立的手机应用更方便。 最近我又新增了一个 Rss 阅读的功能，后台会自动根据我的订阅列表抓取 Feed，甚至会尝试把网页和图片都下载下来，这样即使是一些”内网”不能直接访问的文章也可以在手机端无障碍阅读。 在这个过程中我学会了 svelte 这个前端框架和 Rust 写服务端接口这些东西。虽然我的 UI 设计和前端技能简直就是渣渣，但是这就是完全贴合我的使用习惯的软件，我可以做到所有细节的定制化。 这是一种渐进式的开发体验，每隔一段时间我会在使用过程中摸索一个需求，然后我会稍微等一等，如果这个需求还是存在并且我考虑好了如何实现，我就会加上去。 折腾这么多年这类软件后，我的感受是工具的使用都是非常私人化的选择，作为程序员我们有能力使用自己的技术来定制化工具来提高效率。最近看到这篇文章 You’re Allowed To Make Your Own Tools 很好的阐述了这个观念。这就像是住房子一样，如果你自己是设计师，估计不会满足房地产商提供的统一装修，而是根据自己的喜好和习惯来重新设计。房子也不是越富丽堂皇就越好，简单但实用即可。 所以在文档和写作这块，数据本地纯文本的方式是对程序员更好的方式，你可以自己写程序来处理这些数据，而不是完全依靠软件或者第三方的功能。比如这篇文章就是我在陪小孩上课的过程中，用手机在 obweb 上敲出来，服务器上的脚本会自动转成 Hexo 文件，提交发布到我的博客。 最后，我们现在有很多华丽的工具来用，也要避免让自己变成一个纯粹信息的收藏者。’数字花园’不是一股脑地往后院搬东西就行，需要花时间精心打理和修剪。工具并不能本质地解决问题，难的是日复一日坚持记录自己的想法和理解，整理知识。柳比歇夫使用纸和笔记录了自己奇特的一生，并且完成大量研究工作。 记录的过程并不是学习本身，而是思考。通过记录这种形式，把自己的理解写下来促进思考，才能产生最大的价值。 题外画: 一个有趣的事是，除了 Roam Research 和大厂的传统产品，目前兴起的这些笔记类软件和服务大多是中国人开发的，包括 Notion、Obsidian、Logseq 等。我们可能真的比较喜欢这类东西，“好记性不如烂笔头” 乃民族真传。 另一个事实，Roam Research，Logseq，以及另外一个开源的类似产品 Athens Research 都使用了 Clojure 这门编程语言来实现。Clojure 作为一门 JVM 上的 Lisp，其热度还没进过前 30 吧。这门语言对于数据处理这样的项目是比较合适的，只是不太适合大团队使用。","tags":[{"name":"工具","slug":"工具","permalink":"http://catcoding.me/tags/%E5%B7%A5%E5%85%B7/"},{"name":"开发","slug":"开发","permalink":"http://catcoding.me/tags/%E5%BC%80%E5%8F%91/"}]},{"title":"最好的学习是输出","date":"2021-09-07T21:49:24.000Z","path":"2021/09/07/learning-by-contribute.html","text":"之前我设想如果有了足够多时间，会做这些事：到处逛逛，锻炼英文写作，​投入到开源社区中。最近一年有了一些空余时间来做这些。我通常是十点到公司，下午五点半左右到六点之间离开公司。晚上陪小孩，洗漱哄睡完毕之后大概是九点钟。所以每天早上、晚上，加上周末，我都有一段时间可以用来自己安排。 ​这半年时间我参与了好几个开源项目，基本是顺着自己感兴趣的领域来的： 3 月左右，微软有个 FHL(Fix/Hack/Learning) 活动，基本有两周左右时间可以做自己感兴趣的项目，或者是学习点什么技术。那段时间我在琢磨怎么下好五子棋，因为和老婆经常比赛赌输赢。所以我写了个程序来下五子棋 gomoku，顺便学了一些技术相关的，比如 Rust，WebAssembly，Azure function，monte carlo，minimax 算法等。可能是我很久没从头到尾写个项目的原因，这个项目写得很来劲，顺便掉入 WebAssembly 的坑里。 接触到了 WebAssembly 发现有些意思, 所以看了很多相关的内容。然后我参与到了 wamser.io。这是一个 Rust 写的 WebAssembly Runtime，还包括各种语言的 SDK 之类的。我开始从一些简单的 PR 到一些 Bug 修复。通过这些投入我大概也熟悉了这个项目的代码。这个项目 Star 数目虽然有1W+，但是其实日常维护者已经只有两位了，其背后是一个公司在支撑。这公司之前是在 YC 孵化的，但是据我观察是没找到合适的商业化途径。当年 Docker 是找不到合适的盈利方式，所以最终选择开源。不过短短几年，现在这些技术型创业公司，基本都是默认开始干开源的，比如那些开源数据库之类的项目。 帮 WasmEdge 做了一些和 Dapr 的集成 Demo，花了大概两周的业余时间来学习 Dapr 和 WasmEdge 相关的技术，最终完成项目 dapr-wasm。这也是我第一次尝试收费帮人做开源，虽然不多但是也算是个不错的开头。既能赚钱又能学点新东西，何乐不为。 玩了一段时间 K8S 和 Linkerd 之后，我对容器相关技术又有一些兴趣。仍然记得 2014 年刚接触到 Docker 时的震撼，所以我想看看容器到底是怎么做的。后来找到了 Rust 实现的 Container Runtime youki。这个项目主要是一群日本年轻人在开发，项目发起人还是 96 年的。真是后生可畏! 我陆陆续续大概提交了十来个 PR，主要是改进一些测试脚本、参考 runc 来实现一些功能，通过容器的基准测试等。在 discord 偶尔和项目发起者聊聊天，交流一些中日的 IT 相关感受也挺有意思。贡献了几个 PR 之后，他邀请我成为项目的 maintainer。我觉得这是一个很好的锻炼、提高自己的机会，所以就欣然接受了。其实容器底层都是一些什么权限管理，namespace，cgroup，file system 等基于操作系统的抽象层做了隔离，跑起来就是进程而已。在开发容器的过程中，有时候会把自己的 Host OS 搞跪，所以最好是在 wsl 或者 VM 里面开发。 最近在使用 Rust 过程中，发现 lint 会重复报告某些提示。经过搜索发现已经有人提出了同样的问题。我曾经好几次尝试过看看 Rust 的源码，但一直没沉下心有所得。这个 Bug 看起来并不难排查，也许是一个很好的契机。我花了大概几个小时时间从理解 lint 相关的逻辑，到复现这个 Bug，找到代码里的问题，然后做出一个初步修复。这个过程中，感觉比较困难的是编译一次 Rust 代码库大概需要半个小时，跑测试则需要更久。另外通过 gdb 虽然可以调试代码，但是还是有某些限制。提交了 PR 之后才只是开始，后来又经过了一周多时间和子模块维护者讨论更细节的问题，来回 20 多 comments 才最终完成了修复。 从 2011 年开始使用 Github，这些年一直在 Github 上做一些自己的开源小项目。只有最近大半年才比较多地参与到一些大的开源项目。这个过程收获很多。 最好的学习方式是贡献和输出。不管是在公司、或者是在开源社区做出贡献才是技术的价值。看书、看资料能学会一些，但是只有实践才能提高自己的能力。比如我学 Rust，肯定不花时间去看 Rust quiz 之类的东西，因为日常开发中常用到的语言特性并不是那些细节。很多领域更重要或者更有价值的是领域知识，编程语言在使用过程中不懂再去看就行了。 有了足够的业余时间，以及纯粹的爱好，才静下心来持续投入到免费的开源中。996 肯定是不行的。做开源很多人都是在 “用爱发电”。很多开发者大多是有一份本职工作，做开源也算是眼望星空吧。但是确实因为热爱，所以代码质量反而比公司代码高。工作中看多了十多年的历史代码，看点优秀的开源代码有洗眼效果。 Github 现在开始在某些国家支持 Sponsor 项目，可是中国不在试用范围内。我认为这是一个很好的趋势，做开源的程序员如果创造出来价值，应该得到一些资金上的支持。这使得有些程序员可以为了自己的项目，依赖这些资金全职投入到开发中，比如 Bevy 的作者，来不及等到筹集 7000 美金一个月的筹款就辞职投入了。 在投入到开源的过程中，除了自己能力的提升，也可以获得精神上的满足感。即使修复是一个小问题，其他人也会因为自己的投入而受益。而因为开源以及其带来的共同协作模式，程序员的学习、生产资料都极大丰富。这真是个好时代。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Rust","slug":"Rust","permalink":"http://catcoding.me/tags/Rust/"}]},{"title":"程序员如何站着每年赚 30w 美金","date":"2020-10-27T21:57:00.000Z","path":"2020/10/27/programmer-out-of-normal-job.html","text":"Daniel Vassallo 是我最近一年都在关注的一个推特用户，我几乎看了他发的所有 Twitter 和文章。 这位程序员去年离开了亚马逊的一份轻松而多金的工作。他在亚马逊干了 8 年，尽管不断获得晋升、薪酬、表彰和表扬等奖励，薪水从 7.5w 刀一路涨到 50w 刀，但他没有足够的动力再干一年。 至于为什么离开亚马逊，他写了一篇很好的文章来解释：只有内在动力才能持续. 主要原因是随着级别的提高，工作的自由度减少了，得平衡各方利益，说服其他人来完成特定的目标。这很正常，在大公司工作有很多固有的限制，关于如何做工作，做什么工作，设定什么目标，以及什么业务值得追求。很多时候会迫使我们去做不想做的事情，而想做的可能也无法施展。 总之，在公司赚钱肯定是比较稳定，收入也不错。只是时间、精神上谈不上自由。 为大公司工作是一种稳定的状态，就像是围城一样。 如何站着把钱挣了？ 完全靠自己得有动力，而且是持久动力才能坚持下来。 什么是持久动力动力分为外部动力和内部动力： 外部动力可以称之为棒子或者萝卜。举例来说，缴税是棒子，虽然我们不想做，但是必须得完成。为了买一辆豪车，努力加班加点赚钱，这就是萝卜。两者都是外在因素迫使我们不断地有『动力』去执行。 内部动力是持久动力，就是自己心甘情愿去做，并且乐于其中。这位程序员的兴趣在于写代码，卖自己的作品。而互联网时代就是最好的舞台，个人可以专注于自己专业领域，完成自己的作品，并获取关注和收入。 当然最重要的是作品的质量，以及推销的手法。 找到自己的切入点通过自己的作品来赚钱，听起来很简单，但实现起来难度其实是巨大的。 辞职后开始做的一个项目叫做 Userbase， 为静态网站增加持久化存储。另外开始和朋友做的是一本电子书：The Good Parts of AWS。售价25美金一份。10个月总共花费 3w 多美金推广，收入 25w 美金。 这本电子书包含一些经验性的东西，对基于 AWS 做技术架构的人挺有用的。对于在 AWS 上工作了10多年的人写出这样一本小册子肯定是不难的，但是难的是如何做推广。 这也是作者做得挺好的一点，在 Twitter 上经营固定的读者。他每天都会发一些作为 Indie 的一些感想，关于工作、生活、经济、创业方面的。14 个月时间从 150 的 follower 涨到了 49000 多。他经常会把一些自己项目的数据贴出来给大家分享，这样显得特别真实、真诚。这种推广套路营造出一种类似《楚门的世界》的观感效果，读者看着他从第一天辞职，然后不断经营自己的项目，就会有动力一直去关注后面的进展。 然后作者把自己最近一年左右的 Twitter 推广实践经验又录成了视频： Everyone Can Build a Twitter Audience， 售价 50 美金。这一连贯手法真是越来越溜了。这是他今天才发的 2021 年收入情况 当然，除了营销外之外能力是最重要的，这位同志的写作能力一流。可以从第一篇辞职撰文可以看出，用词、表达清晰有据。 总结有人可能认为，这赚得看起来还没他自己上班多啊！ 但是，为自己工作的自由度、成就感、安全感是完全不同的，而且这还只是一个开始。 很多人丢掉了自己的全职工作之后，完全不知道如何打造自己的另外一份收入，陷入等米下锅的状态。总结起来都是很简单的道理，只是做到的人很少： 跳出自己的舒适区，向自己期望的生活方式改变 找到自己的兴趣点和优势，寻找自己能满足的实际需求 相信复利效应，做有积累的事情 不可否认英文环境的付费意识相对来说会更好一些 营销太重要了，社交营销是现在非常重要的一种营销能力 写作太重要了，电子书、营销都离不开","tags":[{"name":"副业","slug":"副业","permalink":"http://catcoding.me/tags/%E5%89%AF%E4%B8%9A/"}]},{"title":"DHH - 关于软件开发的少数派","date":"2020-10-10T22:50:38.000Z","path":"2020/10/10/dhh-on-software-dev.html","text":"David Heinemeier Hansson, Software Contrarian 是 Podcast 频道 corecursive 在 2020.2.1 发布的一个 DHH 关于软件开发相关的访谈。 DHH 不用介绍了，Rails 创始人。 可以说之前 Ruby 的流行很大程度上依赖于 Rails 的兴起。Rails 确实影响了很多后来的 Web 框架的设计和实现，并给软件开发带了一些全新的理念。 这期是我之前当作练习英语的材料来听的。DHH 的口音非常清晰，表达方式也是非常直接。因此这期听起来有一种类似 Rap 的快感。 为什么 Rails 成功了Rails 的出现改变了软件开发，至少在 2006 年，当 Java，C# 大行其道的年代。Rails 以其优异的开发效率震惊了不少开发者。Rails 的成功无非是在恰好的时机做了恰当的事情。 DHH 总结了从 Java、PHP 的开发经验。Java 阵营里都是聪明人，有很多好想法，但是他们却在一个糟糕的开发环境里工作，不容易让新人轻易上手。而 PHP 却很简单明了，你直接把一个文件拖入特定的文件夹，就可以生成对应的网页。Rails 的第三个元素就是 Ruby，Ruby 是极其容易安装，容易上手而直接的编程语言。DHH 当时正在写 Basecamp，所以一切都是从实际使用出发的，自己构建工具，然后再用这个工具构建 Basecamp。 而且 DHH 当时也是一个 Ruby 新手(那时的 Ruby 老手估计也没几个?) 新手的好处在于，他不知道 Ruby 的极限在哪里，哪里可能面临挑战。这样可以随着自己的性子，满足自己的期望来构建 Rails 了。在写 Rails 的过程中，DHH 更关注的是作为用户的感受是什么？编程就像是做菜一样，厨子需要关注的色香味俱全。 Ruby 最大的洞见是: 程序员不仅仅是程序员，同时也是人。 依据这个原则，在设计 Ruby 中最重要的事情和设计标准就是：编程语言使程序员更快乐。 最开始如何开始接触 RubyRuby 是日本人 Matz 于 1995。但是直到 2003，这门编程语言仍然是非常小众而神秘的。DHH 也是那段时间在看到些 Martin Fowler 和 Dave Thomas 写的技术文章，他们俩个都选择了 Ruby 作为编程语言介绍一些概念。这引起了 DHH 的兴趣，所以开始关注 Ruby，并去参加了 Ruby 2004 Conf。 那届 Conf 大约也就 42 人吧…. 但是随后几年的 Rails Conf 就开始有 2500 人了。 关于编程语言的选择很多程序员因为喜欢上编程，就是刚好碰到了符合自己口味的编程语言，并激发对编程的巨大乐趣。所以，语言的选择说不重要也不对。如果你还没找到自己的最爱，继续尝试吧。 但并不意味着，在一个小众的编程语言过多投资可能会带来其他的回报。语言的流行有很多其他的因素。Rails 的初衷并不是完全用来满足自己的创造轮子的快感的，而是依据自己的实际项目出发的。 这给我们的不错启示：从实际的需求出发，使用新的工具造轮子。 关于微服务的吐槽DHH 对微服务保持否定态度，认为业界这么流行微服务其实是有害的。 大多数情况下，一个人可以完全理解、部署的单一应用，比微服务更容易维护。 微服务的优势在于，如果团队足够地大，我们需要给开发者一些界限。 不要盲目地沿用大公司的套路，因为解决的问题不同！ 关于 TDDTDD 也是 Rails 社区很流行和推崇的，但是 DHH 其实对此并不太感冒。并不是 TDD 就能写出更好的，更健壮的软件。 事先写测试用例还是事后写并不重要，重要的是自动化测试。","tags":[]},{"title":"网络相关","date":"2020-09-08T20:59:08.000Z","path":"2020/09/08/networking-notes.html","text":"DNS 域名解析分为递归解析和迭代解析 https://blog.csdn.net/lycb_gz/article/details/11720247 APR 欺骗ARP 欺骗是一种在局域网中常用的攻击手段，目的是让局域网中指定的（或全部）的目标机器的数据包都通过攻击者主机进行转发，是实现中间人攻击的常用手段，从而实现数据监听、篡改、重放、钓鱼等攻击方式。 TCP/IP 报文长度和格式IP 头部信息：头部长度：通常 20 字节，有选项时更长，总共不超过 60 字节。IP 数据报长度：65535 字节。 TCP 协议，在传输层。特点：可靠性。通过连接管理（三握四挥），序列号，确认号，拥塞控制，重传控制来保证可靠性。头部长度：一般为 20 字节，选项最多 40 字节，限制 60 字节。 TCP 最大报文长度 (MSS)https://blog.csdn.net/codejoker/article/details/5437141 TCP 提供的是一种面向连接的，可靠的字节流服务，TCP 提供可靠性的一种重要的方式就是 MSS。通过MSS，应用数据被分割成 TCP 认为最适合发送的数 据块，由 TCP 传递给 IP 的信息单位称为报文段或段(segment)。代表一个 TCP socket 的结构体 struct tcp_sock 中有多个成员用于确定应用数据被分割成最大为多大的数据块较为合适(最大报文段长度 MSS)。我们不难联想到，跟最大报文段长度最为相关的一个参数是网络设备接口的 MTU，以太网的 MTU 是 1500，基本 IP 首部长度为 20，TCP 首部是20，所 以 MSS 的值可达 1460(MSS 不包括协议首部，只包含应用数据)。 本地以太网中 MSS 为 1460 的说法并不正确，它还会动态变化，如果 IP 首部和 TCP 首部中出现选项，则 MSS 要相应的减小，一般 TCP 首部中会 有 12 字节的时间戳选项(外加两字节的填充选项)，这时的 MSS 就等于 1448。MSS 的主要作用是限制另一端主机发送的数据的长度，同时，主机本身也控制自己发送数据报的长度，这将使以较小 MTU 连接到一个网络上的主机避免分段。 如果使用 TCP 希望传输一个复杂的对象应该怎么传输？TCP 中的流是指流入进程或者从进程中流出的字节序列。所以向 Java/golang 等高级语言在进行 TCP通信是都需要将相应的实体序列化才能进行传输。 TCP/IP 中如何解决粘包问题？如果一直传输数据怎么拆包?应用层协议，不管是标准的还是自己定义的。“粘包”问题是伪问题。 http://www.hchstudio.cn/article/2018/d5b3/ https://img.hchstudio.cn/TCP.gif TCP 连接和断开的状态图connect: disconnect: 为什么 TCP 连接断开的时候要进行四次握手： TCP 四次挥手的 TIME_WAIT时间段长为 2MSL（报文段最大生存时间） TIME_WAIT 存在的理由之一是尽可能护送最后的 ACK 达到对端，保证可靠地终止 TCP 链接。 假设 tcp 连接是： A(1.2.3.4:8888)——B(6.7.8.9:9999), 这就是一个 tcp 四元组。当 tcp 连接关闭后， 四元组释放。TIME_WAIT 存在的理由之二是新旧四元组互不干扰。 RPCRPC（Remote Procedure Call）—远程过程调用 ，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。RPC 协议假定某些传输协议的存在，如 TCP 或 UDP，为通信程序之间携带信息数据。在 OSI 网络通信模型中，RPC 跨越了传输层和应用层。RPC 使得开发分布式程序就像开发本地程序一样简单。","tags":[]},{"title":"程序员如何提高英文写作","date":"2019-11-07T08:45:53.000Z","path":"2019/11/07/improve-english-writing-as-progammer.html","text":"最近几个月坚持了一段时间英文写作，兴趣和自信心都大为增强。为什么突然想锻炼自己的英文写作能力呢，是因为工作中要写个什么英文的白皮书，然后发现懂技术的不太会写，会写英文的不太懂技术。最后找了团队中的一个留学生帮忙，大家跌跌撞撞把工作完成了。仔细想想这就是稀缺能力啊，按照刻意练习的套路，我应该好好提高一下自己的英文写作能力。 然后，我就开始在一些社区，比如 dev.to 写技术文章，在 Quora 上回答问题等，这些坚持了两个月左右，自我感觉收获不少。至少，现在让我写一篇英文类的长文，我是好无压力并且有些享受的(可能还处于自我感觉良好的时期的缘故)。 下面总结一下关于英文写作的一些自我心得。 抛去恐惧心理这是很多人要克服的第一关，想着中文都写不溜，英文如何写？写作这个东西就是需要不断练习的，即使文笔不行，首先要做到的是写出来，并且简明扼要。文章最重要的目的是表达自己，并且让人易懂，更高的要求才是让人产生读的乐趣。对于绝大部分科技类的写作来说，准确是第一要素。 如何抛去恐惧心理？唯一的办法就是多读、多写，并且让大家看，收集反馈然后不断改进。 在哪里写像我刚才说的，有很多不错的技术社区，比如 Github、StackOverflow、Quora, 这些都是英文表达的场所，也是一个很好的锻炼自己英文写作的平台。从小处开始，可以写一个英文的 README，代码中使用良好的英文注释？在 Quora 上回答问题是更好的方式，因为这是一个互动的平台，你的回答会被多个人看到，这样可能会有一些反馈。 比如这个找 Quora 里的回答，题主问的是学习编程是否需要很多数据技巧？这对于我们这样的多年程序员来说，自然是有一些心得的，然后我就写了一些自己的想法作为回答。后面有一位朋友写了另外一个回答： “题主，数学技能是次要的，你应该好好学学英文写作，这样至少不会让你像上面这位回答者这一样犯一些低级的错误。” 没多久我就看到了这条回答，然后看了看自己真的是犯了一些很明显的语法错误，修正后再回复了一下这位朋友，他表示自己也有点刻薄了，哈哈。其实大家对这种“助人助己”的学习方法是很乐于接受的，只要是给社区提供有用的东西。 在 Quora 上还碰到另外一个瑞典的伙计，也帮我提出了一些建议。然后第二天还帮我一句一句做了一个修改版本，发到了我的邮箱。英语不是母语的人写的文章，如果不是让英语为第一语言的朋友阅读，这些表达方面的问题是不容易看出来的。 一些技巧词汇很多人对于自己的词汇量没有信心，觉得词汇量不够不足以表达自己的想法。这是不对的，其实你看看大部分技术类英文文章，对于接受过大学教育的技术人人员来说，应该是 95% 以上的单词都是认识的。对于不认识的单词来说也可以根据上下文来推测的，所以至少词汇不会构成阅读障碍。对于英文写作来说，基于简明表达自己的要求，我们那点四六级词汇也很够玩的。词汇在于平时积累，我现在也在着重注意积累一些词汇。日常使用过程中，多注意一些应文的惯用词汇。有一个 Chrome 插件叫做“单词小卡片”，可以把日常浏览网页的过程中发现的不太熟悉的单词加入列表，可以日后以便回顾。 阅读 阅读和写作是分不开的，只有多读才会发现更多套路。上面提到的那些社区都有很多不错的英文内容可以读，另外要特别提到一个的是 medium.com，类比为国内的简书。不过个人感觉质量比简书的内容好很多，可能是我阅读了付费内容的缘故。这个付费也挺便宜的，一个月 5 美金。 作为程序员，另外要多阅读就是技术类的书籍。这些年我买了不少英文类的技术书籍，大多是翻过的，而且有少部分是精读完了。其实只要你能坚持阅读完一本 300 页左右的技术书籍，第二本就很简单了。如果是非技术类的英文文章，要数量阅读就需要提高词汇。 撰写其实写作无非是表达自己，中文和英文写作有很多都是相通的。 撰写过程中需要时刻明白，写的东西是给其他人看的。所以排版也很很重要，如果文章比较长，需要让人看得不至于疲累。适当地配一些贴近情景的图片也非常有助于提高可读性。段落要分明，不要某些段落太长。 最后，即使是英语是母语的人也很容一些常见的语法错误。所以我们需要工具来减少这类问题，grammarly.com 就是非常有用的工具，即使是免费版本对于日常使用来说也是足够了的。 建议不断练习，收集反馈，持续改进。唯此而已。 有两本书可以看看。 《七十二堂写作课》 《风格的要素》","tags":[]},{"title":"C 语言的 typecheck","date":"2019-08-06T01:31:18.000Z","path":"2019/08/06/type_check_in_c.html","text":"类型保证强类型的编程语言通常编译器自带一些类型检查，保证代码编译后不会出现类型方面的错误，比如 Rust 之类的甚至做了变量的生命周期检查，以防止内存出错或者未定义行为。常见的变成语言类型如下： typecheck 但是 C 为弱类型语言，弱类型语言，类型检查更不严格，如偏向于容忍隐式类型转换。譬如说 C 语言的 int 可以变成 double。 这样的结果是：容易产生 forbidden behaviours。为了解决类似问题，Linux 内核中的这个宏比较有技巧。 #define typecheck(type,x) \\ (&#123; type __dummy; \\ typeof(x) __dummy2; \\ (void)(&amp;__dummy == &amp;__dummy2); \\ 1; \\ &#125;) 使用的时候可以保证某些变量为特定的类型： int a;typecheck(char, a); 这样就会报出一个编译错误：","tags":[]},{"title":"My org-mode stuff","date":"2019-08-01T19:31:24.000Z","path":"2019/08/01/org_mode_stuff.html","text":"I switched to org-mode from EverNote recently, and the experience imrpoved much for note and journal writing, especially for technical notes. After the whole tool is set appropriately, I am even addicted to writing. During my setting up for org-mode and related tools, I found these code snippets are really handy, so let’s have a share. Insert Pic from paste You need to install pngpaste first, then with this elisp function, we can copy the picture from paste very quickly, the picture will store on current directory’s img sub-directory, it will create it if img directory is not exists. (defun org-insert-image () (interactive) (let* ((path (concat default-directory &quot;img/&quot;)) (image-file (concat path (buffer-name) (format-time-string &quot;_%Y%m%d_%H%M%S.png&quot;)))) (if (not (file-exists-p path)) (mkdir path)) (shell-command (concat &quot;pngpaste &quot; image-file)) (org-insert-link nil (concat &quot;file:&quot; image-file) &quot;&quot;)) ;; (org-display-inline-images) ;; show inline picture ) Using org-ruby for Hexo publishing I using Hexo for blogging, the default format is markdown in Hexo, so I need to convert org format to markdown format very conveniently, and finally org-ruby solve it. I did some dirty hacks on the codebase, please have a look at this PR, this PR solve three issues. Add title and path attributes in org file, and the ruby script will extract it for dumping markdown file. Fix the fill paragraph problem, I don’t need the blanks which will broken the paragraph layout. Copy the images to proper directory for Hexo, support image size attributes. Then I added an elisp function for auto publish it after saving file whenever “#MD_TITLE:” is founded in buffer: (defun org-publish-to-hexo () (interactive) (shell-command (concat &quot;org-ruby &quot; &quot;--translate &quot; &quot;markdown &quot; &quot;-a &quot; (buffer-name))))(defalias &#x27;op &#x27;org-publish-to-hexo)(defun buffer-contains-substring (string) (save-excursion (save-match-data (goto-char (point-min)) (search-forward string nil t))))(defun org-auto-publish-save-hook () (when (and (eq major-mode &#x27;org-mode) (buffer-contains-substring &quot;#+MD_TITLE:&quot;) (buffer-contains-substring &quot;#+MD_PATH:&quot;)) (message &quot;publishing to Hexo markdown&quot;) (org-publish-to-hexo)))(add-hook &#x27;after-save-hook #&#x27;org-auto-publish-save-hook)(defun org-before-save-hook () (when (eq major-mode &#x27;org-mode) (message &quot;saving org-file&quot;) (pangu-spacing-space-current-buffer) ;;(fill-region (point-min) (point-max)) ))(add-hook &#x27;before-save-hook #&#x27;org-before-save-hook) pangu-spacing This package will add spacing between Chinese word and English word, so I hooked it before save org file: (require &#x27;pangu-spacing)(global-pangu-spacing-mode 1);;(setq pangu-spacing-real-insert-separtor t)(defun org-before-save-hook () (when (eq major-mode &#x27;org-mode) (message &quot;saving org-file&quot;) (pangu-spacing-space-current-buffer) ))(add-hook &#x27;before-save-hook #&#x27;org-before-save-hook) org-capture And the best thing is org-capture, with this we can write all kinds of tempaltes, for journal writing, I need to generate file according to date and time: (defun create-code-file () (interactive) (let ((name (concat (format-time-string &quot;%Y_%m_%d_&quot;) (read-string &quot;file-name: &quot;)))) (expand-file-name (format &quot;%s.org&quot; name) &quot;~/Dropbox/org/snippets/&quot;)))(defun gen-date-file () &quot;Create an org file in ~/notes/snippets.&quot; (format-time-string &quot;~/Dropbox/org/journals/%Y_%m_%d.org&quot;))(setq org-capture-templates &#x27;((&quot;t&quot; &quot;Todo&quot; entry (file+datetree &quot;~/Dropbox/org/work.org&quot;) &quot;** TODO %?\\n %i\\n &quot; :empty-lines 1) (&quot;x&quot; &quot;Task&quot; entry (file+datetree &quot;~/Dropbox/org/work.org&quot;) &quot;** TODO %^&#123;priority|[#A]|[#B]|[#C]&#125; %?\\n&quot;) (&quot;e&quot; &quot;Task&quot; entry (file+datetree &quot;~/Dropbox/org/life.org&quot;) &quot;** TODO %^&#123;priority|[#A]|[#B]|[#C]&#125; %?\\n&quot; :empty-lines 1) (&quot;l&quot; &quot;Todo&quot; entry (file+datetree &quot;~/Dropbox/org/learn.org&quot;) &quot;** TODO %?\\nEntered on %U\\n %i\\n\\n &quot; :kill-buffer t :empty-lines 1) (&quot;k&quot; &quot;Todo&quot; entry (file+datetree &quot;~/Dropbox/org/learn.org&quot;) &quot;* TODO %?\\n %i\\n %f\\n %a&quot; :empty-lines 1) (&quot;j&quot; &quot;Journal&quot; entry (file+datetree &quot;~/Dropbox/org/_journal.org&quot; ) &quot;** %?\\nEntered on %U\\n %i\\n&quot; :empty-lines 1) (&quot;J&quot; &quot;Journal&quot; entry (file gen-date-file) &quot;** %?\\nEntered on %U\\n %i\\n&quot; :empty-lines 1) (&quot;c&quot; &quot;Code snippet&quot; entry (file+headline &quot;~/Dropbox/org/_code.org&quot; &quot;Code&quot;) &quot;** %^&#123;desc&#125;\\n#+BEGIN_SRC %^&#123;language|ruby|shell|c|rust|emacs-lisp&#125;\\n%?\\n#+END_SRC&quot; :empty-lines 1) (&quot;C&quot; &quot;Notes&quot; entry (file create-code-file) &quot;** %^&#123;desc&#125;\\n#+BEGIN_SRC %^&#123;language|ruby|shell|c|rust|emacs-lisp&#125;\\n%?\\n#+END_SRC&quot; :empty-lines 1) ))","tags":[]},{"title":"满足感源自细节","date":"2019-07-31T23:40:03.000Z","path":"2019/07/31/details_matter.html","text":"最近自我感觉生活质量提高了不少，并不是突然撞大运发大财了，总结下来居然都是一些小细节，奇怪正是这些小细节每次都会让我会心一笑。 org-mode作为一个近十二年的 Emacs 用户，最近开始使用 org-mode 了。之前一直偶尔看到说什么单独为了org-mode 而花时间熟悉 Emacs 也是值得的，不过我一直没认真看，因为我认为在 Emacs 下不太适合大量编辑中文，快捷键太多在中文输入的过程中会有一些影响。 最近因为杂事比较多，我特别想要一个结合了日程管理和文档管理的软件。之前用过 Bear，这款软件的好处在于其编辑支持得特别好，但是 Bear 没有日程管理。后来又重新用回 EverNote，这东西的文字编辑支持有点弱，日程管理就是个最基本的清单。还有一些代码嵌入方面的问题，拷贝进去支持再拷贝出来居然其中嵌了部分中文符号。 最后我终于花了点时间来看看这个传说中的 org-mode 到底神奇在何处。结果真的符合了好香定律，我怎么不一开始用 Emacs 就着手用这呢，后悔万千！ 其实不管日程管理也好，日志、技术笔记等也好，本质上都是文字。org-mode 的日程和笔记都是存储的最原始的文本格式，而 org-mode 的编辑模式类似 Bear，写起来非常容易上手。和 Markdown 类似属于「易读易写」的轻量级标签格式。 日程管理也有一些记录时间、统计时间，培养习惯的打卡类日程计划。配合 org-agenda 的各种视图，org-capture 的可定制的模板，用起来真是简洁而又迅速。自己再定制一些函数和脚本，实现从剪切板拷贝图片，使用修改过的 org-ruby 自动从 org 转换为 Markdown，反正只要是文本其可塑性就非常强。 这才是对程序员最友好、最强大的文档和日程管理工具，其满足点在于『可定制』。 全屏中小红点当我开始大量使用 org-mode 记录之后，就不可避免地需要在全屏的 Emacs 下输入中文。而这经常会被打乱，总结一下发现其实是因为全屏状态下我经常会不知道目前是否启用了中文输入法。全屏模式下看不到输入法的任何图标，Baidu 的 Mac 输入法这个浮动状态栏不会在 Emacs 全屏的模式下显示，而且那个辐条本身看起来也太占空间了。在没有图标的情况下只有靠 Shift 或者 Ctrl blank 瞎切换了，非常让人厌烦。 这个困扰很久的问题最近也终于解决了， 这个 ShowEdge 工具可以根据不同的输入法，配置不同的颜色，而且在任何全屏状态都根据输入法显示颜色。我的屏幕顶部就配置了这么一个小红点： 从此输入中文的体验大幅提高！虽然这是非常细节的一个地方，但是当你想到折磨自己的问题，其他人也关注到了，并且用了极其符合自己使用习惯的开源软件解决了，顿时觉得世界真美好！ 这里的满足点在于『可控性』。 黑暗中的黄色光这东西犹如黑暗中的萤火虫，让人温暖，哈哈，其实就是小米的一款感应夜灯。我对小米的这种小的智能家电比较感兴趣，比如小爱同学也不错。这款夜灯的好处在于自动感应，进洗手间自己就亮，我每次都是比较晚才去洗漱刷牙，这灯不太亮也不太暗，而且可以根据声音、移动、和自然光亮度自动开关。其实功能很简单，符合软件设计中的哲学：专注唯一功能，但是功能做到极致。 这应该是简单地满足了『确定性』的心理需求，为什么像语音助手这类东西虽然看起来比较炫酷，但用的人并不多，因为语音识别在日常使用过程中还是会存在各种干扰，最终造成使用过程中存在一些不确定性，从而影响了根本的使用体验。 Entered on [2019-07-26 五 23:31]","tags":[]},{"title":"保存 kmacro ","date":"2019-06-23T23:48:42.000Z","path":"2019/06/23/2019-06-23-random-notes.html","text":"宏是很强大的编辑方法，如果要长久保存一些宏可以使用下面的办法： M-x start-kbd-macro 开始记录宏，通常快捷键为”C-x (“, 结束的快捷键为 “C-x )”。 然后使用命令: M-x kmacro-name-last-macro 可以把这条宏给命名，如果要保存这个宏以便日后使用，需要打开 init.el 继续使用命令： M-x insert-kbd-macro 选中命名的宏，这样就在 init.el 里面插入了刚才的宏，这个名字也就可以当作日常命令使用了。 例如我新建一个宏，作用是查找测试文件中的 “#[ignore]”，并删除掉那行： (fset &#x27;rust-ignore (lambda (&amp;optional arg) &quot;Keyboard macro.&quot; (interactive &quot;p&quot;) (kmacro-exec-ring-item (quote ([12 115 101 97 114 99 104 return 35 91 105 103 110 111 114 101 return 1 11 11 14] 0 &quot;%d&quot;)) arg))) 如果要重复执行，则需要运行： C-x z 当然后面可以连续按 z z z …. ， 执行多遍。 参考: https://emacs.stackexchange.com/questions/70/how-to-save-a-keyboard-macro-as-a-lisp-function","tags":[{"name":"Notes","slug":"Notes","permalink":"http://catcoding.me/tags/Notes/"},{"name":"Emacs","slug":"Emacs","permalink":"http://catcoding.me/tags/Emacs/"}]},{"title":"2019，愿你也健康","date":"2019-01-23T23:48:42.000Z","path":"2019/01/23/2019-wishes.html","text":"坚持最近在坚持养成每天尽量花一小时锻炼的习惯，因为我想在 2019 年有个更健康、有活力的身体。 随着年纪的增长，身体的一些反馈还是如实地告诉自己在变老。衰老就是能力不断地退化、消失。之前打球能蹦蹦跳跳的，现在多跑跑就会喘气；之前精力更好、更喜欢到处走动，现在更倾向于静静休息。去年有的时候身体感觉不太好，有段时间特别疲劳，甚至也体验过一段低迷的至暗时刻。大概是因为生活不规律，而且基本没有怎么锻炼，体重也不断上升。因为在 2017 年初打篮球的时候把膝盖伤了，后来也不能激烈打球了。现在比较适合自己的运动方式就是跑步、游泳、散步之类的。 人总是会忘掉这件事当然锻炼养生也不能抵抗衰老，这是个自然过程，锻炼至少能有助于健康。健康是所有幸福的最大基础，比什么都重要，俗话说『宁做健康的乞丐，也比做病恹恹的国王快活得多』。人更无法逃避的是死亡，这是所有生物的最终归宿和命运。只是人总会渐渐忘记自己会死，梁文道说的一个故事： 很多年前，一位德国摄影师跟一个记者合作的拍摄计划，很有意思。那个摄影师去很多的临终病房，拍摄一些快要死去的人，趁他们还在世的时候，拍下他们的遗照。然后他们刚刚离开，合上眼睛的时候，又为他们再拍一张照片，两张照片放在同一版上，前面则是文字记者做的采访。 在这一系列的采访跟摄影当中，其中一个已死的老太太，在她的采访里面说的一句话，他一辈子都不会忘记。她说什么呢？她跟文字记者说，“你看，你看”，就指着病房玻璃外面楼下对面马路的一个超级市场，她指着那个超级市场跟摄影师和记者说：“你看那里头的人们，天天进进出出买东西，买面包、买肉、买卫生纸，你看他们的样子，他们好像从来不觉得自己会死。” 读《最后的告别》这本书很多人都推荐过，我最近刚好也看了一遍。这里面谈了一些人在最终衰老、告别时必须面对的问题和思考，其中也有一些作者所经历的老人故事，还有自己的父亲最后的抗争。其中有一个故事印象深刻，看完后我又查了查还真有这么个人和事。 1980年3月，当附近火山已经开始冒水汽、隆隆作响时，这位83岁的老人却仍然拒绝撤离他在华盛顿奥林匹亚市附近圣海伦山脚的家。他是第一次世界大战时期的飞行员、禁酒时期的私酒制造者，已经在灵湖的这所房子里住了半个多世纪了。5年前，他成了鳏夫。所以，当时，在山脚这处300多亩的地盘上，只住着他和他的16只猫。三年前，他在屋顶铲雪的时候掉下来，摔断了腿。医生说他是个“该死的傻瓜”，在这样的年龄还爬到房顶去做事。 “该死！”他给医生骂回去，“我都 80岁了！我有权做决定，有权做我想做的事。” 由于受到火山喷发的威胁，官方要求附近居民全部撤离，但是杜鲁门哪儿都不去。火山闷烧了两个多月，官方把撤离区域扩大到火山周围16千米。杜鲁门固执地不肯离开。 “如果这个地方要毁灭，那我想跟它同归于尽，”他说，“反正如果失去它，我也会在一周之内结果我自己。”他直率、不和悦的讲话方式吸引了记者。他说起话来滔滔不绝，头戴一顶绿色的约翰·迪尔棒球帽，手拿一大高脚杯波旁威士忌和可乐。当地警察考虑为了他好而逮捕他，但是，由于他的年龄以及他们必须得承受的负面新闻，只好作罢。他们提出但凡有机会就带他离开，但他坚决予以拒绝。他告诉一位朋友：“如果我明天死去，我也已经度过了愉快的一生。我能做的事都做了，想做的事都做了。” 1980年5月18日早上8点40分，火山终于爆发了，其威力相当于一颗原子弹。巨量的岩浆流吞没了整个湖，埋葬了杜鲁门、他的猫和他的家。事后，他成了偶像——一个老头留在自己家里碰运气，在这种可能性似乎已经消失的年代，他按照自己的方式生活。 相对书中的很多老人来说，这位老人的选择充满了勇气，他以决绝的选择来面对衰老和死亡，并没有经受医院的无尽折磨。年轻人看起来这算是是自杀吧，加缪认为自杀是唯一严肃的哲学问题，看来老人对此已经有了答案。能有多少人老了能还以自己喜欢的生活方式活着，并在最终告别的时候心里都是满足：我已经愉快地度过了一生。 孔子说『未知生，焉知死』，反过来如果没有认真思考过死这件事，人又能真的知道怎么活。 最后最近大环境不太好，很多人都在纠结于今年能拿到多少年终，好多事情并不是个人所能决定，自己能最能把握的是自己的身体，珍惜生命、保护好自己，以免年纪轻轻落得一身病，年纪大了用钱换命。 最后推荐一个纪录片：《人世间》。每天都有无数的人在和疾病、死亡抗争，活着对很多人来说其实真不是件容易的事。 日子中很多艰辛和苦难，和生死比起来那就不是事。","tags":[{"name":"Notes","slug":"Notes","permalink":"http://catcoding.me/tags/Notes/"}]},{"title":"Rust 的 dbg! 宏","date":"2019-01-18T00:23:24.000Z","path":"2019/01/18/rust-dbg.html","text":"前几天在群里看到有人讨论 dbg! 宏已经在 Nightly 可以使用了，最近发布的 stable 版本 1.32.0 也可以使用了。 翻看了一下并玩了玩，这个简单的宏确实是调试好帮手，特别是适合我这样的喜欢打印调试的开发者。这个提议从 2017 年 10 月开始，从 https://github.com/rust-lang/rfcs/pull/2173 可以看到，为了增加这个宏很多贡献者经过了无数次的讨论和回复。真是太佩服 Rust Team 的开发者，付出了这么多时间来增加这个看似很小又实用的功能。 使用先看看这个调试宏是怎么使用的，目前使用这个宏需要切换到 Nightly 版本或者最新的稳定版，已经安装了 rustup 的话就很简单了： rustup default nightlyrustup update 然后很简单就是把一个表达式当作参数传入: fn factorial(n: u32) -&gt; u32 &#123; if dbg!(n &lt;= 1) &#123; dbg!(1) &#125; else &#123; dbg!(n * factorial(n - 1)) &#125;&#125;fn main() &#123; dbg!(factorial(5));&#125; 运行结果如下： [src/main.rs:4] n &lt;= 1 = false[src/main.rs:4] n &lt;= 1 = false[src/main.rs:4] n &lt;= 1 = false[src/main.rs:4] n &lt;= 1 = false[src/main.rs:4] n &lt;= 1 = true[src/main.rs:5] 1 = 1[src/main.rs:7] n * factorial(n - 1) = 2[src/main.rs:7] n * factorial(n - 1) = 6[src/main.rs:7] n * factorial(n - 1) = 24[src/main.rs:7] n * factorial(n - 1) = 120[src/main.rs:12] factorial(5) = 120 实现原理当然也就是把表达式和位置打印出来，但是这里有个技巧，在宏里面使用 match，这是为了避免参数被调用多次，因为宏在编译之前会被展开。Rust 的宏比较复杂，也不可避免会有些 hacky，对于喜欢爱折腾的程序员还是有吸引力。再看看这个宏是怎么实现的，代码很少。： macro_rules! dbg &#123; ($val:expr) =&gt; &#123; match $val &#123; tmp =&gt; &#123; eprintln!(&quot;[&#123;&#125;:&#123;&#125;] &#123;&#125; = &#123;:#?&#125;&quot;, file!(), line!(), stringify!($val), &amp;tmp); tmp &#125; &#125; &#125;&#125; 可以看到目前这个实现是只支持一个参数的，如果传入的参数类型没有实现 Copy Trait，可以传入引用。另外如果想同时打印多个参数，可以使用类似这样的做法： dbg!((exp1, exp2))","tags":[{"name":"Rust","slug":"Rust","permalink":"http://catcoding.me/tags/Rust/"}]},{"title":"《见识》阅读笔记","date":"2019-01-10T23:22:40.000Z","path":"2019/01/10/book-review-wujun.html","text":"到年底小组内还有多余的预算，于是大家都在网上选书。看到吴军出了两本新书，出于对作者的信任就直接下单了。上个周末就花了些时间很快地看完了两本。内容稍微有些重合，主要是有的例子会拿来阐述多个道理。所以两本连着看会有些作者凑书的感受。当然两本都还是不错的，读完《态度》对于我这个新手爸爸来说也是收获不少。个人更推荐《见识》这本书。 《见识》更多关注个人成长、看待问题的视角、工作职场中的一些经验。其中几个主题： 人生是一条河每个人都希望自己这条河能够更宽一点、更深一点、更长一点。只有给予才能带来幸福感。 认识到生命是有限的，应该挑重要的事做，向死而生。 人生需要做减法不做选择的幸福，从另外一个角度去解释为什么印度人在硅谷更容易成功。我觉得是有一定道理的，印度人因为名族的阶级观念，在生活工作中少了一些选择，却能一直在某个领域坚持数十年。第一份工作的过程中，接触了不少印度人。其中一位从印度到硅谷，一直都是在一个公司工作了 14 年左右，我问他为什么不跳槽，他倒觉得无所谓，安家乐业地每天过得很稳。少了选择就不容易思前想后，一门子扎进去了。在工作上，很多人都不能坚持一直耕耘于某个特定的领域，坚持下来的就成了。 做人与作诗：这章讲的道理类似于『出世』与『入世』，让我想起《月亮和六便士》里的画家。 要会做减法，为“做重要的事”服务，同时认清什么是重要的事。 西瓜与芝麻想起骚年的时候总是花时间去找些破解软件，舍不得一点钱买些软件或者工具，渐渐地意识到了这就是为了芝麻丢西瓜的事。类似的还有很多，现在则改变了认知，能付费节约时间则付费，能花钱买到更好的则花钱。 生也有涯 知也无涯正因为如此，生活、学习、工作中需要聚焦，别分散精力。人能在某一段时间内做好一件事，并且做得比其他人好，好到自己觉得不能更好为止。也正是因为『知也无涯』，不要为了自己的未知而焦虑，因为这是再正常不过的了，自己学起来就好，别丢掉好奇心。 我们一定比 18 世纪的人过得幸福么？显然，当代人并不幸福，特别是我们这些年轻的一代。物质上倒谈不上匮乏，而是没有自己的时间，然后则是人到中年必不可免的生活压力和焦虑。EB的说唱里有段歌词『所有人都忙着想要更多的东西 所以得到之后就没有精力去珍惜 情歌越来越多 真情却越来越少 巧克力的保质期越来越长 爱情的保质期却越来越短 生活变得越来越丰富多彩 于是越来越多的人变得分不清黑白』。 我们与天才差多远我们绝大部分人成长过程中，迟早会意识到自己不过是芸芸众生中的普通人。硅谷中，我认为有一种气氛特别好，就是对聪明人的崇敬。之前的老板应该已经算是又聪明又勤奋的那种，谈话中总是会说起自己碰见过的聪明人，聪明到如何程度，以及一些小故事。有的生理上的差异是解释不清的，比如有的人就是善于计算，有的人精于细节。不过天才的见识、勇气、或者方法上有的是值得学习的。","tags":[{"name":"Books","slug":"Books","permalink":"http://catcoding.me/tags/Books/"}]},{"title":"使用 Markown 编辑公众号方法","date":"2019-01-06T23:48:39.000Z","path":"2019/01/06/wechat-tools.html","text":"技术人员很多都喜欢使用 Markdown 格式来编辑文档，但是公众号后台默认不支持。 所以关于工具和流程，最近我摸索出来目前最适合自己的一套是： 还是维护之前 Hexo 那套，像代码那样使用 Git 管理，内容会上传到 Github 上。 继续使用 Typora 编辑 Markdown 文件。注意使用图片工具 IPic 来方便地把图片上传到图床上，其实免费的微博图床就足够。然后使用在线的转换工具md.codingpy.com即可很方便地把 Markdown 转成适合公众号的内容，复制粘贴到后台编辑器里。 这样在个人网站和公众号里都会有相同的内容，而且格式之类的都比较统一。 这里再次推荐 Typora: https://typora.io/ 这个工具，会让人特别有写东西的冲动。","tags":[]},{"title":"开始写公众号","date":"2019-01-04T22:57:24.000Z","path":"2019/01/04/try-wechat-blog.html","text":"2018 过得很快，对于自己来说有点颓废、也很辛苦。说是颓废因为花了一些时间在游戏上，还有不少焦虑。最近看书，翻到胡适 1932 年一篇《寄语即将毕业的大学生》中写到，人到社会容易丢掉求知的欲望、抛弃学生时代的理想追求，为了防止堕落文中给出三点建议。读来觉得颇有道理，这三点建议放在现在也合适： 总得时时寻一两个值得研究的问题 总得多发展一点非职业的兴趣 你总得有一点信心 新的一年想着尝试做些改变，逼着自己再做一些其他尝试，不然生活除了工作和日常，真是过得有些索然无趣了。业余写些东西是很好的积累，从 2006 年左右开始一直都有写博文的习惯，从搜狐、Yo2、WordPress， 一直到后来的 Hexo 托管到 Github 上。个人域名 http://cyukang.com 用了多年，其中的文章大概也有 140 来篇。在这么多年写博客的过程中收获不少，认识了一些朋友，也锻炼了自己的文字能力。 平台和工具一直在变化，文字只是一种表达的方式，能写出来还是得靠自己平时所想、所做。之前写的技术类的文章偏多，因此一直觉得公众号这种生态圈有些封闭，不利于检索。不过终究是大众的选择，公众号里好的内容也很多。如果要逼着自己写，有些人看、有些互动自然是更好的。不求有多少关注，但愿自己能坚持多写写而已。 关于写什么，我也还不太清楚。在技术方面可能涉猎较多，精通的不算多。总之算得上技术爱好者，还未丢掉这块兴趣。所以这里多是关于工作、技术的一些学习总结、实践等。把技术相关的东西写得通俗易懂绝非易事，希望在这方面能有更多进步。另外我更想拓展自己在其他方面的知识和积累，所以公众号上会写更多读书笔记和思考。『构成我们学习的最大阻碍是已知的东西，而非未知』，局限于技术角度并非好事。 关于公众号名字『递归说』，这是乱想的，刚好在取名的时候想到了而已。听起来比较好念，而且递归真是计算机里一个很简洁、优美的概念，也是解决问题的一种方法，还可以延伸理解为『自我进化』吧。人这一辈子不也像一个递归么，过一年就像过了一个迭代，而且都是有终点的。 先写起来再继续摸索找方向吧，总得对自己有些信心。 扫描关注：","tags":[{"name":"WeChat","slug":"WeChat","permalink":"http://catcoding.me/tags/WeChat/"}]},{"title":"使用 peco 飞起 zsh","date":"2019-01-04T22:55:22.000Z","path":"2019/01/04/peco-for-zsh.html","text":"pecopeco 是一个能做交互式 filte 的工具，是 percol 的 Go 实现。特别适合在 shell 里做一些过滤操作，当然适合做日志方面的过滤。典型的使用方法是： zsh 配置下面这个配置主要增强了 zsh 的 history 补全，以及pwdf可以用来迅速找一个文件，并拷贝其全路径： function exists &#123; which $1 &amp;&gt; /dev/null &#125;if exists peco; then function peco_select_history() &#123; local tac exists gtac &amp;&amp; tac=&quot;gtac&quot; || &#123; exists tac &amp;&amp; tac=&quot;tac&quot; || &#123; tac=&quot;tail -r&quot; &#125; &#125; BUFFER=$(fc -l -n 1 | eval $tac | peco --query &quot;$LBUFFER&quot; --layout=bottom-up) CURSOR=$#BUFFER # move cursor zle -R -c # refresh &#125; zle -N peco_select_history bindkey &#x27;^R&#x27; peco_select_historyfiOS_NAME=`uname`function pclip() &#123; if [ $OS_NAME = &quot;CYGWIN&quot; ]; then putclip &quot;$@&quot;; elif [ $OS_NAME = &quot;Darwin&quot; ]; then pbcopy &quot;$@&quot;; else if [ -x /usr/bin/xsel ]; then xsel -ib &quot;$@&quot;; else if [ -x /usr/bin/xclip ]; then xclip -selection c &quot;$@&quot;; else echo &quot;Neither xsel or xclip is installed!&quot; fi fi fi&#125;function pwdf() &#123; local current_dir=`pwd` local copied_file=`find $current_dir -type f -print | peco --layout=bottom-up` echo -n $copied_file |pclip;&#125;","tags":[{"name":"Linux","slug":"Linux","permalink":"http://catcoding.me/tags/Linux/"}]},{"title":"编译脚本到二进制","date":"2019-01-01T22:55:22.000Z","path":"2019/01/01/compile-script-to-binary-for-obfuscation.html","text":"缘由因为自己习惯使用 expect 脚本登录各种服务器，有一段时间因为要登录的服务器太多了，所以之前写过一个程序来管理各种 expect 脚本。实现思路是根据配置文件，用一个程序来动态生成脚本，执行完之后再删除。这样临时生成的文件里也是包含密码等信息的。最近突然想是不是可以直接写一个程序，把所有脚本类的程序转换为二进制可执行文件^image。我不想把密码之类的直接写在固定的脚本里面，所以密码也是被编译在可执行的二进制文件里的，这样能达到一些代码混淆的目的。 rshc 的开发这个程序看起来有些好玩，所以先我先搜了一下是否之前有其他人这样做过。于是找到了 shc 这个开源程序，这个最初版本是 96 年用 C 写的，最终执行的时候还是用 execvp 调用解释器执行各种脚本。我使用了一下发现居然不支持 expect 之类的。然后想着自己写个玩玩，顺便再动手用用最近看得又心痒的 Rust，最后用搞出来一个初版: rhsc。 目前我这个程序只是能把脚本程序，转换为 Rust 代码，然后使用 rustc 来编译为二进制，为了做一些代码混淆，其中也类似 shc 使用了 RC4 算法来做了一个简单的转换，加密用的 key 是随机生成的。然后也做了另外一个增加密码的模式，这样可以为任何脚本增加密码校验功能，最终使用 Process 来执行解释器。当然也谈不上多安全，如果要破解可以使用一些类似 ptrace 或者其他方式来试试。以后我会继续完善这方面的防御。另外，为了在生成代码之后尽量减少依赖，所以目前密码输入时还未做到隐藏输入。 安装使用使用方式非常简单，先安装： cargo install rshc 然后使用命令： rshc -f demo.sh -o demo.rs// add a passowrd when compile it, // then binary will prompt for correct password before executionrshc -f demo.sh -o demo.rs -p 其他时隔两年再用 Rust 写一些小项目，发现整个语言还是成熟很多： 工具链很好用，特别是 cargo 之类的，从开发到发布都非常方便 相关的库和文档也多了起来，相对来说更加容易上手写一些东西了 编译器的错误提示特别好，可以通过错误索引号找到示例","tags":[{"name":"Rust","slug":"Rust","permalink":"http://catcoding.me/tags/Rust/"}]},{"title":"SQL Injection attack","date":"2018-03-10T20:51:40.000Z","path":"2018/03/10/sql-injection-attack.html","text":"注入原理SQL注入一直是 Web 应用的一大安全隐患，注入的基本原理是通过修改输入的参数来操作后台执行的 SQL，注入可能会导致数据库被恶意修改、数据被恶意读取等严重行为。所以如果一个参数有漏洞，通过小心的构造注入点即可利用，这里的渗透攻防Web篇-SQL注入攻击初级有一些编写注入点的教程。 最初的时候我在一个用 C 写后台的项目里待过，现在回想起来我们当时根本没注意SQL 注入，C 拼接处 SQL 的字符串很常见。不过现在大多数 Web 框架都已经有 ORM 了，ORM 可以在很大程度上避免注入的产生，因为程序员通常来说不用写纯的 SQL 了， 在最佳实践的前提下 ORM 会生成安全的 SQL。当然什么工具最终还是依赖程序员，比如下面的 Ruby 代码即会有问题: User.where(&quot;email = #&#123;params[:email]&#125;&quot;).first 更多作死的办法可以参考： https://rails-sqli.org/ WAF通常我们会使用一些 WAF 来阻挡 一些SQL 注入，但是 WAF 也有其局限性。WAF 一般是通用的，不会局限于某个特定的框架。我们可以实现在 Nginx 上，或者使用一些商用的 WAF，通常来说对于应用也不用修改其代码。不过 WAF 的问题在于其实基于规则的，而 SQL 本省是比较复杂的，可以看看2003 SQL BNF 的描述有多么的长。所以 WAF 的规则大多数是一大堆较难维护的正则表达式，比如： Nginx Waf示例，注意这个项目用不太成熟，初步看会有比较严重的性能问题。正因为规则是固定的，会导致存在很多误拦截的情况，所以我在 Kong 上实现的 WAF 就还不敢用起来。例如现实情况中出现过包含select的 uri被拦的情况，一脸忧伤。 静态代码扫描静态代码扫描会发现一些 SQL 注入，比如 Brakeman 之类的。不过通常静态代码扫描的问题也是分析得不够精准，会漏报、也会出现误报比较多，扫描的结果需要进行人工审计。当然这些工具也在逐步改进。 RASP 工具RASP 的意思是Runtime Application Self Protection，这个概念近些年才提出，目前已经有一些安全公司做出了对应的产品，比如Sqreen, 百度最近也新开一个开源项目叫做OpenRASP，目前来说只支持 Java，开发者可以自己使用 Javascript 编写自己的插件。RASP 除了自己的规则还会依据请求时候的上下文来进行分析，这篇文章里有一些描述，这样误报的问题会大大减少。","tags":[{"name":"security","slug":"security","permalink":"http://catcoding.me/tags/security/"}]},{"title":"Kong集群Left Cluster Node问题","date":"2018-03-04T11:02:32.000Z","path":"2018/03/04/kong-cluster-left-node.html","text":"问题Kong在实践中会有一些疑惑的地方，这里记录一下。注意这里记录的Kong集群部署的问题是0.10.3版本的，最新Kong版本已经不是通过serf来管理不同节点之间的配置同步问题。 在Kong多节点部署的时候，有时候某个节点停掉后，我们在后台可以看到left的信息，而且这个left信息会保留一段不短的时间。类似于如下： 分析管理后台Konga是通过api获取的节点信息，在kong/kong/api/routes/cluster.lua文件里可以看到如下路由处理逻辑： GET = function(self, dao_factory, helpers) local members, err = singletons.serf:members() if err then return responses.send_HTTP_INTERNAL_SERVER_ERROR(err) end local result = &#123;data = &#123;&#125;&#125; for _, v in pairs(members) do if not self.params.status or (self.params.status and v.status == self.params.status) then table_insert(result.data, &#123; name = v.name, address = v.addr, status = v.status &#125;) end end result.total = #result.data return responses.send_HTTP_OK(result)end, 具体serf:members()的实现在serf.lua里面可以看到，就是执行了serf cluster members命令获取结果然后返回JSON。所以我们在服务器上执行这个命令其实也可以看到类似的结果： 那么问题的根源当然是在Serf本身里面，通过看文档发现原来确实是有一定延迟的。 Serf keeps the state of dead nodes around for a set amount of time, so that when full syncs are requested, the requester also receives information about dead nodes. Because SWIM doesn’t do full syncs, SWIM deletes dead node state immediately upon learning that the node is dead. This change again helps the cluster converge more quickly. 参考serf文档» serf的具体实现接着稍微看了一下Serf的代码，果然Go的项目代码直观好读。在Serf这个结构体里面保存了一个leftMembers的状态列表，每次收到left事件的时候处理逻辑是： // handleNodeLeaveIntent is called when an intent to leave is received.func (s *Serf) handleNodeLeaveIntent(leaveMsg *messageLeave) bool &#123; .................. // State transition depends on current state switch member.Status &#123; case StatusAlive: member.Status = StatusLeaving member.statusLTime = leaveMsg.LTime return true case StatusFailed: member.Status = StatusLeft member.statusLTime = leaveMsg.LTime // Remove from the failed list and add to the left list. We add // to the left list so that when we do a sync, other nodes will // remove it from their failed list. s.failedMembers = removeOldMember(s.failedMembers, member.Name) s.leftMembers = append(s.leftMembers, member) ................ return true default: return false &#125;&#125; 通过索引变量发现这个列表会定时通过handleReap函数更新，逻辑如下： // handleReap periodically reaps the list of failed and left members, as well// as old buffered intents.func (s *Serf) handleReap() &#123; for &#123; select &#123; case &lt;-time.After(s.config.ReapInterval): s.memberLock.Lock() now := time.Now() s.failedMembers = s.reap(s.failedMembers, now, s.config.ReconnectTimeout) s.leftMembers = s.reap(s.leftMembers, now, s.config.TombstoneTimeout) reapIntents(s.recentIntents, now, s.config.RecentIntentTimeout) s.memberLock.Unlock() case &lt;-s.shutdownCh: return &#125; &#125;&#125; 所以看起来这里相关的Timeout是s.config.TombstoneTimeout, 接着需要看看reap到底做了什么，这里果然是把到了一定时间间隔的节点删掉了： // reap is called with a list of old members and a timeout, and removes// members that have exceeded the timeout. The members are removed from// both the old list and the members itself. Locking is left to the caller.func (s *Serf) reap(old []*memberState, now time.Time, timeout time.Duration) []*memberState &#123; n := len(old) for i := 0; i &lt; n; i++ &#123; m := old[i] // Skip if the timeout is not yet reached if now.Sub(m.leaveTime) &lt;= timeout &#123; continue &#125; // Delete from the list old[i], old[n-1] = old[n-1], nil old = old[:n-1] n-- i-- .......... &#125; return old&#125; 那么这个时间间隔是多久呢，在serf/config.go有一个默认配置： TombstoneTimeout: 24 * time.Hour, 其他serf这个软件值得好好分析一下，节点的状态同步和事件处理都是分布式软件的基础，后续继续看看这个gossip protocol based on SWIM的具体实现。另外hashicorp这个公司的开源代码和文档都非常好，值得学习一番。","tags":[{"name":"Tools","slug":"Tools","permalink":"http://catcoding.me/tags/Tools/"},{"name":"Kong","slug":"Kong","permalink":"http://catcoding.me/tags/Kong/"},{"name":"Golang","slug":"Golang","permalink":"http://catcoding.me/tags/Golang/"}]},{"title":"Docker compose初始化失败问题","date":"2018-03-02T23:17:35.000Z","path":"2018/03/02/docker-postgres-password.html","text":"问题今天在Docker Postgresql用户名和密码授权的问题上花了一些时间，问题是： psql: FATAL: password authentication failed for user &quot;postgres&quot; admin的用户名和密码是可以在docker-compose.yml里设置的，通常我们可以配置为： postgresql: image: postgres:latest ports: - &quot;5434:5432&quot; volumes: - ./data/pgsql:/var/lib/postgresql/data - ./initialize/pgsql:/docker-entrypoint-initdb.d environment: POSTGRES_USER: postgres POSTGRES_DB: postgres secrets: - pg_superuser_password 某个用户的密码可以在./initialize/pgsql目录的脚本里设置： #!/bin/bashset -epsql -v ON_ERROR_STOP=1 --username &quot;postgres&quot; &lt;&lt;-EOSQL CREATE USER user WITH PASSWORD &#x27;the-password&#x27;; ALTER USER user CREATEDB;EOSQL 只是今天碰巧想修改一下这个密码，所以就把这个脚本里的密码修改了，然后执行命令： docker-compose up --build -d --force-recreate 而后就一直出现上面的用户授权失败。 原因刚开始一直认为是可能dockerfile配置得不对，结果花费了些时间。后来突然想到了，PG里数据初始化应该只是第一次做了，后续如果发现/var/lib/postgresql/data里已经有数据了就再也不会重新设置密码，这里是配置volume的，如果还未有重要数据把./data/pgsql删除了即可，或者应该是可以通过attach进入容器通过pg命令修改。 总结最近在自己工作的项目都完全Docker化，感觉是配置来折腾用起来飞。最近也在做一个重度依赖Docker的项目，所以Docker的文档需要看完，特别是网络和数据存储那块，否则会花费不少时间折腾。","tags":[{"name":"Tools","slug":"Tools","permalink":"http://catcoding.me/tags/Tools/"},{"name":"Docker","slug":"Docker","permalink":"http://catcoding.me/tags/Docker/"}]},{"title":"使用overcommit生成git hooks","date":"2018-02-26T19:02:14.000Z","path":"2018/02/26/overcommit.html","text":"git hooks很方便地可以在git操作流程的各个阶段加入hooks，比如执行一些脚本来检查代码风格、跑单元测试、做代码静态检查等。git hooks的试用方法是在.git/hooks目录下写各种脚本，但是.git目录的这些脚本是不会checkin到repo里的，所以如果一个代码如果被多个开发人员共享就会显得不太方便同步hooks。 当然也有一些其他方法来解决这个问题，比如配置links或者对于git 2.9以后也可以使用来定制hooks的目录: git config core.hooksPath hooks 对于熟悉Ruby的同学可以使用overcommit这个gem来解决。使用方法就是通过配置.overcommit.yml，比如: PreCommit: RuboCop: enabled: true command: [&#x27;bundle&#x27;, &#x27;exec&#x27;, &#x27;rubocop&#x27;] # The shell command should run AuthorName: enabled: false 然后执行命令: overcommit install 来自动生成各种hooks，通常后面的修改都是修改这个yaml文件即可，不过记得修改后需要overcommit --signed来重新生成hooks。","tags":[]},{"title":"Nginx https too many redirect","date":"2018-02-23T17:38:44.000Z","path":"2018/02/23/nginx-https-too-many-redirect.html","text":"Http请求在经过多层Nginx的时候，通常强制http跳转到https的时候会这样配置: return 302 https://$host$request_uri; ## 需要注意这里是request_uri而不是uri，否则会引起安全问题 但是如果是多层Nginx，前面的Nginx需要把用户原始请求的scheme传递到后端，可以加上头部设置： proxy_set_header X-Forwarded-Proto $scheme; 后面的Nginx再判断一次: if ( $http_x_forwarded_proto != &#x27;https&#x27; ) &#123; return 301 https://$host$request_uri;&#125; 否则强制https经常会出现类似ERR_TOO_MANY_REDIRECTS 将您重定向的次数过多这样的问题。 可是在实践过程中偶尔也碰到过一些ELB会丢掉scheme的问题，比如在这样的请求链路情况下elb =&gt; nginx =&gt; nginx =&gt; application第二层Nginx获取的scheme就有问题了，这也可能会导致too many redirects问题。 可以尝试在第二层Nginx上这样解决： proxy_set_header X-Forwarded-Proto $http_x_forwarded_proto; 当然强制https这样的跳转逻辑尽量放在请求链路的最外层，这样问题会少一些。","tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://catcoding.me/tags/Nginx/"}]},{"title":"Linux 当前 shell 执行命令","date":"2018-02-22T21:46:33.000Z","path":"2018/02/22/linux-source.html","text":"Linux shell 执行脚本的时候一般是会 fork 出一个子 shell，这样在有的时候就不方便了，比如要unset 当前shell 的环境变量等， #!/usr/bin/env zshif [ -z $http_proxy ]; then echo &quot;not using proxy, set it now ... &quot;; export http_proxy=&quot;http://127.0.0.1:1087&quot;; export https_proxy=&quot;https://127.0.0.1:1087&quot;; echo $http_proxy;else echo &quot;using proxy now, unset it now ...&quot;; unset http_proxy; unset https_proxy; echo $http_proxy;fi 这时候需要执行 . ./proxy_toggle.sh 或者 source ./proxy_toggle.sh。 . (a period) is a bash shell built-in command that executes the commands from a file passed as argument, in the current shell. source is a synonym for . From Bash man page: . filename [arguments]source filename [arguments] Read and execute commands from filename in the current shell environment and return the exit status of the last command exe‐ cuted from filename. If filename does not contain a slash, file names in PATH are used to find the directory containing file‐ name. The file searched for in PATH need not be executable. When bash is not in posix mode, the current directory is searched if no file is found in PATH. If the sourcepath option to the shopt builtin command is turned off, the PATH is not searched. If any arguments are supplied, they become the posi‐ tional parameters when filename is executed. Otherwise the positional parameters are unchanged. The return status is the status of the last command exited within the script (0 if no commands are executed), and false if filename is not found or cannot be read.","tags":[]},{"title":"Ruby的 open 函数导致命令执行","date":"2018-02-12T20:39:46.000Z","path":"2018/02/12/ruby-open-vul.html","text":"说明首先看看 open 函数的文档说明， https://apidock.com/ruby/v1_9_3_392/Kernel/open/class： If path starts with a pipe character, a subprocess is created, connected to the caller by a pair of pipes. The returned IO object may be used to write to the standard input and read from the standard output of this subprocess. If the command following the “|” is a single minus sign, Ruby forks, and this subprocess is connected to the parent. In the subprocess, the open call returns nil. If the command is not “-”, the subprocess runs the command. If a block is associated with an open(“|-”) call, that block will be run twice—once in the parent and once in the child. The block parameter will be an IO object in the parent and nil in the child. The parent’s IO object will be connected to the child’s stdin and stdout. The subprocess will be terminated at the end of the block. 其中说明了如果以|开头则会 fork 出一个进程，| 后面的内容则会当成一条命令执行，比如： cmd = open(&quot;|date&quot;)print cmd.getscmd.close=&gt; 2018年 2月12日 星期一 21时37分45秒 CST 漏洞正因为这样，这个 open 函数真的是很容易出错，最近的这个 PR： https://github.com/ruby/ruby/pull/1777 之前我们的项目里也出现过类似的情况，直接相当于一个 webshell，任意执行命令。这样的 command injection 当然也很好检测，brakeman 之类的就可以。所以 Rails项目还是时不时地扫描一下比较好。 Ruby 里面有几个 Open，这里有比较明晰的解释，Kernel.open 这个函数就是一个 wrapper，根据不同的情况做对应的处理。趟多了坑之后，才会觉得这样的特性其实是增加了程序员的负担，比如这个|特性可能有的人就没注意到，即使是看过文档也可能看到了老版本的文档，从而不知道这个边边角角。 当然同样的 system这样的命令执行函数也是类似的情况，比如railsgoat 里的这个 command injection。原则是对于任何用户输入的参数，都需要做不安全的假设，做好检查。 https://github.com/OWASP/railsgoat这个项目里有各种 Rails漏洞，值得看看。","tags":[]},{"title":"BuckleScript and Reason","date":"2017-09-17T22:47:27.000Z","path":"2017/09/17/bucklescript-and-reason.html","text":"BuckleScript虽然我不是前端工程师，不过因为喜欢 OCaml，所以偶尔关注 BuckleScript 有一段时间了，今天又花时间看了看文档和代码。BuckleScript 是张宏波主导开发的开源项目，『有希望成为第一个完全由国人设计主导实现并被世界各地广泛使用的编译器』，不过是否能广泛被使用还得看后续推广。 简单来说BuckleScript 是一个代码转换器，把你写的 OCaml 代码生成为纯 JS 代码。这样做的好处和必要性在于： JS 太牛了，这个跨平台语言正在吞噬着所有软件领域 JS太难维护了，大规模的 JS 代码更是噩梦。不管是从开发者角度和是从代码安全的角度，JS 需要类型！微软的 Typescript 和 FB 的 Flow ，甚至是Elm都是为了给 JS 带来类型。 OCaml类型系统稳定可靠，关键是编译器速度快，并且可以编译在多个平台上。 就我个人而言非常喜欢 OCaml，之前也有一些自己的小项目用过 OCaml。BuckleScript从技术角度来说是非常好的，我看了一些生成的代码可读性比很多代码生成器要好。并且除了直接翻译代码，这个编译器也做了很多代码优化的工作，生成 size 更小，performance 更好的 JS 代码。遗憾的是目前还不支持 Core 这个库，我之前用 Core 比较多，ಥ_ಥ。 关于代码生成，想起我们原来做过的 Gorazor，从技术角度来说还是有些挑战的，不过从使用角度我个人持保留态度。代码生成毕竟会引入新的语法，我发现很多前端程序员其实并不怎么熟悉函数式编程那套，OCaml 的语法是否能在前端程序员中推广开来是个问题。BuckleScript的文档有待改进，可以给更多大一点的完整的例子。 关于BuckleScript和js_of_ocaml 的区别，从文档上来看js_of_ocaml 可以把 bytecode 转换为 JS 代码，而BuckleScript是在从编译器里面的rawlambda生成代码，所以理论上来说 js_of_ocaml 对 OCaml 的兼容性更好，而BuckleScript 能生成更可读的 JS 代码，目标在于兼容npm平台。 ReasonMLReasonML的来由是之前我说的 OCaml 独特的语法，在很多人看来并不是很友好，所以FB 的这群人做了一个更符合大众品位的方言。然后可以通过 BuckleScript 再翻译为 JS 代码。好绕啊！不过据说 FB 已经在生成环境使用这些了。ReasonML 的开发者移植了一个之前用js_of_ocaml 写的mario 的例子，看了一遍觉得reason 的语法其实改动并不大，可能对 JS 的程序员来说更友好吧。reason 和 OCaml 的关系类似于 Elixir 和 Erlang 之前的关系，为了讨好一类程序员，又为了利用一个已经非常成熟可靠的现有平台。 在 HN 上有一个比较老的讨论帖，有时间也可以再看看。 Why bucklescript matters for Javascript platform","tags":[{"name":"OCaml","slug":"OCaml","permalink":"http://catcoding.me/tags/OCaml/"},{"name":"Javascript","slug":"Javascript","permalink":"http://catcoding.me/tags/Javascript/"}]},{"title":"《深度工作-如何有效使用每一点脑力》读后","date":"2017-09-14T22:20:14.000Z","path":"2017/09/14/deep-work.html","text":"深度工作这本书主要讲解了一些时间和精力管理方面的东西，人到了一定年龄就会觉得时间不够用，日子过得太快，每天觉得都没干什么就过去了。工作几年后这种感觉时不时袭来。反而是如果某段时间一直有一个阶段性的目标，就会觉得很踏实，进度和效率也可以。那种完全沉浸在思考中的状态真的也并不是累，相反所得到的结果往往是真实的收获和进步。用这本书里的术语可以称之为『深度工作』的阶段吧。 说起来也有道理，如果自认为我们是知识工作者，那么大多数时间处于浮潜的工作状态就得不到什么深刻的结果。作为程序员，我也有时候感觉自己并不是在做什么高深的工作，那么这样长久下去会怎么样呢，随之而来的是不可避免的压力。 这里讲的四个准则，任何一个都值得好好修炼，对于大多数人而言，大脑都已经被互联网和手机训练得愚钝和不可专注了： 工作要深入拥抱无聊远离社交媒体摒弃浮浅 深入工作的价值在当今社会格外突出，因为机器的迅猛发展，特殊的技能所展现的价值越发明显。『连续听一系列中等水平的歌手唱歌并不能累加成一场无与伦比的演出— 换言之，才能并非一种商品，你不可以通过大批购买，然后累积起来达到一定水准，只有成为最优秀的才会得到额外奖励』。我们所面临的时代需要掌握一些更为复杂的工作和技能，而这些技能并不是随便看看就能轻易得到的。深入的东西只有静下心来，持续花大量时间和精力才能逐渐掌握。 想要进入深度工作，会有两个方面需要注意: 时间分配，如何避免被频繁打断，如何尽量延长一大段可以持续的时间 学习和锻炼持续专注的能力 关于时间分配，我之前尝试过番茄工作法，但是感觉并不好。因为仪式感太强和太频繁，在我正在进入工作状态的时候可能就到了节点。对于大多数程序员来说晚上可能是最能安静的写程序和思考的时间，不过随着更多的家庭责任，晚上的时间也短了。所以现在我打算早上尽早起来，这样还有一两个小时加以利用。 关于专注能力这块： 不断地切换注意力会对大脑产生长久的负面影响 这个结论应该大家都有体会，持续专注的能力往往决定人的能力，有的人可以一直脑袋里想着问题，即使是在走路或者吃饭的时候。之前在学校我也有过一段时间，脑袋里一直在想着要找的答案，那种体验已经好久没有了。 总之，这本书还不错，推荐有时间的话看看。","tags":[{"name":"Books","slug":"Books","permalink":"http://catcoding.me/tags/Books/"}]},{"title":"Kong的0.11.0版本","date":"2017-09-12T14:43:00.000Z","path":"2017/09/12/kong-new-release.html","text":"Kong发布了新的版本0.11.0，从这里开始区分了社区版本和商业版。这次改动比较大的是丢弃了serf，这样整个Kong节点之间的缓存同步方式变化了。开发者给出的理由如下： 依赖serf，serf并不属于Nginx/OpenResty 这种依赖相互间通信来同步的机制对于deployment和容器化都有些不便 在运行的Kong节点触发serf需要一些租塞的I/O 新的实现的思路是以数据库作为中心，增加一个cluster events的表。任何Kong node都可以向数据库发送变更消息，其他节点polling数据库改动，然后来更新缓存内容。这个改动非常大，不过最终Kong终于实现了节点无状态，之前那个数据库里的nodes可以丢弃掉了，任何时候节点重启只要连上数据库即可工作。我们需要担心的是这么多节点去polling数据库(当然这些动作都是在后台)，是否是一个比较耗时的工作。 Kong增加了新的配置选项db_update_frequency，默认为5s，表示多长时间polling一次，这需要用户自己权衡效率和及时性了。对于我们的业务来说及时性还是很重要的，比如我们新品发布时间精确到秒，那么我们就需要尽量调低这个参数。 所有的改动在https://github.com/Mashape/kong/pull/2561/files， 我大概看了一下代码，一些值得注意的地方如下： cluster相关的API和cmd都被移掉了，启动部分和serf信号处理部分都删掉了不少代码。 polling需要避免一个问题，比如上一次polling还未执行完成，下一次polling就不应该启动，所以这里需要锁来处理。kong/cluster_events.lua实现了polling的主要过程。 kong/cluster_events/strategies/postgres.lua目前polling还不支持分页，cluster_events是一个新建的表用来存储缓存更新事件，Kong节点就是来查询这些事件。 缓存部分换成了lua-resty-mlcache，原来还是和之前分析的类似 L1级别缓存为一个LURcache，在LuaVM里可见， L2级别的缓存为lua_shared_dict，同一个Nginx下的所有worker可见， L3就是缓存未命中的情况，需要调用其他hookup的函数去获取数据然后缓存在L2。只是这里个ipc并不是用的lua-resty-mlcache里的，而是使用的resty.worker.events。 事件处理部分分两部分，worker之间的事件和node之间的处理，分别由worker_events和cluster_event.lua来处理。","tags":[{"name":"Kong","slug":"Kong","permalink":"http://catcoding.me/tags/Kong/"},{"name":"Lua","slug":"Lua","permalink":"http://catcoding.me/tags/Lua/"}]},{"title":"Lua时间处理","date":"2017-09-12T09:51:00.000Z","path":"2017/09/12/lua-time-related.html","text":"我需要用Lua处理一个与时间相关的问题，比如我们在配置文件里面配置一个日期(北京时间)，然后在Openresty里面判断当前时间是否在这个日期之前或者之后来做对应的逻辑。 Lua的时间处理还有点麻烦，主要是自带的相关库函数比较少。 os.time() &lt;== 返回当前系统的日历时间， 1505181586os.date() &lt;== 返回本地化的时间字符串，Tue Sep 12 09:59:56 2017os.clock() &lt;== 返回执行该程序CPU花去的时钟秒数，这里是1156.726 我首先需要一个日期字符串转换为时间戳的函数，找来找去有了这么一个函数，使用正则表达式然后组成表： function convert_time(time_str) -- Assuming a date pattern like: yyyy-mm-dd hh:mm:ss -- Assuming timezone is Beijing local pattern = &quot;(%d+)-(%d+)-(%d+) (%d+):(%d+):(%d+)&quot; local year, month, day, hour, minute, seconds = time_str:match(pattern) if not (year and month and day and hour and minute and seconds) then return nil end local converted_timestamp = os.time(&#123;tz = &quot;CST&quot;, year = year, month = month, day = day, hour = hour, min = minute, sec = seconds&#125;) return converted_timestamp end 然后我们可以使用os.time()获取当前时间戳来对比。但是必须注意时区问题，Lua里面要获取当前时区和UTC里面的offset可以使用一个比较笨拙的办法： function get_timezone_offset_with_utc() local now = os.time() return os.difftime(now, os.time(os.date(&quot;!*t&quot;, now)))end 使用这个函数获取时区的offset之后，对convert_time返回的结果做一下偏移即可和os.time()做对比。有个问题是上面的函数居然调用了三次系统调用，开销是比较大的。 在 OpenResty 的世界里，不推荐使用这里的标准时间函数，因为这些函数通常会引发不止一个昂贵的系统调用，同时无法为 LuaJIT JIT 编译，对性能造成较大影响。推荐使用 ngx_lua 模块提供的带缓存的时间接口，如 ngx.today, ngx.time, ngx.utctime, ngx.localtime, ngx.now, ngx.http_time，以及 ngx.cookie_time 等。 Penlight库也有很多日期相关的函数封装，不过大多也都使用了os相关函数。为了避免多次调用get_timezone_offset_with_utc\u001b我使用了Kong里面自带的cache相关函数做一下缓存： -- 缓存上面的时区差，减少系统调用local offset_with_cst, err = cache.get_or_set(&quot;timezone_offset&quot;, nil, get_timezone_offset_with_utc, nil)","tags":[{"name":"Lua","slug":"Lua","permalink":"http://catcoding.me/tags/Lua/"}]},{"title":"使用 exercism 来练手学语言","date":"2017-08-22T12:12:02.000Z","path":"2017/08/22/pl-practice-with-exercism.html","text":"有时候我们想学一门编程语言，但是光看看书和代码用例总是找不到感觉，这时候我们应该尝试写点不短不长的程序片段，可能是一个函数，或者是实现一个简单的算法。最近我发现这个叫做exercism.io的网站不错，自己也在闲余时间在上面看看。 这里支持30多种编程语言，每种语言大概有80个左右的小问题，每个题目已经写好了对应的测试用例。这些题目不是专门的算法题目，但会涉及到编程语言相关的基本方面，单元测试、字符串，数字处理，代码风格等。我们可以随机的找一些来练练手，提交自己的代码后也可以看看别人的代码。然后再对自己的代码进行一些改进。其他人也可能会对我提交的代码 review 并提交改进评论。多写和多看确实就是学习编程的最好途径。 http://exercism.io/当然是开源的，大家都可以提供题目和测试。具体使用起来可以参考文档，其中有已经实现好的 cli 工具，每做一个 fetch 一下即可看到下一题。如果你对数学或者算法方面的问题更感兴趣，也可以试试https://projecteuler.net/，这个则不限语言，只需要最终结果即可。","tags":[{"name":"PL","slug":"PL","permalink":"http://catcoding.me/tags/PL/"}]},{"title":"从 Jekyll换成Hexo","date":"2017-08-12T08:38:00.000Z","path":"2017/08/12/migrate-to-hexo.html","text":"昨天看到自己的 Blog 在移动端显示丑死了，所以想着优化一下，找一个 mobile first 的风格试试。顺便把 blog 从 jekyll 换成了 Hexo。最后找到这个 hexo 的主题非常顺眼，便拿来用了，感谢yanm1ng为大家提供如此优秀的主题。回想起自己之前用过搜狐博客，然后是 yo2，然后是 wordpress 自己搭，后来又出现了 jekyll，最终才找到最适合的写日志的方式。这次我把之前残留的 html 完全转换为了 markdown，并保留了创建日期，没想到这么多年来断断续续已经写了100来篇文章了。 hexohexo 其实和 jekyll 非常类似，只是迁徙过程中还是需要做一些处理。hexo 的文章排序选择了 date 倒序排，但是依赖于_post 里的文件创建时间，为了解决这个问题，然而 git 是不管理文件的时间戳的。结果会出现一些诡异的问题，文章的顺序会变乱。后来才发现 hexo 为了解决这个问题引入了一个叫做 db.json 的文件，存的内容大概是文件的时间戳之类的。为了保持之前的文章链接有效，写了一些小脚本处理文章。 gitment关于评论还发现一个很好的解决方案，那就是使用gitment，这个方案是专门针对 github 上 host 的博客系统的，唯一不爽的地方在于需要自己为新增文章初始化创建一个 issue，每一条评论会增加对应文章 issue 的comments。当然结果也导致了只有 github 帐号才能评论。不过我觉得这还是挺不错，毕竟 github 作为程序员的社交系统已经如此流行。 typora另外经大家推荐尝试使用 markdown 编辑软件Typora。之前因为自己使用的 markdown 格式稍微有点差别， 而且也习惯了用 Emacs，所以并没用深度使用 Typora。这次好好尝试了一下，发现其可见即可得还是非常方便的。另外就是插入图片的时候可以直接拖入，并且配置一下图片的根目录，自动拷贝到图片目录(或者上传到图床)。这个功能真的很暖心，typora 的作者肯定也是用 git来管理自己的日志。","tags":[{"name":"Blog","slug":"Blog","permalink":"http://catcoding.me/tags/Blog/"}]},{"title":"Kong源码分析: 事件","date":"2017-07-23T08:38:00.000Z","path":"2017/07/23/kong-intro-5.html","text":"Kong的缓存更新很多依赖于事件，而事件看起来是相对来说比较复杂、也是最有趣的一部分。 worker模型假设我们对Kong做了一个更改的请求，这个请求通常是通过admin_api这个路由处理的。也就是说最终执行数据库操作的动作是在一个Nginx worker进程里。因为操作了数据库所以我们需要刷新这个Kong节点的所有worker的缓存，而且要把事件分发给其他Kong节点，让其他Kong节点刷新所有worker的缓存。 这就涉及到两部分: Kong节点之间的消息通信, 这是使用serf来实现的 Kong每个节点内部，也就是Nginx worker之间的通信，这是使用lua-resty-worker-events来进行。 发布订阅模式发布订阅是实现事件的一种经典设计模式，主要需要有两类操作： 发布消息 订阅消息，收到消息后触发指定的函数。 Kong使用的是一个叫作mediator_lua，mediator中文意思为”中间人”，很符合项目的意思。可以看到kong/core/events.lua里面实现如下： function Events:subscribe(event_name, fn) if fn then self._mediator:subscribe(&#123;event_name&#125;, function(message_t) fn(message_t) return nil, true -- Required to tell mediator to continue processing other events end) endendfunction Events:publish(event_name, message_t) if event_name then self._mediator:publish(&#123;string.upper(event_name)&#125;, message_t) endend Kong.init初始化的时候会调用一个叫做attach_hooks的函数: attach_hooks(events, require &quot;kong.core.hooks&quot;) 在load插件的时候也会把插件对应hooks绑定上： -- Attaching hookslocal ok, hooks = utils.load_module_if_exists(&quot;kong.plugins.&quot; .. plugin .. &quot;.hooks&quot;)if ok then attach_hooks(events, hooks)end 事件的来源上面说过，Kong节点之间通信是通过serf发送的。我们来看看事件是如何触发发出通知的。事件来于源数据库的修改，那就应该在数据库代码部分有触发事件的代码，查看dao/dao.lua这个文件里的代码，我们可以看到在insert、update、insert执行的时候都调用了一行代码 event(self, event_types.ENTITY_DELETED, k, v.schema, entity) 这个函数的实现如下，这里做了数据的序列化，然后发布了一种叫做CLUSTER_PROGATE类型的消息： local function event(self, type, table, schema, data_t) if self.events_handler then ..... 执行数据序列化 self.events_handler:publish(self.events_handler.TYPES.CLUSTER_PROPAGATE, payload) endend 在core/hooks.lua接受消息部分，events.TYPES.CLUSTER_PROPAGATE对应的处理部分是singletons.serf:event(message_t)，所以我们看serf.lua这个源文件，最终event调用了invoke_signal，这个函数会运行一个serf命令，类似于这样： serf event -coalesce=false -rpc-addr=127.0.0.1:7373 kong &#x27;&#123;&quot;type&quot;:&quot;ENTITY_UPDATED&quot;,&quot;primary_key&quot;:[&quot;id&quot;],&quot;collection&quot;:&quot;apis&quot;,&quot;entity&quot;:&#123;&quot;id&quot;:&quot;94acca76-d61a-429e-86a9-5abf2c61ee31&quot;&#125;&#125;&#x27; 这就出发了一个serf event，其他Kong节点会收到此消息。 serf: Kong节点之间通信那么Kong节点收到消息之后是如何处理的呢？Kong在启动的时候会在后台执行一个serf进程，类似这样： serf agent -profile wan -bind 0.0.0.0:7946 -log-level err -rpc-addr 127.0.0.1:7373 -event-handler member-join,member-leave,member-failed,member-update,member-reap,user:kong=/usr/local/kong/serf/serf_event.sh -node Kang.local_0.0.0.0:7946_be3b9352808e4839a272f30ca6025650 可以看看serf_event.sh这个脚本，内容如下： PAYLOAD=`cat` # Read from stdinif [ &quot;$SERF_EVENT&quot; != &quot;user&quot; ]; then PAYLOAD=&quot;&#123;\\&quot;type\\&quot;:\\&quot;$&#123;SERF_EVENT&#125;\\&quot;,\\&quot;entity\\&quot;: \\&quot;$&#123;PAYLOAD&#125;\\&quot;&#125;&quot;fiCMD=&quot;\\local http = require &#x27;resty.http&#x27; \\local client = http.new() \\client:set_timeout(5000) \\client:connect(&#x27;127.0.0.1&#x27;, 8001) \\client:request &#123; \\ method = &#x27;POST&#x27;, \\ path = &#x27;/cluster/events/&#x27;, \\ body = [=[$&#123;PAYLOAD&#125;]=], \\ headers = &#123; \\ [&#x27;content-type&#x27;] = &#x27;application/json&#x27; \\ &#125; \\&#125;&quot;/usr/local/openresty/bin/resty -e &quot;$CMD&quot; 可以看到serf收到消息后会触发这个脚本，然后把消息发送到本节点的/cluster/events这个路由。api/routes/cluster.lua这个文件里有收到消息后的处理代码，其中最关键的是： -- Trigger event in the nodeev.post(constants.CACHE.CLUSTER, message_t.type, message_t) 就是通过resty.worker.events publish出收到的消息，本节点的worker会处理这些消息。 worker刷新缓存假设当前Kong节点收到一个消息，这个消息是如何分发给各个worker的？从代码看出，在Kong初始化的时候有调用一个叫做kong.lua里面的Kong.init_worker()函数，其中有一段代码注册了event handler:local worker_events = require &quot;resty.worker.events&quot;local handler = function(data, event, source, pid) if data and data.collection == &quot;apis&quot; then assert(core.build_router()) elseif source and source == constants.CACHE.CLUSTER then singletons.events:publish(event, data) endendworker_events.register(handler) 可以从上面的handler代码看到，一个worker接收到消息之后执行的是： singletons.events:publish(event, data) 也就是通过mediator_lua再把消息publish。之前初始化的时候已经attach_hooks了各种handler，这时候那些注册的函数才会被最终执行，比如核心的刷新缓存部分代码在core/hooks.lua的invalidate函数里面。 回顾总的来说Kong事件部分的代码相当精妙，也很统一。比如当前worker做了修改，这个事件会发送给各个节点，包括当前自己所在的节点。通过发布订阅模式，写代码的时候只需关心消息发送、接受消息索要处理的逻辑。","tags":[{"name":"Lua","slug":"Lua","permalink":"http://catcoding.me/tags/Lua/"}]},{"title":"Kong源码分析: 缓存","date":"2017-07-22T08:38:00.000Z","path":"2017/07/22/kong-intro-4.html","text":"Nginx里的缓存使用在Kong里面我们缓存的内容大部分是配置，不管是API本身的配置还是插件相关的配置，缓存之后就存储在内存中。 Kong里的缓存基础代码在tools/database_cache.lua文件里面。这里又分两种类型的缓存，一种是shared dict, 一种是使用lua-resty-lrucache。这两者之间是有区别的: shared dict如同其名字一样是Nginx worker之间共享的，而lrucache是worker级别的，内存空间在Lua VM里由GC管理，不能在进程之间共享，自然也不会在Nginx worker之间共享。 具体我们开发中使用哪一种由具体场景分析，比如在Kong的插件rate-limiting里就使用了共享缓存，因为我们需要针对一个Nginx所有的worker做请求数统计。 share dict最常规的使用方法是: http &#123; lua_shared_dict dogs 10m; server &#123; location /set &#123; content_by_lua_block &#123; local dogs = ngx.shared.dogs dogs:set(&quot;Jim&quot;, 8) ngx.say(&quot;STORED&quot;) &#125; &#125; location /get &#123; content_by_lua_block &#123; local dogs = ngx.shared.dogs ngx.say(dogs:get(&quot;Jim&quot;)) &#125; &#125; &#125;&#125; lrucache的使用方法如文档所示。 Kong里的多级缓存实现有了上面的了解，看database_cache.lua这个文件就比较直观了，这里Kong会分多类缓存: apis, consumers, plugins等。具体这样分是因为如果我们对配置做了修改，需要发出serf消息来指名这次改动涉及到哪些，其他Kong节点收到消息后自然只更新对应的缓存部分。所以Kong里申明了一个列表CACHE_KEYS来存要缓存的数据类别，同时写了不少生成缓存key的方法，比如: api_key，plugin_key等。 仔细查看database_cache.lua，我们发现其实这里是做了两级缓存。Kong要从缓存里取出一个key/value，首先从lrucache里取，如果有则返回。如果没有则从share dict里去取，如果取到则deserialize然后存储在lrucache里，然后返回。如果shared dict里也没有，则返回nil。标准的两级缓存流程，这样做的好处在于减少deserialize的次数，而且shared dict可能被多个worker同时修改，要修改的时候需要加互斥锁。 这里最常用的方法是get_or_set，尝试获取一个key的值，如果没有就执行对应的callback，返回结果当做value设置到缓存里，并把value作为最后的返回结果。这里的callback函数通常做的当然是从数据库里读取内容。 如何避免缓存失效风暴我们在实现缓存的时候缓存失效风暴问题需要谨慎考虑。agentzh在这里详细描述了加锁解决的策略，ngx.shcache这里也使用了相同的方法，具体可以好好研究一下那个图。 主要注意的是在加锁后，再尝试去读取一次key，因为可能在加锁之前其他worker刚好把数据更新到了缓存里。","tags":[{"name":"Lua","slug":"Lua","permalink":"http://catcoding.me/tags/Lua/"}]},{"title":"Kong源码分析: 插件","date":"2017-07-16T11:43:00.000Z","path":"2017/07/16/kong-intro-3.html","text":"插件的强大之处在我自己使用 Kong 的过程中，最方便的还是在于 Kong 的强大的插件机制。 Nginx 本身提供了提供模块开发机制，但是相对来说更底层一些，并且需要使用 C/C++ 来开发，对于很多开发人员来说 Nginx 仍为一个黑盒。OpenResty 集成了很多好用插件，并提供了通过 Lua 扩展 Nginx 的机制，所以 OpenResty 相对来说更灵活。而 Kong 在 OpenResty 基础上提供的插件机制更灵活，在于： ​ 复用：OpenResty 的复用在于函数级别，我们可以把一些通用的 Lua 函数引入各个项目。而 Kong 的插件复用可以通过 API 修改一下配置即可。是否启用某个插件，这只是数据配置问题，启用与否不会涉及到代码的改动。 抽象、统一: Kong 实现了基础的插件配置的存储和更新机制，所以我们只需按照要求定义插件配置的数据类型，插件实现的时候不用再去关心这些细节。 灵活、组合: OpenResty 的一些处理部分有限制，比如 access_by_lua 在同一个 location 能调用一次， 当然我们可以把多个处理逻辑都放在这里，这又涉及到代码改动。 而 Kong 可以依次调用各个插件对应的 phase，并且通过引入优先级来解决前后顺序问题。 插件开发的原则是提供机制，而非实现，在做插件开发的时候一定需要考虑这个插件能否满足一类相似的需求，这样我们只需要做一下参数的配置就能把插件启动在另外一个站点上。 对于插件这块我的疑问在于这套机制如何运行的？如何找到站点对应的插件？如此多的插件是否会有性能问题？​ Kong插件的运行机制在上一文 Kong 初始化分析中，我们看到 nginx_kong.lua 模板文件里面有这么一段代码： location / &#123; rewrite_by_lua_block &#123; kong.rewrite() &#125; access_by_lua_block &#123; kong.access() &#125; header_filter_by_lua_block &#123; kong.header_filter() &#125; body_filter_by_lua_block &#123; kong.body_filter() &#125; log_by_lua_block &#123; kong.log() &#125;&#125; 在 kong.lua 文件里面， kong.access 的实现是这样的: function Kong.access() core.access.before() for plugin, plugin_conf in plugins_iterator(singletons.loaded_plugins, true) do plugin.handler:access(plugin_conf) end core.access.after()end 从这里可以看出 Kong 的插件运行机制就是从 loaded_plugins 里面依次执行。 学习 Kong 插件开发的方法是参考现有的一些插件实现，学着写几个就会了。用户自己定义的插件是在 base_plugin 基类上继承而来。Kong 里面使用的了 这套 class 机制，可以看到使用 Lua 实现面向对象还是很简单的。 singletons.loaded_pluginssingletons.loaded_plugins在这里初始化的，在具体实现过程中就是从数据库里面把插件配置读出， local ok, handler = utils.load_module_if_exists(&quot;kong.plugins.&quot; .. plugin .. &quot;.handler&quot;) 在每一个插件在 handler.lua 的最后都是 return XXXXHandler，所以在调用 handler()后我们在内存中导入了插件的对象。另外在初始化后需要按照优先级来排序，以此来保证各个插件之间的执行顺序。 从上面的分析上看出，插件导入后都会在内存中的全局对象中存储，后面的开销在于依次迭代插件。 plugins_iterator我们再来看看某个站点是否启用某个插件是如何处理的，最主要的实现在于 plugins_iterator 这个函数。首先我们得理解如何确定当前 request 对应的唯一标识符， 在core.handler.access的过程中保存了经过路由后的 api在ngx.ctx 里，这个 ngx.ctx 会在整个request 处理过程中反复被使用。再回到 plugins_interator 函数，这个函数的参数有两个，后一个叫access_or_cert_ctx， 因为对于一个 request处理中 plugins_iterator 会调用多次，这个参数的作用在于判断是否是第一个调用这个函数。第一次调用可能发生在ssl_certificate或者access 阶段， 因为在 ctx 里面 Kong 还是初始化了一个叫做ctx.plugins_for_request的变量来存储当前 request 启用的插件，这样后续 iterator 阶段就完全不会去重复 load 插件配置，这样做当然是为了性能上的考虑。 读取插件配置的函数调用是： if api then plugin_configuration = load_plugin_configuration(api.id, consumer_id, plugin.name)end load_plugin_configuration也会首先尝试从内存缓存中取，如果取不到再从数据库中取出，然后存储在缓存中。 从上面的分析看出，插件相关的读取和执行在大部分时间里是完全不会去读数据库的，所以性能损失并不会大。 错误处理Kong的插件部分并没有错误处理部分，从现有代码上看错误处理分两个部分: 一种方式是responses.lua， 如果是在 Kong 的 Lua 代码部分检查出来的错误一般使用类似responses.send(500)这样的方式来向客户端返回错误码。 第二种是通过 kong_error_handler。 这种错误可能是执行了 ngx.exit(500) 之类的代码或者是 Nginx 内部触发的。 这在某些情况下对用户不友好，我们不能只简单地返回一个错误信息，有的时候我们需要展示一个漂亮些的错误页面或者是把请求转到别的降级站点，对于这个需求我做了一个分支来扩展错误处理。 目前实现还未完整，不过已经可以定制化错误页面了。 这里增加了一个 ngx.var.api_id，这个变量的初始化也在 core.access 阶段。因为存储在 ngx.ctx 里的这些信息在执行了 ngx.exit 之后已经释放了，所以我需要一个 ngx.var 级别的变量存储 api_id，然后使用这个变量来判断 error-handler 插件是否启用。","tags":[{"name":"Lua","slug":"Lua","permalink":"http://catcoding.me/tags/Lua/"}]},{"title":"Kong源码分析: 启动","date":"2017-07-07T11:43:00.000Z","path":"2017/07/07/kong-intro-2.html","text":"Kong的初始化过程安装好Kong之后我们是用命令sudo ./bin/kong start -c kong.conf -vv来启动。其中kong.conf为配置文件，-vv选项打印出一些重要信息展示出来，方便发现问题。 可以看到./bin/kong是一个脚本，是用的#!/usr/local/openresty/bin/resty程序来执行，而resty是OpenResty的一个Perl可执行脚本。kong的内容很简单，就是一个入口函数调用：require(&quot;kong.cmd.init&quot;)(arg) 所以我们可以从cmd/init.lua这个文件开始入手看启动过程。一翻开init.lua这个文件，发现其实不过是个wrapper，解析了args之后就是调用start，stop，quit等命令。然后我们顺藤摸瓜找cmd/start.lua文件，整个启动过程就在这里了： local conf = assert(conf_loader(args.conf, &#123; prefix = args.prefix&#125;))local errlocal dao = assert(DAOFactory.new(conf))xpcall(function() assert(prefix_handler.prepare_prefix(conf, args.nginx_conf)) assert(dao:run_migrations()) assert(serf_signals.start(conf, dao)) assert(nginx_signals.start(conf)) log(&quot;Kong started&quot;)end, function(e) err = e -- cannot throw from this functionend) 从代码上来看很直观，首先conf_loader载入配置文件，DAOFactory构建数据库连接层，prefix_handler.prepare_prefix是准备一些由程序生成的配置文件。dao:run_migrations是迁移表结构到数据库，类似其他 Web 框架。serf_signals是启动serf程序，nginx_signals是启动nginx进程。 读取配置文件conf_loaderconf_loader读取的当然是命令行里面传入的kong.conf文件，打开conf_loader.lua看了看，是是用一个lua第三方库来做文件解析的。local pl_config = require &quot;pl.config&quot;，最开始不太知道这个pl是什么，经过搜索后才知道是这里定义的，在kong.rockspec里面有定义了该库的依赖&quot;penlight == 1.4.1&quot;。读取配置的整个过程比较琐碎，最后回构建一个解析好的conf表。这里学到了Lua里面的setmetatable设置元表的方法，table作为Lua里面的最基本数据结构，setmetatable可以方便的绑定一个key和其对应的方法。看起来也像是面向对象的风格，在conf_loader的最后部分是: return setmetatable(&#123; load = load, add_default_path = function(path) DEFAULT_PATHS[#DEFAULT_PATHS+1] = path end, ......&#125;, &#123; __call = function(_, ...) return load(...) end&#125;) 这样其他地方调用的时候local conf, err, errors = conf_loader(args.conf)自然就把args.conf传入load，返回解析后的结果。 prepare_prefix动态生成Nginx和serf的配置prefix_handler.lua这个文件主要在准备一些Nginx的配置文件和serf的配置文件。prepare_prefix函数前半部分在创建各个子目录，logs、serf、pids、以及各个日志文件。关于Kong的config部分需要参考一下这里。这个函数比较长，重要的部分是生成Nginx的配置文件。可以看到compile_kong_conf函数其实是是用kong/templates目录下的nginx_kong.lua和nginx.lua分别生成两个文件，其中nginx_kong.lua里面包含了嵌入Kong的Lua代码的逻辑。 init_by_lua_block &#123; require &#x27;luarocks.loader&#x27; require &#x27;resty.core&#x27; kong = require &#x27;kong&#x27; kong.init()&#125;location / &#123; rewrite_by_lua_block &#123; kong.rewrite() &#125; access_by_lua_block &#123; kong.access() &#125; header_filter_by_lua_block &#123; kong.header_filter() &#125; body_filter_by_lua_block &#123; kong.body_filter() &#125; log_by_lua_block &#123; kong.log() &#125;&#125; 因此我们可以知道Kong每次reload或者启动的时候会生成新的Nginx配置文件，所以我们如果要加入自己的配置可以直接修改nginx_kong.lua文件。另外我在使用的时候发现一个小问题，Kong把serf的node_id存在一个文件里，如果我们把之前跑过Kong的机器做了镜像，然后再启动一个新的实例时，这个node_id文件既然存在则没有重新生成，最终导致两台kong实例并没有相互通信形成一个集群。我认为这里其实可以再检查一下node_id的文件和本机的ip是否一致，如果不一致则重新生成。 dao:run_migrations()初始化过程的下一步则是执行数据库操作，Kong目前只支持cassandra和Postgres，个人认为应该增加Redis的支持。 serf_signals.start之前提到过serf是用来保证kong instance之间的通信的，启动的时候的一个很重要参数是--event-handler，参数的内容是一个可执行脚本(通常叫做serf_event.sh)，文件的内容是前面生成配置文件的时候写入的。默认情况下serf会监听在7946端口，如果多台server需要形成一个集群，这个端口之间需要能相互通信。这里就有一个问题，在一个新的server刚启动的时候，该server是如何发现其他节点的呢？我们可以看到serf_signals.lua里的start函数调用了serf:autojoin()函数，跟踪到autojoin里面看代码，其实是从数据库里读取出其他nodes的信息，然后依次告诉对方新同志加入了，然后把自己的节点信息写入到数据库里。自然如果要退出也需要把自己的信息从数据库里删掉。 nginx_signals.start启动的最后一步即是Nginx的启动，其实最终执行的命令就是: /usr/local/openresty/nginx/sbin/nginx -p /usr/local/kong -c nginx.conf 总结通过上面的分析，可以总结Kong的启动过程即是：解析输入参数，验证参数合法性并生成必要的目录和配置文件，执行数据库操作，启动serf，启动Nginx。最终其实就是一个OpenResty启动过程，嵌入Kong里面的core部分的Lua代码。后面继续分析其可扩展的插件机制。","tags":[{"name":"Lua","slug":"Lua","permalink":"http://catcoding.me/tags/Lua/"}]},{"title":"Kong源码分析","date":"2017-07-02T11:43:00.000Z","path":"2017/07/02/kong-intro.html","text":"缘由最近在工作上接触了Kong这个开源项目，因为我们内部做微服务化重构，所以导致系统相互间通信比较复杂，如果想做一些涉及各个系统的功能就很困难。比如我们前段时间实现的灰度系统就把人折腾得很惨。因为我们的设计中有一些http header 需要在各个系统之间传递。每个项目的 Nginx 里面都用了 Lua 写一些授权逻辑，最终这些逻辑分散在各个项目的 Nginx 层，维护困难。除了灰度，其他的一些比较基础的Nginx层功能也是各自为政。所以我们的教训是: 在做微服务化之前，需要统一的、可扩张的API网关。我们希望网关性能好，并且扩张性足够好。使用OpenResty是很自然的选择，我们希望有一层 Nginx 是所有请求都会经过的，这层 Nginx 会负责做一些基础操作，当然最重要的是做流量转发。 调研了一阵子之后，我们所面临的是两条路，一是自己写一个类似于京东JEN的系统，在调研一圈之后我们发现 Kong 是比较适合自身业务需求的。二是在 Kong 的基础上做一些插件开发，然后集群部署Kong即可。 我之前稍微看了一下介绍，认为 Kong 可能对我们来说太重了些。后来又仔细看了一阵源码，自己认为代码质量挺好，而且模块化和可扩张性做得很好，因此决定采用。 Kong简介Kong 项目的目的是这样一幅图kong-intro： 可以看到这正是我们要做的事情。使用Kong的优势在于： 可扩展性，Kong依赖一个数据库来实现配置存储，依赖 serf 来实现 instance 之间的通信。任何一个节点修改了其他节点会收到通知并重新reload配置。 模块化，Kong 可以方便地增加新的插件，并且插件可以通过 Restful API 进行管理 主要代码模块Kong的使用方法这里不做介绍，这里有非常详细的文档和示例。我主要分析一下其源码和原理。 core目录里面是一些基础框架代码，包括hooks，事件，插件基础 plugins目录包括所有kong自带的插件，kong的插件扩展有一套自己的规范，按照规范来非常容易地就能扩展kong dao是数据库抽象层，目前kong自带支持数据库postgresql和cassandra。 tools为一些工具函数，需要注意的是cache。因为所有配置（包括插件的配置）都会是用cache来缓存，为了减少读取数据库次数。 api Kong会提供一个系列接口来更新配置 我觉得Kong的代码质量很好，另外依照带着问题来学习新东西感觉非常有收获，这几个部分我都是从一个主题问题逐个分析，这几个问题解决了之后自然对代码就熟悉了很多，并且有信心在生产环境使用。后续我会陆续继续写一些Kong相关原理分析，顺便更深入熟悉一下Lua。主要涉及到Kong的初始化部分、缓存如何更新、插件机制如何实现等。","tags":[{"name":"Lua","slug":"Lua","permalink":"http://catcoding.me/tags/Lua/"}]},{"title":"小说推荐","date":"2017-06-27T11:43:00.000Z","path":"2017/06/27/recent-reading-list.html","text":"之前我用过一段时间 Kindle，因为没有使用保护套导致在书包里面被压坏。而后一两年用 IPad 看了一些电子书，始终觉得稍微有些笨重，而且看久了眼睛不舒服。前段时间在 z.cn 上瞎逛又有了买个 Kindle 的欲望，拿到手后又好好找了一些电子书比较多的网站。目前使用最舒服的还是 http://readfree.me。 我已经在上面免费同步了好多本书。 最近用 Kindle 看了不少书，重新燃起了自己看小说的兴趣，当然也不全是小说。印象比较深书的有下面这些： 《历史转折中的邓小平》 小说口吻讲述近代历史人物略显奇怪，不过还是可以看看。其中恢复高考那段印象深刻。值此香港回归20周年时，感谢邓小平的远见和智慧。 《褚时健传》强烈推荐的一部传记。特别敬佩褚时健解决问题的精神和执行力。褚时健一生的坎坷经历令人感叹。没几个人能做到，不管在哪个年龄段，都全心全意的做事解决问题，80多岁的年龄还能种出一大片果林。人生经历当得上『传奇』二字。 《牛鬼蛇神录》 王小凯在牢房里的各种见闻，以前还是禁书来着？看看还是有所收获。 《围城》 之前看过一次，而这次再重新读的时候才有所感触。有时候既然能在方鸿渐身上看到自己的影子，哈哈。总得来说挺幽默，女人吵架套路很固定。婚姻的不幸很多是来自两个家庭的矛盾，大多如此。 《檀香刑》 莫言的小说，最初是在知乎的一个回答上看到的行刑的那段描写，让人窒息，所以一定要找来看完这本。值得一看，看来莫言的其他基本小说也不能放过了。 《白鹿原》 这本书只看了一半，个人觉得一般。可能是因为我之前看了电影，大致的情节都知道了，所以觉得书稍显太慢，好长篇幅。 《约翰·克利斯朵夫》一个大部头小说，我应该是花了好两周的业余时间看完。最初想看这本书据说傅雷翻译得特别好，然而我下单的时候却买的是韩沪麟版本，在我看来也翻译得挺好。这本大部头叙述了一个音乐家一生的故事，前半部分情节更好。特别是描述小孩的友谊和爱情部分很吸引人。不少部分写的是对音乐的理解，只能怪自己音乐素养不够，浅尝辄止罢了。 大部分人在二三十岁上就死去了，因为过了这个年龄，他们只是自己的影子，此后的余生则是在模仿自己中度过，日复一日，更机械，更装腔作势地重复他们在有生之年的所作所为，所思所想，所爱所恨。 所谓英雄，就是干了自己力所能及的事情的人，而常人还做不到这一点。 毛姆系列 据说毛姆文笔优美，我便开始找他的小说看。最开始是看了比较流行的《月亮和六便士》，看完后真是大呼过瘾，震撼。据说月亮是头顶上的理想，六便士是脚下的现实。小说里主人公斯特里克兰德为什么突然放下家庭，完全投入到画画中文中并没有交代清楚，像是命中注定了的，他必须画画，冷酷地完全舍弃其他。一个人完全沉浸在自己的追求中，现实看起来就微不足道了，道德也不会是约束。天才有时候是一种伟大的不幸，比如主人公，而绝大部分人过的是平庸的幸福，比如施特略夫。施特略夫这个觉得有些可爱，而遭遇有些悲惨。 然后看了《在中国的屏风上》，是毛姆游历中国的随笔，记录的比较杂。这本粗略看了看。 而后继续看《刀锋》，感觉和六便士有点点类似，都是讲一个完全追求精神生活的『圣人』，最后在印度看似有所悟。比较喜欢这女主个角色，诚实地知道自己所要并决心取舍，虽然她的小心机使得儿时的女伴完全堕落。 最后粗略看了《毛姆读书心得》，讲了一些读小说的事情，推荐品论了不少小说。 《霍乱时期的爱情》 这部小说被拍成了电影(我还没看)，大家都说写尽了人间的爱情。这本书我非常喜欢，从拿起就不能停了。故事吸引人，并且文笔有些幽默。比如抓鹦鹉的那段，前面花了大篇幅来描述鹦鹉的来历，而后突然鹦鹉就把医生给弄死。还有男主和女主的各种书信，在那样嘈杂热闹的环境下女主一回头突然崩溃。男主作为纯情男孩，突然被夺了童贞，后面又心安理得地穿梭于各个寡妇之间，并倔强、默默地继续爱女主五十年。妙的是，小说里详细的叙述，让我觉得这也并不矛盾，人性以及爱情就是这么复杂，不乏欺骗和隐瞒。婚姻里到处是妥协和不满。 结尾也非常好，让他们在『霍乱的船』上一直飘荡下去。 《树上的男爵》 经同事推荐看的。故事和海上钢琴师类似，讲一个公爵小男孩因为一次偶然的被罚，爬上了树！又因为对一个女孩的承诺，他打算一辈子不下树了。一个很好的故事，结尾也来得有想象力。","tags":[]},{"title":"OpenResty使用总结","date":"2017-05-22T11:43:00.000Z","path":"2017/05/22/try-on-openresty.html","text":"OpenResty最近用OpenResty比较多，除了一些业务逻辑的实现也做了AB组灰度相关的实现。OpenResty是在Nginx基础上做的扩展，应该算是国人开源项目中很成功的一个。在做的过程中写了不少Lua代码，写Lua代码的体验就是库好少，语言好简单。 OpenResty lua编程相关参考 OpenResty最佳实践 OpenResty Readme 其中Readme要看完，大概会有一个全局的了解。最佳实践辅助看看。理解Nginx处理的几个阶段： http://www.nginxguts.com/2011/01/phases/ 处理Response Body在我们的实现中有一步需要给后端返回的结果里面加一段水印(也就是一段JS代码)，这步可以在body_filter这个里面做。不过需要注意body_filter是按流式方式处理的，需要把各个buffer存下来然后拼接起来。而且后端返回的结果可能是zip压缩过的，所以需要解压，然后才能做替换或者拼接的操作。 local chunk, eof = ngx.arg[1], ngx.arg[2] local buffered = ngx.ctx.buffered if not buffered then buffered = &#123;&#125; -- XXX we can use table.new here ngx.ctx.buffered = buffered endif chunk ~= &quot;&quot; then buffered[#buffered + 1] = chunk ngx.arg[1] = nil endif eof then local whole = table.concat(buffered) ngx.ctx.buffered = nil -- try to unzip local status, debody = pcall(com.decode, whole) if status then whole = debody end -- try to add or replace response body local js_code = .... whole = whole .. js_code ngx.arg[1] = whole end 最后因为修改了response body，所以需要修改header filter里面的部分:ngx.header.content_length = nilngx.header.content_encoding = nil 容易出现的bug 尽量使用local变量： 具体的解释，我在实践的过程中出现过变量乱窜的情况，结果发现是没有是用local。 ngx.ctx 比 ngx.var 性能要好很多，但是在执行了ngx.exec后在子请求里ctx不一样，在我们的项目里大部分是用的是ngx.var。使用ngx.var需要注意的是需要在Nginx配置文件里面提前声明。另外ngx.ctx在使用的时候也有需要注意的地方 不同阶段共享变量 不要使用错误码来做内部跳转，使用ngx.exec很方便。 是用推荐的方法来实现module","tags":[]},{"title":"rubytt 续","date":"2017-04-09T11:43:00.000Z","path":"2017/04/09/rubytt-cont.html","text":"前段时间继续做了 rubytt 这个小项目，遇到一些问题。 我想做一个自动检测未定义变量的功能，发现如果只是做静态分析，是很难做出来的。还有涉及到各种 gem 包的分析，这些工作量较大。可以看出在这个PR里我甚至用上了一些硬编码。 然后我想做一个自动分析代码复杂度的功能，比如某些函数太长，或者逻辑太多之类的。这个我实现起来很快，也是比较简单的遍历语法树，递归统计逻辑操作和幅值操作的总数之类的。不过这些在 rubocop 里面都实现了，其中Cyclomatic complexity可用来衡量代码的复杂度。我仔细看了看 rubocop 的内容，这个项目里面做的检查还挺全的，不过很多都是风格类的检查。在我下一个项目一开始我就引入了 rubocop ，对于保证代码质量还是挺有帮助的。对于之前老的项目，如果不是一开始就保持代码风格和静态分析的检查，后面要追加就非常耗时了，往往大家也没有时间来做各种重构。 rubytt 暂时告一段落，作为一个业余项目还是花费了些时间，造轮子的过程中收获不少。","tags":[]},{"title":"程序员病","date":"2017-01-24T11:43:00.000Z","path":"2017/01/24/disease-of-programmer.html","text":"最近看费曼的书《发现的乐趣》，里面有一段描述非常好玩: 好，弗兰克先生开始实施他的计划了，与此同时，他也得了一种病——『计算机病』。现在每个使用计算机的人都知道这个毛病，那种病非常厉害，会干扰整个工作。这是我们面临的一个严重问题。所谓『计算机病』就是你一『玩』上计算机，就会上瘾。计算机真的非常奇妙，你手上操作着那些 x 转换开关，这样弄得到某个偶数，那样弄得到某个奇数。如果你够聪明，很快你就能在一台机器上做越来越复杂的计算。只不过，没多久，整个系统就瘫痪了。 他对工作不再上心了，也不再管理手下，整个系统运转得很慢很慢。但是，真正麻烦的是，他一直坐在一间办公室里，琢磨怎么让制表机自动打印出反正切值，然后机器就开始打印，成排成排地打印，扑哧，扑哧，扑哧，一边打印一边还自动用积分计算反正切值，整张表都是方正切值计算结果。 其实，这毫无意义，因为我们人手一份反正切表。不过，如果你用过计算机，你就会理解他为什么得这种病。计算机能让你知道自己究竟能做多少事情，这也是一种乐趣。他第一次接触这机器，就染上了这种病，这个可怜的家伙——整个项目都是他发起的，可他却得了这种病。 其实很多程序员都有这种病，可以概括为一句话『沉迷于工具』，计算机也是工具，这位弗兰克先生还未解决眼前的问题时就丢掉了方向。好奇心是程序员必不可少的东西，而如果管不住自己的好奇心就会耽误事。对于非程序员来说，这件事情看起来就是『某个杀猪佬，拿到了一把新刀，他觉得这么刀真他妈锋利，然后磨磨刀，再磨磨刀，反正猪是不会杀的』。 程序员经常会『磨刀』，学习算法，是磨练自己的头脑和思维。学习语言，是为了多拥有一个工具或者也可说是锻炼自己的思维(不改变自己思维习惯的语言不足以学之?)。学习操作系统的原理和细节，也可以理解为加深对工具的认识和理解。在学校的学习方法大多数从基本原理和经典书籍学起，顺便找一些小项目练练手。在步职业阶段后，从实用的角度，我们是否应该直面问题，带着问题找工具，学用工具，理解工具，这个过程中更可以锻炼自己的能力。从个人体验来说，这种方式优于『先锻炼自己的能力，先学会某个工具，然后再找个问题来解决』。举例来说，其实做一些 ACM 之类的题也挺有乐趣的，但我理解为刷题也是在『磨刀』。更让自己有成就感的是，在工作中碰到一个解决不了的算法问题，通过学习和思考相关的东西解决了，这样的方式理解更深。其实如果是步入职场，很多程序员也没多少时间来广泛学习，带着问题来『磨刀』也是必然且更有效的选择。 再多扯一点，不少程序员有一些类似于强迫症的症状(在很多情况下这是一个好的特点)。而在计算机这个领域里有太多东西容易沉溺，比如编辑器，编程语言，操作系统，框架， 范式等。这类工具都有可能让程序员走向某个极端，形成『偏见』。我也有类似的体验，只是现在回想起来觉得挺傻缺、傻气的。大多数程序员都不够拥有开阔的心态来面对这些工具，我们会觉得自己的选择是更好的，能解决一切问题的银弹。这副图能说明这个道理。 我现在会注意避免自己陷入这些『疾病』中。比如一个工具，不管是框架也好，语言也好，不要在还没摸清楚门路的时候，花大片时间去学习。而是最好带着一个需要解决的问题，边做边摸索。 发现自己的傻缺，就是成长，对吧！","tags":[{"name":"Books","slug":"Books","permalink":"http://catcoding.me/tags/Books/"}]},{"title":"Ruby 程序的静态分析: rubytt","date":"2016-12-27T11:43:00.000Z","path":"2016/12/27/rubytt.html","text":"rubytt是一个 Ruby 程序的静态分析器，这个项目从16年年初一直到年底，断断续续持续了近一年。这里稍微总结一下自己的开发过程。 0. 缘由14年开始，从我进入 DJI 之后开始接触 Rails 开发。Ruby 之前也接触过，不过都是写一些小脚本之类的东西。我们几乎用 Rails 写各种系统，开发的效率很快。对于经常变动的 Web 开发 rails 还是挺好的。在我经历过的一个对正确性要求很高的项目里，有一次系统出现一个致命的问题。我们6个开发人员在小黑屋里面足足找了一个下午。最后却发现不过是一个 type 错误引入的，导致后台任务一直执行错误。后来稍微多想了想，这样的类型错误应该是在开发阶段就及时发现的。 Rails 项目没有测试是不行的，所以我们后续补充了更多单元测试。另外我所使用过的静态语言几乎都能及早避免这样的错误，特别是在使用过 OCaml 这样的强类型语言后，我对类型有了更强的偏好。于是想我能不能做一个自动检测出类似 bug 的工具。据我所知王垠的rubysonar 可以做类型分析，于是我 checkout 出来看了看代码。Java代码不是特别复杂，也发现了两个问题并提交了 PR。然后觉得这个东西还是比较好玩，干脆就自己另起一个项目来玩玩。 1. rubytt 的开发首先得给这个坑起一个名字，想了想就 rubytt 吧，其实就是”ruby to type” 的意思吧。然后语言还是用了最近业余使用得比较多的 OCaml。这可能对后期其他开发参与进来不利，不过也无所谓了，业余的项目先依自己的偏好吧。 parser首先面临的问题是 parser。rubysonar 的parser 也是依靠 Ruby 自己的ripper。主要是 parser 太过繁琐，如果从头开始写整个坑估计是填不完了。所以我也就直接拿来了 rubysonar 的dump_ruby.rb。 dump_ruby 把 ruby 源文件作为输入，输出一个 json 文件作为后端分析器的输入。这里我做了一些改动，rubysonar 里面是起来一个进程，把 dump_ruby 启动起来，用管道的方式一个个 parse 源程序。这样做的目的是避免 ruby 解释器频繁启动，避免整个速度会被拖慢。 我觉得还不如让dump_ruby 一次接收多个源程序，甚至可以是用 parallel 这个库来做并行。这样的结果是 parsing 的速度确实快了很多，一般大点的项目在10s 以内可以完成。这样项目的大概流程如下: type annoation我想做自动的类型错误检查，所以需要类型分析。dump_ruby 出来的结果里面是带一些基本类型的，类型分析过程 rubysonar 里面有一个基本过程了。然后对于 Rails 项目来说，我们很多类型都可以在 db/schema.rb 里面可以分析出来，所以如果我把 schema.rb 文件也扫描分析一边，就可以为这些 model 加上不少类型。结果做出来还可以，至少目前可以分析出来很多 rubysonar 没有的类型。运行rubytt -s source_dir -t type -o res把结果输出到 res 目录。这里还有不少东西未做，比如函数的分析还是很复杂，目前做了一个初步。类型错误报出可以做一些了，但是还未来得及实现。因为我突然想到另外一个有趣的东西。 visualize rails project我既在 traverse 整个 AST，可以做很多好玩的事啊。比如把类之间的继承关系找出来，做一个类的继承关系图。于是就有了类似这样的结果(看大图)： 既然我能解析 schema.rb，也可以把数据模型给展示出来，然后再通过 model 文件里面分析模型之间的关系(has_one, has_many 等)， 于是就有了这样的结果： 不过做了一些之后我发现这两个 feature 有点鸡肋。特别是第一个，要找出 ruby 程序内部对象之间的继承关系其实很简单，比如我之前写过的一篇文章。第二个模型的关系图还好，不过项目稍微大一些的时候这些图看起来很复杂。 variable bug finder在做完上面两个蛋疼的 feature 之后，碰巧碰到了项目里面另外一个 bug。是因为重构的时候不小心引入了一个 copy &amp; paste bug。类似代码如下： event = (order.status == &#x27;success&#x27;) ? &#x27;success&#x27; : &#x27;fail&#x27;Job.send([&#x27;Worker&#x27;], &#123;&#x27;order_id&#x27; =&gt; order.id, &#x27;event&#x27; =&gt; &#x27;success&#x27;&#125;) 可以看到这个 event 本来应该使用的，结果却因为重构的时候 copy 了代码忘记把&#39;event&#39; =&gt; &#39;success&#39;改成&#39;event&#39; =&gt; event。event这个变量是未使用的变量，对于编译型语言来说这样的问题是可以在编译的时候发出报警的。因为一个变量未使用必然意味这要么是冗余代码，要么是 bug。那我可否通过 rubytt 给出类似报警？然后我就继续写了这么一个 checker，去检查ruby 程序中各种没使用的变量。最后还真能找出项目中一些其他的类似问题，比如： result = &#123;&#125;trans = self.transactions.where(..blah...)trans.each do |tran| result[:amount] = trans.amount_cent &lt;------- bug: `trans` is typo of &#x27;tran&#x27; ...blah...end 当然还是能找到函数中未使用的参数等问题。修复的办法是如果确定这些变量是不被使用的，就在前面加_，这样rubytt 这样的 lint 类检查工具就跳过。后续我也正在做未定义变量的检查。 2. OCaml的程序发布在做完上面的几个 feature 之后，我觉得可以尝试着把这个项目推广一下给同事们玩玩。如果让从来没接触过 OCaml 的朋友从头开始编译安装会显得很麻烦。所以我就尝试着把 rubytt 合并到 OCaml 的包管理仓库。于是在经过几次和 travis CI 的斗争后，终于发布了rubytt.0.1 。 安装方法如下： gem install parallel ruby-progressbarsudo apt-get install --force-yes ocaml ocaml-native-compilers camlp4-extra opam// brew install opam (MacOS)eval `opam config env`opam install rubytt OCaml 的圈子比较小众，不过其实很多工具还是挺好用的，比如这个 OPAM 包管理器。 3. 其他心得做这个程序这么久，除了好玩还是收获不少。 OOP 和 FP 哪个好？通过这个项目的实践，我好好体会了一把 FP 写稍微大些的程序的感觉。说不上哪个好，我倒认为 type 确实很重要，rubytt 的过程中自动类型推导帮我发现了好多代码错误。编程语言应该让程序员能够精确无误地表达自己，尽量地避免人为引入的错误。 构建测试脚手架，这也是第一份工作带给我的习惯。把每一个 feature 或者 bug 都写测试来覆盖。每次提交的时候都 review 一下测试用例的改动，这样才能不断保持质量。 希望来年能继续保持对这个程序的热情。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Ruby","slug":"Ruby","permalink":"http://catcoding.me/tags/Ruby/"},{"name":"OCaml","slug":"OCaml","permalink":"http://catcoding.me/tags/OCaml/"}]},{"title":"读《饥饿的盛世》","date":"2016-12-11T11:43:00.000Z","path":"2016/12/11/qianlong-history.html","text":"最近又读了本张宏杰的书《饥饿的盛势》。张宏杰的书今年看了好几本，讲述历史都挺生动，特别是对人物内心的剖析很到位。很多时候作者是站在历史人物的角度去分析，书里所展现的历史人物特别鲜活。很多历史人物都被脸谱化或者自带几个标签，这人不是好的则是坏的。可是人都是复杂的、多面的，真实的历史事件又会有各种偶然因素。这本书看完后，对乾隆印象具体了很多。乾隆盛世的背后，隐藏着这位皇帝仁慈和残暴、宽容和计较。乾隆作为为数不多的自律而有头脑的皇帝，几乎是创记录地维持帝国专制统治近60年。 雍正仓促去世，乾隆在25岁的盛年继位，继位过程光明正大，水到渠成。上任之后就改变了帝国的航向。乾隆把被雍正折腾得要死的各种皇室宗族放出，给予产业和爵位，一下子扫除皇室王宫对雍正乾隆一族的怨恨。为了争取官僚集团对自己的效忠，他仿效祖父，宽大待下，从实际角度考虑问题，解决困难。对农民也采取了仁政，停捐纳，重视农业，赢取农民的爱戴。乾隆精通驭臣之术，虽然初征的时候执行仁政，他对于权利的集中却丝毫没有松懈过，时刻警惕名称、后宫、宦官等一切可能干扰权利的因素。 张廷玉是雍正时的老臣，对大清可谓鞠躬尽瘁，雍正点名其可配太庙。而乾隆因为各种鸡毛蒜皮的小事和张廷玉斗，最后把人弄得晚节不保。这章读起来真的是好生动啊，这个宇宙第一的皇帝心眼小得夸张！ 原配皇后富察氏的两个皇子的相继去世、富察氏后来也病死，这对乾隆影响很大。皇帝权利再大也抵不过生老病死。终于，乾隆13年时，借皇后富察氏去世，乾隆刮起政坛风暴，重回雍正时期刚猛、狠戾、阴险的政治风格。无数人被无辜定罪，包括自己的儿子们。原配妻子的死是乾隆一生的怨念。 在200多年前，乾隆为了留给后人一个『安全』的帝国，在内蒙古做了人类历史上一次惨绝人寰的灭族！纯朴的牧民们、归降的地人们一律被杀。 从驯身到驯心，集权统治的最后一步是驯心，就是所谓的『大清精神文明建设』。从书的描述看来，乾隆缔造了中国历史上最严酷的文字狱。无数书籍被烧，文人不敢写字发声。中国的帝王所要的向来是服服帖帖、老老实实的子民，这些子民除了基本的生存权，就不应该有其他诉求了。朱元璋洪武年间甚至规定了子民怎么穿鞋、怎么着衣。乾隆对于越级上访一律惩罚，民间的异说也是不能放任的，疯子在朱元璋手下还能逃脱，乾隆可是能杀则杀。 “千古第一全人”，乾隆年老后一直喜欢把自己和历史上的君王们比较，对自己所缔造的盛世甚为满意。甚至做到了历史上少有的权利的平稳交接，把自己的皇冠带在了嘉庆皇帝头上。不过晚年还是不得安稳，花了三年直到自己死时白莲教都没被压下。乾隆的60年统治中，中国的人口和版图都达到了峰值，而这又有什么用呢。自己培养出来的嘉庆守旧胆小，西方列强经过工业革命的洗礼已经远远超越大清。二十世纪初开始大清已经摇摇欲坠。甚至乾隆的坟墓都被炸开，真的是『千古第一全人』的巨大讽刺。","tags":[{"name":"Books","slug":"Books","permalink":"http://catcoding.me/tags/Books/"}]},{"title":"Nginx限流","date":"2016-11-30T11:43:00.000Z","path":"2016/11/30/nginx-traffic-limit.html","text":"Nginx 限流可以通过几种方式实现： 1. Nginx自带的流量控制模块ngx_http_limit_req 根据特定的key(通常为IP) 控制访问频率 ngx_http_limit_req_module 控制连接数 通过修改Nginx的配置文件，然后reload。这种方式配置比较简单，然而 reload 对于当前访问量比较大的服务器开销也有一些。 根据新浪的经验，每一次的 reload 对 Nginx 的 QPS 与耗时的影响通常会持续 8~10s，考虑到一次扩容会有频繁的变更，这对在线业务来说是不堪承受之重。因此，要避免对 Nginx 进行 reload。 2. 使用lua-resty-limit-traffic 流量控制代码和文档。这个库分为limit_conn 和 limit_req模块，limit_req限制某个 ip 或者 server 的访问频率，limit_conn 限制连接数。lua-resty-limit-traffic 的原理是使用 Nginx 的 shared_dict，建立一个 hashtable，根据目前连接数或者访问请求记录相关信息。对于每一个Nginx请求都有一系列执行阶段，每个阶段可以增加 hook，access_by_lua是处理前调用的hook, log_by_lua 是处理完成后调用的 hook。进入的时候通过 ip 作为 key 找到share_dict 里面的连接数，增加1。处理完之后找到连接数， 减去1。 通俗的理解就是顾客进入试衣间前持一个牌子，出来后归还牌子。当前的正在使用的牌子数目可以配置，以达到限流目的。 依据系统状态动态改变限流的配置，可以考虑两种方案： limit_conn 和 limit_delay 存放在 Redis内，在 access_by_lua_block 的部分去取出当前限制，这个方案的弊端在于对每个 request 多了一次 redis 请求。 limit_conn存放在 Nginx 的 shared_dict内，通过 Nginx 的配置增加一个 location，专门用来请求来修改其值，任何一个 Nginx worker 修改成功后，其他 worker 都可见。 3. 使用nginx-upsync-modulenginx-upsync-module是新浪的开源库，也是依赖 openresty 的。 这套工具可以修改 backend 的各种属性，weight, max_fails等。为了避免 reload，可以使用Consul或者Etcd 进行动态配置。 其他为了做一些自动限流，可以考虑分析 nginx 日志，或者系统负载信息。系统负载分析工具，ruby gem 包usagewatch可以获取系统目前的 CPU 使用率，Memory使用率，系统 load 等相关信息，日志分析工具https://github.com/allinurl/goaccess，使用goaccess，可以实时分析rails app日志。","tags":[]},{"title":"菊与刀","date":"2016-08-09T11:43:00.000Z","path":"2016/08/09/dao-yu-ju.html","text":"前些天在家偶然翻到一部日本电影《黄昏的清兵卫》，看完后觉得非常符合个人口味。顺着同类型的电影又看了《隐剑鬼爪》。两部电影都是由山田洋次导演，主要故事都是围绕德川幕府末期的武士展开。剧情其实有些类似，一个武士，一个柔弱女主，甚至是同一个仆从，在“义务”和“义理”的冲突下来一场厮杀。武士爱着女主，却因为种种“理”而不能靠近。突出武士阶层的隐忍和不可避免的没落。 看完电影后，又顺着看了多人推荐的《菊与刀》。二战后美国急需了解日本，特别是日本人民的习俗和心理特征，因为日本在西方人看来太过特别，他们在战争中所体现的凶残程度也是前所未有的。《菊与刀》正是在这样的历史背景下由本尼迪克所写。据说作者本人并没有去过日本，而是通过书籍和调研来完成。这本书也许有的方面写得有所夸张。 看完这本书后，对上面两部电影有了更深些的理解。日本崇尚秩序，上级对下级的命令是无法抗拒的。这也解释了为什么二战时日本士兵凶暴残忍得像禽兽一般，而当天皇下诏投降书后，日本人绝大部分立马放弃抵抗，站在街头服服贴贴迎接盟军。在《隐剑鬼爪》中，藩府上级要求片桐出卖朋友交出叛党名单，片桐出于“义”而拒绝。但藩府换成“命令”的时候，他还是会去执行。“义务”和“义理”发生冲突的题材是很多日本故事和电影的基础。剧中人为履行义务忍受了一切，无论不幸、遗弃、疾病还是死亡，都未能使他们偏离。他们认为。所谓强者恰恰在于敢于抛弃个人幸福而去履行义务。他们认为，“性格的坚强不是表现为反抗，而是表现为顺从”，“真正的尊严在于各安其分，不卑不亢，自王子以至农夫，皆可以此自许”。 总的来说，日本呈现出了复杂的矛盾： 日本人好斗而又温和；黩武而又爱美；自尊自傲而又彬彬有礼； 顽固而又善变；驯服而又不愿 受人摆布；忠心而又易于叛变； 勇敢而又怯懦；保守而又欢迎革新。 他们十分介意别人对自己行为的看法，但当别人对其劣迹毫无所知时，又怡然自得。 关于个人欲望：日本人并不谴责满足私欲。他们不是清教徒。他们认为享乐是件好事，是值得培养的。他们追求享乐，尊重享乐，但享乐必须恰如其分，不能妨碍人生重大事务。 日本是比较讲究专注精神修炼，在他们看来，培养“一心”和“无我”对任何事业都是有好处的。 这本书算是我看过的翻译书籍里面很流畅的一本，甚至基本看不出来是翻译的。这和《自私的基因》比起来好多了，后者的这个版本基本没法看。 两部电影中，相对来说我更喜欢《隐剑鬼爪》。 －－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－ 最后，两部电影的女主角都挺好，宫泽理惠和松隆子。","tags":[]},{"title":"Add syntax check for Capistrano","date":"2016-07-22T11:43:00.000Z","path":"2016/07/22/capistrano-syntax-check-for-rails.html","text":"In an normal release, Rails app’s unit testing will avoid most errors. But for the urgent code publishing, we have got several time of typo error. Code syntax error may cause server crash for a little while(Passenger web server and we using ./tmp/restart.txt to restart). We use Capistrano to publish code, so I plan to add a syntax checking before publishing code.The method is writing a task to bundle exec rails runner, this will report most ruby syntax error(except the undef variables in some functions, runner will load .rb files). namespace :app do desc &quot;check all the ruby code&quot; task :check =&gt; :environment do res = `RAILS_ENV=#&#123;Rails.env&#125; bundle exec rails runner &quot;&quot; 2&gt;&amp;1` raise res if res.size &gt; 0 endend then add this in the deploy.rb (Capistrano 3.1): namespace :deploy do task :run_code_check do on roles(:all) do within release_path do with rails_env: fetch(:rails_env) do execute :rake, &#x27;app:check&#x27; end end end end before &quot;deploy:updated&quot;, &quot;deploy:run_code_check&quot;end This is not a tricky part, but please pay attention to the line: res = `RAILS_ENV=#&#123;Rails.env&#125; bundle exec rails runner &quot;&quot; 2&gt;&amp;1` This line of code cost me some time, I forget the 2&gt;&amp;1. so res will just got the stdout, not the stderr output, which causes the exception is not raised, and Capistrano flow is not stopped.","tags":[{"name":"Rails","slug":"Rails","permalink":"http://catcoding.me/tags/Rails/"}]},{"title":"刷刷算法和 OJ","date":"2016-07-08T11:43:00.000Z","path":"2016/07/08/fun-on-hackerrank.html","text":"最近我们部门内部组成了一个算法读书小组，每周大家轮流分享自己的学习心得。为了方便学习我还写了一个小的 内部OJ，看起来还挺还好玩的。界面风格学习了青岛大学的 OJ，后台使用 Docker 来做沙盒跑测试输出结果。顺便学习了实际使用Docker。唯一麻烦点的是选了一个阿里的主机，最开始更新起来比较慢。还是用亚马逊的比较好。讨论形式还在摸索，我们现在每周选择一两个主题，会有两个分享人主讲，另外在 OJ 上弄几道题目大家做。总的来说还是可以提高一些东西，算法方面的知识，比如分享、表达的技巧。 等 OJ 完善得差不多了再分享出来。 另外业务时间也在 HackerRank 上做了一些题目，刚开始是为了熟悉 OCaml，专门用 OCaml写FP 方面的题目。 最近两周也顺便参加了一些比赛。这些比赛有的是和一些公司合办的，有的是各个主题的。比如有周赛，从周一到周五每天一个问题。个人觉得这个比较适合已经工作了的程序员，因为可以在空闲时间慢慢思考。等比赛结束之后也可以看其他人的解法和代码。我最近写得比较多，又找到了在学校时写程序的乐趣了。而且熟悉了之后用 OCaml实现算法还是挺快的。我的一些代码放在了这里，感兴趣的可以参考。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"}]},{"title":"Tiny Interpreters","date":"2015-09-29T11:43:00.000Z","path":"2015/09/29/programming-language-and-interpreters.html","text":"After reading the first simple Scheme interpreter of bootstrap-scheme, I have some interests on studying various programming languages and interpreters. It’s really fun to implement tiny programming languages. For learning a new programming language, a simple Scheme interpreter is a good starting project. Because in this small project we need to know some core aspects of a new programming language, including the basic I/O operations, abstraction methods for expression representation, recursive for eval, and unit testing. Also mini Scheme is so easy for parsing, we can focus on data representation and eval. Two programming language are best suited to implementing interpreter, The first one is Scheme, which used in many famous PL books, such as EOPL, SICP, etc. Another good language in OCaml,which is a sweet spot in language design space: strict, type system and type-inferer, functional. It’s very convenient to implement a parser, and also because of the pattern matching and algebraic data types, it is nature for building AST and traverse on it. For your references, I have these small projects during my studying of languages(to be continued): eopl, hundreds of interpreters written in Scheme, trying to solve most of the EOPL exercises. rust-scm, which is a Scheme interpreter written in Rust GoScheme, yet another Scheme interpreter written in Go ocaml-scheme, yet another Scheme interpreter written in OCaml toy-compilers, still they are interpreters, but not compilers, with js_of_ocaml we can compile OCaml code to Javascript, then run it on web browsers!","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"}]},{"title":"最近读的一些杂书","date":"2015-08-09T11:43:00.000Z","path":"2015/08/09/reading-notes.html","text":"最近看了几本书，大多都是觉得有些意思就从亚马逊上买了。自从我的Kindle坏了之后，我就基本只买纸质书了。虽然纸质书携带不够方便，看起来更够味。 别逗了，费曼先生! (5*)这是我最推荐的一本，断断续续看了两遍。这本书虽然是翻译的，但是质量很够水准，费曼聪明的坏教授形象跃然纸上。费曼作为物理学家也挺逗的，从小喜欢发明各种东西、恶作剧，折腾电子器件，好玩。青年时期开始折腾物理，在暑假期间顺便当了一段时间『化学家』。后面又对破解密码锁、画画、打鼓、学习外语产生浓厚兴趣，并极其投入。贯穿其中最让人敬佩的是费曼的好奇心好韧性。整本书都是在用一种诙谐平叙事写法，不过突然怀念自己的妻子那段特别感人，他的妻子去世那段时间正是在研发原子弹期间： 当我返回的时候他们都来问我发生了什么事儿， “她死了，工作进行的怎么样？” 他们立刻明白了，我不想为此终日哀伤。我显然要做些安慰心理的事：现实是重要的。我一定要理解，从生理学上说，阿琳究竟是怎么了； 我没哭，直到几个月之后。当时我在橡树岭，我正走过一家百货商店的橱窗，里头挂着女士服装，我想阿琳或许喜欢其中一件。此时此刻，我不盛悲戚。 他谢绝芝加哥大学高薪聘请的那段挺逗： “我将有能力做我一直想做的事 ——- 找个迷人的情妇，为她买一座漂亮的房子，给她买好东西……用你们给的这份薪水，我必定真的会这么做，我知道那会是什么结果，我会为她操心，挂念她在干什么，我们会吵架。我回家的时候，又会如何如何。这些闹心的事儿，会让我寝食不安，会让我心情不快。我搞物理也搞不好了，一切都将是一团糟！……因此，我已经决定，我不能接受你们的好意。” 费曼的理念是一个东西都可以用更通俗的说法来解释，但必须是建立的自己理解的基础上。 在巴西的教学过程中，费曼对填鸭式教学进行了思考和批判，里面所描述的场景和国内的教学何其相似！学生只是背诵，根本不理解那些科学概念背后的生动的东西。 最后，我认为判断人是否老了的一个标准就是其是否还对新鲜东西保持好奇心，有好奇心的人竟然这么好玩！ 鱼羊野史 (4*)一直比较喜欢高晓松，他的一些老歌都挺好听的。在深圳的时候听过一次他的演唱会，观众大多都是一些30岁以上的中年人。高晓松家庭显赫，一直都随性游荡，涉猎广泛，吹起牛来根本停不下来。有一段时间我也会在上班路上听他的小松奇谈，东南西北特别能侃。小松奇谈里面我最喜欢的故事是其二叔的爱情故事《文革时期的何以笙箫默》，是真是假无从考证，不过这还真是个能拍成电影的好故事。偶然在网上看到高晓松的这三本书，空闲时间把这些都看完了。总得来说不如听小松奇谈来劲，而且很多篇都是比较八卦，比如李宇春、齐秦生日之类的。这些还活着的明星们八卦怎么说也不能算作历史吧，即使是野史。另外就是三本的内容竟然有不少是重合的！ 李光耀观天下 (4*)中国的改革开放从新加坡借鉴了，中国相关的篇章还挺直接的。对邓小平和老毛的描述比较多，其他人就呵呵了。 成大事者不纠结 (3*）逻辑思维的公众号更新很勤快，内容也不错。不过这本书倒是没什么太多内容，李鸿章和曾国藩的章节都是在逻辑思维里面讲过的。更让我不爽的是书的封装，居然带了一打微信推广号。 从0到1 (3*)这本书挺有名的，不过看完后并没产生多少共鸣。可能是因为我现在对创业这个词有些抵触，创业现在动不动就是改变人类、情怀。这个词被玩坏了。在互联网这个行业，创业看起来有点类似大跃进。大家都吹牛，比如前段时间被扒皮的云视链就属于吹牛吹破了的。真正从0到1创造出新事物的公司太少。","tags":[{"name":"Life|Notes","slug":"Life-Notes","permalink":"http://catcoding.me/tags/Life-Notes/"}]},{"title":"惰性求值和流","date":"2015-04-26T11:43:00.000Z","path":"2015/04/26/lazy-eval-and-stream.html","text":"什么是惰性求值惰性在函数式编程语言中很常见，他的通俗解释就是一个变量或者表达式，不到必要的时候不会被eval。比如函数在传递参数的时候，参数的值可以不确定。 这种方式叫做call-by-name, 首先很明显这可能会造成一部分performance差异，如果一个表达式没有用到，那么计算出其结果是毫无意义的。而惰性求值是memoized的call-by-name, 叫做call-by-need。从技术实现上来说，一个表达式在计算其结果之前其状态是Deferred或者Delayed的，在计算之后将其结果存储下来并修改状态为Value，之后再取就没有必要重新去计算。用一些OCaml代码来说明： # let v = lazy (print_string &quot;performing lazy computation\\n&quot;; sqrt 16.);;val v : float lazy_t = &lt;lazy&gt;# Lazy.force v;;performing lazy computation- : float = 4.# Lazy.force v;; - : float = 4. 关键字lazy表示延迟计算这个表达式， Lazy.force表示求值。可以看到第一次force的时候会打印出performing…信息，后面的force就直接返回了value。 为了更好的理解这个概念，我们可以实现一把Lazy。首先定义一个lazy_state: # type &#x27;a lazy_state =| Delayed of (unit -&gt; &#x27;a)| Value of &#x27;a| Exn of exn;;# let create_lazy f = ref (Delayed f);; 这个lazy_state有三种状态，第一种就是dealyed，’a表示任何类型的value。Value表示被eval过了，并且保存下来他的值。Exn表示错误或者异常的状态。那么create_lazy就表示创建一个lazy_expression,这里的参数f可以是任何类型的函数(函数的参数类型和返回类型都可以不确定)，ref是OCaml里面的类似指针的概念。 上面例子就可以这样来写了: # let v = create_lazy (print_string &quot;performing lazy computation\\n&quot;; sqrt 16.);; 然后实现核心的force:# let force v = match !v with | Value x -&gt; x (* 如果已经求值就直接返回value *) | Exn e -&gt; raise e (* 如果发生错误，raise错误*) | Delayed f -&gt; try let x = f () in (* 如果还未求值，eval保存下来的f *) v := Value x; (* 并把结果保存下来 *) x with exn -&gt; v := Exn exn; (* 如果发生错误，保存下来 *) raise exn ;; 这里的!v就是取这个引用里面的值(类比C语言里面的*pointer)。然后pattern match这个lazy_state，注释里面写了每一行的操作。这里的代码很简短，最核心的意思是我们能把一个函数或者代码块保存下来，在真正需要的时候去运行这个代码块。在函数式编程里面这很常见，函数和变量一样可以自由传递。虽然看起来好不起眼，不过这会给编程带来一些深刻的影响。 Memoization通过上面对laziness的解释，我们可以发现这个概念的核心思想类似算法设计里面的memoization，这样在计算过程中把重复计算的过程省略掉。比如这段代码有些好玩: let memoize f = let table = Hashtbl.Poly.create () in (fun x -&gt; match Hashtbl.find table x with | Some y -&gt; y | None -&gt; let y = f x in Hashtbl.add_exn table ~key:x ~data:y; y );; 这个函数接收任何类型的函数f，他会像一个wrapper一样给你包装一下: 给你一个table用来存储这个函数的结果，键值是你的参数x，如果发现参数是x的结果还没计算的时候，把结果算出来并存储在table里面。这里我们又能看到函数式编程带来的好处，f是任何类型的函数(这里暂且还没处理递归)，这类问题在算法设计里面挺多的比如fibnacci，edit-distance。 在递归情况下如何处理可以看看这，这是我看过的排版最好的技术类博客Type OCaml:Recursive Memoize &amp; Untying the Recursive Knot Stream有了lazy的概念之后，我们可以在编程里面表示一些看起来很数学的概念，比如一个表示所有整数的流: type &#x27;a stream_t = Nil | Cons of &#x27;a * (unit -&gt; &#x27;a stream_t)let rec from i = Cons (i, fun() -&gt; from (i+1))let hd = function | Nil -&gt; failwith &quot;hd&quot; | Cons (v, _) -&gt; vlet tl = function | Nil -&gt; failwith &quot;tl&quot; | Cons (_, g) -&gt; g()let rec take n = function | Nil -&gt; [] | Cons (_, _) when n = 0 -&gt; [] | Cons (hd, g) -&gt; hd::take (n-1) (g()) Cons是把两个元素组成链表，递归函数from做的事情就是把i和一个匿名函数fun() -&gt; from(i+1)链起来，当然匿名函数又在做类似的事情。那么(from 1)就可以表示从1开始的所有整数了，hd是取一个流的头部，tl是取流的尾部(除头部剩下的)，take是从一个流里面取前n个元素。这可是非常的方便，还有更方便的： let rec filter f = function | Nil -&gt; Nil | Cons (hd, g) -&gt; if f hd then Cons (hd, fun() -&gt; filter f (g())) else filter f (g()) 我们虽然只知道有这么一个流，但还是可以加一个筛选条件给他，filter函数接收筛选函数f和一个流，返回的结果就是被筛选后的流！ (* delete multiples of p from a stream *)let sift p = filter (fun n -&gt; n mod p &lt;&gt; 0)(* sieve of Eratosthenes *)let rec sieve = function | Nil -&gt; Nil | Cons (p, g) -&gt; let next = sift p (g()) in Cons (p, fun () -&gt; sieve next)(* primes *)let primes = sieve (from 2) 所有素数就可以这么来写了，有了这个流之后要取多少就取多少。 其他Haskell是纯函数式纯Lazy的实现，OCaml有imperative的部分，而且运行时不是Lazy的。相对来说我更喜欢OCaml的语法以及设计原则，FP有其好处，但imperative programming也有其益处。Lazy有其好处，但还是在用户明确需要的时候能提供就好。 部分代码引用Real World OCaml","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"OCaml","slug":"OCaml","permalink":"http://catcoding.me/tags/OCaml/"},{"name":"PL","slug":"PL","permalink":"http://catcoding.me/tags/PL/"}]},{"title":"Types and Programming Languages (2)","date":"2015-03-07T11:43:00.000Z","path":"2015/03/07/types-and-programming-languages-2.html","text":"ReferencesSide effect In particular, besides just yielding results, evaluation of terms in these languages may assign to mutable variables (reference cells, arrays, mutable record fields, etc.), perform input and output to files, displays, or network connections, make non-local transfers of control via exceptions, jumps, or continuations, engage in inter-process synchronization and communication, and so on. In the literature on programming languages, such “side effects” of computation are more generally referred to as computational effects. 引用指向的对象可以是基本类型、组合类型，甚至是函数，把指向函数的ref放进对应的record，就变成一个简单的object，OOP的原型就出来了。 update = λa:NatArray. λm:Nat. λv:Nat. a := (λn:Nat. if equal m n then v else (!a) n); 通过这个习题的例子可以看出ref引进的副作用。 Garbage CollectionGC or not This is not just a question of taste in language design: it is extremely difficult to achieve type safety in the presence of an explicit deallocation operation. The reason for this is the familiar dangling reference problem: we allocate a cell holding a number, save a reference to it in some data structure, use it for a while, then deallocate it and allocate a new cell holding a boolean, possibly reusing the same storage. Now we can have two names for the same storage cell—one with type Ref Nat and the other with type Ref Bool. Pointer Pointer arithmetic is occasionally very useful (especially for implementing low-level components of run-time systems, such as garbage collectors), it cannot be tracked by most type systems: knowing that location n in the store contains a Float doesn’t tell us anything useful about the type of location n + 4. In C, pointer arithmetic is a notorious source of type safety violations. Store typings: 引入引用后类型系统需要处理Cyclic reference structures，比如double linked list。Store typings就是一个locations到typings的映射。 实现fullref： 引用部分的实现非常简单， | TmRef(fi,t1) -&gt; TyRef(typeof ctx t1)| TmLoc(fi,l) -&gt; error fi &quot;locations are not supposed to occur in source programs!&quot;| TmDeref(fi,t1) -&gt; (match simplifyty ctx (typeof ctx t1) with TyRef(tyT1) -&gt; tyT1 | TyBot -&gt; TyBot | TySource(tyT1) -&gt; tyT1 | _ -&gt; error fi &quot;argument of ! is not a Ref or Source&quot;)","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"OCaml","slug":"OCaml","permalink":"http://catcoding.me/tags/OCaml/"},{"name":"PL","slug":"PL","permalink":"http://catcoding.me/tags/PL/"}]},{"title":"Types and Programming Languages (3)","date":"2015-03-07T11:43:00.000Z","path":"2015/03/07/types-and-programming-languages-3.html","text":"Subtypingsubtyping解决的问题是多态，OO的一个基本要素。 we say that S is a subtype of T, written S &lt;: T, to mean that any term of type S can safely be used in a context where a term of type T is expected. This view of subtyping is often called the principle of safe substitution. 这章只是以record来作为例子说明，直白的所一个类型S是另外一个类型的T的子类型，意思是任何使用T的context，我们可以安全的使用S。对于record类型来说，field数量多的是field数量少的子类型，因为这样任何从T要取得的field都可以从子类型里面取到。 对于函数类型来说，如果S1-&gt;S2, T1-&gt;T2, S1是T1的子类型，S2是T2的子类行，那么S1-&gt;S2是T1-&gt;T2的子类型。 引入Top类型，是所有类型的父类，对应很多编程语言里面的Object(OOP里面常见的伎俩)，Go里面我就这样定义： type Object interface&#123;&#125; 引入Bottom类型似乎就没什么大用处了，还增加了typecheker的复杂度。 Ascription and Casting类型的强制转换，分为up-cast和down-cast。up-cast对于类型检查来说要简单一些，比如类型Animal -&gt; Dog, Animal -&gt; Cat，由Cat到Animal的类型转换为up-cast。在很多语言里面是当做一种抽象方法。 down-cast要复杂一些，而且也可能会导致类型系统的不安全，比如： f = λ(x:Top) (x as &#123;a:Nat&#125;).a; 这个函数接收任何类型的参数，但是隐含一个假设，必须是一个有成员变量为数字类型的a，如果传递一个错误的参数typechecker也不报错，但运行的时候就会有错误了。所以含有down-cast的类型系统应该遵循： trust, but verify，编译的时候不报错，但是留着运行的时候检查。为了避免down-cast引起的复杂问题，ML等语言选择的是down-cast with type tags。 channels: The key observation is that, from the point of view of typing, a communication channel behaves exactly like a reference cell: it can be used for both reading and writing, and, since it is difficult to determine statically which reads correspond to which writes, the only simple way to ensure type safety is to require that all the values passed along the channel must belong to the same type. subtyping的引入导致分支多的情况下类型检查麻烦，因此引入了Join和Meet的概念，实现可参考代码里面的: let rec join ctx tyS tyT = if subtype ctx tyS tyT then tyT else if subtype ctx tyT tyS then tyS else let tyS = simplifyty ctx tyS in let tyT = simplifyty ctx tyT in match (tyS,tyT) with (TyArr(tyS1,tyS2),TyArr(tyT1,tyT2)) -&gt; TyArr(meet ctx tyS1 tyT1, join ctx tyS2 tyT2) | _ -&gt; TyTopand meet ctx tyS tyT = ....... Case Study: Imperative Objects不考虑实现效率和语法简洁的条件下，目前为止学到的语言特性已经足够来模拟实现OOP。最简单的例子就是一个counter: c = let x = ref 1 in &#123;get = λ_:Unit. !x, inc = λ_:Unit. x:=succ(!x)&#125;; OOP作为一种抽象手段，可以让通过接口来隐藏实现，客户端的代码只通过同一个接口才操作各种子类的对象。这里的例子一个子类只是比父类多接口而已。 newResetCounter = λ_:Unit. let x = ref 1 in &#123;get = λ_:Unit. !x, inc = λ_:Unit. x:=succ(!x), reset = λ_:Unit. x:=1&#125;; self的简单是现实需要动态找到对应的method，更高效的实现当然是对象创建好后method table建好。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"OCaml","slug":"OCaml","permalink":"http://catcoding.me/tags/OCaml/"},{"name":"PL","slug":"PL","permalink":"http://catcoding.me/tags/PL/"}]},{"title":"Types and Programming Languages (1)","date":"2015-03-01T11:43:00.000Z","path":"2015/03/01/types-and-programming-languages.html","text":"最近掉进另外一个PL的坑里面，就是想读一下这本书，顺便继续熟悉一下Ocaml。下面的记录是阅读过程中的一些摘录和理解。 1-2章是数学预备部分，理论部分有些地方比较难懂，主要是一些数学符号看久了眼花。解释器的实现大多只用看syntax.ml和core.ml，就是语法和具体eval，typeof函数。 Untyped Systemsarith是一个无类型的解释器，是后面所有章节的基础。printtm_Term用了Format模块来格式化打印。 The Untyped Lambda-Calculus浅显易懂的Lambda-Calculus解释，同时列举了一些lambda calculus扩展其他语言部分的例子。 An ML Implementation of the Lambda-Calculusshifting和substitution的实现挺难看懂的，本质上是把context里面的变量用index来替换，处理变量查找的一种实现而已。eval部分是非常地简洁，我觉得ML系的语法看起来比Scheme都舒服紧凑。 Just because you’ve implemented something doesn’t mean you understand it.​ —Brian Cantwell Smith 说起来全是泪，用这种函数式的编程语言来解释自己确实比较简单，但现实往往不是这样。语言能比较容易地实现自己至少可以表明语言的内核挺小，一个语言能实现bootstrap是成熟的一个表现。Rust的实现最初是用Ocaml写的，然后编译出一个Rust的编译器，然后用上一版本的Rust再重新实现Rust编译器。 Typed Arithmetic Expressionstyarith是最简单的带类型的解释器，有bool和Nat类型。 Progress: A well-typed term is not stuck (either it is a value or it can take a step according to the evaluation rules).Preservation: If a well-typed term takes a step of evaluation, then the resulting term is also well typed These properties together tell us that a well-typed term can never reach a stuck state during evaluation. Safety = Progress + Preservation Simply Typed Lambda-Calculus In general, languages in which type annotations in terms are used to help guide the typechecker are called explicitly typed. Languages in which we ask the typechecker to infer or reconstruct this information are called implicitly typed. Well-typed programs cannot “go wrong.” —Robin Milner (1978) An ML Implementation of Simple Typessimplebool是一个只有bool类型的解释器，但是加上了函数。typeof挺简单，主要是函数这里注意处理形参和实参: | TmAbs(fi,x,tyT1,t2) -&gt; let ctx&#x27; = addbinding ctx x (VarBind(tyT1)) in let tyT2 = typeof ctx&#x27; t2 in TyArr(tyT1, tyT2)| TmApp(fi,t1,t2) -&gt; let tyT1 = typeof ctx t1 in let tyT2 = typeof ctx t2 in (match tyT1 with TyArr(tyT11, tyT12) -&gt; if (=) tyT2 tyT11 then tyT12 else error fi &quot;parameter type mismatch&quot; | _ -&gt; error fi &quot;arrow type expected&quot;) if的判断部分必须为bool，而且两个分支必须为同一类型: | TmIf(fi,t1,t2,t3) -&gt; if (=) (typeof ctx t1) TyBool then let tyT2 = typeof ctx t2 in if (=) tyT2 (typeof ctx t3) then tyT2 else error fi &quot;arms of conditional have different types&quot; else error fi &quot;guard of conditional not a boolean&quot; Simple Extensions在上一章的基础上，加上各种Drived Form。 Sequencing: 是多个表达式串，这在有副作用的语言里面很常见。另外也可以把t1;t2理解为(λx:Unit.t2) t1。 Wildcards: 如何翻译好，意思就是无用形参可以不指定名字。 Ascription 是指类型缩写(或者昵名)，C++里面的typedef，和Rust里面的usize as U都是。这个的好处在于文档和接口更清晰，如果函数的参数可以是函数，类型加进以后语法看起来就比较繁琐了，用类型缩写更清晰。typechecker的时候当然需要展开来进行。ascription和casting也有一定关系。 增加各种简单的基础类型，比如String，还有Pairs，Tuple，Record， Sum，Enum，List。支持一种类型除了一个新类型名字外，其evaluation rules和type rules也要明确。这里的datatypes是按照Ocaml的语法来说明的。 因为加上了好多种类型，fullsimple这个解释器复杂多了。 Type DynamicEven in statically typed languages, there is often the need to deal with data whose type cannot be determined at compile time. This occurs in particular when the lifetime of the data spans multiple machines or many runs of the compiler—when, for example, the data is stored in an external file system or database, or communicated across a network. To handle such situations safely, many languages offer facilities for inspecting the types of values at run time. General Recursiontyped lambda-calculus加上fix combinator就是一门极小的但是是full abstraction的语言。Ocaml里面的letrec可以用来定义递归函数。fix point的概念需要继续理解。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"OCaml","slug":"OCaml","permalink":"http://catcoding.me/tags/OCaml/"},{"name":"PL","slug":"PL","permalink":"http://catcoding.me/tags/PL/"}]},{"title":"Understanding Computation","date":"2015-02-10T11:43:00.000Z","path":"2015/02/10/understanding-computation.html","text":"前些天花了一些时间读这本书《计算的本质：深入剖析程序和计算机》。总的来说这本书非常不错。虽然讲述的是一些看似理论的东西，里面有不少短小的Ruby程序，读起来还是非常有趣的。回想当年大学的时候有一门课程叫做形式语言与自动机，当时觉得这门课真是太没劲了。理论的东西终究需要一些实践才能掌握，早早读到这样的书就好了。 首先第一部分介绍了一些基本Ruby语法，十来页的介绍就够了。Ruby的语法真的是非常直观，人性化的。两年前我被Ruby吸引，现在我每天大部分时间都敲着Ruby代码，用Ruby很省事！对Ruby来说数据也是程序是很常见的，这本书使用Ruby来做示例是很好的选择。 什么是程序？这是一个可以从各个角度深入的问题，程序是程序员表达自己脑海中的思想的形式。我们需要从编程语言开始，语言的语法和语义完整地定义了一门编程语言。这本书开始以小步语义来解释一个简单的语言，这样就得到一个的解释器程序。小步语义提供了一种轻松的方式来模拟计算的中间过程。随后介绍了大步语义，我觉得这两者之间的关联有些像自顶向下和自底向上。然后介绍了treetop这个工具，自定义grammar来实现一个简单的语法解释器。 第三章开始介绍自动机，从最简单的确定性有限自动机开始(DFA)，然后是非确定性自动机(NFA)和正则表达式。我原来上学的时候大多在手动画这些状态图，远没这些简单的代码好玩。有输入，有状态，有输出，这些状态机就是最简单的机器了。而NFA虽然看起来比DFA有更多的特性，但本质上它可以转化为DFA。为了增加计算能力，为自动机加上一些外部存储。用自带栈的确定性有限状态机(DPDA)能识别出平衡字符串。 第五章介绍图灵机，图灵机本质上是有外部存储的状态机。我之前看过图灵传记，图灵对密码学非常感兴趣，而且在二战中破译了大量德军密电。图灵机的概念很简单，而计算的本质就是如此简单直接的描述。模拟图灵机的过程倒并没什么大的乐趣。 第六章开始lambda演算，lambda演算是从另外一个角度去理解计算。这一章非常好玩，这里只是用了Ruby的三个特性： 对变量的引用，创建proc，调用proc来实现一个极小的编程语言。lambda演算的基本元素就是这三个： &lt;exp&gt; ::= &lt;var&gt; :变量引用 | (lambda (&lt;var&gt;) &lt;exp&gt;) :创建proc | (&lt;exp&gt; &lt;exp&gt;) :调用proc 从这些简单的元素构建出语言的各种特性非常好玩，最终一个简单的gcd被解释成充满了proc的Ruby程序，然后就能运行了。 后面几章继续简述了可计算行问题。停机问题表明我们无法拥有能力不受限制的编程语言，淡淡的忧伤。 这位作者Tom Stuart的博客非常有料，他在自己的网站上用幽默了一把I Have No Idea What I’m Doing，这本书是这么写出来的。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Books","slug":"Books","permalink":"http://catcoding.me/tags/Books/"}]},{"title":"广告","date":"2015-01-19T11:43:00.000Z","path":"2015/01/19/refer.html","text":"我到了一个做无人机的公司工作，叫做大疆创新(DJI)。最近内部有一些推广活动，有感兴趣的朋友了解一下。 大疆精灵 这页面我隔壁小伙子做的，看起来还不错 :) Phantom系列是公司卖得最好的一款产品，市场主要在欧美。 这个东西挺好，比如能拍出这样的照片：stacy-s-breathless-moment。 https://www.skypixel.com/#/photos这里是大量用户上传的航拍照片。从不同的视角来欣赏地球，自有另一番风景。 当然如果以后还能做得更好，或许可以这样自拍了: DJI 云拍 Inspire是下半年出的产品，这个还是挺惊艳的。设计很前卫，4k镜头，操作灵敏且稳定性极佳。不过价格也不便宜，接近2w了。 “悟” INSPIRE PHILIP BLOOM DJI Inspire 1 – “Soar” This is the most amazing drone we’ve seen yet 顺便，再分享一个好东西给大家。大家都知道我们外面有个墙，红杏出墙就是个梯子。 我用了一段时间了，挺方便的。 所以在这里推荐一下，可以用这个链接注册。","tags":[]},{"title":"Rust coming to 1.0","date":"2015-01-10T11:43:00.000Z","path":"2015/01/10/rust-10-alpha.html","text":"Again, one article just for writing practice. :) Rust-lang release alpha 1.0 today. Rust aims to be a systems level programming language to replace C and C++. I hit Rust-lang about two month ago, and found it’s a funny language. Then I read some Rust code and also wrote a hobby project with it. There are several feature attract me: Write low-level code with safety guaranteesRust have the concept of onwership. For the resource in computation(this is usually refer to memory, file handler etc), the should be an owner. Rust try to solve the common errors caused by pointers in C/C++, such like dangling pointer, unfree pointer, double free issues. The borrow checker in compiler will keep the resource onwership move correctly with some rules. for more details please refer to offical guide. So as a newbie, writing code in Rust code seems always fighting with compiler. We can not just write code and then fix the memory later, the compiler refuses to accept anything which maybe unsafe, but this also make me think more about the code and design.By the way, the error hints from compiler is very helpful, this is not like C++(specially templates got in). There are some comparisons between Go and Rust, Gc is optional in Rust, compare Rust with Go is not sensible. Recent changes of removing runtime make Rust lower level. There are even some hobby projects writting OS with Rust, refer to this and this. High level abstraction for system programmingAs a modern system programming, Rust is surprisingly expressive. I like the Ruby syntax, Rust has the same similarly mind-blowing effect. Rust carry some functional programming concepts, these make code looks just simple and elegant. Let’s have some trivial code snippet: // construct array with 0 3 6 ...let v = (0..10us).map(|x| x * 3).collect::&lt;Vec&lt;_&gt;&gt;();for i in v.into_iter() &#123; println!(&quot;&#123;&#125;&quot;, i); &#125; // construct array with random valuesuse std::rand;let v = Vec::from_fn(10, |_| rand::random::&lt;uint&gt;()); Pattern match is so elegant:match number &#123; 1 =&gt; println!(&quot;One!&quot;), 2 | 3 | 5 | 7 | 11 =&gt; println!(&quot;This is a prime&quot;), 13...19 =&gt; println!(&quot;A teen&quot;), _ =&gt; println!(&quot;Ain&#x27;t special&quot;), &#125; Colsures, reminds me with Ruby’s block:fn main() &#123; let captured_value = 7u; let closure = |&amp;:argument| &#123; println!(&quot;I captured this: &#123;&#125;&quot;, captured_value); println!(&quot;Argument passed was: &#123;&#125;&quot;, argument); true &#125;; println!(&quot;Closure returned: &#123;&#125;&quot;, closure(&quot;a string&quot;));&#125; Almost every statement is an expression, this means that the statement returns a value. Blocks are also expression. This is good thing, we may write less “return”! Mixing with pattern match ends with a better sugar. Of course, nice syntax doesn’t really mean real expresiveness, There are more abstraction tools in Rust, like traits, macro definiation, generic types etc. I have tried some macros for testing in rust-scm. High SpeedI have found my favorite interpeter language, it’s Ruby. But in real world, we need to write some code need critical time performance. For this kind of task, Rust maybe a good choice. Benchmarks show Rust is almost as fast as C++. CommunityThe Rust have a small, but exciting, openly community. The language have been evolving several years, most design discussion are open source. The core team seems nice. Have a try for Rust.","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Rust","slug":"Rust","permalink":"http://catcoding.me/tags/Rust/"}]},{"title":"lcc阅读记录","date":"2014-09-14T11:43:00.000Z","path":"2014/09/14/a-retargetable-c-compiler-design-and-implementation.html","text":"之前看EOPL感觉收获挺大，最近又花业余时间看了看编译相关的东西，这是我看lcc的时候顺手记下的一些自己的理解。这本书《A Retargetable C Compiler》还挺大头的。lcc代码量不是特别大，更复杂的是tinyCC，tinyCC甚至可以直接运行C代码。 alloc.c为了尽量的少调用系统调用，在alloc基础上封装了一下。 sym.c用来存储symbol，注意scope的表示方法。 input.c为了减少读取文件的开销，用一个buffer来缓存源文件内容。cp表示当前读取出来的字符位置，limit表示缓存的结尾字符位置，如果fillbuf一次以后仍然cp == limit则表示读取文件到EOF了。 注意这里的fread读取的时候是通过stdin的，但是在main.c/main_init函数的时候通过freopen将源文件重定向到了stdin。 fillbuf其实读取的时候是永远先把内容读取到buffer[MAXLINE+1]的位置，如果发现cp &lt; limit就把前面剩下的内容往前移动，这样永远保证buffer足够下一次预读取,这里有点巧妙。 比较复杂的部分是处理resynch，input处理的内容是经过C语言预处理器的，这部分没有包含在这个编译器内。 lex.c一个完全是手写的C语言Parser，虽然只是兼容C99，但手写还是比较复杂的。码农约架比写Parser是个体现实力的比赛。 getchr逐个字符读取，cp就是input.c里面的当前字符。跳过BLANK，如果碰到NEWLINE则调用input.c读取下一行。 token.h看起来有很多列，这个文件被多个地方用到。是用宏来生成一些Enum里面的代码。比如token type和expr type。 gettok顾名思义在lex运行的时候不断提供一个一个的token，这主要是通过cp匹配map来判断，条件分支很多(依据当前的第一个字符)。register unsigned char* rpc存储当前字符。register作为一个对编译器的提示，尽量用register来存储变量。事实上现在的编译器很多都能做auto register allocation，有的时候编译器的选择可能比人的选择更好。register在老的C代码里面可能更为常见。 这个函数里面很多地方都用到了goto，主要是在匹配关键字的时候区分identifier。主要几大类是: number, keyword, identifier, string。 icon处理数字的前缀，fcon处理浮点数。 Lexical analyzer基本理论是自动状态机，没一个token可以根据相应的正则表达式来表示。有一些工具可以用来自动生成这些繁琐的代码，比如LEX，更新一些的有Flex和re2c。 error.c终于来到Parser部分了，lcc使用的是recursive-descent，很多商业的编译器都是用的这种直观的算法，事实上对于大部分语言都足够了。recursive-descent是自上而下的递归的，依据当前的token匹配语法结构。一个重要的问题是如何在处理的过程中给出适当的错误信息。error.c里面的函数test和expect用来测试下一个token是否是预期的,expect可以打印出错误信息。 tree.c最重要的数据结构struct tree，AST中的基本节点，包含子节点，和operator类型(比如AND，OR，NOT等）。在构建AST的时候root函数经常被用到。 expr.c enode.cparser的一部分，用来识别表达式。代码好复杂，和paresr有些类似，整个过程是构建AST。编译器的前端最重要的事情就是这了，后面的操作都是在这个基础上做的。为什么Scheme/Lisp的front部分比较简单，因为这货代码就和AST有些类似了，括号把一个一个的节点组合了起来。初看起来很难看，其实习惯了还好。 上面说的是语法的识别，在构建AST的过程中另外一个事情就是语意的分析。包括类型检查，类型的转换，操作符优先级等，这些也在构建AST的时候顺便做了。比如在遇到expr1 ? expr2 : expr3的时候，expr1的值最后被cast成一个bool。指针之间的隐式转换也比较复杂。function call比较复杂，这里还做了函数参数的写法是否是老的风格，类型说明放在函数头的最后。assignments和binary operator的分析相对来说简单一些，需要做各种cast。 前些天稍微看了一些Erlang，发现里面的类型推导比较好玩，甚至可以发现一些代码里面的逻辑错误： 比如： fact(0) -&gt; 1;fact(N) -&gt; N * fact(N-1).test() -&gt; fact(-5). 不用运行Erlang的dialyzer就可以发现这里面的死循环，因为可以通过上面的定义推断出fact的参数是non_neg_integer,而-5是不符合的，所以报出来一个错误： fact(-5) will never return。 stmt.ccodelist为双向列表，遇到新的执行块就加到这个列表上。在处理control-flow的过程中有的死代码块是可以被编译器发现的，只是我们平时都被忽略了。 比如C代码:int loop() &#123; Loop: goto Loop; return -1;&#125;int main() &#123; printf(&quot;loop: %d\\n&quot;, loop()); return 0;&#125;loop永远不会返回，Gcc选项-Wsuggest-attribute=noreturn可以报出一个warning。 decl.c声明是C语言中最难解析的部分，原因是声明涉及到变量和类型，而从C声明中弄出类型信息还是挺复杂的。另外声明还分局部，全局，其中还涉及到函数参数，结构体等。decl.c可能是最复杂的文件了，1100多行代码，里面的函数之间又相互调用。finalize()函数最后检查是否有重复定义的变量。 dag.clcc的intermediate code是用listnodes把前面parser的tree转换为DAG，最终整个程序会经过转换变成由多个DAG组合成的森林。listnodes还负责把一些公共的sub-expression简化。 接口为gencode,emitcode。后面每一个代码生成的后端都是一个Interface结构，在function函数里面调用这两个函数生成汇编代码，其中还包含一个Xinterface成员，这是平台相关的接口。 小结到现在我只是大概看了了前端和中间层，后面lcc跨平台的指令生成还没来得及研究，这本书的电子版不是很清晰，还是买个中文版来再稍微看看。总的来说，lcc是的Parsing和语义分析是同时进行的，就是所谓的one-pass方法。现在很多编译器所用的方法是先建立AST，后面可能要多次遍历整个AST进行分析，LLVM好像就是采用的这种方案。另外代码的优化是一个trade-off，作为教学用途的lcc没有过多做代码优化，这样lcc代码还是可以花不多的时间来一个大概的学习。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Compiler","slug":"Compiler","permalink":"http://catcoding.me/tags/Compiler/"}]},{"title":"折腾服务器","date":"2014-08-01T11:43:00.000Z","path":"2014/08/01/install-server.html","text":"最近花了一些时间研究机器的部署，主要是实践了网络安装服务器和OpenStack部署。 网络安装Ubuntu如果有多台服务器，网络安装似乎是唯一的选择。基本原理就是在局域网里面配置一个host，里面配置好一个HDCP服务和TFTP服务，用Apache弄一个系统镜像供服务器下载。当然这里面有许多许多的坑，一个一个爬出来感觉还是挺好的。我把一些记录在了这个Gist里面。Kickstart用来自动化安装过程，这样安装过程中就不会弹出等待用户输入的对话款。总的来说就是： dhcp + tftp + web服务器 + ubuntu镜像 + kickstart : 局域网自动部署 弄这些似乎有点回到从前的感觉，我在05年左右大二的时候开始折腾系统。那时候Ubuntu正在作推广，在校学生可以免费申请光盘。因此，从4.04开始所有的Ubuntu盘我都有一份，经常乐此不疲地安装。当然也安装过各种Linux其他发行版。有时候出现问题还会找一些学长来帮忙弄。现在想来挺浪费时间的，应该花时间来多学些基础的东西。 弄完这网络安装以后我就想，如果当年整个男生宿舍弄这么一个安装系统的服务器，那可是能节省很多同学的时间啊！ OpenStack 安装部署OpenStack号称下一个Linux，分为很多独立的部件组成，看起来是一套很复杂的系统。我们主要是想利用OpenStack来构建私有云。OpenStack的安装涉及到非常多的包，过程和配置都稍微有些复杂。所幸这里有一个比较成熟的安装脚本OpenStackGeek。是一些比较简单的shell脚本，我们在这个基础上自己做了一些默认配置，这样基本能够做到一键安装OpenStack。 其他运维做的事情虽然很杂，不过中间还是能学到不少东西，比如我在这些折腾过程中学到了一些网络知识。虚拟化技术真是很好玩，『云』这个东西其实并不只是一个大家炒作的概念，即使公司现在只是用OpenStack来弄个私有云，这其中的便利真是让人感叹。有了这一套机器资源真是挥之即来，用完即丢。每个服务独立跑一个虚拟机上，相互独立。","tags":[]},{"title":"Automatically cleanup the buffer for Eshell","date":"2014-07-29T11:43:00.000Z","path":"2014/07/29/buffer-size-limit-for-eshell.html","text":"Keep writing some simple thing in English, for I will have less chance for writing English words in daily working. I will always run eshell for shell tasks, because this is really like the normal buffer in Emacs, so all the command for Emacs will keep working for this buffer. This is convenient for some actions. The problem annoying me is that if the size of buffer for eshell is too big, Emacs will gets more and more slow. Emacs essentially is a sole process program. So I have some digg and written a trivial elisp code like this solved the problem. (defun clear-and-send-input() (interactive) (if (&gt; (count-lines 1 (point)) 800) (let ((inhibit-read-only t)) (message &quot;Clear the eshell now !&quot;) (erase-buffer))) (eshell-send-input))(add-hook &#x27;eshell-mode-hook (lambda () (local-set-key (kbd &quot;&lt;return&gt;&quot;) &#x27;clear-and-send-input))) clear-and-send-input is a wrapper for eshell-send-input, I set the maximal number of eshell buffer to 800, and I bind this function to , so every time if the buffer size is too big, this wrapper will automatically clean up the buffer. And yesterday I found this article Mastering Emacs in one year guideis really thought-provoking, Hope this may help you.","tags":[{"name":"Emacs","slug":"Emacs","permalink":"http://catcoding.me/tags/Emacs/"},{"name":"shell","slug":"shell","permalink":"http://catcoding.me/tags/shell/"}]},{"title":"A mini Scheme interpreter written in Go","date":"2014-06-28T11:43:00.000Z","path":"2014/06/28/scheme-go.html","text":"Scheme-Brained Hare 在我学Go的时候开始了一个自己的业余小项目，就是这个GoScheme，打算用Go来写一个Scheme解释器，因为重写轮子是学习新东西的好手段。现在基本完成了，当然只是一些基本的语法支持，没有宏。 我只是用这个项目来熟悉Go的语法，Go来做这种项目没有特别大的优势，这个项目用C来实现代码量会更少一些。比如这里个里面的基本数据对象包括各种类型，boolean, symbol, fixnum, proc等等，又都是一个Object类型。如果是C可以用union类型来表示，然后通过Object*实现接口上的统一操作各种数据，类似的代码像这样子： typedef struct object &#123; object_type type; union &#123; struct &#123; char value; &#125; boolean; struct &#123; char *value; &#125; symbol; struct &#123; struct object *car; struct object *cdr; &#125; pair; // .......... &#125; data;&#125; object; Go里面没有Union这种类型，所以我用了reflect来实现这些东西，看起来还不是那么简洁。Go的自带的一些toolset还可以，比如testing，format，coverage等，可以减少一些琐碎的事。 另外，以后项目里配一下travis-CI可以做集成测试。 Go更适合做一些需要并发的任务，比如服务端的事情。","tags":[{"name":"Scheme","slug":"Scheme","permalink":"http://catcoding.me/tags/Scheme/"},{"name":"Go","slug":"Go","permalink":"http://catcoding.me/tags/Go/"}]},{"title":"最近在用Go","date":"2014-06-22T11:43:00.000Z","path":"2014/06/22/go-dev.html","text":"最近一直在用Go做开发，我们打算整一套和Rails对应的Go开发框架。一些代码在我们的Github小组里有。这里的几个项目都用到了代码生成的方法，生成Go文件，最后的整个web程序被编译成一个可执行文件。我们正在用一个项目来验证这个想法。其中： 1. xuanwu(玄武)根据thrift文件产生对应MVC里面的Model。生成的go文件里面，一个thrift类型对应一个go里面的type struct，生成的代码中包含一些基本的方法，比如FindByID等等，这都是根据thrift文件定义的对象属性自动生成的。这里用到了ptsd来解析thrift文件，自己定义模板来生成Go代码。我后来加了crud.py和crud.tmpl来生成Controller的代码，这样MVC里面Model和Controller就都有了。不过对于Go这样的静态语言，生成代码这套方案有个难解决的问题就是如何在生成的代码基础上实现用户自定义。我们现在的解决办法是另外写一个对应的fix文件，在里面写入自己要重写的函数，另外写一个程序根据gen文件和fix文件来做一个基于函数定义的diff，如果用户定义了就忽略自动生成的函数。好绕的方法，不过因为Go库里面自带的的parser和AST，做这么一个diff程序还挺简单的。 2. gorazor(白虎)功能是MVC里面的view engine，从C#里面的razor模仿而来，具体为什么要这么做这个详细的中文文档里面说了。有了这个东西我们可以混着html写Go代码了。我是从这个项目开始正式学习Go的，整个开发过程还是比较顺利的。刚开始lexer大量使用了正则表达式，后来发现速度有些受影响就手动写了一部分。parser部分现在还有些难看，后面继续重构一下。Debug一直都是Println，很多时候已经够用了。 3. web在web.go的基础上做了一些自己的修改。 再说一下使用Go的一些感受，大部分时候是很爽的。对于喜欢C和Python的人来说上手Go是很容易的事情。Go更像是一个更现代化的C(而不是C++)，因为简洁是其一个重要特性。和Python相似的地方是提倡一种事有一种解决方法，而不像Ruby那样有各种魔法写法，所以看别人的代码容易一些。Go对代码的格式化有一些强制约定，但是缩进并不是语法的一部分，而是通过gofmt工具来自动纠正格式，这太方便了。再加上goimport这样的工具来自动加上或者移除不必要的import，我现在写Go代码的时候基本不需要关心格式和import这些琐事，绑定Emacs快捷键保存文件以后基本都解决了。 Go的编译速度很快，我的机器上这里20w行左右的Go代码基本编译在13s左右，这和C++比起来要快很多很多。 其他我是这么配置Emacs的Go相关的东西的 其中go-autocomplete是来自动补全的，对于内置的库函数补全还是很好的。有的自定义的补全不出来。 goimports修正import的。 gocover是我自己写的一个程序，看到同事写在Vim里写Go代码的时候一个快捷键就跑相关的pkg的testing，并把结果打印出来。对于Go的这么快的编译速度，真的可以边写代码迅速按下快捷键测试的结果就出来了(还包括coverage噢)。于是我也写了个程序分析出当前编辑文件对应的package名字，设定好GOPATH，然后去tmp目录跑测试。这个程序就是gocover，我绑定到C-x g，太方便了。 Vim和Emacs的可扩展，是我们这群装逼党依然坚持用这些老古董的原因。因为可扩展意味着将来要面对新的编程语言和环境时候，我们可以做出自己改变来适应。 好的Go上手教程: Go by Example","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Go","slug":"Go","permalink":"http://catcoding.me/tags/Go/"}]},{"title":"Visualize Git Projects with Ubigraph","date":"2014-04-18T11:43:00.000Z","path":"2014/04/18/visualize-git-proj.html","text":"一个比较大的项目一般都由一群人协作开发，开发人员可能活动于各个模块之间。前两天突然想起如果把一个工程的所有commit数据提取出来，然后按时间顺序动态演示出来可能会比较好玩。从这个过程中我们可以看到一个项目是如何进化的，各个开发者到底在折腾哪些模块。比如这是一个多个开发者参与的一个项目展示图，其实是3D动态的。 我写了两个脚本来做这件事情，代码放在这里了。第一个脚本是Ruby写的gitstat.rb，用来提取git的commit数据，这些信息包括：提交者名字，日期，增加的行数，删减的行数，相关的模块。所有这些数据都按照提交的时间排序，然后输出到一个文本文件里。使用方法是: $./gitstat.rb -l eventmachine,tinyrb -o log.txt -l后面是模块名字列表，如果不加-l脚本会自己检测出当前文件夹下所有的.git，每一个目录当做一个模块。log.txt的格式看起来像这个样子： Francis 2008-07-28T16:57:15+00:00 1 1 eventmachineFrancis 2008-07-28T17:03:46+00:00 2 0 eventmachineFrancis 2008-07-29T23:34:53+00:00 3 1 eventmachineMacournoyer 2008-07-31T23:34:52+00:00 13 47 tinyrbMacournoyer 2008-08-01T00:36:27+00:00 32 0 tinyrb 另外一个脚本就是gitshow.py用来从文件中读取数据，然后发送给Ubigraph渲染。 Ubigraph可以从官方网站上下载，解压后会看到一个example目录，里面有几种语言的示例。使用方式是： $./bin/ubigraph_server [在Ubigraph目录启动服务端]$./gitshow.py log.txt 这里开发者用圆球表示，模块用多边形球表示，并且颜色加以区分。另外加入了一点效果就是当开发者有提交的时候，其颜色闪红一下，同时开发者和模块之间加上一条虚线。并且开发者和模块的体积会随着代码改变量而增大，这样也能看出哪些模块工作量比较大(当然用行数来衡量工作量本身并没有多大参考价值，只是为了效果)。 对于一个多人参与的项目也可以看出一些好玩的信息来，如果一个开发者贡献大其体积越大，而且离项目的节点越近，比如eventmachine的演示图如下： 有一个类似的开源的C++项目叫做: Gource，效果做得很漂亮。","tags":[{"name":"Tools","slug":"Tools","permalink":"http://catcoding.me/tags/Tools/"}]},{"title":"Heartbleed简单分析","date":"2014-04-11T11:43:00.000Z","path":"2014/04/11/heartbleed.html","text":"这几天不断听到一个词“心血漏洞”，近年来影响最严重的互联网漏洞。今天小小地研究了一把，顺便把引起一些思考记录下来。 到底是什么样的代码有一些C语言和开发经验的朋友看看这个Fix就能了解些具体细节了。在网络传输中有一个叫做心跳的概念，简单来讲就是客户端发送一个简单的心跳包给服务端，服务端又返回给客户端，然后客户端检查传回来的内容是否是预期，这样就知道了当前的TLS通信是否正常。这个Bug不是协议的问题，而是具体实现的时候的遗漏了相关的逻辑。 这个函数dtls1_process_heartbeat就是处理这块代码的，先读出长度和包类型，然后申请一段内存空间做一个memcpy，其中长度为write_length, 而这里遗漏的就是这个长度的合法性检查。 /* Read type and payload length first */ hbtype = *p++; n2s(p, payload); pl = p; unsigned char *buffer, *bp;unsigned int write_length = 1 + 2 + payload + padding;buffer = OPENSSL_malloc(write_length);bp = buffer;/* Enter response type, length and copy payload */*bp++ = TLS1_HB_RESPONSE;s2n(payload, bp);memcpy(bp, pl, payload);bp += payload;/* Random padding */RAND_pseudo_bytes(bp, padding);r = dtls1_write_bytes(s, TLS1_RT_HEARTBEAT, buffer, write_length); 可以想象如果客户端发送一个长度为很大的数，而实际给的内容还是在符合范围内的长度，而memcpy仍旧拷贝了一个比较大范围的内存空间(因为申明的包长度类型这里最大为64K)。而这个临近的内存空间存的是些什么东西就不确定了，偶尔可能包含一些敏感信息，比如用户密码等等，这些数据有一定特征，是可以通过一定手段检测出来的。这个Bug的名字很形象，就像是血从服务器这个身体里慢慢渗出来一样。 这个简单的长度检查遗漏照理来说应该会被发现，因为内存如果越界了可能会引起SegmentFault。但是OpenSSL有一个自己的内存分配器。可以想象OpenSSL先开辟一大块内存，后面的内存使用再自行分配。这样memcpy即使超出了预订的范围也没有造成问题。 影响有多大OpenSSL作为一个基础设施，世界上大量现存的网络相关的软件都在使用，特别是一些服务器。光Apache和nginx就占了Web server的66%，甚至还包括Email服务器(SMTP,POP, IMAP协议等)，VPN，和一大堆的客户端软件。这些都使得大量用户的密码有可能泄露。各个互联网公司都在为自己的产品打patch来解决这个潜在的风险。用户也有可能要再修改自己的密码来规避风险。 如何避免这样的Bug这个Bug引起了一些争议，是否开源软件存在更大的风险。因为这个Bug如果是在私有软件里，可能不会一下引起这么多人的关注，整个互联网也不必整个为此patch一遍。 对于程序员来说，如何避免这样的Bug? Redis的开发者Antirez的这篇文章Using Heartbleed as a starting point 写得挺不错，公司应该投入更多的资金在这种关键的涉及到安全的代码上，OpenSSL每年接收到的资助为2000美金。系统程序员和测试人员应该使用一些静态代码分析器，另外动态检测器(比如Valgrind)也很有帮助。因为C是一个贴近硬件的语言，可以在C上再增加一个抽象层来保护关键信息。Random测试有可能发现很多软件中潜在的问题，单元测试有可能测不到这种情况。我现在工作的公司对于测试这块还是做得挺不错(这也与我的产品特性有关，测试相对容易一些)，我们每天晚上除了跑单元测试，还需要跑Valgrind来检测内存问题，还有大量极端的random case可以发现很多Bug。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Bug","slug":"Bug","permalink":"http://catcoding.me/tags/Bug/"}]},{"title":"另一本魔法书: EOPL","date":"2014-03-29T11:43:00.000Z","path":"2014/03/29/eopl.html","text":"概述很多学习计算机的同学都知道有一本号称魔法书的经典教材叫作《SICP》，《计算机程序的构造和解释》，MIT的计算机入门课程用的教程。这本书内容广泛而深邃，从出版几十年来影响了很多程序员。今天介绍另外一本我认为也是魔法书的教材，叫做《Essential of Programming Language》，简称EOPL，当然能获得简称的书都是不简单的。这本书虽然也年代久远，但是知名度不如SICP高。其作者是Dan Friedman，就是那位王垠同学的导师。这位程序语言领域的大牛写过很多Scheme相关的书籍，比如《The Little Scheme》系列，这个系列广受好评，可能很多人都读过。 我读的是EOPL3，据说这个版本稍微有点冗长，不过我还没读过前面的版本，所以对此不好评价。EOPL主要关注程序语言的方方面面，一共分为9章。这本书的讲解方式是先稍微概述主题，然后会有相关语法的定义，然后是关键代码的实现。这里同样采用了Scheme来讲解。用Scheme的好处的我们可以站在一个更抽象的角度来编写程序(Scheme如此强大，可以定义自己的语法，比如这里面的define-datatype和sllgen)。你可以看到这本书在反复折腾各种解释器，里面都是在往一个简单的解释器添加各种特性。 预备基础阅读这本需要一些简单的Scheme基础，不过对于有一些编程经验的人来说不难。我推荐这本Teach Yourself Scheme in Fixnum Days。Scheme的基本元素很少、内核简单（用Scheme写一个能自身的元解释器非常容易），这和象棋有些像：规则简单，组合变化多。至少需要了解以下Scheme的基本内容 递归思想递归不只是理解程序的一种方式，同样也是写程序的一种方式。在EOPL中到处都是递归，解释器执行的过程是递归，里面的Checker也是递归。递归无处不在。 高阶函数在函数式编程语言中，函数和变量一样也是一等公民。在Scheme里函数可以接收函数作为参数，可以把函数作为返回值。在EOPL中的envrioment可以用函数来表示。 代码即数据 数据即代码抛开效率不说，用List可以表示很多数据结构。用Scheme的一个好处，就是代码和数据几乎没有界限，比如Parser部分，因为书里自带的sllgen如此强大，要修改语法的定义是如此的简单。而Parser出来的结果就是语法树，这语法树同样是个层层嵌套的表，解释器把这个作为输入就行了。 各章内容Abstraction前两章都是基础准备，介绍了如何用递归来做抽象，包括定义和相关数据结构的实现。比如Enviroment，这不过是在一个小的envrioment上添加一个新的绑定。仔细思考那种用高阶函数的表示方法，这在以前的语言中不常见。 Expression基本的解释器，但这个解释器是后面章节的基础。到这里这个简单的语言已经可以支持递归了。 State实现了一个简单的store，用来映射variable到value。接着讲述call-by-value, call-by-reference。到这里你可以看到程序语言中指针到底是个什么东西，以及这到底是如何实现的。 CPSCPS内容比较难理解，但是CPS也是一个很有用的概念。可以看到使用CPS使得程序的空间固定，如何使用CPS来实现多线程。后面一章也是关于CPS的，实现了一个通用算法来进行CPS转换。 Type System为语言添加类型的好处，类型推倒如何实现，用替换法来做的一个简单的Type Checker。 Module如何从语言层面支持Module，以及面向接口编程。 OO面向对象和接口是如何实现的，在这里OO的实现看起来是有点繁杂，通过实现OO来看清楚本质。 习题这本书有很多习题，每一个题目都有相应的星号标示难度，三颗星的习题大部分还是需要很多思考。这里大部分习题都是需要coding，在解释器里添加一些新的特性，往往需要一些简单的代码修改即可。 我做了大部分习题，https://github.com/chenyukang/eopl，不敢保证全是正确的代码，可供参考。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"}]},{"title":"关于随机数","date":"2014-03-06T11:43:00.000Z","path":"2014/03/06/random-number.html","text":"随机数代表着不确定性，其在计算机中广泛使用，比如用作加密的key、密码的生成、模拟，扑克游戏中，还有一些经典的算法(比如Monte Carlo)依赖随机数的产生。以下是一些随机数相关的问题简单总结。 随机数产生，真随机数和伪随机数生成器随机数的产生是一个很有趣的问题。我们希望只通过计算机来产生随机数的时候会有一些困难，计算机擅长做确定的事情，按照制定的指令去依次执行。有两种产生随机数的方法，真随机数和伪随机数，这两种有各自的优点和缺点。 伪随机数生成器(PRNG)，顾名思义产生的不是严格意义上的随机数，一般是通过一些数学公式(或者计算好的表)来产生。比如简单的Linear congruential generator，可以用来产生伪随机数。伪随机数的行为是可被预测的，但是在统计意义上来说是随机的。因为这个特点其所以使用范围有限，比如一些模拟程序。而且伪随机数有可能出现固定的周期，比如下面这两幅图分别是通过真正的随机数产生器和Windows下面的PHP的伪随机数生成器产生的Bitmap，可以清楚地看到右边的那副图有规律可循。 另外如Borland随机数生成器Random的实现:long long RandSeed = #### ;unsigned long Random(long max)&#123; long long x ; double i ; unsigned long final ; x = 0xffffffff; x += 1 ; RandSeed *= ((long long)134775813); RandSeed += 1 ; RandSeed = RandSeed % x ; i = ((double)RandSeed) / (double)0xffffffff ; final = (long) (max * i) ; return (unsigned long)final;&#125;可以看到Random的最初一个随机数依赖于seed，后一个随机数依赖前一个随机数。 真随机数生成器(RNG)，通过向计算机中引入一些不可预测的物理信息，比如键盘敲击和鼠标移动等。所以真随机数才是很难预测的或者根本来说不可预测。每个操作系统的实现有各自的区别，比如Linux中产生随机数引入了物理噪音作为输入，比如mac地址可以用来初始化entropy pool，随机源可以加入中断时间，硬盘的寻址时间等等。接口是/dev/random、/dev/urandom、get_random_bytes()，其中get_random_bytes在内核中使用。/dev/random和/dev/urandom的区别是/dev/random强度更大并且是阻塞的，因为要收集更多熵。 随机数的使用涉及到随机数的程序要特别小心。比如一个很简单的程序，我们知道C语言中的rand()产生的随机数是有范围的，0～32767，如果我要生成范围在0～10的随机数如何做？可能你会简单认为rand()%10可以得到(惭愧我以前也这样用的)，但是这真的是随机的吗？如果你把0～32767的所有数字依次%10，统计一下可以发现有的数出现的次数要大一些，因此最后出现某些数的概率相应的要大一些。 另外一个思考题，给一个rand()可以产生[1, 5]之间的随机整数，利用这个rand产生[1, 7]之间的随机整数？ 另写一个抽奖程序，从30w个用户中随机抽取10w个中奖用户？ 写个好的洗牌程序不容易 写一个对的洗牌程序看起来很容易，其实不然。Robert Sedgewick说过： &quot;That&apos;s a pretty tough thing to have happen if you&apos;re implementing online poker. You might want to make sure that if you&apos;re advertising that you&apos;re doing a random shuffle that you go ahead and do so.&quot; —Robert Sedgewick, Professor of Computer Science, Princeton 比如ASF Software在多年前写的一个流行的网上扑克游戏，其中的洗牌程序是这段Pascal代码： procedure TDeck.Shuffle;var ctr: Byte; tmp: Byte; random_number: Byte;begin &#123; Fill the deck with unique cards &#125; for ctr := 1 to 52 do Card[ctr] := ctr; &#123; Generate a new seed based on the system clock &#125; randomize; &#123; Randomly rearrange each card &#125; for ctr := 1 to 52 do begin random_number := random(51)+1; tmp := card[random_number]; card[random_number] := card[ctr]; card[ctr] := tmp; end; CurrentCard := 1; JustShuffled := True;end; 可以分析一下这里的好几处问题，这里的洗牌算法也有问题，52!个排列出现的概率不一样。拿三张牌来作为例子就明白了。 for (i is 1 to N) Swap i with random position between 1 and N 可以看出231, 213, 132出现的次数要多一些，因此相对应的概率也大。 正确的洗牌程序算法是： for (i is 1 to N) Swap i with random position between i+1 and N 一个32位的数作为seed，对于伪随机长生器是有问题的，因为如果给定seed伪随机产生器的行为是可以预测的。32的seed的所有可能值的个数为2^32个，这相比52!(8.0658 * 10 ^ 67)小得很多。所以对于32位的seed，甚至可以用蛮力法来攻破。 其他摘自&lt;&lt;思考的乐趣&gt;&gt;10个人坐在一起谈天，突然他们想知道他们的平均年薪是多少，但每个人都不愿意透露自己的工资数额，有没有什么办法让他们能够得到答案，并不用担心自己的年薪被曝光？一个简单的协议模型，当然与随机数有点关系。 参考： Wiki: Random number generation。 How We Learned to Cheat at Online Poker: A Study in Software Security。 顾森, 思考的乐趣。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Algorithms","slug":"Algorithms","permalink":"http://catcoding.me/tags/Algorithms/"}]},{"title":"LeetCode: anagrams","date":"2014-01-14T11:43:00.000Z","path":"2014/01/14/leetcode-anagrams.html","text":"LeetCode这个题目想出来一个好办法，题目的意思是输入一组字符串，把他们按照Anagrams归组出来，Anagrams的意思是字母相同，排列不同的两个字符串。 比如：aabcbaaccbaa 这些都是anagrams的。如果两个字符串是满足这种关系的，那么把字符串排序后的结果一定相同。因此想到用一个map去存来。 class Solution &#123;public: vector&lt;string&gt; anagrams(vector&lt;string&gt; &amp;strs) &#123; typedef map&lt;string, vector&lt;string&gt; &gt; Dict; vector&lt;string&gt; res; Dict S; for(int i=0; i&lt;strs.size(); i++) &#123; string tmp = strs[i]; sort(tmp.begin(), tmp.end()); if(S.find(tmp) == S.end()) &#123; S[tmp] = vector&lt;string&gt;(1, strs[i]); &#125; else &#123; S[tmp].push_back(strs[i]); &#125; &#125; for(Dict::iterator it = S.begin(); it != S.end(); ++it) &#123; vector&lt;string&gt;&amp; vec = it-&gt;second; if(vec.size() &lt;= 1) continue; res.insert(res.begin(), vec.begin(), vec.end()); &#125; return res; &#125;&#125;;","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Algorithms","slug":"Algorithms","permalink":"http://catcoding.me/tags/Algorithms/"}]},{"title":"正则表达式匹配和NFA/DFA","date":"2014-01-04T11:43:00.000Z","path":"2014/01/04/regular-expression-matching-dfa.html","text":"正则表达式匹配是一个经典问题，这里有一个问题。实现isMatch，其中.表示任意一个字符，*表示0个或者任一个前面的字符： isMatch(&quot;aa&quot;,&quot;a&quot;) → falseisMatch(&quot;aa&quot;,&quot;aa&quot;) → trueisMatch(&quot;aaa&quot;,&quot;aa&quot;) → falseisMatch(&quot;aa&quot;, &quot;a*&quot;) → trueisMatch(&quot;aa&quot;, &quot;.*&quot;) → trueisMatch(&quot;ab&quot;, &quot;.*&quot;) → trueisMatch(&quot;aab&quot;, &quot;c*a*b&quot;) → true 这是一个正则表达式问题的简化版本只有.和*，可以用递归来解决。正则表达式涉及到自动机理论，顺便再复习一下当年没好好学的东西。查找一番后发现了这篇Russ Cox写的文章非常好(这家伙写了不少文章，xv6里也有他的代码，现在在为Go项目工作)。于是我也尝试着用DFA来解决这个问题。 DFA和NFA的概念首先对于没一个正则表达式都有一个对应的DFA可以来表示, DFA是Deterministic Finite Automaton的简称，还有NFA(Non-deterministic Finite Automata)。NFA对于一个字符的输入有可能存在多个以上的状态转移，而DFA对于没一个输入只存在一个选择。所以每一个NFA都可以转化为一个DFA，但是一个DFA可以转化为多个NFA。我们来看一个例子: 对于正则表达(a|b)*abb的NFA和DFA分别表示为： DFA的状态数目和NFA一样，但是一般实践过程中DFA的状态转移要多，所以DFA相对来说要难构造一些，同时DFA比NFA需要的内存空间更大。正因为在NFA中一个状态可能向多个状态转移，在极端的情况下其效率比不过DFA。更多关于正则分类可以参考正则表达式引擎及其分类。 对于NFA不同的实现效率会不一样，这也是Russ的文章里所说的。Russ的文章里面介绍了Thompson NFA算法实现(没错就是发明C的那神)，一些老的Unix工具是用的这个算法，比如Awk，Tcl，GNU grep等，而一些更通用的编程语言用的是基于回溯的一种NFA实现，比如Perl/Python。通过数据比较，在最坏的情况下用Thompson NFA实现的awk表现比匹配回溯的NFA要好很多倍。最坏情况下的复杂度不一样，回溯NFA是O(2^N)，而Thompson的复杂度是O(N^2)。文中的代码可以号好看看，非常简洁的C实现。 一个尝试实现对上面那个问题我尝试着实现了一个程序构建DFA来解决，提交上去完成439个测试用例只用了28ms，相对于递归版本的需要104ms。也可能LeetCode上面的测试数据太少，比较的意义不大。代码长度当然要比递归的长不少。定义State： enum OpType &#123; ZERO_PLUS_ONE, ANY_ONE, MUST_ONE&#125;;struct State &#123; OpType type; int id; char value; bool end; State* prev; vector&lt;State*&gt; next; State(OpType t, int i, char v, State *p) : type(t), id(i), value(v), end(false), prev(p) &#123; if(type == ZERO_PLUS_ONE) next.push_back(this); //匹配任意个 next加上自己 if(p == NULL) prev = this; &#125; void add(State* n) &#123; next.push_back(n); if(type == ZERO_PLUS_ONE &amp;&amp; prev != NULL) //匹配任意，前驱加上当前需要添加的状态 prev-&gt;add(n); &#125;&#125;; 构建DFA的过程如下，注释的部分需要注意： State* construct_dfa(const char* pattern) &#123; if(pattern == NULL) return NULL; const char* p = pattern; State* start = new State(ANY_ONE, Num, &#x27;.&#x27;, NULL); State* cur = start; State* next = NULL; char prev = &#x27;.&#x27;; Num = 1; while(*p &amp;&amp; *p != &#x27;\\0&#x27;) &#123; if(*(p+1) != &#x27;*&#x27;) &#123; OpType type; char value; if(*p == &#x27;*&#x27;) &#123; type = ZERO_PLUS_ONE; //匹配0个或者多个 value = prev; &#125; else &#123; value = *p; type = *p == &#x27;.&#x27;? ANY_ONE : MUST_ONE; //匹配任意一个. 或者指定的字符 &#125; next = new State(type, Num, value, cur); prev = *p, p++; &#125; else &#123; next = new State(ZERO_PLUS_ONE, Num, *p, cur); prev = &#x27;*&#x27;, p+=2; &#125; cur-&gt;add(next); cur = next; Num++; &#125; cur-&gt;end = true; // 例如 ab*a*c* 对于 &quot;a&quot;， 即使后面几个*, &quot;a&quot;也算是一个end， while(cur-&gt;type == ZERO_PLUS_ONE) &#123; cur = cur-&gt;prev; cur-&gt;end = true; &#125; return start;&#125; 匹配的过程就是一个搜索的过程，需要注意避免重复访问，另外如果下一层要访问的为空就可以退出整个搜索过程了，整个代码看这个Gist。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Algorithms","slug":"Algorithms","permalink":"http://catcoding.me/tags/Algorithms/"}]},{"title":"Kernel analysis: Defunct Process","date":"2013-11-23T11:43:00.000Z","path":"2013/11/23/kernel-analysis-process-defunct.html","text":"我发现带着问题去看内核代码比较容易理解。如果一个父进程显示的设置SIGCHLD为Ignore，子进程将自己清理自己。 #include &lt;signal.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;int main() &#123; struct sigaction sa; memset(&amp;sa, 0, sizeof(sa)); sa.sa_handler = SIG_IGN; sigaction(SIGCHLD, &amp;sa, NULL); int pid = fork(); if(pid &gt; 0) &#123; printf(&quot;parent:%d\\n&quot;, getpid()); sleep(30); &#125; else &#123; printf(&quot;child:%d\\n&quot;, getpid()); sleep(4); &#125; printf(&quot;finished\\n&quot;); return 0;&#125; 我们可以顺便看看内核里面是怎么写的， linux/kernel/exit.c里面这部分是负责进程退出的，我截取了相关的代码： /* * Send signals to all our closest relatives so that they know * to properly mourn us.. */static void exit_notify(struct task_struct *tsk, int group_dead)&#123; bool autoreap; forget_original_parent(tsk); write_lock_irq(&amp;tasklist_lock); /* .... */ &#125; else if (thread_group_leader(tsk)) &#123; autoreap = thread_group_empty(tsk) &amp;&amp; do_notify_parent(tsk, tsk-&gt;exit_signal); &#125; else &#123; autoreap = true; &#125; tsk-&gt;exit_state = autoreap ? EXIT_DEAD : EXIT_ZOMBIE; /*..... */ /* If the process is dead, release it - nobody will wait for it */ if (autoreap) release_task(tsk);&#125; 其中有一段是判断是否autoreap，我们继续可以看看linux/kernel/signal.c里面的do_notify_parent函数: bool do_notify_parent(struct task_struct *tsk, int sig)&#123; struct siginfo info; unsigned long flags; struct sighand_struct *psig; bool autoreap = false; /* .... */ if (!tsk-&gt;ptrace &amp;&amp; sig == SIGCHLD &amp;&amp; (psig-&gt;action[SIGCHLD-1].sa.sa_handler == SIG_IGN || (psig-&gt;action[SIGCHLD-1].sa.sa_flags &amp; SA_NOCLDWAIT))) &#123; /* * We are exiting and our parent doesn&#x27;t care. POSIX.1 * defines special semantics for setting SIGCHLD to SIG_IGN * or setting the SA_NOCLDWAIT flag: we should be reaped * automatically and not left for our parent&#x27;s wait4 call. * Rather than having the parent do it as a magic kind of * signal handler, we just set this to tell do_exit that we * can be cleaned up without becoming a zombie. Note that * we still call __wake_up_parent in this case, because a * blocked sys_wait4 might now return -ECHILD. * * Whether we send SIGCHLD or not for SA_NOCLDWAIT * is implementation-defined: we do (if you don&#x27;t want * it, just use SIG_IGN instead). */ autoreap = true; if (psig-&gt;action[SIGCHLD-1].sa.sa_handler == SIG_IGN) sig = 0; &#125; if (valid_signal(sig) &amp;&amp; sig) __group_send_sig_info(sig, &amp;info, tsk-&gt;parent); __wake_up_parent(tsk, tsk-&gt;parent); return autoreap;&#125; 可以看到如果父进程对子进程的生死不关心，那么设置autoreap为TRUE，甚至这个信号也可以不发送了。","tags":[{"name":"Linux","slug":"Linux","permalink":"http://catcoding.me/tags/Linux/"},{"name":"Kernel","slug":"Kernel","permalink":"http://catcoding.me/tags/Kernel/"}]},{"title":"拓扑排序","date":"2013-11-20T11:43:00.000Z","path":"2013/11/20/topological-sort.html","text":"最近在看一些图算法，发现拓扑排序频繁出现，这里写一下自己的一些总结。 拓扑排序是对于有向无环图而言的(DAG)，就是对于这个图所有的点(V1, V2, … Vn)找到一个点序列使得任意边(u, v)， u出现在v的前面。很容易证明，如果一个有向图中有环那么不存在拓扑排序。 现实中的问题首先来看现实中哪些问题需要拓扑排序的，课程排序，编译依赖问题，类似的凡是涉及到相关顺序的时间安排，比如Rails里面的初始化调用了库Tsort来进行排序。Unix中有个命令也叫tsort)，在有的makefile里面还直接使用了这个命令来解决依赖问题。 O(V+E)的算法 拓扑排序的基本算法是用DFS，我们希望把有出度的点尽量排在前面，所以这里需要注意和DFS的区别。比如上面图中的一个DFS访问顺序是: 5 2 3 1 0 4, 但是这不是一个拓扑排序，4需要排在0的前面，5, 4, 0, 2, 3, 1。拓扑排序中需要等迭代完节点的连接邻点后再把当前点压入栈。 #include &lt;iostream&gt;#include &lt;stdio.h&gt;#include &lt;list&gt;#include &lt;stack&gt;using namespace std;class Graph &#123; int V; list&lt;int&gt;* adj; void _topological_sort(int v, bool visited[], stack&lt;int&gt;&amp; stack);public: Graph(int v); ~Graph(); void addEdge(int v, int w); void Topological_sort();&#125;;Graph::Graph(int v):V(v) &#123; adj = new list&lt;int&gt;[V];&#125;Graph::~Graph() &#123; delete [] adj;&#125;void Graph::addEdge(int v, int w) &#123; adj[v].push_back(w);&#125;void Graph::_topological_sort(int v, bool visited[], stack&lt;int&gt;&amp; stack) &#123; visited[v] = true; for(list&lt;int&gt;::iterator it = adj[v].begin(); it != adj[v].end(); ++it) &#123; int u = *it; if(visited[u] == false) _topological_sort(u, visited, stack); &#125; stack.push(v);&#125;void Graph::Topological_sort() &#123; bool visited[V]; stack&lt;int&gt; stack; for(int i=0; i&lt;V; i++) visited[i] = false; for(int i=V-1; i&gt;=0; i--) &#123; if(visited[i] == false) &#123; _topological_sort(i, visited, stack); &#125; &#125; while(!stack.empty()) &#123; int v = stack.top(); stack.pop(); std::cout &lt;&lt; &quot; &quot; &lt;&lt; v &lt;&lt; &quot; &quot;; &#125; std::cout &lt;&lt; std::endl;&#125;int main() &#123; Graph g(6); g.addEdge(5, 2); g.addEdge(5, 0); g.addEdge(4, 0); g.addEdge(4, 1); g.addEdge(2, 3); g.addEdge(3, 1); cout &lt;&lt; &quot;Following is topological sort result: \\n&quot;; g.Topological_sort(); return 0;&#125; 唯一性如果一个DAG的拓扑排序中任意连续的两点都是可连通的，那么这个序列也就是DAG的Hamiltonian路径，而且如果DAG图的Hamiltonian路径存在，那么拓扑排序就是唯一的。否则如果一个拓扑排序结果不是Hamiltonian路径，那么就存在多个拓扑排序结果。 其他图算法的预处理 DAG的强连通分支问题先得到拓扑排序，形成逆向图(所有边与原来方向相反)，然后根据拓扑排序依次再进行DFS。 DAG的最短路径问题，这可以在O(V+E)复杂度解决最短路径问题。同样类似的算法适用与DAG的最长路径问题，给定一个点求DAG中的各个点与给定点之间的最长路径。最长路径问题要比最短路径问题难，因为最长路径问题没有最优子结构，对于通用的图的最长路径算法还是NP难的问题。","tags":[{"name":"Algorithms","slug":"Algorithms","permalink":"http://catcoding.me/tags/Algorithms/"}]},{"title":"Do Presentation like a Geek","date":"2013-10-05T11:43:00.000Z","path":"2013/10/05/do-presentation-like-a-geek.html","text":"很多程序员不喜欢做PPT之类的东西，我也不喜欢。这有另外的原因是一直没找到一个合适的工具，Linux下PPT是个悲剧，Latex学习成本又大了点。上次在公司分享的时候偶然找到了这个叫做showoff的工具，熟悉了大概半个小时就上手了，迅速把自己的PPT完成。 showoff是Ruby写的一个适合程序员写PPT的工具，你可以用类似Markdown的语法编辑文本文件，同时在terminal下开一个服务，浏览器访问localhost:9090可以预览的成果。这个过程非常类似用Jekyll来写博客。当然最后可以导出成PDF格式的，或者直接在浏览器上展示。 安装Showoff安装非常简单: $ gem install showoff$ git clone (ppt-repo)$ cd (ppt-repo)$ showoff serve 使用我觉得showoff一些特别好的特点是: 纯文本编辑 (对程序员有吸引力) 嵌入代码方便，高亮代码 嵌入图片方便 可执行内嵌Javascript，Coffeescript 或者Ruby代码，并显示结果。(对程序员来说很不错) 一些显示特效 赶快看看example目录吧，你就能上手了。","tags":[{"name":"Tools","slug":"Tools","permalink":"http://catcoding.me/tags/Tools/"},{"name":"Ruby","slug":"Ruby","permalink":"http://catcoding.me/tags/Ruby/"}]},{"title":"初到美国","date":"2013-09-26T11:43:00.000Z","path":"2013/09/26/gotous.html","text":"很久没有更新了，这段时间挺忙的。公司让在美国待一段时间，所以7月份开始办理相关签证，由于自己粗心大意导致跑签证馆好几次。第一次是因为没有填写完教育信息，签证馆挂着个牌子写着 The main difference between a cat and a lie is that a cat only has nine lives. - Mark Twain 我这还不算撒谎吧，他们还算通情达理给我个纸条让回来重新填写表。 终于费劲周折前两天到了湾区，我穿着沙滩裤下了飞机，一时特别的困。这边温度19度左右，风又特别的大，感觉有点冷。 当地时间上午11点到的，为了倒时差那天就不能睡觉，所以吃了午饭我和同事骑车到处逛了逛。 这边风景不错，最让人羡慕的是各种树比较多，而且高大茂盛。树上有果子，天上有老鹰。 作为土鳖虽然以前在电视和Google街景上看过美国的房子，不过亲眼来看看还是忍不住羡慕嫉妒，可恶的美帝，这让我们这些省吃俭用买个小笼子的共产主义奋斗者情何以堪。 这边亚洲人多，华人占的比例应该也很大。跑去大华超市附近买东西，那一片和上海没什么区别。 在这边待到11月中旬回去，打算周末再出去溜达一下，主要是自己还不会开车，在这边没车就基本残废。 我前一两个月开始看本书《Essentials of Programming Languages》，顺便做做里面的练习，写了不少Scheme代码，这些习题基本都是往一个解释器里面添加一些东西。总得来说挺好玩的，做到第五章了。代码在Github上：https://github.com/chenyukang/eopl。","tags":[]},{"title":"Metaprogramming Ruby","date":"2013-08-24T11:43:00.000Z","path":"2013/08/24/meta-programming-ruby.html","text":"『Metaprogramming Ruby』这本书看了两遍，从这本书里获取了一些乐趣。技术书籍就应该这样简明扼要，寓理于事。通过一个显示中的例子引入问题，展示元编程的解决办法， 顺带介绍一下用到相关技术的gems。 下面这些不是书评，只是我在看第二遍的时候的一些简单的择要，用于自己的记忆和检索。 Introduction Meteprogramming is writing code that writes code 鬼城和集市，很多语言的运行环境在执行的时候已经固定，一片死寂。而支持Metaprogramming的语言的执行环境是充满活力的集市。很好的比喻。 动态元编程和静态元编程，C++的template属于静态元编程。 The Ruby Object Model Class定义永远是开放的，你能重新定义任何类或者给类加上一些新的东西。注意MonkeyPatch可能导致的Bug。 分清楚instance_method和class_method， Class也是对象。与C#/Java的Class不一样的地方，Ruby允许在代码运行期间操作类相关的信息，比如增加method或者重新定义method。 Methods static type checking, for example, if you call simple_talk() on Layer object that has no such method, the compiler protests loudly. call method dynamic using send(). define_method generates instance method dynamically, to_s vs to_sym. Ghost method, method_missing. 过多是用会不会拖慢执行效率，要顺着继承链一直查找method。 注意method_missing可能导致的死循环调用。 和继承过来的method之间的冲突， undef_method解决。 Blocks class, module, and def change scope. Flat Scope. instacen_eval/instance_exec create block : lambda/proc/Proc.new lambda vs Proc return in Proc also return from the scope. lambda’s argument checking is more strict. A event DSL, a elegent example for blocks. Class Definitions A Ruby class definition is actually regular code that runs. class_eval vs instance_eval class_eval both changes self and current class Eigenclass, the metaclass of a object three way to define class method Around alias Code writes code The powerful weapon: eval A good example: add_attribute Three ways to express this idea Active record Validations alias_method_chain Dynamic attributes, define read/write/question Dynamic Methods for all the columns in databases, for performance. Lesson learned, performance/complexity/readable trade-offs. Metaprogramming safely Defusing Monkeypatches, make it explicit with module, check it before patche, add warning messages.","tags":[]},{"title":"Learning Ruby with Ruby Warrior","date":"2013-07-14T11:43:00.000Z","path":"2013/07/14/ruby-warrior.html","text":"Ruby上总有好玩的东西，偶然看到这个RubyWarrior，玩了一把感觉还有些意思。这个有些像我原来介绍的RubyRobot,不过更像之前的Wumpus，看来我对这种游戏有些兴趣。 Ruby新手边玩边熟悉了语言。需要代码的可以clone下来看看，如果只是玩可以gem装上，然后运行rubywarrior就开始练级了。 gem install rubywarrior 我现在只是完成了初学者模式，这里的AI还比较简单，主要实现一个函数就行了。分为两种模式，第一种只用对付当前的场景，第二种为epic(史诗?)模式，要从1~9连续闯关。 我的平均成绩是C，所有级的代码放在Github上了。 Level Score: 27Time Bonus: 18Level Grade: FTotal Score: 374 + 45 = 419Your average grade for this tower is: CLevel 1: SLevel 2: CLevel 3: BLevel 4: BLevel 5: DLevel 6: FLevel 7: BLevel 8: FLevel 9: F 中级模式是二维的地图，所以更有挑战。 这里有一个前端，不过我还没用过。 这还有人用神经网络的方法来做的，可以学习一下，:)。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"}]},{"title":"初学Rails","date":"2013-07-06T11:43:00.000Z","path":"2013/07/06/studying-rails.html","text":"我在2012年左右开始关注Ruby，平时有的时候会用Ruby写一些脚本。这是一个很活跃的社区，Ruby火起来也不是最近的事。可贵的这里总是有一些新的东西出来，比如我现在的这个博客是基于jekyll和Github的。Ruby的迅速崛起更多的还是因为Rails，所以学习Rails也是了解Ruby的一个好方法。 最近为公司内部所配置的GitLab是Rails开发的。另外我自己也在公司做一些Web程序，其实是很简单的东西，就是把每天晚上跑的程序各种测试结果展示出来(nightly/weekly/coverage等等)。我选用Rails来开发，果然一个最初的版本很快就做出来了。在初学Rails的过程中让我体会到了一些web开发的乐趣。 Rails适合小团队的快速开发，其中的一些理念是： Encourage Agility –鼓励敏捷开发 Convention Over Configuration –约定高于配置 DRY –不要重复自己 Less Code –更短小的代码 正是这些开发原则使得Rails开发如此简单明了(当然前提是你按照Rails约定的方式来)。我原来做过一些web开发服务器方面的工作，在那种模式下开发需要每个人各司其责。但是Rails不同，在ActiveRecord这样的抽象层基础上你需要关注的数据库方面的东西少了，明确的MVC模式把你需要关注的撤离开来，这种复杂程度一个人完全能掌控下来。当然这种高度的抽象是以牺牲一部分效率为前提的，但其实在很多时候开发效率的优先级是高于实现效率的，这也是Ruby所选择的一个理念。 学习Rails的过程中这些资料是非常好的，这几本书都面向初学者，写得非常详细： Ruby On Rails教程 Begining Rails 3 Agile Web Development with Rails 当我熟悉了一些基本概念的时候，我就可以看Github上各种Rails的代码了，约定高于配置的另外一个优点就是所有Rails开发的东西结构看起来是一样的，便于不同开发者之间的交流。 Rails的一个比较突出的问题是版本之间的兼容性比较差。 比如Begining Rails里面Plugin那章的那个例子，在Rails3.1系列开始已经不支持那种方式的plugin了，其中用到的class_inheritable_accessor也变成了class_attribute。这种问题非常多，另外据说最新的Rails4.0改动也很大。 这是一个老问题，在早起的版本就有人在这上面都发生过争吵。一些人说变化太频繁，不容易学习。其中这篇“WTH is happening to Rails?” I’ll tell you解释了一下Rails如此的原因，并称这种改变位『成长』。 学习Rails的路还比较长，后面继续。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Rails","slug":"Rails","permalink":"http://catcoding.me/tags/Rails/"}]},{"title":"高效的Crit-bit Tree","date":"2013-05-18T11:43:00.000Z","path":"2013/05/18/critbit.html","text":"最近了解到有这么一种数据结构，想拿来在工作中做一些事情，结果效果不好。原来我的理解有一些不对。在这里记录一下。 Crit-bit tree是一种特别的树结构，一般用于存放字符串。Critbit tree是一种BitWise tries，其树的深度为O(longest-length)，有点像二叉树，不过对于字符串做分支检测的时候代价很小。 Crit-bit快速高效的支持下面的一些操作： 插入一个字符串 测试一个字符串是否在树里 删除一个字符串 查找出树中所有以某个字符串开始的所有字符串 和hash有点像，不过hash对于第四点没这么方便。我做了一些性能对比，测试数据是/usr/share/dict/words里面的所有单词，同时做插入和查询的操作。具体测试代码看这里，结果是： critbit 11.6MB 23.34 set 21.6 MB 45.85s trie 332.3 MB 17.84s 从中可以看到trie树的内存消耗是比较大的，但是查找速度最好。critbit的内存消耗真的非常小，如果只是把这里所有的单词存下来都要4MB的内存，其查找的速度虽然和trie树比起来差一些，但还是相当不错。 好好的研读了crit-bit的实现和这篇文章，里面技巧挺多的。critbit的结构很简单: typedef struct&#123; void* child[2]; uint32 byte; uint8 otherbits;&#125;critbit0_node;typedef struct&#123; void* root;&#125;critbit0_tree; 其中child是void*指针，对于树的内部节点其指向的是子节点，对于叶子节点其指向的是字符串。byte用来表示当前节点匹配的长度，otherbits是一个mask，可以用来快速的取得不同最高位，在查询的过程中用这个来做branch。 具体的代码分析这里比较少，最复杂的函数是critbit0_insert。在插入过程中需要记录下来byte和otherbits,并且更新前面的父节点。​ 然后再继续插入后的结构变化是: 下面记录一下其中的几个技巧。 align指针最后一位用来做标志树的结构需要一个标志变量来表示是否是内部节点或者是叶子节点。这个变量如何能省掉？看上面的void root和void child, 都是即可以用来指向字符串又可以指向节点，一般申请过来的指针变量都是align好的，所以最低位为0，这是可以拿来用的。因此对于内部节点我们可以在这个位上设置为1，只是要注意在通过这个指针取值的时候需要减回去。 a = (posix_memalign((void**)&amp;x, sizeof(void*), ulen+1)) posix_memalign在这里用的是sizeof(void*)，其实就和malloc一样了，因为一般Linux上编译器和C库已经处理了对齐问题。 因此在查找的这段代码里是这样的： int critbit0_contains(critbit0_tree*t, const char* u) &#123; const uint8* ubytes= (void*)u; const size_t ulen= strlen(u); uint8* p= t-&gt;root; if(!p) return 0; while( 1 &amp; (intptr_t)p )&#123; //内部节点? critbit0_node* q = (void*)(p-1); //取得真正的指针 uint8 c = 0; if(q-&gt;byte &lt; ulen) c = ubytes[q-&gt;byte]; const int direction= (1+(q-&gt;otherbits|c))&gt;&gt;8; p = q-&gt;child[direction]; &#125; //叶子节点 return 0 == strcmp(u, (const char*)p);&#125; 取最高位的非0bit在插入过程中计算最高位的不同位。 newotherbits = p[newbyte]^ubytes[newbyte]; 其实也可以用一个for循环来计算，不过这里是这样实现的: newotherbits |= newotherbits&gt;&gt;1;newotherbits |= newotherbits&gt;&gt;2;newotherbits |= newotherbits&gt;&gt;4; 这相当于是计算不小于它的2的整数次幂，对于32bit的代码可以看看这里的next_pow_of_2。 文章和代码，其中那篇文章有详细分析。 我的测试代码,trie/set等。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Critbit","slug":"Critbit","permalink":"http://catcoding.me/tags/Critbit/"}]},{"title":"迁移到Git","date":"2013-05-09T11:43:00.000Z","path":"2013/05/09/git-command.html","text":"公司这群人终于打算从CVS迁徙到Git上了，CVS这套公司用了六年。CVS这是90年代的东西，我们不能因为年代久远而嫌弃这，只是CVS这东西对于一个比较大的项目来说创建分支是相当漫长，大多数程序员都没有耐心的。迁徙计划虽然纸上谈兵了很长时间，直到现在才终于打算行动。 上午把Git在服务器上搭建好，主要卡在一个Git的命令上，因为一些权限问题。 git init --bare --shared=group ; --shared=group forget this Git的web接口是用的是ViewGit，自己做了一些修改，加上GeShi来高亮代码，并使用了GitStats来做代码统计。GitStats统计的项目非常多，看起来很直观。 稍微记录一下常用的一些git命令。 这里有一个最直观的Git学习的地方leanGitBranch。 检出仓库 git clone repo 更新 git pull 提交到远程 git push提交到本地 git commit -am”log message” 创建branch git branch branch_name切换branch git checkout branch_name合并branch git merge branch_name图形界面 gitk解决冲突 git mergetool撤销上一次commit git revert HEAD撤销上上次commit git revert HEAD^ 撤销上一次的merge git reset –hard HEAD^","tags":[{"name":"Tools","slug":"Tools","permalink":"http://catcoding.me/tags/Tools/"}]},{"title":"一些包管理命令","date":"2013-04-17T11:43:00.000Z","path":"2013/04/17/apt-usage.html","text":"包管理器是Linux上一个经常用的东西，我觉得下面这几个命令是非常有用的，便于查询包的状态，或者搜索我该安装哪些包。 apt-cache用来根据名字查询软件包，比如apt-cache search vim查询vim相关的。 apt-file用来根据某个文件查询软件包，这在编译程序的时候非常有用，可以通过所需要的头文件去查询要安装的东西，可以避免去Google了。注意使用之前需要安装并update。 sudo apt-get install apt-file sudo apt-file update 比如我在编译某个软件的时候找不到&lt;readline/readline.h&gt;，使用下面的命令来查询一下： sudo apt-file readline.h 结果中有这么一行，那么我就知道继续安装libreadline5-dev库就行了。 dpkgapt是基于dpkg开发的，dpkg是更古老更底层的一套工具，Debian系统管理器的基础。 dpkg -l 列出所有已经安装的包 dpkg -s vim 列出包vim的状态 dpkg -L vim 列出本地所有vim相关联系的文件 dpkg -S vim 搜索所属包的内容 brewMac下推荐Brew来替代apt，大部分的开源包都有对应的地址源了。我没使用过MacPorts，无法比较这两套的差别。不过我个人很喜欢的一点是brew所有安装的东西都在brew -prefix/Cellar这个统一目录下， brew相关的命令： brew list — 列出已安装的软件 brew update — 更新Homebrew brew home — 用浏览器打开 brew info — 显示软件内容信息 brew deps - 显示包依赖","tags":[{"name":"工具","slug":"工具","permalink":"http://catcoding.me/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"巧妙的XOR Link List","date":"2013-04-11T11:43:00.000Z","path":"2013/04/11/xor_link_list.html","text":"XOR Link List, 只用一个附加的变量来实现双向链表。首先xor本身是个稍微有点难理解的操作。xor有下面的一些特性: A ^ 0 = A A ^ A = 0 A ^ B = B ^ A (A ^ B) ^ A = B (B ^ A) ^ B = A 注意最后两条，这是XOR Link List的关键，这也是通过xor操作来实现swap的关键。 void xorSwap (int *x, int *y) &#123; if (x != y) &#123; *x ^= *y; *y ^= *x; *x ^= *y; &#125; &#125; 这里注意需要判断x!=y，否则如果传入的是相同的指针，最后所指向的变量被设置为0了。 通过最后两条联想到双向链表中的两个指针的实现，一般如下图所示： ... A B C D E ... –&gt; next –&gt; next –&gt; next –&gt; &lt;– prev &lt;– prev &lt;– prev &lt;– 如果把next和prev用一个变量替换还能实现前向和后向遍历，那就节省了一个变量的空间。 ... A B C D E ... &lt;–&gt; A⊕C &lt;-&gt; B⊕D &lt;-&gt; C⊕E &lt;-&gt; 比如当前在B节点，其pointer变量为A⊕C，如果前面的A地址保存下来然后做运算(A⊕C)⊕A -&gt; C，这样就得到下一个节点指针，反向遍历同样如此。当然其缺点是逻辑复杂了，删除其中的某一个节点也不方便(删除头和尾要好点)，遍历的时候需要保存上一个节点。这样看来为了省一点点空间这样实现似乎有点不值，在大部分情况下这样的一个pointer的节省并没什么用，不过这其中的细节有趣、巧妙。 同样上面的xorSwap对于现代的CPU来说也没什么优化，这样的代码只是更加不便于编译器来实现指令级别的优化。这种类型trick的东西还是要避免使用才好。 自己稍微写了一下，代码在这个Gist。","tags":[{"name":"C/C++","slug":"C-C","permalink":"http://catcoding.me/tags/C-C/"},{"name":"XorLinkList","slug":"XorLinkList","permalink":"http://catcoding.me/tags/XorLinkList/"}]},{"title":"Jekyll使用MathJax来显示数学式","date":"2013-03-03T11:43:00.000Z","path":"2013/03/03/try-mathjax.html","text":"使用Jekyll写作文章的时候有可能需要内嵌一些数学公式, MathJax就是用来干这个的，试用了一下感觉非常方便。步骤如下: 修改html头部。 在每个页面开头加上这么一句，在Jekyll下可以通过修改default.html加上。 &lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&gt;&lt;/script&gt; 本地安装kramdown。 因为rdiscount和默认的markdown在解析带公式文件的时候都会出现一些问题，所以最简单办法还是安装kramdown。$ gem install kramdown 修改_config.yml，把markdown选项修改为: markdown: kramdown 然后在发布的时候就可以使用$$来把需要显示的数学式子扩起来。像这样： $$a^2 + b^2 = c^2$$ 发布出来就是漂亮的公式了。 $$a^2 + b^2 = c^2$$ $$x^my + a^2 + b^2 = c^2$$ $$x_\\mu$$ 一些更酷的例子： $$ J_\\alpha(x) = \\sum\\limits_{m=0}^\\infty \\frac{(-1)^m}{m! \\, \\Gamma(m + \\alpha + 1)}{\\left({\\frac{x}{2}}\\right)}^{2 m + \\alpha} $$ $$ \\frac{1}{\\Bigl(\\sqrt{\\phi \\sqrt{5}}-\\phi\\Bigr) e^{\\frac25 \\pi}} =1+\\frac{e^{-2\\pi}} {1+\\frac{e^{-4\\pi}} {1+\\frac{e^{-6\\pi}}{1+\\frac{e^{-8\\pi}} {1+\\ldots} } } } $$ $$ \\left( \\sum_{k=1}^n a_k b_k \\right)^2 \\leq \\left( \\sum_{k=1}^n a_k^2 \\right) \\left( \\sum_{k=1}^n b_k^2 \\right)$$ $$\\begin{aligned}\\nabla \\times \\vec{\\mathbf{B}} -\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{E}}}{\\partial t} = \\frac{4\\pi}{c}\\vec{\\mathbf{j}} \\ \\nabla \\cdot \\vec{\\mathbf{E}} = 4 \\pi \\rho \\\\nabla \\times \\vec{\\mathbf{E}}\\, +\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{B}}}{\\partial t} = \\vec{\\mathbf{0}} \\\\nabla \\cdot \\vec{\\mathbf{B}} = 0 \\end{aligned}$$ 不过我可能永远用不到这么复杂的表达式 :). 另外今天找了一个markdown-mode.el，在Emacs下编辑Markdown文件又方便了不少。 Mac下的Markdown编辑器Mou也是非常不错的。","tags":[{"name":"Jekyll","slug":"Jekyll","permalink":"http://catcoding.me/tags/Jekyll/"}]},{"title":"读bootstrap scheme","date":"2013-02-15T11:43:00.000Z","path":"2013/02/15/reading-bootstrap-scheme.html","text":"For a List in Lisp, Car is the First, Cdr is the Rest, and Lisp means List-Proccessing. 前段时间偶然在网上看到这个bootstrap scheme这个开源程序，读来简洁明了，十分有趣。我对scheme有一点了解，毕竟以前看过一段时间SICP，自己做练习的代码也是scheme写的。scheme本身属于Lisp方言，语法也极其简单，学习起来非常快的。 看看这个简单的scheme实现，不禁再次感叹递归的优美。Lisp这样的语言直接使用语法树结构来表示程序，不仅使得表示出来的程序异常简洁，就是用C语言来实现这种语言的解释器代码也看起来非常优美。在这里区区2000行的C语言代码，当然没有完整地实现scheme所有的内容，甚至只支持了整数。但是包含scheme的基本语法层面的东西，还有lambda。抛开实现的效率不说，递归是易于编写和理解代码的一种方式，这里语法是递归的，parser是递归的，eval也是递归的。在这里所有的东西都是object，没有显示的列表结构，但是嵌套的pair里蕴含着列表和树的关系。在parse阶段建立好一个以object为基本元素的树结构，做eval的时候顺着往下走就是了。 推荐对语言实现感兴趣的同学阅读一下这个代码，如果对scheme不了解也没关系，用一个小时看几个scheme程序基本就了解了。再看这个解释器，你就懂了代码是如何被运行的。 参考scheme-from-scratch-introduction 图片来自Draperg’s cartoons","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Lisp","slug":"Lisp","permalink":"http://catcoding.me/tags/Lisp/"}]},{"title":"Emacs会说话","date":"2013-01-27T11:43:00.000Z","path":"2013/01/27/emacs-speaking-now.html","text":"出来工作之前我从来没认真考虑过我的英语口语问题，大学时候的四级口语考试C级也没让我意识到自己的发音比较烂。学了好多年哑巴英语，又因为本人生性有点害羞经常不好意思开口说英语，悲剧早就注定。其实我的英语阅读能力还是可以的，不过工作之后同事们都嘲笑我口语听起来像印度人，据说发音极其古怪。 在Mac下有一个叫做say的命令行程序，我有时候会用来听单词单词发音。这个程序加上-f参数也可以用来朗读整个文件。 say hello wrold say -f demo.txt 前几天突然觉得如果写个Emacs Minor Mode，能在边写单词的时候Emacs就把你写的朗读一遍就好了，Emacs号称能煮咖啡，这点小事当然不在话下。其实除了在公司我也很少写英文，不过这个想法看起来比较好玩，于是动手做了一下。预想的基本功能是实现了，我把它叫做EmacSay-mode，意为在Emacs+Mac+Say下实现的，所以这东西可能不能在Linux下运行。 这也是我第一次学着写一个minor mode，实现起来也很简单。整个不到100行elisp代码。 基本思路就是如果当前输入的字符是空白(或者其他非字母字符)，寻找前面一个字符串，格式化成一个命令行，用start-process或者shell-command来调用。注意start-process会fork出来一个子进程来执行命令，在书写过程中最好还是使用start-process来调用命令，因为say可能要待个一两秒才返回，如果使用shell-command来调用会造成输入有迟钝的感觉。 绑定的快捷键有这些，其中eamcsay-say-buffer是用来朗读当前的整个buffer，如果你想在其中中断朗读使用emacsay-say-stop。 (defvar emacsay-mode-map nil &quot;Keymap for emacsay minor mode&quot;)(unless emacsay-mode-map (let ((map (make-sparse-keymap))) (define-key map &quot;\\C-cs&quot; &#x27;emacsay-say-current-string) (define-key map &quot;\\C-cp&quot; &#x27;emacsay-say-buffer) (define-key map &quot;\\C-ct&quot; &#x27;emacsay-say-stop) (setq emacsay-mode-map map))) 还可以有一些小的改进，比如阅读时候闪烁单词，或者say声音的选择等等。 所有代码在GitHub: emacSay-mode。","tags":[{"name":"Emacs","slug":"Emacs","permalink":"http://catcoding.me/tags/Emacs/"}]},{"title":"迟到的POJ 500","date":"2013-01-22T11:43:00.000Z","path":"2013/01/22/poj-500.html","text":"我发现自己有了很重的拖延症，一个表现就是在2011年3月定下的目标POJ 500最近才完成。 这一页500道题耗费了我很多时间和精力，同样也带给了我很多知识和乐趣。 当然工作后毕竟还是没有学校的时间充足了，现在还花时间来做题似乎显得很悠闲，这500题最后十个是在元旦的几天假期里完成的。我是从2010年的4月份开始在Poj上做题，那天偶然发现自己原来2006年还注册过账号，于是做了两题试试，没想到后面就竟然沉迷其中，一直到自己从学校毕业出来。这两年强度还不算大，平时还是要在实验室做做项目的。我没参加过专业队的训练，不过参加过一次学校的比赛，和王骆驼两个人一个下午做出来五道，比较悲剧的是差一道没进决赛。不过当时还是挺欣慰的，毕竟自己还是不算专业选手啊。这一年多静下心来写程序收获很多，因为体会到了写程序的乐趣，有时候在睡觉的时候脑袋也在不知不觉地想问题。有时候我选择按不同的数据结构或者算法思想来选题做，有时候就在线上泡着看排我前面的人在做什么，然后自己也跟着做，这真写的是寂寞啊。不过现在回想起来这一两年算是最自由、最充实的写程序的日子了。 像ACM题这些东西最好还是大学开始接触，在开始学习基本算法和数据结构的时候就开始进行训练是最好的。当然如果大学能进专业队训练就更不错了，如果只是业余拿来练练手也是大有裨益的。也许我们做不到专业队哪些人写代码就像秀肌肉一样，体会到其中的乐趣就够了。在我开始做POJ之前我还是对算法充满了恐惧，感觉太高深。经过这些渐进的学习和训练，现在至少说有点入门的感受，面对一个问题多多少少会有一些思路和想法。也许平时项目和工作并没用到多少纯粹的算法部分，只是这有了这基本功还是能让你迅速上手其他东西。 《黑客和画家》里写到学习写程序和学习绘画的诸多相同点，这都是一门技能，除了多写、多看、多思考之外没有其他捷径可走。折腾多了自然就会有一点感觉。学习绘画的另外一个途径就是观摩经典的杰作，同样对应地看开源项目是另外一个很好的学习编程的途径。 幸好GitHub又被解封了。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"POJ","slug":"POJ","permalink":"http://catcoding.me/tags/POJ/"}]},{"title":"获取挂掉程序的栈信息","date":"2013-01-04T11:43:00.000Z","path":"2013/01/04/print-stack-before-exiting.html","text":"在程序挂掉的时候最好还是留点有用的遗言，特别是对于一些比较难重现的Bug，也许这些信息会成为解决问题的关键。 下面这个技巧可以让程挂掉的时候打印出来栈信息。这个办法来自这里, 我觉得把SIGABRT、SIGBUS信号加进去也挺好的，在此做了点修改。曾经尝也试过glibc的backtrace函数，，但是给的信息不全(没有行号)，对此做得最好的还是gdb。 在终端可以用gdb获取某个进程的当前栈： $ gdb -p 5595 -batch -ex bt 0xb7fb4410 in __kernel_vsyscall () #0 0xb7fb4410 in __kernel_vsyscall () #1 0xb7dc2d50 in nanosleep () from /lib/tls/i686/cmov/libc.so.6 #2 0xb7dc2b87 in sleep () from /lib/tls/i686/cmov/libc.so.6 #3 0x0804874f in main () at print_stack.cc:64 那么一个好的办法就是在程序开始的时候设置好信号，绑定SIGSEGV和SIGABRT到DumpBackTrace()函数，DumpBackTrace函数fork出来一个新进程，运行上面的命令来获取调用栈。 #include &lt;stdlib.h&gt;#include &lt;signal.h&gt;#include &lt;stdio.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;#include &lt;unistd.h&gt;#include &lt;assert.h&gt;void DumpBacktrace(int) &#123; pid_t dying_pid = getpid(); pid_t child_pid = fork(); if (child_pid &lt; 0) &#123; perror(&quot;fork() while collecting backtrace:&quot;); &#125; else if (child_pid == 0) &#123; char buf[1024]; sprintf(buf, &quot;gdb -p %d -batch -ex bt 2&gt;/dev/null | &quot; &quot;sed &#x27;0,/&lt;signal handler/d&#x27;&quot;, dying_pid); const char* argv[] = &#123;&quot;sh&quot;, &quot;-c&quot;, buf, NULL&#125;; execve(&quot;/bin/sh&quot;, (char**)argv, NULL); _exit(1); &#125; else &#123; waitpid(child_pid, NULL, 0); &#125; _exit(1);&#125;void BacktraceOnSegv() &#123; struct sigaction action = &#123;&#125;; action.sa_handler = DumpBacktrace; if (sigaction(SIGSEGV, &amp;action, NULL) &lt; 0) &#123; perror(&quot;sigaction(SEGV)&quot;); &#125; if (sigaction(SIGABRT, &amp;action, NULL) &lt; 0) &#123; perror(&quot;sigaction(SEGV)&quot;); &#125;&#125;void test() &#123; //assert(0); int* p = 0; *p = 0;&#125;int main() &#123; BacktraceOnSegv(); test();&#125; 另外前段时间看到这篇文章Solving vs. Fixing写得不错，在面对一个bug的时候，先不要急于立马上gdb调试，根据现有的信息好好思考为什么会出现这个情况。Reddit上的一个得分最高的回复： The ability to reason about code is probably the most important skill. But it is sadly rare, and doesn&apos;t seem to be taught much, if at all. Some things are simple, others take some more thought: * Under what conditions will this branch get taken? * What could cause this API to fail? * Are all these parameters even valid? * What sequence of events could lead to this situation? * What assumptions does this code make? * What side-effects does this code have? * What contract is this code making (or breaking)? The most talented engineer I know, when presented with a bug, does nothing but read the code and think about the code and how it could fail. Most of the time, he just figures it out in his head and fixes it. Sometimes he will insert some strategic printfs and narrow it down like that. I don&apos;t think I have ever seen him use a debugger, even on the most complex of problems.","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"C/C++","slug":"C-C","permalink":"http://catcoding.me/tags/C-C/"}]},{"title":"Browser objs and class hierarchy  in Ruby","date":"2012-12-26T11:43:00.000Z","path":"2012/12/26/browser-objs-in-ruby.html","text":"Ruby里一切都是对象，如何能看到Ruby内建的对象模型呢。这里有个小程序来查看Ruby内部构建好的的对象和类。ObjectSpace可以迭代所有对象。 set = Set.new() ObjectSpace.each_object do |x| set.add(x.class) endset.each do |x| puts xend 下面这段就能根据对象，取得class对象，建立起类的继承图。 # Creates or updates a klass_tree.# When updating no classes or objects are removeddef object_browser(classtree = ClassTreeNode.new(Kernel)) ObjectSpace.each_object do | x | classnode = classtree x.class.ancestors.reverse[1..-1] \\ .inject(classtree)&#123; | classnode, klass | classnode.add_class(klass) &#125;.add_object(x) end classtreeend use this command to get image: $ruby prog.rb &gt; class.dot; dot -Tpng class.dot -o class.png 结果看起来像这样，所有对象都画出来比较多，看大图还稍微能看到一些。完整的代码在这里。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Ruby","slug":"Ruby","permalink":"http://catcoding.me/tags/Ruby/"}]},{"title":"Clang is Making Emacs Smarter","date":"2012-12-16T11:43:00.000Z","path":"2012/12/16/use-clang-autocomplete-mode.html","text":"在Emacs下自动补全总是个问题，对于同一个buffer内的基于symbol补全auto-complete-mode做得非常好了，但是因为没有进行代码的分析，所以像结构体的成员变量或者类的成员函数的补全是不可能的。当然你可能试过这个号称最智能的GCCSence,但是我觉得这个东西够复杂的，在使用之前还需要用户手动运行一个命令来用Gcc处理一遍，它还会把一些东西放在sqlite数据库里面。这大概是因为Gcc不编译做静态分析工具造成的，在这里、这里、这里有讨论，Google的一个静态分析的项目从Gcc迁移到LLVM，重点是这: The gcc version has been difficult to support and maintain, due mainly to the fact that the GIMPLE intermediate language was never designed for static analysis. The abstract syntax tree provided by Clang is an easier data structure to work with for front-end analyses of this kind. 这个thread挺好玩的，后面变成了一大群人争论functional programming和Imperative Programming。这篇The Downfall of Imperative Programming再好好看看。 回到正题，我最近切换到Mac下。因为在Mac OS X下编译器变成了Clang， Clang是基于LLVM的。LLVM对于分析代码是有比较方便的支持，所以基于LLVM有各种分析源程序的工具了，Xcode下的一些辅助开发的工具还是很舒服的。前些天突然想到那么会不会有个东西来作为Emacs的自动补全的后端，一搜果然有了这个auto-complete-clang，使用了一下非常的方便。其实看看其代码是在后面调用Clang的，比如在main.cc源文件里面写一些代码: #include &lt;string&gt;#include &lt;vector&gt;using namespace std;class Demo&#123;public: void print(); void test();private: int value;&#125;;int main() &#123; std::string s; Demo demo; demo.&#125; 结果还是非常精准的，不想截图了。后端运行的命令其实是:cmd: clang -cc1 main.cc -fsyntax-only -code-completion-at main.cc:18:10 所得到的结果是:COMPLETION: Demo : Demo::COMPLETION: operator= : [#Demo &amp;#]operator=(&lt;#const Demo &amp;#&gt;)COMPLETION: print : [#void#]print()COMPLETION: test : [#void#]test()COMPLETION: value : [#int#]valueCOMPLETION: ~Demo : [#void#]~Demo() auto-complete-clang做的事情就是把这个结果再展示出来，其实这条命令也做了语法检查的，所以加上一个语法检查的功能应该也是可以的。一搜果然还是有了，看这个Realtime syntax checking with emacs，需要翻墙，不过代码在Github上。其实其后端运行的命令是： cmd: clang -fsyntax-only -fno-exceptions main.cc 最近用这个插件，基本代码都会是一遍编译通过啊，哈哈。Clang错误提示也人性化一点，比如在Xcode下会提示你想的是不是”XXX”之类的。","tags":[{"name":"Emacs","slug":"Emacs","permalink":"http://catcoding.me/tags/Emacs/"},{"name":"LLVM","slug":"LLVM","permalink":"http://catcoding.me/tags/LLVM/"},{"name":"Gcc","slug":"Gcc","permalink":"http://catcoding.me/tags/Gcc/"}]},{"title":"Have a try on Ninja","date":"2012-12-13T11:43:00.000Z","path":"2012/12/13/have-a-try-for-ninja.html","text":"什么是Ninja 在Unix/Linux下通常使用Makefile来控制代码的编译，但是Makefile对于比较大的项目有时候会比较慢，看看上面那副漫画，代码在编译都变成了程序员放松的借口了。所以这个Google的程序员在开发Chrome的时候因为忍受不了Makefile的速度，自己重新开发出来一套新的控制编译的工具叫作Ninja，Ninja相对于Makefile这套工具更注重于编译速度。除了Chrome现在还有一些其他的比较大的项目也在开始使用Ninja，比如LLVM。我试用了一下感觉还是不错，比如编译Cmake时间大概是原来的1/4。Ninja试用C++实现，其支持的语法非常简单，作者在这里说明了为了控制复杂度。 代码如何编译其实对于C/C++和很多其他程序的编译都是一个道理，就是把一些源代码文件编译成目标文件，或者有的目标文件再编译到一个库里，然后再链接起来。所以Ninja的配置文件分为两个部分，rule和文件依赖关系。看个简单的例子: cc=gcccflags= -g -crule cc command = $cc $cflags $in -o $outrule link command = $cc $in -o $outrule cleanup command = rm -rf *.exe *.obuild func.o : cc func.cbuild main.o : cc main.cbuild app.exe : link main.o func.obuild all: phony || app.exebuild clean: cleanup 非常易懂，编译的可执行未见叫做app.exe, 其中有三条rule: cc, link, cleanup。看看这个官方的试用手册，还有一些附加参数可以加在rule的下面，比如description用来在编译的时候显示出来。Ninja还有个比较好玩的功能就是Ninja -t graph all命令，这可以用来生成编译时候的依赖关系，可以用dot来生成图片等。Ninja的实现也可以大概推测到，根据用户给的依赖关系图，_并行_ 地编译各个文件。 使用Ninja的一个问题就是需要生成这个build.ninja文件，对于大型项目来说这样一条一条地写配置文件是不可能的。幸好我们可以使用Cmake来生成这个配置文件，Cmake对应的是automake这样的东西。在Cmake的最新版本中已经支持参数Camke -G Ninja，Cmake会根据用户给定的CMakeLists.txt来生成build.ninja文件。而CmakeLists文件相对来说要简单一些，只要写清楚编译的可执行文件的名字，和其依赖的包含main函数的源文件。把我的迷宫小项目来举个例子,在项目文件夹下写配置文件CMakeLists.txt: cmake_minimum_required(VERSION 2.8)project (Maze)add_library(maze A_star.cpp Algorithm.cpp DFS_L.cpp DFS_R.cpp DisjSets.cpp Maze.cpp)add_executable(Maze.exe main.cpp)target_link_libraries(Maze.exe maze) add_library写明了生成一个叫做maze.a的库文件，然后和main.cpp编译出来的main.o生成可执行文件，写好CmakeList.txt后运行Cmake -G Ninja, 然后运行ninja all就能编译这个工程。具体的Cmake语法参考这里，对于不少项目来说Cmake已经足够使用，只是我觉得Cmake还是稍微复杂了一点。 我这样来使用 整个Ninja是使用C++写的开源项目，如果我们想增加一些自己的feature可以hack一下，不过作者估计不会接受增加语法支持的patch。我准备做一个小的hack来自动分析我当前的源码，自动生成build.ninja文件，不要求处理所有的复杂情况，只是分析.cc和.c，自动检测main函数文件。最后用户只用配置链接参数就可以了。我觉得这样用起来就非常方便了，待完成中，顺便看看Ninja的内部实现。","tags":[{"name":"Ninja","slug":"Ninja","permalink":"http://catcoding.me/tags/Ninja/"},{"name":"makefile","slug":"makefile","permalink":"http://catcoding.me/tags/makefile/"}]},{"title":"Ruby Robot AI","date":"2012-11-22T11:43:00.000Z","path":"2012/11/22/ruby-robot-ai.html","text":"最近看到一个RRobot，这是一个用Ruby来实现的坦克对战平台。感觉挺好玩的，周三在公司也顺带和同事分享了一下。有时间的同学可以尝试尝试，用Ruby来写坦克的AI。另外这个不到1000行的程序也比较好读，这种Robot AI平台以前也有C++/Java版本的，不过都要比这个实现得复杂一点吧。 每个你控制的robot的api是这些，注意雷达扫描到的目标只包含距离信息，没有x和y，如果雷达扫描得越快所得到的目标位置准确率越低。自己摸索着写，找一些别人写好的策略来对战一把吧。 battlefield_height #the height of the battlefield battlefield_width #the width of the battlefield energy #your remaining energy (if this drops below 0 you are dead) gun_heading #the heading of your gun, 0 pointing east, 90 pointing #north, 180 pointing west, 270 pointing south gun_heat #your gun heat, if this is above 0 you can&apos;t shoot heading #your robots heading, 0 pointing east, 90 pointing north, #180 pointing west, 270 pointing south size #your robots radius, if x &lt;= size you hit the left wall radar_heading #the heading of your radar, 0 pointing east, #90 pointing north, 180 pointing west, 270 pointing south time #ticks since match start speed #your speed (-8/8) x #your x coordinate, 0...battlefield_width y #your y coordinate, 0...battlefield_height accelerate(param) #accelerate (max speed is 8, max accelerate is 1/-1, #negativ speed means moving backwards) stop #accelerates negativ if moving forward (and vice versa), #may take 8 ticks to stop (and you have to call it every tick) fire(power) #fires a bullet in the direction of your gun, #power is 0.1 - 3, this power will heat your gun turn(degrees) #turns the robot (and the gun and the radar), #max 10 degrees per tick turn_gun(degrees) #turns the gun (and the radar), max 30 degrees per tick turn_radar(degrees) #turns the radar, max 60 degrees per tick dead #true if you are dead say(msg) #shows msg above the robot on screen broadcast(msg) #broadcasts msg to all bots (they recieve &apos;broadcasts&apos; #events with the msg and rough direction) 最近关注Ruby比较多，平时工作中也会用Ruby来写一些脚本(渐渐代替了Python)。有两个原因，Ruby的语法更符合口味(不喜欢用Python的indent约束),Ruby也更Lisp化，Ruby的开源气氛非常好。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Ruby","slug":"Ruby","permalink":"http://catcoding.me/tags/Ruby/"}]},{"title":"Ruby's Block and Proc","date":"2012-11-14T11:43:00.000Z","path":"2012/11/14/ruby_block_proc.html","text":"Callable objects在Ruby当中一切都是对象，但是有一个例外，那就是block。Block和Proc类似，但是还是有稍有差别的，Block更常用一些。最近在看《Metaprogramming Ruby》，在这节中有个例子是这样的。 require 'highline' hl = HighLine.new friends = hl.ask(\"Friends?\" , lambda {|s| s.split(',' ) }) puts \"You're friends with: #{friends.inspect}\" ⇒ Friends? Bill,Mirella,Luca You're friends with: [\"Bill\", \"Mirella\", \"Luca\"] 这里看起来hl.ask把Proc当作参数来传递，而不是接受了一个block，接受Block是另外一种使用模式： require 'highline' hl = HighLine.new new_pass = hl.ask(\"password: \") { |prompt| prompt.echo = false } 在highline代码可以看到相应的处理方式，第一种方式lambda构造成的Proc其实传递给了answer_type，而yield来处理block。 def initialize( question, answer_type ) # initialize instance data @question = question @answer_type = answer_type # allow block to override settings yield self if block_given? Proc, Lambda, Block有三种方式转化Block为Proc, Proc.new、Lambda、&amp;Operator。但是在使用过程中Block还是比Proc要常见，在给一个函数传递这种callable objcts的时候，可以隐式或者显示传递，像这样： def foo(*args) yield(args.join(' ')) end foo('Yukang', 'Chen'){|name| puts \"Hello #{name}\"} # => \"Hello Yukang Chen\" def foo(*args, &blk) blk.call(args.join(' ')) end foo('Yukang', 'Chen'){|name| puts \"Hello #{name}\"} # => \"Hello Yukang Chen\" 隐式传递要比显式传递performance要好一些。这很早就有讨论，具体原因是根据Ruby的实现一个Block在yield的时候并没有转换为Proc或者其他对象，所以少了一些开销。Ruby中的函数块是高阶函数的一种特殊形式的语法，Matz在设计块的时候考虑到： (1)在高阶函数中，这种只有一个函数参数非常常见，在实际使用中几乎没有必要在一个地方使用多个函数参数，(2)外观和形式上更直观，Enumerable利用块写的代码简洁易懂。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Ruby","slug":"Ruby","permalink":"http://catcoding.me/tags/Ruby/"}]},{"title":"丽江印象","date":"2012-11-08T11:43:00.000Z","path":"2012/11/08/lijiang.html","text":"上周我们公司一行九个人去丽江开会、游玩了四天。我去之前心里还没什么期望的，不过在那边待了一段时间后对丽江的印象还是挺好的。其实像这种古镇以前也逛过不少，成都的和江浙一带的都去过，大多商业化比较严重。不过丽江的古镇确实是我见过的最大的，虽然说也是商业化，还是存在不少原生态的东西。我们去的时间也刚好还算是合适，避开了人流的高峰期，也还有暖暖的阳光。 关于住宿因为前面两天要讨论一些技术问题，所以刚到丽江住的是宾馆。在丽江古城的边缘地带，价格比较贵。如果是个人去旅游，坚决不要住宾馆，找个靠谱的客栈吧，比如我们后来一天所住的泡沫之夏就非常实惠，老板人也挺好。丽江古城的客栈非常多，而且据我观察不少看起来非常干净，有的还可以跟着客栈主人一起吃饭，价钱也便宜。当地人给人印象还算是朴实，也很容易和游客乐成一片。 关于吃饭第一天我们因为旅途劳累所以随便选择了一个古城边缘的饭店吃饭，气氛不错，就是有点小贵。其实丽江吃饭便宜又好吃的地方挺多的，找那些当地的特色馆子，我们去过的唠叨妈私房菜是个很好的馆子，里面有个唠叨妹特别好玩，唠叨妈开馆子不是为了多赚钱，价钱实惠份量又足。在人多的时候他们准备收拾收拾为自家做饭了，要不是我们人多都不会被接待。 关于艳遇在丽江到处都写着艳遇，艳遇乃丽江的另一个代名词。丽江的酒吧非常多，各种风格的都有，这歌声和酒精为所谓艳遇创造了条件。在丽江玩的人大多都比较放松，在那种环境下人的隔阂也会少一些，问问几个哲学基本问题搭讪基本没问题的。但我觉得大部分人都是普通旅客，所谓”艳遇”也不过是交个陌生朋友，谈谈旅行见闻而已。当然也有不少是单独在那边待着“疗伤”的，如果恰好能碰上聊得来的也算是缘分了。去酒吧泡着是丽江夜生活的常态，我们去了几个比较有名气的酒吧，其中江湖酒吧感觉是最好的，乐队的现场表演非常吸引人。我在丽江等你音乐要要轻一些。Bamboo很有名因为小倩那首《一瞬间》是丽江今年的街歌，不过现场表演的效果不如江湖酒吧。后街2号就没有时间去了。 一点照片丽江的狗挺多，大多都还看起来很干净，无聊地天天在那里晒太阳。 江湖酒吧，小松的嗓音极好。 茶马古道上面那座山，因为时间紧张，所以我们没爬到山顶，遗憾。 拉市海附近非常漂亮，蓝天碧水。 拉市海旁边老太太的玉米，我所吃过的最好吃的玉米。 云南玩的地方还真是非常多，丽江附近可去的还有泸沽湖、玉龙雪山、香格里拉等等。有机会再去一次把这些地方看一看，最好能稍微多住一段时间。","tags":[{"name":"旅行","slug":"旅行","permalink":"http://catcoding.me/tags/%E6%97%85%E8%A1%8C/"}]},{"title":"Emacs iedit/occur 插件","date":"2012-11-05T11:43:00.000Z","path":"2012/11/05/emacs-symbol-util.html","text":"今天看到Mastering Emacs上介绍iedit插件的一篇文章。对于程序员来说，经常要重命名一个变量，之前我在Emacs下面使用替换命令来完成的，而Iedit可以编辑当前buffer里面多处相同的一个单词，编辑一处其他地方相同的symbol会自动被修改，这对于这样的操作是非常地直观有效，看下面这样的效果，图片来自Mastering Emacs。 最开始看到这个功能是在比较新的编辑器Sublime上，算是编辑器里一个很好的小创新吧。 另外在buffer中查找一个symbol也是经常需要的一个操作，我基本会用 (global-set-key [f3] 'highlight-symbol-next) (global-set-key [(shift f3)] 'highlight-symbol-prev) 来快速地在相同的symbol之间切换，这是来自highlight-symbol.el里面的。 同样的操作也可以用occur-mode来实现，occur的好处在于可以在另外一个窗口列出所找到结果大纲，这样更方便快速跳到相应的位置，这对于任何类型的文件都可以使用，而不止是可能需要静态分析后生成tags的程序。在Mastering Emacs后面有一段代码使得occur-mode可以在当前所有打开的buffer里找关键字。","tags":[{"name":"Emacs","slug":"Emacs","permalink":"http://catcoding.me/tags/Emacs/"}]},{"title":"调优的小工具RunLim","date":"2012-10-29T11:43:00.000Z","path":"2012/10/29/runlim.html","text":"在公司有同事用这个小程序RunLim来调试程序的内存问题。刚开始以为是我们上海的一个同事写的，就弄来看了看。后来发现是公司一个早期同事Armin Biere写的，还开源了，debian的源里有这个东西。我在公司维护的一部分代码是这个人写的，据说厉害的程序员，他现在在学术圈里。 用这个小程序来测试程序跑的时间和内存，用法很简单: ./runlim prog.exe 比如： kang@ubuntu:~/download/runlim-1.7$ ./runlim sleep 1 [runlim] version: 1.7 [runlim] time limit: 311040000 seconds [runlim] real time limit: 311040000 seconds [runlim] space limit: 4294966090 MB [runlim] argv[0]: sleep [runlim] argv[1]: 1 [runlim] start: Tue Oct 30 00:02:52 2012 [runlim] main pid: 22546 [runlim] end: Tue Oct 30 00:02:53 2012 [runlim] status: ok [runlim] result: 0 [runlim] children: 0 [runlim] real: 1.63 seconds [runlim] time: 0.00 seconds [runlim] space: 0.5 MB [runlim] samples: 10 查看help，这个工具还可以指定time limit和space limit,在指定的时间和内存限制内强制退出程序，其功能很像那些Online Judge，只是没有检测结果输出是否正确。 发现代码里有一个小小的Bug，根据源代码如果没有指定space limit， space limit那栏应该是当前的空闲内存大小，但是看我上面运行的命令，显示的4294966090 MB明显偏大，是其中的一个获取系统内存大小的函数溢出了。这里应该是这样： static unsigned get_physical_mb () { unsigned long long mem; mem = (unsigned long long)sysconf(_SC_PAGE_SIZE)* (unsigned long long)sysconf(_SC_PHYS_PAGES); return mem >>= 20; } sysconf获取页大小和页数目，具体看这里How to get information about the memory subsystem?。 这个小工具还是查询/proc下的进程统计信息的，根据fork出来的子进程pid，递归地查询统计信息。 时间的统计可能会稍显粗略，如果需要更精确的时间统计该如何实现。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"RunLim","slug":"RunLim","permalink":"http://catcoding.me/tags/RunLim/"}]},{"title":"Ruby vs C++ for delegation","date":"2012-10-16T11:43:00.000Z","path":"2012/10/16/delegate_ruby_cpp.html","text":"下班之前同事BigBird给我show他的一段C++代码，对于我等拿C++当作C来用的未入门者实看起来实在是炫丽。虽然比较冗长晦涩，不过还是能看懂个大概，然后觉得这对于动态语言是非常容易实现的。 于是晚上回来用Ruby来搞搞，弄出下面这么段代码。 C++版本在这里https://gist.github.com/3900077。可见动态语言和编译型语言实现起来效率还是好太多了，同时代码也好理解。再次我讨厌C++类型推导，^_^。 Ruby实现这个方式很多，另外Ruby的库包含SimpleDelegator的，将调用的方法直接传递到其他对象。 #!/usr/bin/rubyclass Delegate attr_reader :proc_list def initialize() @proc_list = [] end def add(*proc) proc_list.push(proc) end def eval(obj) for e in proc_list: if obj.respond_to?(e[0]) if e.size == 1 obj.__send__(e[0]) else obj.__send__(e[0], e[1]) end else printf &quot;ERROR:%s is not defined\\n&quot;, e[0] end end endendclass Demo attr_writer :valuepublic def print() printf &quot;value:%d\\n&quot;, @value end def hello() printf &quot;Hello world!\\n&quot; end def set(val) @value = val endenddelegate = Delegate.new()delegate.add(&quot;print&quot;)delegate.add(&quot;set&quot;, 1)delegate.add(&quot;print&quot;)delegate.add(&quot;hello&quot;)delegate.add(&quot;nodefine&quot;)d = Demo.new()delegate.eval(d)","tags":[{"name":"Ruby","slug":"Ruby","permalink":"http://catcoding.me/tags/Ruby/"},{"name":"C++","slug":"C","permalink":"http://catcoding.me/tags/C/"},{"name":"delegator","slug":"delegator","permalink":"http://catcoding.me/tags/delegator/"}]},{"title":"UbiGraph动态显示Python函数调用","date":"2012-09-27T11:43:00.000Z","path":"2012/09/27/3d-python-call-path.html","text":"UbiGraph显示环境 UbiGraph是一个显示平台，可以非常方便地使用Python/C/Ruby来控制渲染，只需要制定节点和边还有其他相关属性，其余的都不用管了。其使用XML-RPC服务于客户端，所以甚至可以在一台机器上开server，在另外一台机器上用渲染代码控制，这个环境对于算法和数据的可视化很有用。 比如： import ubigraphU = ubigraph.Ubigraph()U.clear()x = U.newVertex(shape=&quot;sphere&quot;, color=&quot;#ffff00&quot;)smallRed = U.newVertexStyle(shape=&quot;sphere&quot;, color=&quot;#ff0000&quot;, size=&quot;0.2&quot;)previous_r = Nonefor i in range(0,10): r = U.newVertex(style=smallRed, label=str(i)) U.newEdge(x,r,arrow=True) if previous_r != None: U.newEdge(r,previous_r,spline=True,stroke=&quot;dashed&quot;) previous_r = r 显示效果如下： 只是这个软件是免费的但不是开源的，另外还没有支持Windows平台。 使用Ubigraph显示Python函数调用这是在这里看到的，貌似需要翻墙。代码比较简单，在点击查看prof3d.py。 使用方法是先启动Ubigraph的server，然后运行下面的代码： import prof3ddef run_main(): # your codeif __name__ == &quot;__main__&quot;: prof3d.profile_me() run_main() 这段Python的代码函数调用关系就显示出来了，而且还是动态的。 效果如下：","tags":[{"name":"Python","slug":"Python","permalink":"http://catcoding.me/tags/Python/"},{"name":"Tools","slug":"Tools","permalink":"http://catcoding.me/tags/Tools/"}]},{"title":"A*算法解决kth-shortest路径问题(2)","date":"2012-09-18T11:43:00.000Z","path":"2012/09/18/a-start-k-shortest.html","text":"我之前写过一篇图文并茂的文章来介绍这个算法，有好几次有朋友反馈说对自己有帮助，深感荣幸。这次再次写这个也是因为帮忙于一个朋友解决这类问题，这里再成一篇，稍显罗嗦。 问题描述无向图G，需要求出S-&gt;T点的前k短路径，要求路径中没有环。(所有的边的权值不为负) A*算法求解kth-shortest问题A*算法已经被广泛运用于路径规划问题中，同时A*算法作为一种启发式算法的框架，可用于多种搜索问题，还是先回顾一下A*的基本符号： f(s)=g(s)+h(s)，其中h(s)&lt;=h*(s)，h*(s)是某点到终点的真实代价，h(s)是估计代价，并且对s的任意后继t有：h(t)+w(s,t)&gt;=h(s)，其中w(s,t)是从s转移到t的代价，符合这条件的评估函数f(s)可以得到正确的最短路径。 而这里评估函数f(s)是A*算法的关键，其效率都取决于此,退化的A*算法就是宽度搜索(即启发函数h(s)为常数)。另外A*算法的最优性证明在这篇论文里有阐述。 所以如果能确切的计算出来h*(s)，那么评估函数f(s)将是s点的最短路径，这可算是一个最优的启发函数。可以利用Dijkstra算法来求解出各个点到T点的最短路径，假设第i个节点到T的最短路径计为Dist_T(i)，Dist_T(i)作为A*函数中的启发函数h(s)，从S开始搜索，因此算法描述如下： int Astar()&#123; if(dist[S]==INF) return -1; priority_queue&lt;Node&gt; Q; //极小堆，定点为f(s)=g(s)+h(s)最小的节点 Q.push(Node(S,0)); //源点S加入堆，估计代价为0 while(!Q.empty())&#123; int len=Q.top().len; int u=Q.top().v; Q.pop(); cnt[u]++; //节点u访问一次 if(cnt[T]==K) return len; //第K次从队列弹出的值为kth-shortest的值 if(cnt[u]&gt;K) continue; for(int i=0;i&lt;Adj[u].size();i++) &#123;//取v节点的临接节点计算评估函数并加入优先队列 int v = Adj[u][i].v; int eval = len + Dist(u,v) + Dist_T(v); Q.push(Node(v, eval)); &#125; &#125; return -1;&#125; 因为没有标识哪些节点访问过哪些节点没有访问过，所以这种方法计算出来的结果路径可能含有环，即可能出现1-&gt;2-&gt;3-&gt;2-&gt;5，为了避免这样的情况可以在每个扩张Node里面增加当前路径已经访问过的点，在进行下一次扩张的时候可以避免访问这些已经在路径中的节点。但是这样所需要的空间复杂度是巨大的，所以需要再次用一些剪枝办法来避免过多的扩展。 一个优化A*算法在扩展节点的时候，如果我们能筛除掉更多无用的节点，那么都可以利于减少搜索的空间复杂度和时间复杂度。当k取值较小的时候，即当我们并不需要知道所有路径长度和其排序，而只需要知道前k(假设k&lt;=10)段的路径，这里加上一个剪枝会有很大的优化。 假设我们事前知道kth-shortest的最大值，就能在扩张的时候加入这个限制，避免大部分的无用的节点扩张。 for(int i=0;i&lt;Adj[u].size();i++) &#123;//取v节点的临接节点计算评估函数并加入优先队列 int v = Adj[u][i].v; int eval = len + Dist(u,v) + Dist_T(v); if(eval &gt; max_dist) continue; else Q.push(Node(v, eval));&#125; 如何知道kth-shortest的最大值这个临界点呢？ 假设我们知道某条经过点v的S-&gt;T路径的最短长度，即对于所有的点v1,v2,v3,….vn,有dist(v1)为S-&gt;…-&gt;v1-&gt; …-&gt;路径的长度，一共n个dist，把这n个dist排序以后，取第k小的dist(v_kth_smallest)即为kth-shortest。如何计算出dist(v)，通过Dijkstra(T)可以计算出v到T的最短路径，同样可以通过Dijkstra(S)可以计算出S到v的最短路径Dist_S(v)，这里有如下定理： 对于任意最短路径S-&gt;K中，假设经过点v，则必有: min(S-&gt;v)和min(v-&gt;T)。因此要计算经过v的从S-&gt;K的最短路径可以用: min_dist(v) = Dist_S(v) + Dist_T(v) 因此如果我们用这种方法计算出Dist(v)，那么最后第k小的dist(v_kth_smallest) &gt;= kth-shortest。这对于A*算法的最后结果没有影响，但是同样可以作为一个条件来删除掉大部分不符合条件的节点，因此得到一个很好的优化方案。这个优化可以用于k&lt;N时的kth最短路径问题，可以预见k越小剪枝效果越好。 据我实现在18600个节点的图上，这个算法比Yen’s算法快了很多倍，甚至在我的PC(3G内存)机上，后者在算到k=3的时候内存就支持不住了。 算法复杂度分析假设图G有m条边和n个节点，Dijkstra算法的复杂度为((m+n)log n)(二叉树实现的优先队列)。A*算法的时间复杂度取决于启发函数，事实我还不清楚如何分析这样的算法的时间复杂度和空间复杂度，根据这篇文章来说是O(delta*V^2*(lgV+lg(delta)))的。 如果哪位知道如何分析A*算法的复杂度，劳烦请教。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Algorithms","slug":"Algorithms","permalink":"http://catcoding.me/tags/Algorithms/"}]},{"title":"换域名了cyukang.com","date":"2012-09-13T11:43:00.000Z","path":"2012/09/13/change-domain-name.html","text":"昨天晚上突然发现自己的域名moorekang.com不能用了，上午问了一下域名提供商Bloghost，原来因为双方沟通上的问题导致我的域名没及时续费，甚至进入了赎回期，在这个时候只有这么几种选择： 换一个域名 赎回自己原来的域名，价格不太便宜，国际域名和国内域名也有差别，我的需要150美金 等域名过了赎回期再重新购买，期间需要等待40来天左右 所以，血的教训啊，及早续费自己的域名，免得面临这么一个窘境。无奈，我选择了换域名，虽然原来那个稍显长的域名已经用了近两年多。稍微找了一下，觉得这个域名cyukang.com还比较短，于是就申请了下来。国际域名不用各种备案，所以几分钟就下来了。另外对于Jekyll和GitPage这样的组合，换域名是多么的简单，几分钟就搞定了，所以这次折腾也没花多少时间。 另外我觉得twitter这个主题已经够简洁了，今天稍微做了一下改动，用我仅有的一点css知识让顶部的导航栏固定下来。 有我链接的麻烦换一下，呃，其实也没几个人用我做友链:)，不过还是得喊一声的。 –","tags":[]},{"title":"OS dev的Bochs调试","date":"2012-08-19T11:43:00.000Z","path":"2012/08/19/os-dev-debug.html","text":"最近在弄一个自己的hobby OS，作为菜鸟在调试时候积累一些经验，记录一下。 Bochs调试Bochs自带调试功能，但是如果你是apt装上的是不行的，下源码来自己编译，编译选项为： ./configure --enable-debugger --enable-disasm 这个我只是尝试过，在OS的loader阶段可能会用到，当如果进入C语言实现部分的代码如何调试?我希望看到C的源码级别调试，而不是汇编的。 Bochs + gdb调试同样需要在编译的时候加上选项，这个选项必须注意，否则在gdb调试的时候会出现”Cannot find bounds of current function”之类的问题。 ./configure --enable-debugger --enable-disasm --enable-gdb-stub 诡异的是这个–enable-gdb-stub选项和上面的 –enable-debugger选项只能二选一。也行，编译出来后重命名吧。编译完成后在Bochs的配置文件.bashrc中加上这么一行: gdbstub: enabled=1, port=1234, text_base=0, data_base=0, bss_base=0 另外注意kernel的代码也需要加入-g编译选项。最后在编译完成后的文件是带调试信息的，但是我们在用Bochs启动的img文件不需要这些，现在比如kernel.elf是带编译信息的kernel文件，用下面的这个步骤去掉调试信息，据说也可以用strip来。 cmd=&quot;objcopy -R .pdr -R .comment -R .note -S -O binary kernel.elf kernel.bin&quot; cat boot.bin setup.bin kernel.bin &gt; ../a.img; Bochs 使用的是这个a.img文件， gdb载入的是kernel.elf文件。 启动Bochs后会等待gdb连进来(其实Qemu也可以这样进行调试的)，查资料过程中发现还可在调试的目录加上.gdbinit，这样每次启动gdb就不那么麻烦了： file ./objs/kernel.elf target remote localhost:1234 set disassembly-flavor intel b kmain 一些有用tipsOS的代码中经常会有内联汇编，有的时候一条内联过去就崩溃了，所以在gdb里需要查看反汇编语句和registers。下面这些gdb指令比较有用： (gdb) info line main.c:26 (查看main.c:26行在目标文件中的位置，为0x1cbc) Line 26 of &quot;./kernel/main.c&quot; starts at address 0x1cbc &lt;kmain&gt; and ends at 0x1cc2 &lt;kmain+6&gt;. (gdb) info line *0x1cbc (上面的反操作) Line 26 of &quot;./kernel/main.c&quot; starts at address 0x1cbc &lt;kmain&gt; and ends at 0x1cc2 &lt;kmain+6&gt;. (反汇编kmain函数，箭头指向的是当前运行的汇编代码) (gdb) disas kmain Dump of assembler code for function kmain: =&gt; 0x00001cbc &lt;+0&gt;: push ebp 0x00001cbd &lt;+1&gt;: mov ebp,esp 0x00001cbf &lt;+3&gt;: sub esp,0x28 0x00001cc2 &lt;+6&gt;: mov eax,DWORD PTR [ebp+0x8] 0x00001cc5 &lt;+9&gt;: mov ds:0x5ccc,eax 0x00001cca &lt;+14&gt;: call 0x2a29 &lt;init_video&gt; 0x00001ccf &lt;+19&gt;: mov DWORD PTR [esp+0x4],0xb 0x00001cd7 &lt;+27&gt;: mov DWORD PTR [esp],0x4777 0x00001cde &lt;+34&gt;: call 0x2a40 &lt;puts_color_str&gt; 0x00001ce3 &lt;+39&gt;: mov DWORD PTR [esp+0x4],0xa 0x00001ceb &lt;+47&gt;: mov DWORD PTR [esp],0x478d 0x00001cf2 &lt;+54&gt;: call 0x2a40 &lt;puts_color_str&gt; 0x00001cf7 &lt;+59&gt;: cli 0x00001cf8 &lt;+60&gt;: call 0x3876 &lt;time_init&gt; 0x00001cfd &lt;+65&gt;: call 0xc13 &lt;gdt_init&gt; 要正确的看到反汇编最好设置好gdb里面的汇编指令集，对于Nasm设置”set disassembly-flavor intel”,在.gdbinit里面弄好就行。 最后info registers查看cpu寄存器内容，info registers %eax只查看eax内容，而info all-registers会把cpu的所有寄存器内容显示出来，不过cr0,cr3这些貌似没有 :(。看看这里GDB参考。","tags":[{"name":"debug","slug":"debug","permalink":"http://catcoding.me/tags/debug/"},{"name":"bochs","slug":"bochs","permalink":"http://catcoding.me/tags/bochs/"},{"name":"OS","slug":"OS","permalink":"http://catcoding.me/tags/OS/"}]},{"title":"Linux下快捷切换屏幕","date":"2012-08-09T11:43:00.000Z","path":"2012/08/09/switch-screen.html","text":"在办公室工作的时候一般面对两个显示器，大部分时候左边用来看代码，右边用来写程序。双显示屏还是有助于提高工作效率的。有一点困扰我的是如果要切换屏幕一般得用鼠标，这对于Emacs党是有些不能忍受的，右手离开键盘总是得停顿一下的感觉。今天找到一个解决办法。 最终找到的是这个号称Linux下键盘精灵的一个程序:xdotool，下载下来编译安装。这个东西可以模拟鼠标和键盘的行为： 比如： xdotool search &quot;Mozilla Firefox&quot; windowactivate --sync key --clearmodifiers ctrl+l (快速切换倒firefox,并focus在地址输入栏)xdotool getmouselocation --shell (获取当前鼠标位置等信息)X=880Y=443SCREEN=0WINDOW=16777250xdotool getactivewindow windowmove 100 100 # Moves to 100,100xdotool getactivewindow windowmove x 100 # Moves to x,100xdotool getactivewindow windowmove 100 y # Moves to 100,yxdotool getactivewindow windowmove 100 y # Moves to 100,yxdotool mousemove --screen 0 100 100 # Moves to screen 0 pos at 100,100 有了上面windowmove命令，屏幕的切换就好实现了。写个丑陋的python脚本来保存当前的位置，切换到另外一个屏幕，再次调用的时候返回到原来的位置，保存为mouse.py。 #!/usr/bin/pythonimport osimport sysimport commandsdata_f = &quot;/tmp/window_data&quot;now_info = commands.getoutput(&quot;xdotool getmouselocation --shell&quot;).split(&#x27;\\n&#x27;)x = (now_info[1])[2:]y = (now_info[2])[2:]screen = (now_info[3])[7:]window = (now_info[4])[7:]def do_store(): data = open(data_f, &quot;w+&quot;) content = screen+&quot;\\n&quot;+x+&quot;\\n&quot;+y+&quot;\\n&quot;+window data.write(content) data.close() def do_update(): if screen == &quot;1&quot;: new_sc = &quot;0&quot; else: new_sc = &quot;1&quot; cmd = &quot;xdotool mousemove --screen &quot; + new_sc + &quot; 0 0&quot; commands.getoutput(cmd)if os.path.exists(data_f): data = open(data_f, &quot;r+&quot;) content = data.readlines() data.close() screen = content[0][0:-1] old_x = content[1][0:-1] old_y = content[2][0:-1] old_window = content[3] if old_window != window: cmd = &quot;xdotool mousemove -w &quot; + old_window + &quot; &quot; + old_x + &quot; &quot; + old_y commands.getoutput(cmd) do_store() else: do_store() do_update()else: do_store() do_update() 最后，通过Emacs下绑定快捷键来调用这个脚本即可实现两个屏幕之间的切换，又可以远离鼠标了。哈哈。 (defun switch-screen() (interactive) (start-process \"mouse.py\" nil \"bash\" \"-c\" \"/home/yukang/apps/bin/mouse.py\")) (global-set-key (kbd \"C-x q\") 'switch-screen) Jekyll下写点东西快多了。","tags":[{"name":"Tools","slug":"Tools","permalink":"http://catcoding.me/tags/Tools/"},{"name":"Linux","slug":"Linux","permalink":"http://catcoding.me/tags/Linux/"}]},{"title":"分支预测优化","date":"2012-07-11T11:43:00.000Z","path":"2012/07/11/branch_prediction.html","text":"问题Stack_overflow上有这么一个帖子:为什么排序后会快很多，说是下面这段代码比较诡异，引发了比较多的回复，一起来看看。 #include &lt;algorithm&gt;#include &lt;ctime&gt;#include &lt;iostream&gt;int main()&#123; // generate data const unsigned arraySize = 32768; int data[arraySize]; for (unsigned c = 0; c &lt; arraySize; ++c) data[c] = std::rand() % 256; std::sort(data, data + arraySize); //排序这行不注释掉下面的for循环会快得多 // test clock_t start = clock(); long long sum = 0; for (unsigned i = 0; i &lt; 100000; ++i) &#123; // primary loop for (unsigned c = 0; c &lt; arraySize; ++c) &#123; if (data[c] &gt;= 128) sum += data[c]; &#125; &#125; double elapsedTime = static_cast&lt;double&gt;(clock() - start) / CLOCKS_PER_SEC; std::cout &lt;&lt; elapsedTime &lt;&lt; std::endl; std::cout &lt;&lt; &quot;sum = &quot; &lt;&lt; sum &lt;&lt; std::endl;&#125; 如果把std::sort(data, data + arraySize);注释掉，下面那段for循环所花费的时间是11.54秒。 如果不注释掉，即排序后下面那段所用的时间是1.93秒。 相差比较大。那个for循环总是要执行完的，为什么排序后会快不少? 分支预测 下面的获得票数最多的回复质量非常高，很生动细致地说明了cpu的分支预测技术。 看上面这情形，如果在没有通讯设备的年代，如果你是这个火车枢纽的操作人员，是不是要让火车驾驶员把车停下来，然后告诉你他需要往哪个方向行驶，等你完成转向操作的时候再继续行驶火车呢。也许有一些更好的办法，你可以猜测火车要往哪边行驶。 如果你猜对了，那么节省了不少时间。 如果猜错了，火车停下来，等你撤销刚才的操作，再往前走，这会比较耗费时间。 同样在执行指令的时候，cpu也能做这样类似的工作。现代cpu都采用 指令流水线技术 ，即处理器会预取下面要执行的一些指令，如果下面的指令正是需要被执行的那就节省了时间，如果在概率上大部分能猜对下面要运行的指令，那就提高了cpu的运行效率。更详细的图文介绍可以参考wiki。简单的说明就是cpu会根据前面所执行的指令的历史，归纳出相应的模式，把预测的指令预取进来，然后继续沿着预测的指令执行。如果发现预测错误，则倒过来重新初始化预测表、刷新指令管道然后继续执行。所以看上面的例子： T = branch takenN = branch not takendata[] = 0, 1, 2, 3, 4, ... 126, 127, 128, 129, 130, ... 250, 251, 252, ...branch = N N N N N ... N N T T T ... T T T ... = NNNNNNNNNNNN ... NNNNNNNTTTTTTTTT ... TTTTTTTTTT (easy to predict) 后面作者又加了一条hack，把这段代码重新改写一下： if (data[c] &gt;= 128) ====&gt; int t = (data[c] - 128) &gt;&gt; 31; sum += data[c]; ====&gt; sum += ~t &amp; data[c]; 那么前面是否排序就对这段代码效率没有影响了，同样是2秒多。 这和编译器的优化非常相关，不同的编译器的结果不一样，4.6.1 GCC 加上-O3或者-ftree-vectorize编译选项可以对这种情况进行优化，所以排序与否没有关系，而VC++2010却不能进行类似优化(GCC果然强大)。 一个优化例子 在Linux kernel里面会看到类似likely和unlikely这样的代码，从其名字就很直观的解释了其意义。看其定义为两个宏。 include/linux/compiler.h#define likely(x) __builtin_expect (!!(x), 1)#define unlikely(x) __builtin_expect (!!(x), 0) Linux内核开发者使用这两个宏来通过编译器提示cpu：某一段代码很可能会执行，应该被预测，而有的情况出现的概率比较小，不必预测。类似这样的代码： if(likely(some_cond)) &#123; //this is often happen! /* Do something */&#125;if (unlikely(some_cond)) &#123; //this is rare! /* Do something */&#125; 关于这个方面，在这篇论文What every Programmer should know about Memory里面有更详细的讲述。分支预测在现代cpu上如此通用，竟然还有人利用这个来尝试破解RSA的，看这个On the Power of Simple Branch Prediction Analysis。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"优化","slug":"优化","permalink":"http://catcoding.me/tags/%E4%BC%98%E5%8C%96/"},{"name":"分支预测","slug":"分支预测","permalink":"http://catcoding.me/tags/%E5%88%86%E6%94%AF%E9%A2%84%E6%B5%8B/"}]},{"title":"GDB调试动态链接库","date":"2012-06-25T11:43:00.000Z","path":"2012/06/25/gdb-with-libso.html","text":"今天解决了一个长期会碰到的问题，就是用GDB如何来调试动态链接库。我这个问题的难点是我的需要调试代码是在动态链接库里面，但是启动的不是普通的可以调试的二进制文件，换句话说这不是我所能控制的代码所编译出来的，甚至可能是由脚本程序来控制启动的。这个问题时不时地困扰着我，总结一下尝试过几种调试方式： 1 使用print来打印log，有时候有用，不好的地方是有时候定位出问题的代码位置还是稍显麻烦。很常用的会定义一对宏，进入函数和退出某个函数的时候都相应调用。 #define APP_LOG(X) \\ fprintf(stderr, &quot;log: %s %d %s %s\\n&quot;, \\ __FILE__, __LINE__, __FUNCTION__, X); \\#define LOG_ENTER \\ APP_LOG(&quot;enter&quot;) #define LOG_LEAVE \\ APP_LOG(&quot;leave&quot;) 2 对于crash掉的bug，打印出来调用栈是非常有用的。使用libc提供的Backtraces函数来获取调用栈。这是在不能提供GDB环境下拿到调用栈的不错方法。不过经过我的实验这对于动态链接库有一定的问题。 3 最后就是今天试用的比较通用办法。 我们不管是如何调用到动态链接库文件的，但是肯定会调用进来。所以需要想办法让代码在库代码处停下来，然后把找机会把GDB弄进去。于是乎有这么一个变态的办法，在动态链接库入口处来这么一段，就是执行到这里停住，等待GDB attach这个进程，然后在GDB里设置一个断点，touch创建当前文件夹debug文件就跳出死循环，接下来就是一切在GDB控制下了。 void wait_attach() &#123; fprintf(stderr, &quot;Waiting attach pid: %d\\n&quot;, getpid()); while(1) &#123; if((access(&quot;./debug&quot;, F_OK)) != -1) &#123; break; &#125; else ; &#125;&#125; 这是一个stupid and work的方法，不过我总觉得还有更好的办法来在这种情况下调试。 在查找资料的过程中有点意外收获，顺便推荐GDB一个选项，gdb -tui, 以texture gui方式启动GDB，这是非常方便的文字界面。如果不用这个选项也可以在运行GDB以后按下快捷键盘C-x C-a(怎么这么像Emacs快捷键)来进行gui和非gui的切换。CLI爱好者可以试用一下，DDD什么的可以放下了，嘿嘿。 另外一些有用的GDB命令： rbreak: break on function matching regular expressionwhere: Line number currently being executedtbreak: Break once, and then remove the breakpointwatch: Suspend the process when a certain condition is metfinish: Continue till end of functioninfo locals: View all local variablesbacktrace full: Complete backtrace with local variablesup, down, frame: Move through framesset print pretty on: Prints out prettily formatted C source codeset print array on: Pretty array printingenable and disable: Enable/disable breakpointsset logging on: Log debugging session to show to others for support","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"gdb","slug":"gdb","permalink":"http://catcoding.me/tags/gdb/"},{"name":"debug","slug":"debug","permalink":"http://catcoding.me/tags/debug/"}]},{"title":"bsfl指令和Bitmap的一个优化","date":"2012-06-20T11:43:00.000Z","path":"2012/06/20/bsfl-bitmap.html","text":"如何找出int中第一个1对于这个问题我们可以从最原始的做法开始，如果没找到1返回0，如果第一位为1返回1。所以代码很简单如下： static int first_onebit(int x)&#123; if(!x) return 0; else&#123; int idx = 0; if(x%2 != 0) return 1; while( x%2 == 0 ) &#123; x&gt;&gt;=1; idx++; &#125; return idx+1; &#125;&#125; 如何能做到更好呢?这里有一个trick使用一条指令来完成这个工作，具体可以参考Linux Kernel里面这个ffs的代码。我来简化一下就是这么一个函数: /* ffs: if ret == 0 : no one bit found return index is begin with 1 */static int first_onebit(int x)&#123; if (!x) &#123; return -1; &#125; else &#123; int ret; __asm__(&quot;bsfl %1, %0; incl %0&quot; : &quot;=r&quot; (ret) : &quot;r&quot; (x)); return ret; &#125;&#125; 这里的bsfl是一条intel汇编指令，它的用法是bsfl op1,op2:顺向位扫描从右向左（从位0–&gt;位15或位31）扫描单节字或双字节操作数op2中第一个含”1”的位，并把扫描到的第一个含’1’的位的位号送操作数op1中。所以就是一条指令完成了这个计算过程。 这里真的会有多大的差别么，我们可以用程序来计算一下，测试如下: int main()&#123; int x; for(x=0; x&lt;=1000000000; x++)&#123; first_onebit(x); &#125; return 0;&#125; 第一个版本花费时间15.685s，第二个版本花费时间5.960s,而其实如果只是循环1000000000次什么也不做也好花费3.091s,所以第二个版本快到如此程度。 bitmap的优化bitmap是一种常用的数据结构，在编程珠玑有详细介绍，应用也比较广泛比如可以用来做操作系统当中的地址索引查询。对于bitmap中我们常常需要一个操作来找一个空位的bit来做set操作。既然我们知道了第一个1是如何快速查找的，第一0也就好办了，先取反，然后再找第一个1就行了。 #define first_zerobit(x) (first_onebit(~(x))) 继续bitmap的first_empty就优化成这样了: u32 first_empty()&#123; u32 idx; for(idx=0; idx&lt;max_idx; idx++)&#123; if(arr[idx] == 0xFFFFFFFF) //full continue; u32 v = arr[index]; return 32*idx + first_zerobit(v) - 1; &#125; return -1;&#125; 注意这样的用汇编指令来优化可能会有平台差异，所以你最好清楚自己的平台是否适用。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"bitmap","slug":"bitmap","permalink":"http://catcoding.me/tags/bitmap/"}]},{"title":"使用Jekyll和Github搭建博客","date":"2012-06-13T11:43:00.000Z","path":"2012/06/13/try-jekyll-git.html","text":"为什么要折腾折腾了几次终于把博客从wordpress搬到Github了，迁徙这事本来是够麻烦的，而且也比较无聊。不过最终还是抑制不住诱惑，这有下面几点点好处。 编辑方便，专注写作 在线下编辑，可以随便选择自己喜欢的编辑器。当然wordpress也有离线编辑工具，不过Linux下我还没找到合适的，我平常是用Muse生成html，然后再粘贴到站上。其实还好，就是插入图片不方便。使用Github和Jekyll是完全的离线，你甚至都不需要离开终端就可以发布文章，一切都只是简单的git push而已。写的过程中还可以用jekyll –server预览最终排版。 可以使用Github进行版本管理 像写程序一样写日志，这对程序员吸引很大。我用这个小脚本来完成发布: #!/bin/shdo_commit() &#123; cmd=&quot;git commit -a -m\\&quot;$log\\&quot;&quot; echo $cmd git add .; git commit -a -m&quot;$log&quot; git push;&#125;while [ $# -gt 0 ]do case $1 in -commit |-u) shift; log=$1; do_commit; exit 0;; esac shiftdone 简洁 我喜欢这套是因为感觉一切都很简单,在_post目录下写markdown格式的文章，生成网页、push上去就发布了。页面也非常整洁，这对于一个以文字和代码为主要内容的站点来说最合适不过了。而且因为生成的全是静态网页，所以打开的速度也非常快。 折腾过程 这套工具适合程序员，因为一切都可以在本机上操作，你可以自己写程序来批量处理文档。我是自己写了一点Python小程序转移图片。 迁徙的过程中也会碰上一些问题，不过如果你懂一点Ruby，这些都还是比较好解决的。基本步骤为： 申请GitHub，这个不少程序员有，直接跳过。 安装Jekyll 在本地，可能会遇上ruby版本的问题，我的机子上是1.8.7，需要1.9.2，使用rvm来解决，具体参考这里。具体使用下面一些命令: sudo apt-get install gems curlgem install rvmrvm get latest rvm reloadrvm install 1.9.2rvm use 1.9.2ruby -v #(use 1.9.2)gem install directory_watcher liquid open4 maruku classifier jekyll 再建立yourname.github.com项目，git clone jekyll bootstrap到自己的代码库。 从wordpress迁徙，我使用wordpress.xml这个方法，最后修改域名解析就大功告成了。修改域名的时候在Git上建立CNAME为demo.com，在DNS处设置demo.com的A记录到Github的地址(207.97.227.245)，同时为了使得www.demo.com也指向GitHub,设定www的A记录到这个地址。这是我设置的时候出错了的地方。 整个流程非常简单，你甚至可以在三分钟内完成Github的博客搭建，更相详细可以参考这里这里。","tags":[{"name":"jekyll","slug":"jekyll","permalink":"http://catcoding.me/tags/jekyll/"},{"name":"git","slug":"git","permalink":"http://catcoding.me/tags/git/"}]},{"title":"Find duplicated Number and Cycle detection","date":"2012-04-11T11:43:00.000Z","path":"2012/04/11/find-duplicated-cycle-detection.html","text":"一个有趣的问题，据说这个题目耗费了Don Knuth 24小时解决。一起来看看。 You are given an array of integers of length n, where each element ranges from 0 to n - 2, inclusive. Prove that at least one duplicate element must exist, and give an O(n)-time, O(1)-space algorithm for finding some duplicated element. You must not modify the array elements during this process. 这有几个重要的约束，O(n)，O(1)的复杂度，不能修改这个数组。可能有多个数重复了，但至少有一个数重复了。首先第一个证明问题，等价于n个鸽子，n-1个笼子，那么至少有一个笼子里面有2个鸽子，就是鸽笼原理(抽屉原理), 反证法可以证明。难的是第二个问题，假设a[0, n], 值都在0,1, …, n-2 范围内。如果扫描这个数组，重复的会出现第二次(废话,囧)，关键是只能用O(1)的空间，否则用空间记录出现过的就行了。如果把数组看成一个映射，i -&gt; f(i) = a[i]， 那么这个问题可以转换成更抽象的模型。 举个例子： n = 6index: 0 1 2 3 4 5value: 1 4 0 0 3 2 其index对应value映射为为0-&gt;1, 1-&gt;4, 2-&gt;0等等，那么把这个图画出来就是这样： &nbsp; 这个问题转换为求图中环开始的点，因为出现环说明某个点重复出现了。从5开始遍历这个图会在0处发现环，为什么选取5，因为5肯定为一个起点，并且不在0~N-2内。其实只要选取不孤立的那个点当作起点就可以检测环，极端情况比如： n = 6index: 0 1 2 3 4 5value: 0 1 2 4 5 3 选择index=5还是可以发现环，如果选取0就发现不了3和4,5之间的那个环。 [Cycle detection]是一个经典的计算机问题。经典的算法是Floyd’s cycle-finding algorithm，这个算法简单而优美。严格的数学证明当然可以，也能更明显的从现实经验得出结论。如果一个赛道中间出现某个环(分两种情况，赛道本身是环、赛道前面有一段没环而中间出现一个环9字形)，求这个环的周长C。让两位运动员同时出发，并且P1的速度是P2的两倍，当他们第一重新相遇的时候，一定是在环的某个点上，并且其路程之差为这个环的周长的K倍(K&gt;=1)，这解决了一部分问题，我们知道了KC的值，如果K==1，则得出结果，说明两人刚好是在环开始点相遇。否则就是在环内其余点相遇，可以得知现在P2的路程为KC(P1的路程为2KC), 如果让P3以和P2同样的速度从起点开始，P2继续从相遇点开始跑，那么P2和P3肯定还会相遇，并且相遇的点一定为环开始点! 回到这个问题，这个index的值就是重复的值。代码描述如下： int detectCycle(int* seq， int Num)&#123; int slow = Num -1; int fast = Num -1; while(1) &#123; slow = seq[slow]; fast = seq[seq[fast]]; if(slow == fast) break; &#125; int finder = Num - 1; while(1) &#123; slow = seq[slow]; finder = seq[finder]; if(slow == finder) break; &#125; return finder;&#125; 算法描述很简单，但其中思维的却很有乐趣。以前同样有一个问题，检测一个链表是否有环，这是由此出来的一个特例，因为对于一个链表的每个节点除了头节点都有一个前节点和后节点(无环则末节点指向空)，而图是一个更通用的模型。 bool hasCycle(ListNode *head) &#123; ListNode* slow = head; ListNode* fast = head; while(fast &amp;&amp; fast-&gt;next) &#123; slow = slow-&gt;next; fast = fast-&gt;next-&gt;next; if(slow == fast) return true; &#125; return false;&#125;","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Algorithms","slug":"Algorithms","permalink":"http://catcoding.me/tags/Algorithms/"}]},{"title":"eproject","date":"2012-03-08T11:43:00.000Z","path":"2012/03/08/eproject.html","text":"我之前一直用的是project-mode.el来管理项目，在碰上代码很多的工程时还是有点不方便，源文件太多速度有点慢。快速检索文件还是可以，需要指定代码目录，可以增加目录。工程的概念还是不太直观，主要用来快速查找文件。 以前看有同学推荐过eproject, 当时没仔细看。这会儿想自己写一个，而今天偶尔试用了一下这个eproject.el这才是真正需要的好东西啊。 一个工程包含的是经常需要访问的文件，另一个重要的地方是可以自己绑定Make, clean, run, configure等命令。 一组常用命令加文件检索，非常方便。看下面的配置文件很清楚，make绑定到了一组命令。 (setq prj-tools &apos;((&quot;Make&quot; &quot;cd ~/source/Panda/; ./run.sh -c;&quot; &quot;f9&quot;) (&quot;Clean&quot; &quot;cd ~/source/Panda/; ./run.sh -x;&quot; &quot;C-f9&quot;) (&quot;Run&quot; &quot;cd ~/source/Panda/; bochs;&quot; &quot;f8&quot;) (&quot;Stop&quot; &quot;-e eproject-killtool&quot; &quot;C-f8&quot;) (&quot;Configure&quot; &quot;./configure&quot; nil） (&quot;Explore Project&quot; &quot;nautilus --browser `pwd` &amp;&quot; nil) (&quot;XTerm In Project&quot; &quot;xterm &amp;&quot; nil)) 另外再推荐一个扩展viewer.el, 这个可以模拟vi里面的快捷键，其实我不是觉得vi的快捷键好，而是vi分为几个模式，编辑模式、浏览模式。这对emacs有些用，因为往往我打开一个文件只是看看，编辑的时候少，有时候按错了键使得文件内容不经意就改变了。所以通过这个扩展，默认打开一个文件都是浏览模式，还可以设置和vi一样的移动光标的快捷键，当需要进行编辑操作的时候按下i键进入编辑模式。状态栏可以显示当前所处的模式。 (add-hook ‘find-file-hook ‘view-exist-file) (global-set-key (kbd “C-o”) ‘view-mode)","tags":[]},{"title":"A Emacs func","date":"2011-12-21T11:43:00.000Z","path":"2011/12/21/a-emacs-func.html","text":"这个操作好像经常要用到，拷贝当前光标连续的一段字符串(除了空白和换行), 写了个小函数来实现。 (defun get-continue-string () (interactive) (skip-chars-backward &quot;^ \\n&quot;) (setq low (point)) (skip-chars-forward &quot;^ \\n&quot;) (setq high (point)) (copy-region-as-kill low high) (message (buffer-substring low high)))(global-set-key (kbd &quot;C-x y&quot;) &#x27;get-continue-string)","tags":[{"name":"Emacs","slug":"Emacs","permalink":"http://catcoding.me/tags/Emacs/"},{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"}]},{"title":"A Basket-Ball Demo","date":"2011-10-20T11:43:00.000Z","path":"2011/10/20/basketball.html","text":"最近闲暇时间用C++写了个小Demo，一个小小的篮球模拟。在学校的时候看过《人工智能编程精粹》，里面有个足球模拟，看起来还比较逼真。我这个篮球模拟是比较类似的，主要好玩的地方是在于状态机。图形方面做得很简单，还是用OpenGL来实现的，另外用了一个库glui，这个东西很好，把GUI方面琐碎的事情就简化了。整个效果图如下，这可是湖人对火箭噢。 调试状态机是个很有趣的过程，每一个球队有自己的状态机，分为进攻状态、防守状态、准备发球状态，每个球员也有自己的状态机，如下图所示。这里使用的是状态模式，把复杂的转移逻辑分散到各个状态节点，这正是状态模式的精华啊。现在这个还只是个粗糙的版本，虽然看得出来有那么点意思，规则都出来了，但是每个球员的跑位不逼真，没有多少智能的感觉。当篮球碰到边界的时候自动反弹，这点有点假，不过这也简化了不少比较繁琐的捡球和发球动作。当然现在的规则都比较简单，连三分和两分都没有分出来，罚球也没有，哈哈。现在的状态机看起来大部分时间还可以，很少的时候会出现一些比较反常规的现象。把每个状态转移过程在画面中显示出来能比较直观的去调试。下面这个是球员的状态转移图，也就是FieldPlayerStates.cpp实现的。球队的状态机要简单一些，只有三个。 程序在这里GitHub:BasketBall，感兴趣的可以看一下，也有7000行的代码了，也有点乱:). 后面有时间再调试一下，慢慢细化，球员的站位和防守动作做到更智能些。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"C","slug":"C","permalink":"http://catcoding.me/tags/C/"},{"name":"Game","slug":"Game","permalink":"http://catcoding.me/tags/Game/"}]},{"title":"姓氏的消失","date":"2011-09-25T11:43:00.000Z","path":"2011/09/25/xingshi.html","text":"前些天看到一篇文章有点意思。假设，人口的数目不变，儿子的姓氏随着父亲，那么随着时间的推移一代一代的演化，最后所有的人都只有一个姓了。具体用个例子描述就是：100个父亲，按照上面的假设会有100个儿子，也就是平均每个父亲在下一代会有一个儿子，假设某个父亲姓”王”，并且王在父亲这一代所占的比例是7%，那么概率上来说这个儿子姓”王”的概率为7%。你不能说我姓王，我儿子肯定随我姓呐，概率上的说法都是放在一个大的数目下。上面那句话的意思就是，平均来说占7%姓”王”的父亲在下一代能产出7%姓”王”的儿子，这是合理的吧。那么最后人们只剩下一个姓氏了么？对于这么简化的模型是很好模拟的，比如下面这段python的代码： def run(populationSize): generations = 0 cur = [x for x in range(1, populationSize+1)] count = 0 while max(cur) != min(cur): count = count + 1 next_generation = [] most_occur_name(cur) for x in range(0, populationSize): son = cur[random.randint(0, populationSize-1)] next_generation.append(son) cur = next_generation print &quot;finished through %d generations, last name is %d&quot;%(count,cur[0]) 初始化每种姓氏都有一个，最后只剩下一个姓氏，具体是哪个不确定，要花费多少代的演化也不确定，这一切都是随机的。那可以从上面的模型看出，如果在某个代中某个姓氏所占的比例相对而言比较大，那这个姓成为最后剩下的那个的概率也更大，我觉得这是个合理的结论。就我国目前的姓氏分布来说，这一个结论看起来是被验证了， 据统计我国大小姓的悬殊是十分明显的，这种悬殊还在有逐步增大的趋势，其发展的结果可能是大姓人口越来越多，很多小姓越来越少甚至被淘汰。我国目前使用着3000多个姓氏，但经常使用的仅有500个左右，占人口总数87％以上的人只使用100个姓氏，”王”姓最多占了7.25%，”张”占了6.7%。原来和同学讨论这个问题，对方一副自己将会儿孙满堂的模样”我们姓’王’”的是最多的，这看来是有依据的，而且很有可能会有更多。 继续想想，这也是进化的一个简单模型吧。不论进化论到底是真是假(进化论本身也只是个假说而已)，事实中会有这么一个现象：基数大的物种在下一代会有增大的趋势。而且姓氏看来比其他东西遗传得更坚固，对于单个人而言，后代随着父亲姓的概率应该远远大于身高随着父亲的概率吧，所以理论上看来姓氏的消失应该是比较快的。那到底是哪个姓氏会坚持到最后呢？这个不确定，而且也许在多少年内这都不会发生。我国目前的姓氏分布有地域关系，比如湖南可能姓陈的比例比较大，北方姓王的比例很大，这种不是完全随机的分布可以延缓姓氏的消失吧。张学友有首歌叫做《你的名字我的姓氏》里面的歌词是“可用你的名字和我姓氏 ，成就这故事，从此以后无忧无求”，可见，男人对于自己的姓氏留下来的愿望是多么强烈！哈哈，一点浪漫感都没了。","tags":[{"name":"Backup","slug":"Backup","permalink":"http://catcoding.me/tags/Backup/"}]},{"title":"在外漂着","date":"2011-08-18T11:43:00.000Z","path":"2011/08/18/life_in_shangha.html","text":"来上海有一段时间了，在这段时间里一切都还好。 刚来这边一切都感觉比较新鲜，现在慢慢习惯了。在这边的生活比较规律，每天早上八点四十起来，洗刷完毕，早饭是面包片和同事磨的豆浆。这近两个月早餐都是这样，我觉得挺好的，一点都还没感觉到腻，带黑芝麻或者葡萄干的面包片真的很好吃！每天的九点钟开始出发上班，坐上两路地铁到张江一般整好10点左右。因为比较晚，所以不会赶上地铁的高峰。中午在公司附近的食堂，吃了一个月后觉得有点味觉疲劳了，主要是太清淡，和成都没法比啊。中午还会躺着休息一段，下午的精力才是最好的。公司前辈们都挺好，相处得不错，会耐心教我一些，自己在工作上面还有不少需要自己弄明白的。晚饭在公司吃，我这种刚来从学校出来的饭量是最大的，汗，我以前总觉得自己饭量不行。因此，在上海长胖了一些。在公司比较囧的事是中文式的英文，这个我觉得不太make sense啊，这个actually我不是很understand啊，anyway我想要撞墙，^_^。 另外最近喜欢打乒乓球，每周二下午公司一起活动，一般是乒乓球和羽毛球，我们几个打得都比较菜，过了几周后我觉得自己还是提高了一些。 来上海之前，不少在上海待过的朋友警告我，在上海的各种压力、排斥外地人，好像我要入火海似的。通过这两个月的生活来看，这些还没遇到。可能我在环境比较小，又相对单纯。只是在一个月左右的时候，某天早上我爬起床来，觉得有些不对劲，总感觉少了些什么。再仔细想想，原来我已经很久没和女生说过话了，自从成都到上海后一个师姐接过，之后这么常时间内我没和女生说过话！因为公司一个女生也没有，而我在上海的也没有的生活圈里的女生。嗯，这是个问题，长此以往会是个问题:)。倒也好，最近认识一些朋友和老乡，周末也可以找人耍耍了。上周去了人民广场，没见过世面的迷路了，还时不时没见过世面地感叹一把上海的楼高。周日去了华师大，因为看了“深度游上海”系列，说夏季最美校园为华师大，据说是“爱在华师大”，于是约上一个豆瓣好友一起去。传说中的美女没看到，一群男生暑假没回家在球场上耗费体力。不过荷花池附近还可以看看的。回来的时候坐的四号线地铁，很大一部分是在外面，看了一下觉得很多地方和成都差不多呃，浦东也就是陆家嘴那块要繁华些。问了好几个同事，说上海附近哪里风景比较好人又比较少的，都是得到鄙夷的答案，你看上海都开发成这样了，哪里还有人少的地方。我是个比较恋旧的人，还是会怀念成都，学生时代的无忧无虑，周末骑车乱逛，一群人三国杀。我的一个室友在北京，说成都的手机号多用两个月，保持一点回忆。我之前总说该出来看看外面的世界，少不入川，在成都待久了不好。所以出来感受一段时间后，我更觉得自己以后应该还是会回成都或者回家乡的小镇，“我见过的异地越多，就越怀念我的故乡”，成都算是第二故乡，第一故乡不好找工作。另外，这里 送一本书，因为是在豆瓣上未曾谋面的人送给我的，叫做 《自由在高处》，看完了觉得还不错。现在这本书还是全新的，放在我这里也浪费了，既然我是白白得来的也该白白送出去。如果有人想要的邮件给我你的地址，我邮寄给你，你付快递费(顺丰之类的是可以收货人付款的)。今天看到一些很美的画，然后就把这弄上博客头了，原图是这张。这里还有不少：）","tags":[{"name":"Notes","slug":"Notes","permalink":"http://catcoding.me/tags/Notes/"}]},{"title":"C的面向对象风格代码","date":"2011-08-16T11:43:00.000Z","path":"2011/08/16/ooc_in_python.html","text":"OO是一种编程范型，而不只是特定语言的特定支持，所以用C来实现也是可行的。最近碰到的一部分代码都是用C实现的面向对象风格，可能是参考了Python里面的实现，Python内部实现的基本对象这块也全是这样的代码。在这里做一个小小的总结。 C语言里面没有语言层面的面向对象支持，那OO中的三个基本要素封装、继承、多态如何实现？C里面最强大的东西是指针，指针中最神奇的是void指针，这是一切的基本。首先来看封装，如何通过实例来调用方法，而对内部数据进行隐藏。完全可以写一些struct，然后写对应的函数来针对这个struct来操作，我们需要更进一步，把数据和方法绑定起来。这样写初看起来并没什么好处，后面会发现，通过函数指针去找对应的函数是多态的关键。 //object.htypedef struct _obj&#123; char name[MAXLEN]; int ref_cnt; int value; void (destructor) (void thiz); void (print) (const void thiz); int (equal) (const void thiz, const void* other);&#125; Obj;//object.c destruct,print,equal定义为staticObj Obj_new(int value)&#123; Obj o = malloc(sizeof(Obj)); strcpy(o-&gt;name,“baseobj”); o-&gt;ref_cnt = 1; o-&gt;value = value; o-&gt;destructor = &amp;destruct; o-&gt;print = &amp;print; o-&gt;equal = &amp;equal; assert(o); return o;&#125;//使用方法 &#123; Obj first = Obj_new(1); Obj other = Obj_new(2); first-&gt;print(); other-&gt;print(); first-&gt;equal(first, other); Obj_drop(first); Obj_drop(other); return 0;&#125; 对于继承C当然也没原生的支持，可以在子类的定义中写入父类中的成员变量和成员函数，这里如果父类中定义的时候就是宏，直接拿过来就是。所以把父类的定义重新改写一下，分为DATA类型和TYPE类型，在Python里面就是这样，PyObject和PyVarObject是一切其他对象都包含有的。下面是一个例子People继承Object,Student继承People。 #define PEOPLE_DATA \\ OBJ_DATA \\ int age;\\ char fullname[100]; //OBJ_DATA必须放在子类新的数据成员前面，只有这样才能把子类的指针强制转换成父类指针 或者转化为Object指针 #define PEOPLE_TYPE \\ OBJ_TYPE \\ void (sleep)(void thiz); typedef struct _People_Type&#123; PEOPLE_TYPE&#125; People_Type;extern const Object_Type Object_type;extern const People_Type People_type;typedef struct _People&#123; const People_Type* methods; PEOPLE_DATA&#125;People; 这里sleep为新增加的子类方法，fullname为新增加的成员变量。注释部分为特别注意的，只有在保证内存的里面数据的分布前面部分都是一样的(一个methods指针和obj_data部分)才能进行指针之间的强制转换时候不出问题。例子里面的Student类也是类似的继承People类，这里可以看到sleep这个方法不好弄，因为在People那里申明为static了，这里想复用就麻烦，所以只有再自己写一个(即使实现是一样的)，这也是C++内部帮用户做好的。可以看到通过type里面的函数指针的不同，不同对象相同的方法实现就不同了，因此实现了多态。 最后我们可以写一个基于计数的指针管理，在持有一个指针的时候调用Obj_pick,用完以后执行Obj_drop。 void Obj_pick(const void thiz)&#123; assert(thiz); Object o = (Object*)thiz; o-&gt;ref_cnt++;&#125;void Obj_drop(const void thiz)&#123; Object o = (Object)thiz; const Object_Type p; if( –o-&gt;ref_cnt &lt;= 0)&#123; for( p = o-&gt;methods; p; p=p-&gt;father)&#123; if(p-&gt;destructor) p-&gt;destructor(o); &#125; &#125; free(o);&#125; 按照这种OO的风格的C代码感觉要清晰一些，至少我习惯了。不过还是看个人品位吧，这样的代码风格是我另外一个同事所鄙视的。关于用C实现OO风格，还有一本比较好的书叫做Object-oriented Programming with ANSI-C，感兴趣可以看看。 上面的代码在这里下载：https://github.com/chenyukang/ooc。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Backup","slug":"Backup","permalink":"http://catcoding.me/tags/Backup/"}]},{"title":"一种更快的字符串匹配算法-源自Python2.5","date":"2011-07-30T11:43:00.000Z","path":"2011/07/30/fastsearch-in-python2.html","text":"Python2.5的实现中有一个字符串匹配算法，在s中查找p是否存在，s的长度为n，p的长度为m。这个算法符合以下要求： 任何情况下都要比brute-force算法快 O(1)的空间，O(m)的初始化复杂度 O(n/m)的查找复杂度 最坏情况下不能比O(nm)时间复杂度差 实现简单，对于实际中的查找大部分表现良好，最坏情况出现概率小 标准的字符串查找算法不满足这些要求，KMP的时间复杂度为O(m+n)(初始化O(m)加第二部分O(n)， Boyer-Moore和其变形要求额外的空间，Python2.5里面增加了这个结合了Boyer-Moore和Sunday的思想的变形实现。来看看这是怎么个神奇的算法，KMP的思想是在每一次不匹配的情况下尽量的向右边移动，所以计算一个Next的移动下标数组。如果不匹配，最理想的情况下是向右边移动多长?应该是m，这样就能尽量减少对比的次数。所以每次比较的时候先比较p的最后一个字符，比如s=”aaaaaaad”，p=”aae”，如果从s的开头查找，只要发现第3个和p的第三个不一样，移动指标，移动多少？如果发现没有e，最长能移动p的长度，就是3。如果最后一个不匹配并且s[i+m]不是p中的字符就移动m，否则移动1。这里有两个问题： 如何知道s中的某一个字符是否是p中的一部分?如何尽量移动m而不出现少找的情况? 第一个问题，可以用某个存储空间存下是否有p中的某个字符出现过，方便以后查找。Hash的思想，但是这里字符串查找里面再弄个Hash太无语了吧。一个简单的Bloom-filter，这里是这样实现的。 /*计算mask*/ mlast = m-1;for (mask = i = 0; i &lt;= mlast; i++) &#123; mask |= (1 &lt;&lt; (p[i] &amp; 0x1F));&#125;/*判断s[i]不是p中的一个字符串*/ if(!(mask &amp; (1 &lt;&lt; (s[i] &amp; 0x1F)))) printf(&quot;s[i] is not in pattern&quot;);else printf(&quot;s[i] is in pattern&quot;); 其实我们是要判断一个s中的一个字符串没有出现在p中，取低5位不是可能产生冲突么？产生冲突也没问题，就像一个Hash只要一个元素算出来的Key指定的slot没元素不就能确定这个元素不在里面了么。 第二个问题，有些巧妙。上面那个例子是因为s的最后一个字符没被匹配，所以能移动m的长度。如果这个例子s=”aaacaaaacaa”，p=”aacaa”，第5个位置都为a，最后一个匹配，但是s里面前几个其实不为aacaa，所以需要移动，但是移动多少呢?如果移动p的长度，那从第2个位置开始的aacaa就没被检查到。所以需要一个变量记录在每次最后一个字母匹配的情况下向右移动的合理偏移量，在这里为skip，初始化的时候计算出来，这最偏移量其实是计算的最小偏移量，就是移动skip个位置到第一个s[m-1]的位置。 整个实现既节省空间又速度快，强大。 具体实现如下： //如果mode为FAST_COUNT，则查找pattern出现的次数#define FAST_COUNT 1int fastsearch(const char* s, size_t n, const char* p, size_t m, int mode)&#123; long mask; size_t skip, count = 0; size_t i, j, mlast, w; w = n - m; if (w &lt; 0) return -1; /* 如果m=1，特例，扫描一遍解决*/ if (m &lt;= 1) &#123; if (m &lt;= 0) return -1; if (mode == FAST_COUNT) &#123; for (i = 0; i &lt; n; i++) if (s[i] == p[0]) count++; return count; &#125; else &#123; for (i = 0; i &lt; n; i++) if (s[i] == p[0]) return i; &#125; return -1; &#125; mlast = m - 1; skip = mlast - 1; /*计算mask*/ for (mask = i = 0; i &lt; mlast; i++) &#123; mask |= (1 &lt;&lt; (p[i] &amp; 0x1F)); if (p[i] == p[mlast]) skip = mlast - i - 1; &#125; mask |= (1 &lt;&lt; (p[mlast] &amp; 0x1F)); for (i = 0; i &lt;= w; i++) &#123; if (s[i+m-1] == p[m-1]) &#123;//pattern末尾匹配 /* candidate match */ for (j = 0; j &lt; mlast; j++) if (s[i+j] != p[j]) break; if (j == mlast) &#123;//一个匹配成功 if (mode != FAST_COUNT) return i; count++; i = i + mlast; continue; &#125; /*移动多少?,根据mask*/ if (!(mask &amp; (1 &lt;&lt; (s[i+m] &amp; 0x1F)))) i = i + m; else i = i + skip; &#125; else &#123; /* skip: check if next character is part of pattern */ if (!(mask &amp; (1 &lt;&lt; (s[i+m] &amp; 0x1F)))) i = i + m; &#125; &#125; if (mode != FAST_COUNT) return -1; return count;&#125;","tags":[{"name":"Python","slug":"Python","permalink":"http://catcoding.me/tags/Python/"},{"name":"Algorithms","slug":"Algorithms","permalink":"http://catcoding.me/tags/Algorithms/"},{"name":"C","slug":"C","permalink":"http://catcoding.me/tags/C/"}]},{"title":"让Emacs提醒睡觉","date":"2011-07-24T11:43:00.000Z","path":"2011/07/24/emacssleep.html","text":"最近都睡的比较晚，对身体不好啊。写了几行恶趣味的elisp，晚上10点40开始提醒提醒我准备睡觉，如果10点50还没动，我的上下移动键就不能用了，下面会有一条提示：太晚了，该睡觉了。不过这时可以用方向键盘来移动。但过十分钟后快捷键又恢复正常，因为过了11点表示我确实要再待晚点，下个小时40分钟继续提醒，50分锁死快捷键盘。12点过后emacs彻底对我无语了。真是egg hurt… (defun is-late-now() \"Check if it is now late, emmm, go to sleep\" (let ((hr (nth 2 (decode-time (current-time)))) (minute (nth 1 (decode-time (current-time))))) (and (and (&gt;= hr 22) (&gt;= minute 40) (message \"prepare sleep now....\")) (&gt;= minute 50)))) (defun my-next-line() (interactive) (if (is-late-now) (message \"late now, go to sleep ... baby!\") (next-line))) (defun my-prev-line() (interactive) (if (is-late-now) (message \"late now, go to sleep ... baby!\") (previous-line))) (global-set-key (kbd \"C-n\") 'my-next-line) (global-set-key (kbd \"C-p\") 'my-prev-line) 这样写不好看，更好的办法是用defadvice，那就不用重新绑定C-n和C-p了，defadvice可以直接在运行next-line和previous-line之前检查一下。 (defadvice previous-line (before check-is-later) (if (is-late-now) (progn (message “late now”) (sleep-for 1)))) ;;just sleep 1 second (ad-activate ‘previous-line)这样后只要执行previous-line这个函数之前都会执行我这个defadvice定义的代码，但是这样连方向键也不能移动了，因为向上这个按钮是绑定的previous-line这个函数。","tags":[{"name":"Life|Notes","slug":"Life-Notes","permalink":"http://catcoding.me/tags/Life-Notes/"}]},{"title":"到上海了","date":"2011-07-23T11:43:00.000Z","path":"2011/07/23/toshanghia.html","text":"很久没写咯，我已经在上海了，房子刚好弄好。 毕业之前去了青海湖，我和一个同事本来打算三天环青海湖骑行一圈的，第一天骑车148公里，第二天一早就走错了路（环行的居然走错了路），结果骑过了橡皮山，发现是已经骑了20公里左右。幸好在路上等了个回去的卡车，把我们带回黑马河。重新出发，环湖西路的路况非常好，车也很少。继续骑了120公里到达刚察，到刚察之前的最后一段感觉是最累的。第三天早上我刚出门过了个大坡，下来的时候不小心摔了一下，于是最后那一段就没骑了，真是遗憾啊。在西海镇继续住了一晚，221骑吧的店主人很好，看我摔了下巴，晚上给我做粥喝。牦牛肉粥非常好喝，嗯，非常感谢！也非常感谢同行的同事，一路给了我很多鼓励和帮助。青海一行虽然有些意外，但是也还是觉得挺不错的，那边人和风景都可以。 更多照片在豆瓣上面，照得不好，实景更漂亮，如果七月份去会更好。在从青海回成都的火车上，躺在铺上看《瓦尔登湖》，以前总没好好静下心来看完这本书，那天慢慢翻着有些入味了。“你们要尽可能长久地生活得自由，生活得并不执着才好。执迷于一座田园，和关在县政府的监狱之中，简直没有分别。” 如何生活得简单、自由，是我所难于学会的。 从青海回成都后，在学校办了一些手续，然后直接到上海了。国庆看有没有时间再回家一趟吧。在成都，走之前还和不少朋友没有聚，先记下吧，我觉得我会回成都的:) 在上海待了已经有几天了，说不上适应不适应，至少还没融入，只是一个旁观者。至少楼比成都高多了，交通比较方便也稍微有点贵。房子基本没找，有同事的一个二室一厅的，租下来就行了吧，认识的人住在一起也好些。工作上面还在适应，不少东西要好好学习一下噢。新的开始，努力一把。","tags":[{"name":"Life|Notes","slug":"Life-Notes","permalink":"http://catcoding.me/tags/Life-Notes/"}]},{"title":"Wumpus and 《Land of Lisp》","date":"2011-07-22T11:43:00.000Z","path":"2011/07/22/wumpus-and-2.html","text":"最近在看一本书《Land OF Lisp》，看了大部分。离前一次看Lisp方面的书刚好三年，用Emacs也有四年了，这期间接触的多是简单的Elisp。总得来说，Lisp的书看起来是比较有趣的，这本也不错，稍微比《Practical Lisp》简单。竟然有个第6.5章，Lambda这么重要，怎么说也要占一章！第八章实现了一个小游戏。Wumpus(Hunt the wumpus)是个古老的游戏，那个年代还没有绚丽画面，只有文字界面。这里游戏的规则是： 1. 地图为一个无向图，玩家控制一个人物在图中行走，目的是寻找潜伏在节点中的一个怪兽。其中要边走边推理，得出怪兽在哪个节点。 1. 还有其他角色，有的节点隐藏着超级蝙蝠，它能把你扔到图的任何位置。节点之间的边可能有警察。 2. 如果你推测出怪兽的位置，向那里射箭，如果射中则胜利，否则输掉。如果你不小心从有警察的边通过了，也死掉。 3. 在怪兽的附近两个距离范围内，会有血气。如果一个点的某条边有警察，这个点会有光晕。 说起来复杂，来看副图。有点像挖地雷那种小游戏。有？符号的为没访问过的点，*为当前点，从14到15遇到警察死掉了。上周末玩了好几个小时，还挺难胜，主要还是图比较大，游戏一开是整个地图是已经生成了的，要偷懒可以看看。来看看如何用Lisp代码来实现这个程序，程序比较短。首先是如何生成图，需要生成一个随机的连通图。设定节点数目和边的数目，以编号代表节点。random-node:随机地选一个节点。edge-pair:连接两个点表示边。make-edge-list: 重复N次，生成N条边的集合。这个随机图可能不是连通的，下面的代码找出孤立的点集，用一些边连接起来这些孤立的点集，随机图产生完成。第二步向某些点之间加警察，随机的。这其中用了各种mapcar和Lambda，这样的效果使得Lisp程序看起来全是括号。mapcar的意思就是我要在这个列表上面所有的元素上都执行这个Lambda函数。visited列表保存已经访问过的节点，know-city-nodes更新(不是纯函数式编程的风格)，know-city-edges根据访问的节点，生成已知的路径，当前已知的用dot画出来。graphviz是个好东西，最近也在学习用这个来画一些流程图，效果挺好的。 乱说说Common Lisp，看了一些这方面的资料，这语言不管有多少牛逼人士簇拥(最近Paul Grahamd的书被翻译了)，使用的人还是太少还是有一定的历史原因，早期的实现效率是一个问题，而当实现和硬件都不错了的时候C/C++已经成大局了。另一个很重要的原因是，文档不是很好，我想找个处理图片方面的库，见到一个README文件跟救命稻草似的，打开一看”Do you really need DOCS?”。Lisp的哲学是语言不能给太多限制，甚至做到代码就是数据、数据就是代码，你可以轻而地为语言添加特性，你还可以用宏来写出生成代码的代码。Lisp给了程序员最大的自由来挑战语言的限制，所以会出现如此多种的方言。好的一面是面对特定的问题或许能得到优美而高效率的解决方法，而这个代码对于另外一个程序员来说太难读懂(特别是夹杂了宏的代码)，继而难于流传。这里有篇经典的Lisp:Good news,Bad news，作者为早期用Lisp作为开发语言开公司的。以后看看Haskell吧，这个比较有前途。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Books","slug":"Books","permalink":"http://catcoding.me/tags/Books/"},{"name":"Lisp","slug":"Lisp","permalink":"http://catcoding.me/tags/Lisp/"},{"name":"wumpus","slug":"wumpus","permalink":"http://catcoding.me/tags/wumpus/"}]},{"title":"《Advanced linux progamming》笔记","date":"2011-06-14T11:43:00.000Z","path":"2011/06/14/advanced-linux-porg-notes.html","text":"Writing and using Libraries 链接分为动态链接和静态链接。 Archives archive(静态链接)为目标文件的集合，linker从archive文件中找到obj文件进行链接。 % ar cr libtest.a test1.o test2.o 创建库文件libtest.a(类似windows下test.lib)，当linker处理archive文件的时候，将在库文件中查找当前已经处理但是还没定义的symbols。所以库文件应该出现在命令的最后。 % gcc -o app app.o -L. -ltest Shared Library Shared lib和archive的两个区别： 1，当进行的是动态链接，最后得到的可执行程序中不包含实际库中的执行代码，只是一个对库的引用。所以动态链接最后得到的可执行程序要小一些。 2 多个程序可以共享动态链接库，动态链接库不只是obj文件的集合，其中是单一的一个obj文件，包含了库中所有的信息，所以一个程序动态加载shared lib的时候是把库中所有的东西都加载了，而不是所引用的那部分。 % gcc -c -fPIC test1.c % gcc -shared - fPIC libtest.so test1.o test2.o -fPIC选项指编译为位置独立的执行代码，这样可以动态加载，产生libtest.so文件。 默认的库文件寻找路径变量：LD_LIBRARY_PATH 库文件之间的依赖关系：如果是动态链接，链接库会自动寻找到自己所依赖的其他库文件，如果是静态链接，必须为linker提供所有依赖的库文件名称。 % gcc -static -o tifftest tifftest.c -ltiff -ljpeg -lz -lm 上面例子中tiff依赖jpeg库，因为是-static链接，必须指明所有依赖的库文件。 Pros and Cons 动态链接的优势：可以减少可执行文件的size，如果库文件进行升级，原程序可以不用重新链接。如果是静态链接，库文件改变了程序要重新进行link。 也有一些特殊情况必须使用static link。 动态加载和卸载库 void* handle = dlopen (&#8220;libtest.so&#8221;, RTLD_LAZY); void (*test)() = dlsym (handle, &#8220;my_function&#8221;); (*test)(); dlclose (handle); 上面例子中打开libtest.so动态链接库，找到my_function定义，执行，然后卸载库文件。 进程 创建进程 using system #include &lt;stdlib.h&gt; int main () { int return_value; return_value = system (\"ls -l /\"); return return_value; } system将执行/bin/sh,然后执行命令，因为不同系统中/bin/sh所链接的shell不同，所以会导致执行差异，同时这种方式存在安全隐患。 using fork and exec fork创建一个子进程，fork的返回值用来区别父进程和子进程。子进程将和拷贝父进程一些信息，更详细的东西在这本书内没说明。 exec函数家族，fork创建一个子进程，用exec在子进程中执行命令。 process scheduling nice命令可以调节process的优先权值。 niceness value越大，进程的优先权越低，越小进程的优先权越高。一般进程的niceness value为0。只有root的进程可以减少一个进程的niceness value。 signal signal is asynchronous:进程收到信号的时候会立即处理信号，处理信号的一般方式分为几类：忽略，执行默认处理，执行特定的处理程序。 因为信号处理是异步的，所以在信号处理程序中尽量不要执行IO，或者调用库函数。信号处理函数应该作最少量的工作，尽快返回到主流程中，或者干脆结束掉程序。一般只是设置变量表明某个信号发生了，主程序定时检查变量再处理。SIGTERM和SIGKILL区别，前一个可能被忽略，后一个不能被忽略。 改变sig_atomic_t的值的操作是原子性的。 process exit exit(int return_value)函数退出一个进程，并把exit_code告诉父进车。kill(pid_t,KILL_TYPE)向某个进程发送相应的退出信号。 wait函数家族，让父进程等待某个子进程的结束。WIFEXITED宏判断子进程是否正常退出或者是由于其他原因意外退出。 zombie process(僵死进程)为一个进程已经退出，但是没有进行善后处理。一个父进程有责任处理子进程的善后处理，wait函数即为此用，父进程调用wait一直被阻塞(当子进程没有退出的时候),子进程退出后wait函数返回。如果父进程没有为已经退出的子进程处理善后，子进程将变为init的子进程，然后被处理删除。 一种更好的处理方法是当子进程退出的时候发信号通知父进程，有几种方式可以实现(进程间通信),其中一种比较方便的方式是父进程处理SIGCHLD信号。 Threads 线程作为亲量级进程，切换引起的开销更小，一个进程的多个子线程共享进程的资源。 create thread 创建线程：pthread_create (&amp;thread_id, NULL(pointer_to_thread_info), &amp;thread_func, NULL(argument)) 线程的执行顺序是异步的，不能假设其执行顺序。 向thread传递数据：可以通过pthread_create的地四个参数，传递一个void* 的指针，指针指向一个数据结构体。注意在多线程中的数据空间的销毁。 More about thread_id: if (!pthread_equal (pthread_self (), other_thread)) pthread_join (other_thread, NULL); Thread Attributes,为了设定线程的某些属性，detach线程退出后自动回首资源，joinable则等到另一个线程调用pthread_jion获得其返回值。 Thread-specific data:每个线程都有一份自己的拷贝，修改自己的数据不会影响到其他线程。 Cleanup Handlers:使用pthread_cleanup_push(function,param)和pthread_cleanup_pop(int)在线程退出的时候自动调用清理函数，释放资源。 多线程程序可能出现的问题：竞争，需要使用atomic操作。 互斥锁 只有一个线程能够拥有，此时其他线程访问互斥锁将被阻塞。 pthread_mutex_t mutex; pthread_mutex_init(&amp;mutex,NULL); //&#25110;&#32773;pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; //&#32447;&#31243;&#20013;&#20351;&#29992;pthread_mutex_lock&#21644;pthread_mutex_unlock&#26469;&#38145;&#20303;&#21644;&#35299;&#38145;&#20114;&#26021;&#38145;&#65292; Semaphores for Threads sem_t 可以作为一个share counter 来使用， sem_t job_queue_count; //initialize sem_init(&amp;job_queue_count,0,0); //wait for sem_wait(&amp;job_queue_count); //lock mutext //and do somethting //unlock //new job sem_post(&amp;job_queue_count) Threads VS Process Guidelines: 1，所有线程所执行的指令必须是在一个可执行文件里面，而多进程可以执行多个命令。 2，因为多个线程共享相同的虚拟内存地址，所以一个线程的错误可能会影响到其他线程，而多进程程序中一个进程的错误不会影响到其他进程。 3，为新进程拷贝内存将增加开销，但是只有在新进程写其内存的时候才会进行拷贝(写拷贝)。 4，多线程适用于多个相似的执行任务，而多进程可以执行不同类型的任务。 5，多个线程中共享数据要容一些，但是也会产生相关问题(条件竞争，死锁)，多个进程共享数据难一些，使用IPC机制，虽然实现要难一些，但是不容易出现并发bug。 Interprocess Communication Share Memory share Memeory 是最简单的进程间共享数据的方式。 Allocation shmget函数创建或者访问一个已经存在的share mem。 int segment_id = shmget (shm_key, getpagesize (), IPC_CREAT | S_IRUSR | S_IWUSER); Attachment and Detachment 函数shmat(SHMID,pointer to address,flag)使得一个进程attach到一个共享内存。进程通过fork创建的子进程也将继承这一共享内存。函数shmdt(address)将detach共享内存。 int segment_size; const int shared_segment_size=0x6400; //allocate a shared mem segment_id=shmget(IPC_PRIVATE,shared_segment_size, IPC_CREAT|IPC_EXCL|S_IRUSR|S_IWUSR); //atach the share mem share_memory = (char*)shmat(segment_id,0,0); printf(\"share memory attached at addreass %p\\n\",share_memory); Control share mem 函数调用exit或者exec 可以detach一个共享内存，但是并没有释放它。必须调用shmctl去释放其空间。ipcs -m 命令可以查看系统中当前的share mem的信息，如果没有删除遗留的shared mem，其nattch为0。可以使用ipcrm shm segment_id删除。 Process Semaphores semaphore和shared memory的使用方式类似，可以通过semget,shmctl创建和删除，提供的参数表明要创建semaphore。没详细说，查看其他书。 Mapped memory Mapped memory是不同进程可以通过一个公用的共享文件进行交流。Mapped mem在进程是进程和文件的一个桥梁，linux通过把文件映射到虚拟内存，这样进程可以像访问普通内存一样访问该文件。void* mmap(address,LENGTH,prot_option,option,file_rp,pos) //将一个文件映射到address，如果不提供系统将映射到合适的地址munmap(file_memory,FILE_LENGTH);// 释放memory设置了MAP_SHARED,多个进程可以通过同一文件访问该内存区。 管道 pipe int pipe_fds[2]; int read_fd; int write_fd; pipe (pipe_fds); read_fd = pipe_fds[0]; write_fd = pipe_fds[1]; pipe_fds[0] 为reading file desc,pipe_fds1为writing file desc。 Pipe只能用于同一个进程的子进程之间。 dup2重定向标准输入输出符。 popen,pclose很方便，FILE* stream=popen(&quot;progam&quot;,&quot;w&quot;)向program发送。pclose(stream)关闭。 FIFO 为有名字的pipe，任何不相关的两个进程可以通过fifo来进行数据传递。mkfifo函数创建FIFO。 Socket 系统调用: socket-- Creates a socket close -- Destroys a socket connect -- Creates a connection between two sockets bind -- Labels a server socket with an address listen -- Configures a socket to accept conditions accept -- Accepts a connection and creates a new socket for the connection Unix-domain sockets能用于同一机器上的进程通信。Internet-domain sockets用于不同机子上的通信。struct sockaddr_in addr类型变量为其地址结构。addr.sin_family=AF_INETaddr.sin_addr 存储一个32bit的IP地址。 只是给了两个程序例子，详细内容看网络编程相关书籍。 Mastering Linux Device 分为字符设备和块设备，块设备可一随机访问，字符设备提供流。一般应用程序不会直接访问块设备，而是通过系统调用来使用块设备。设备号，主设备号是根据设备类型分的，从设备号根据具体设备分。cat /proc/devices 查看设备类型和主设备号。 Device Entry 只有root的进程可以通过mknod创建新的Device Entry。mknod name b/c 主设备号 从设备号 linux目录/dev 下面是系统所支持的Device Entry。字符设备可以像一般文件一样访问，甚至可以用重定向去访问。 cat somefile &gt; /dev/audio 可以发出声音了 特殊设备：/dev/null /dev/zero /dev/full /dev/random /dev/urandomLoopback Devices:环回设备，在文件系统上新建一个普通文件，可用于模拟特定设备，比如软盘。也可把实际设备中的内容拷贝到其中，比如把光盘中的内容拷贝到新建的一个cdrom-image中。 /proc mount命令可以看到一行输出：proc on /proc type proc (rw,noexec,nosuid,nodev)/proc包含系统的一些配置信息，不和任何设备相关联。 $cat /proc/version 查看内核版本 $cat /proc/cpuinfo 查看cpu信息 /proc目录下同时包含系统中当前的进程信息，由于权限设置，有的只能由进程本身访问。可以通过访问文件获取系统中进程的相关信息，比如参数，运行环境,内存使用信息等等。 Linux system call system call和一般的C库函数的区别：系统调用一般通过门陷入实现，是系统内核和用户程序的接口，运行过程中会进入系统内核。C库函数一般和普通的函数没有区别。 strace:该命令可以追踪一个程序执行过程中的调用的system call。access:测试进程对于一个文件的权限。 int access(path,bit_flag),注意返回值和errno。fcntl:锁住文件和控制文件操作。fsync,fdatasync:flush disk buffer。getrlimit,setrlimit:资源限制设置。getusage:获取进程的统计信息。gettimeofday:获取wall_clock time。mlock:锁住一段物理内存，使得该内存不能因为swap换出，一些速度要求很高的和安全性要求很高的代码会使用这个功能。 mlock(address,mem_length)mprotect:设置内存的权限。nanosleep:高分辨率睡眠函数。readlink:read symbolic links。sendfile:Fast file Transfer。setitimer:定时器。sysinfo:获取系统统计信息。uname:获取系统版本信息和硬件信息。 Inline Assembly Code /usr/include/asm/io.h 定义了汇编代码中能够直接访问的端口。/usr/src/linux/include/asm and /usr/src/linux/include/asm-i386 linux内核中汇编代码头文件/usr/src/linux/arch/i386/ and /usr/src/linux/drivers/ 汇编代码当使用特定平台的汇编代码时使用宏和函数来简化兼容问题。 Security 用户组 文件 进程权限 用户和组的概念超级用户 无穷权力proccess user id和proccess group id。进程开始的时候其id和启动该程序的用户信息相同。文件权限 chmod stat(filename,&amp;(struct stat))program without Execution Permissions: a security hole。 其他用户能够拷贝该文件，然后修改其权限。Sticky bit:用于文件夹，当一个文件夹的sticky bit设置了后，要删除该文件夹下的一个文件必须拥有对该文件的拥有权，即使已经拥有该文件夹访问权。Linux下的/tmp设置了sticky bit。Real and Effective ID::EID代表进程所具有的系统权限，如果是非root用户，EID=RID；只有root用户可以改变它的EID为任何有效的用户ID。su命令：是一个setuid程序，当程序执行的时候其EID是文件的拥有者，而不是启动程序的用户号。chmod a+s使得文件有这个属性。 缓冲区漏洞 如果栈中有固定长度的输入区，则会含有缓冲区漏洞。最通常的形式： char username[32];/ Prompt the user for the username. /printf (&#8220;Enter your username: &#8220;); / Read a line of input. /gets (username);/ Do other things here… /攻击者可以故意使得缓冲区读满，然后在超出的区域植入想执行的代码段，获得控制权。 Race Conditions in /tmp 攻击者先创建一个链接，如果应用程序在/tmp下创建打开一个相同名称的文件，所有写入的数据将传送到链接所指向的文件里。解决方法：在文件名称内使用Random，open函数使用O_EXCL参数，如果文件存在则失败，打开一个文件后用lstat查看是否是链接文件，检查文件的所有者是否和进程所有者一样。/tmp文件不能挂载在NFS下，因为O_EXCL不能在NFS文件系统下使用。 system ,popen函数的危险 替代使用exec族函数。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Linux","slug":"Linux","permalink":"http://catcoding.me/tags/Linux/"}]},{"title":"从豆瓣FM下载喜欢的音乐","date":"2011-06-07T11:43:00.000Z","path":"2011/06/07/554.html","text":"我是豆瓣FM的忠实用户，用这个东西已经有一年多了吧，累计收听了不少歌曲(316首喜欢的,45首不再播放的,7352首播放过)。通过这个东西发现不少符合自己口味的音乐。这316首是我喜欢的类型，所以想把这个列表弄下来，然后把这些歌曲下载到电脑上。 看了一下豆瓣是有自己开放的API的，不过还是够麻烦的。于是折腾了一个Python程序，输入你的豆瓣用户名和密码，模拟登录豆瓣并记录cookie，自动地到FM的页面去取下这个音乐列表。这个程序在处理HTML文件的时候有点笨拙，正则表达式不够强嗄。需要另一个库python-beautifulsoup。 通过歌曲名，自动下载这个应该是已经有人做了的，于是发现这个getsong.py，是通过Baidu音乐自动下载的，使用了一下速度和成功率都不错，于是在这个上面做了一些修改，直接从上面的程序生成的列表中取歌曲名字，下载下来。如果网速可以一般能在500k左右的下载速度，挺不错的。这个程序有可能会抛出一些异常，我没做仔细的检查，如果一首歌下载不下来就pass掉。 上面的程序都放在GitHub上了，Git/GitHub可个是真好东西。需要的朋友们从这个地址弄下代码:https://github.com/chenyukang/fmmusic 使用方法： 1 修改fm_get_music.py，在里面填入自己的豆瓣用户名和密码。 2 运行这个程序，会在当前目录生成一个歌曲列表：songlist.txt。 3 运行getsong.py程序， python getsong.py -x，就是通过songlist.txt逐个通过百度搜索自动下载，存在当前目录。","tags":[{"name":"Python","slug":"Python","permalink":"http://catcoding.me/tags/Python/"},{"name":"mp3","slug":"mp3","permalink":"http://catcoding.me/tags/mp3/"},{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"豆瓣","slug":"豆瓣","permalink":"http://catcoding.me/tags/%E8%B1%86%E7%93%A3/"}]},{"title":"读memcached","date":"2011-05-22T11:43:00.000Z","path":"2011/05/22/memcached.html","text":"最近在看memcached的源代码，边看边随手记录了一下。 assoc.c: 记录一个item是否存在于缓存中，这里使用了power 2扩展，primary_hashtable,和old_hashtable分别存新申请的hashtable和旧的hashtable。这里起了个线程来做拷贝的工作，当需要扩展hashtable的时候就触发assoc_expand函数，但是这个函数做的工作是备份primary_hashtable，即old_hashtable=primary_hashtable；然后申请新的空间，标识expanding为true，如果申请空间失败则交换回来。通过条件信号量，assoc_maintenance_thread把old_hashtable的数据逐步拷贝到新的hashtable中，当拷贝完了后释放old_hashtable的空间。耗时的操作用另外一个线程逐步来处理，不过查询和插入都要注意是否是在扩展状态，判断是去old还是primary里面去操作。 cache.c: 在malloc和free的基础上封装了一层，多线程安全的。维持了一个指针列表，释放的时候并没有一下就把内存还给系统，而是在列表中保存了下来，申请时如果列表中有没用的指针就直接返回给出来。能这么因为这个cache模块只是负责申请和释放size相同的内存块。 thread.c: 维持连接列表相关的内容。为一个队列，cq_push、cq_pop，维持一个LRU机制。cqi_new函数返回一个新的CQ_ITEM指针，同样维持了一个cqi_freelist，当有空闲指针的时候直接返回，当没有空闲的时候申请一个列表，从第二个开始连结成链表形式，返回第一个元素的指针。create_worker，创建一个处理线程。Item为memcached中处理的主要对象，item_alloc、item_get、item_link、item_unlink、item_remove方法，处理的时候都要锁住cache_lock。threadlocal_stats_reset、threadlocal_stats_aggregate：统计信息相关。slab_stats_aggregate：统计一个线程使用的slab信息。threadlocal_stats_reset：清空统计信息。 thread_init：主程序中调用的创建多线程函数，包括初始化互斥锁(cache_lock,stats_lock)，条件锁，空闲连接列表等。nthreads为初始化的线程数目，继续调用setup_thread启动每一个线程，调用create_worker创建处理线程。 stats.c:负责统计信息，记录get、set、delete、hits的数目。以前缀作为key。 slabs.c：负责管理内存申请和释放，slabs主要是为了避免内存碎片问题，同时提高申请内存的速度，其基本原理是大块地申请内存，根据不同的slabclass块大小分给slabclass，申请内存的时候根据地址选择最适合的slabclass，从中去下内存返回指针，释放的时候只是放在其空闲指针列表中(不少地方都用到这样的方式)。slab_list没什么用，因为释放的指针放在了slots里面啊！slabs贪婪地使用内存，整个这东西的作用就是用内存空间来换时间效率的。 memcached.c：主程序，分析设置参数默认值，分析参数根据参数修改配置参数。初始化stats，assoc，conn，slabs等。thread_init启动线程，每一个线程都有自己的struct event_base，setup_thread函数初始化这些，最重要的设置thread_libevent_process来处理新的连接。一直到： / Create threads after we’ve done all the libevent setup. / for (i = 0; i &lt; nthreads; i++) { create_worker(worker_libevent, &amp;threads[i]); }每个线程进入自己的event_loop。 当请求来临的时候对于每一个连接，增加一个事件来调用处理函数event_handler。每个连接的处理过程是一个状态机，drive_machine(conn* c)来处理，由even_handler来调用，状态转移这部分代码比较复杂，conn_listening —&gt; conn_new_cmd —&gt; conn_parse_cmd —&gt; conn_mwrite —&gt; conn_closing。process_command来处理各种命令。","tags":[{"name":"C","slug":"C","permalink":"http://catcoding.me/tags/C/"},{"name":"Linux","slug":"Linux","permalink":"http://catcoding.me/tags/Linux/"},{"name":"Backup","slug":"Backup","permalink":"http://catcoding.me/tags/Backup/"},{"name":"memcached","slug":"memcached","permalink":"http://catcoding.me/tags/memcached/"}]},{"title":"valgrind","date":"2011-05-06T11:43:00.000Z","path":"2011/05/06/valgrind.html","text":"纪念一下跑测试跑了几天才找出的一个内存泄漏，这个函数源于UNP，还以为UNP有bug呢，找到原书当getaddreinfo失败或者res==NULL的时候直接退出了。但是写这个代码的同学当然不想连接不上直接退出，于是忘记了freeaddrinfo调用直接返回，那个struct addrinfo就没释放。很多错误都是这种，涉及到库函数的时候更加难查。 int tcp_connect(const char host, const char serv)&#123; int sockfd, n; struct addrinfo hints, res, ressave; bzero(&amp;hints, sizeof(struct addrinfo)); hints.ai_family = AF_UNSPEC; hints.ai_socktype = SOCK_STREAM; if ( (n = getaddrinfo(host, serv, &amp;hints, &amp;res)) != 0) &#123; log_sprintf(“tcp_connect error for %s, %s: %s”, host, serv, gai_strerror(n)); freeaddrinfo(res); //oops: memory leak return -1; &#125; ressave = res; do &#123; sockfd = socket(res-&gt;ai_family, res-&gt;ai_socktype, res-&gt;ai_protocol); if (sockfd &lt; 0) continue; / ignore this one / if (connect(sockfd, res-&gt;ai_addr, res-&gt;ai_addrlen) == 0) break; / success / close(sockfd); / ignore this one / &#125; while ( (res = res-&gt;ai_next) != NULL); if (res == NULL) / errno set from final connect() / &#123; log_sprintf(“tcp_connect error for %s, %s”, host, serv); freeaddrinfo(ressave); //oops: memory leak return -1; &#125; freeaddrinfo(ressave); return(sockfd);&#125; 上一篇博文中说到自己包装的内存检测方法，这还有个问题当时没发现，就是那个包装malloc之类的方法对于库函数中的内存申请调用没法记录，所以是不会发现上面这个bug的。这个Memwatch倒是把原生的malloc都重定义了，但是最好的Linux下检测内存泄漏的工具还是valgrind，这真是个神器，在代码上不用做一点修改，这东西甚至能测试程序的cache命中率。看了一下valgrind的相关论文，对于检测方法都是一种称之为shadow value的方法，也就是用信息来记录每一个byte内存的使用情况。这种方式的一个缺点都是会拖慢速度，前面提到的那种稍微包装了一下的方式可能还好(因为使用的是静态数组), Memwatch里面使用了不少链表也会拖慢速度。再看看valgrind的实现，以后工作可能会碰上类似的。 更多valgrind 更多Memwatch","tags":[{"name":"Tools","slug":"Tools","permalink":"http://catcoding.me/tags/Tools/"}]},{"title":"内存又泄漏","date":"2011-04-25T11:43:00.000Z","path":"2011/04/25/memleak2.html","text":"内存泄漏 上一次以为内存泄露查完了，发现服务器跑了比较长时间后又占用太多内存。刚好这段时间加了一些新的模块，又该查查了。整个服务器模块分的还行，但是中间经过几个人一起写，所以看起来就麻烦了。要解决问题还是必须找到泄露的代码段。在C/C++中，只要用了指针这东西，很多逻辑上的问题也会产生内存泄露。在线下用上次封装malloc和free的方法测试，找不到产生内存泄露的样例，grep了一下没有用原来的malloc之类的东西啊，那就应该是测试数量太少的问题。没法，从线上的log中导入一些天的访问记录，其中包含了一天的访问url。试着用Python写个小程序把一天中所有的url依次往线下的服务器发送，这应该有几万条数据了。Python中这相关的库够多的,可以用的httplib,或者webbrowser模块中的webbrowser.open(“url_address”,1),不过这得打开系统的默认的浏览器，并且好像还没关掉一个tab的接口。最合适这个简单任务的是urllib这个模块，下面这样就行了，往线下的服务器狂发请求吧: for rec in alllogs: urlstr = rec[0] #print urlstr line=line+1 print line,allnum,allnum-line,urlstr try: u = urllib.urlopen(urlstr) except IOError,e: print ‘connect refused’,e except UnicodeError,e: print ‘UnicodeError’,e res = u.read() ##print u.info() print “read %d data”%(len(res)) ##time.sleep(0.01) 调试方式 Linux下有一些内存调试工具，不过感觉要么过于复杂要么对代码改动太多，对于在后台这种长时间运行的程序不是很适用。上次提到的封装malloc,calloc,free这些函数的检测方法本来是挺好的，但是有两个问题： 1.用于存储内存信息的空间是用数组的，其大小运行时候就固定。2.不适合多线程程序。 如果用上面所有的url向服务器发送完毕后，再来检查输出文件不可行，因为运行中超过了数组的最大记录数后面的检测就没办法记录下来了。对于第二个问题，这个服务器模型是一种简单的多线程并发，启动时设定其启动线程的数目，多个线程排队，一个线程处理一个请求所以之间并无过多的交互。如果保证一个线程运行过程中不会出现内存泄漏，那应该就没问题了。调试的时候在每一个线程开始跑的时候就启动清空上面的记录内存申请和释放的数组，如果某个一个url请求产生了泄漏就停下来查看生成的meminfo.xls。这样跑完几万个url后，发现一些代码问题。这些bug要是通过人来审查代码不可能查出来，所以测试还是非常重要。其中一部分代码错误是使用了C写了一些基本的数据结构，这些里面有的使用了malloc来动态调整空间大小，用起来倒是比较方便，但是用完后必须显式地释放掉。这和指针的问题是一样的:何时何地释放。调试后会在代码中加入了很多语句，打印信息、脚手架位置等等，这可以用下面这些命令来替换成空白或者注释。 grep debug_str -rl ./*.c | xargs sed -i “s/debug_str/substr/g”","tags":[{"name":"Python","slug":"Python","permalink":"http://catcoding.me/tags/Python/"},{"name":"C","slug":"C","permalink":"http://catcoding.me/tags/C/"},{"name":"Backup","slug":"Backup","permalink":"http://catcoding.me/tags/Backup/"}]},{"title":"面对巨人","date":"2011-04-10T11:43:00.000Z","path":"2011/04/10/mianduijuren.html","text":"昨天小组分享换了种形式，大家一起看了一部片子《面对巨人》。看完后一起分享，我觉得这样很有收获。 这是一部带有一些基督信仰色彩的片子。其实我在今年的1月2日已经受洗成为基督徒，这是个很重要的事，以前也是经过自己的努力探索和思考后做出的决定。但是在受洗后的这段时间里，我并没有活出一个基督的样式，信心大幅度降低。我明白什么是好的，什么是不好的，我相信每个人都明白自己最丑陋的一面，如果长时间不静下心来审视自己就会渐渐麻木，并且认为人就是这样，自私、冷漠、贪婪、好胜、骄傲、虚伪等等。 信仰对于我来说曾经是一个很遥远的话题，或者一想到和宗教什么的联系起来就有点虚幻了，这和大部分人的感觉是一样的。在这片土地上，我们都不需要信仰，信钱、信房子，因为这些看起来能给我们安定。我也从来没有钱过，甚至还没毕业，算是负债累累。但我知道钱和房子远不能给人安宁。而后在自己经历一段痛苦阶段的时候，一些基督徒朋友给了我帮助，并介绍我来认识基督信仰。 信仰的一些基本问题是： 你觉得人是如何来的？不要脱口而出那一套生物进化论，达尔文那一套只是一个假设。其实和创造论是同样的。我们的课本大多只是介绍了进化论，并称之为科学。这里我毕竟学识疏浅，《游子吟》是一本不错的书，可以参考一下。“世界上任何人都没有办法来解释这个问题，毕竟世界的开端没有任何人在场”。进化论的基本依据是人类后来发现的一些化石等等，但是其中有一段时进化论没法解释的。在寒武纪后，地球上突然出现大量的智慧人，这是没有相关化石的。达尔文本人晚年是否坚定这一立场现在也被怀疑。 另一个问题，人在世上的的意义是什么？该如何度过？ 再说这一部片子，讲述的是一个比较简单的故事。高中橄榄球教练泰勒如何从低谷中重持信心和勇气，借助信仰的力量击败恐惧，也就是自己内心中的巨人。其中也包含一些父子、夫妻之间的故事。 其中的一些印象比较深刻的片段： 泰勒教练根据《圣经》的启发，改变团队的哲学。这个团队的存在是为了什么？获得胜利是为了什么？只是为了一场胜利，然后大家都在谈论你，然后获得大学的奖学金么？然后呢，一个人死去的时候，什么都没了，不是么？什么东西都不是永恒的。“日光之下，并无新事”。这是任何问题的根源，你工作是为了什么？赚钱是为了什么？不同的答案对应不同的人生态度，也就是不同的过日子的态度。 教练的妻子在得知自己还未怀孕后，仍然诚心赞美主：”I still love you”. 在低潮中仍然相信上帝还爱你并在你身上自有他的美意，这才是最大的信心。一如云上的太阳，不管我们的生活是处于何种状态，","tags":[{"name":"Notes","slug":"Notes","permalink":"http://catcoding.me/tags/Notes/"}]},{"title":"论文吐槽","date":"2011-03-27T11:43:00.000Z","path":"2011/03/27/fuckpaper.html","text":"前些天在写毕业论文，开题弄了个什么神经网络什么数据融合，至今没搞懂过，真是没话说，但是又不得不硬着头皮写，废话连篇，说来说去就那么几句。做的东西本来挺简单的，没用到那么高深的理论，不过为了装装深度，硬要往上面套，希望最好别出什么问题吧。写论文的时候我就想嗄，写代码好玩多了，异常怀念那段天天在poj上写程序的日子。这两天交完初稿，继续做做题，一是玩玩，二是为了原来定下的一个小目标：毕业前水到500题，还差20。两个比较好玩也折腾得比较久的题目。 poj 2050 这题折腾了很久很久，刚开始误以为每个文件的最大行数为1500，最后因为输出格式问题。代码也比较长330行，954ms。使用数组作为hash，使用位图记录文件中存在的单词，idx为由单词转化得到的该单词在hash表中的index。 unsigned int docs_flag[MAXDOC][(MAXWORDS+31)/32]; //记录某个文件中是否存在某个单词void set_docflag(int doc[], unsigned int idx)&#123; doc[idx&gt;&gt;5] |= (1&lt;&lt;(idx&amp;0x1f));&#125;int get_docflag(int doc[],unsigned int idx)&#123; return doc[idx&gt;&gt;5] &amp; (1&lt;&lt;(idx&amp;0x1f));&#125; poj 2518 这个好玩，一个44的方格，里面分别放四个A,B,C,D，初始状态从输入获取，先随便选取一个字母，然后能进行很多次操作。每次能交换两个相邻的方格，到任何一个小的22的方格中全部都是所选的字母就获胜。对于每一个输入，求最少多少次交换就能达到胜利状态，以及有多少方案可以达到这个目的。例如：AABBABABCDCDCCDD output ==&gt; 1 4 (选择A或者B 交换BA 选择C或者D 交换DC)ACABCBBDADADDCBC output ==&gt; 4 96首先想到还是搜索，用bit来减少空间。求最少次数，BFS搜索也许太慢，毕竟每次状态转移会有16个选择。对于每一个输入，先枚举A,B,C,D进行搜索。对于每一个字母，比如A，用一个整数表示其在方格的位置(最大数字到1&lt;&lt;16)， AABBABABCDCDCCDD state ==&gt; 1100 1010 0000 0000 胜利的状态有9个，可以先枚举出来，1100110000000000等等。胜利状态比较多，照一般的BFS写下去代码肯定比较复杂，时间和空间肯定也都要求比较多。考虑可以从胜利状态反着向初始状态搜，先把9个胜利状态放入数组，求到初始状态最少的步数，同时可以算出有多少种走法。这样做了还是超时，看有人说线上输入有很多组数据。 看来每次计算调用了四次BFS确实比较要时间，看提示打表，对于每一个输入先查查看以前计算过没有，计算过则直接输出结果，否则照上面的枚举字母，调用BFS。提交还是超时。 再想想，每次输入可能A的分布是一样的，其他字母分布不一样，照上面那样做对于A还是BFS搜索了一次。从16个位置选择4个位置给A的总分布数目是C(16,4)=1820，不是很大的。很开心，把A的状态记录下来，对于每个输入先看看A这种布局以前算过了没有，如果算过则不用算了，其他字母都是一样处理。结果还是超时，无语了。 正要崩溃时，发现自己还是没看到本质，对于A的每一个布局，B不是一样么，是A还是B没关系的啊。所以，打表不用分字母需要1820*4这么大的表，只要一个1820的表就行了。对于每个输入，分字母获取四个分布状态，看这个状态以前是否算过了，如果算过直接拿那个结果，如果没算过算了存下来。再提交，终于AC了，：）这一步步够辛苦的。","tags":[{"name":"Backup","slug":"Backup","permalink":"http://catcoding.me/tags/Backup/"},{"name":"ACM","slug":"ACM","permalink":"http://catcoding.me/tags/ACM/"},{"name":"POJ","slug":"POJ","permalink":"http://catcoding.me/tags/POJ/"}]},{"title":"近期","date":"2011-03-27T11:43:00.000Z","path":"2011/03/27/guitar.html","text":"1 学吉他 我终于开始学吉他了，五音不全双手不灵活不识谱的我居然开始学吉他了。跟某些朋友说我要学吉他，对方往往有几种反应：1.头被墙夹了 2.要改变风格了？装文艺小青年了？ 3.要追哪个女生么？其实弹吉他还是符合本人闷骚这一特质的。说来惭愧，很早就想学点乐器了，小时候爸想让我学二胡来着，幸好没学，一听那声音就觉得悲催啊。在我高中毕业那会，会憧憬着大学应该能拿个吉他在湖边，身边还有个妹子坐着。这个画面在沙河少林寺和清水河少林寺连实现的欲望都没有。所以，这么个小愿望到现在才付诸实践。前些天买了个民谣吉他，目前还只上了一堂课，右手拨弦有点感觉了，左手按着很痛，这要靠长期练习，慢慢来吧。等我学会了对某个女生来这么首歌-黑眼睛的姑娘。[audio:http://www.moorekang.com/wp-content/uploads/2011/03/20.mp3|titles=黑眼睛的姑娘] 2 到处逛了一趟 从上学期开始实习并找工作以来就没怎么出门玩过，这段时间刚好论文写完，可以出去耍耍。刚好王聪同学从北京解放后开始到处游荡，打算在成都待一周，所以一起找个地方玩。本来计划去海螺沟的，出发前一天晚上被某失恋男说服去碧峰峡。提前假期一天出发，到了雨城雅安。上里古镇没什么好玩的，就是一条河，半个多小时逛完了。立马往碧峰峡赶，下午三点多才到，已经不卖门票了。在山上的旅馆住了一夜，晚上三个大男人在旅馆看成都电视台的特色节目《今天我相亲》，真实得很喜感。第二天从碧峰峡动物园开始逛，因为学生证没带，我买了全票，看完后真是觉得不值啊！！下午逛植物园，在票上看到一个雅女园。话说雅安三大特色：雅雨、雅鱼、雅女，这雅女园莫非有什么非同寻常的东西:)。沿着碧峰峡逛了一圈，中途发现三个mm，其中两个算是美女双胞胎，于是我们三个后面一直处于两种状态，等mm追上我们，在后面追mm。到最后最后，除了王同学搭讪了一句并且没下文，我们都只是有胆看没胆搭讪，很失败。逛完大概耗时三个多小时，急忙忙看完熊猫就得赶车回成都了，前面一直满怀期望的雅女园都没来得及逛，不过肯定是没雅女在里面的，哈哈。总得来说，这碧峰峡是不值我那两张全票的价格的，风景算一般吧。 回成都第二天去了石象湖，在我印象中石象湖应该是不错的，有几个人向我推荐过此处。于是叫上那失恋男饭量同学三个人一起前往。快出成都上高速的时候才发现出来的不是时候啊，车暴多太堵塞，经过漫长的堵车后13点多才到。在门口感觉已经不好了，人太多。进去后刚开始一块还可以，全是一片一片的郁金香，美女也不少。逛进去也就没什么了，一个小湖加几个小石头象，坑啊，开发商太黑了，弄个几个别墅在这园里，卖房又卖票。三个人很失望，立马找出口。在门口等回成都的车足足等了一个多小时，在路上又堵了一个很久，这一天总共在来回路上耗费七个小时，人挤人看了一个小时！我提议的出游计划，对不住两位了。这几天玩下来还真是有点累！ 接下来该锻炼一下身体，打算去青海骑车，目前有四个人了。","tags":[{"name":"Notes","slug":"Notes","permalink":"http://catcoding.me/tags/Notes/"},{"name":"Backup","slug":"Backup","permalink":"http://catcoding.me/tags/Backup/"}]},{"title":"Cflow分析","date":"2011-03-09T11:43:00.000Z","path":"2011/03/09/cflow.html","text":"cflowcflow是个比较古老的程序(好像比我老一岁)，主要是用来打印C程序的函数调用关系，通过函数调用关系能大概看一下程序的流程。最近看了一下这个程序的代码，主要分为两个小程序组成。首先是prcc.c这个程序，作用是读源文件，提取出函数名称，然后生成一个函数列表。第一列是调用函数，第二列是被调用的函数名称(如果是函数声明则这两列相同)。第二个程序prcg.c是读取函数关系，里面建起一个有向无环图。根据这个图加上缩进打印出函数调用轮廓，这里有一个例子。最后是一个脚本cflow.sh，其核心代码就是。 prcc demo.c | prcg 这是典型的通过管道把小程序组起来的例子。 life is short , use Python 闲着的时候在这个程序上做了些小工作。既然有了第一个程序，那也可以用python来快速写个程序继续做些工作。首先想到的是写个程序把函数名打印出来，在有调用关系的函数之间用直线连起来。python就是容易实现。这里有一个问题，就是怎么排列函数名的位置，使得连线不怎么相交，因为相交起来就不容易看到函数之间的关系了。不好解决，还是用了以前《集体智慧编程》里面的优化函数，也就是优化问题。通用思路就是试着移动各个函数的位置，朝着相交点最少的部分移动(这里给一个解，相交点的个数为评估函数)。效果不是很好，当函数比较多的时候哪种算法都比较慢，而且交点看起来不可避免。这是一个结果。运行方法是: prcc demo.c | python drawfuncs.py 或者 find *.c | xargs prcc| python drawfuncs.py 来处理多个程序。 &lt;img src=”/images/out.jpg” alt=”screen” class=”img-center” width=”400”, height=”400” /&gt; 然后又想着可以做一个标签一样的东西，把调用深度比较潜的放大，调用深度深的缩小。不连线，位置随机画。这样一眼能看出来这个程序的主要函数是哪些。结果成这样了。 &lt;img src=”/images/out5.jpg” alt=”screen” class=”img-center” width=”400”, height=”400” /&gt; 位置随便画还是不好，可以分层。然后再相邻层之间的函数有调用关系的再用直线连起来，就变成这样了。清晰一点。既然有函数关系，其实是可以做到更好的，就像上面那个prcg.c程序，不过代码要复杂些了。 &lt;img src=”/images/out6.jpg” alt=”screen” class=”img-center” width=”400”, height=”400” /&gt; C要的是运行速度，Python实现速度快！","tags":[{"name":"Python","slug":"Python","permalink":"http://catcoding.me/tags/Python/"},{"name":"Tools","slug":"Tools","permalink":"http://catcoding.me/tags/Tools/"},{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"C","slug":"C","permalink":"http://catcoding.me/tags/C/"},{"name":"Linux","slug":"Linux","permalink":"http://catcoding.me/tags/Linux/"}]},{"title":"给老婆介绍OOD(翻译)","date":"2011-03-03T11:43:00.000Z","path":"2011/03/03/ood_for_wife.html","text":"晚上看到个有趣的文章，翻译了一下，看过Head First绕过。 原文在这里。 OOD介绍 Why OOD? Single Responsibility Principle单一职责原则 Open-closed Principle 开闭原则 Liskov’s Substitution Principle 里氏可替换原则 The Interface Segregation Principle 接口分离原则 The Dependency Inversion Principle 依赖倒置原则 总结 我的妻子Farhana想重新她软件开发师的职业生涯(她以前也是个软件开发师，但是因为第一个孩子的出生而没有继续下去)。所以，这段时间我在帮助她学习一些OOD方面的东西，我是一个比较有开发经验的程序员。 从我早期的职业生涯中，我发现不管是多么复杂的技术问题，如果从普通交谈中以平常生活常见的角度去解释往往变得更容易理解。因为之前我和她有不少富有成果的交谈，我想可以和大家一起分享一下这种学习OOD的有趣方式。 下面是我们学习OOD的对话： OOD介绍 Shubho : 好，让我们开始学习OOD，你已经知道了面向对象三大特性，对吗？ Farhana: 你是指封装、继承、多态吗？是的，这些我知道。 Shubho : 好，希望你已经知道了使用对象和类，让我们今天开始学习OOD。 Farhana: 等等，知道面向对象特性还不够面向对象程序设计吗？我的意思是，我能定义类，封装成员变量和函数，我也能根据类之间的关系定义继承类。那还有什么需要学的么？ Shubho : 好问题，OOP和OOD是两码事。让我给个例子给你。当你还是小孩的时候你学会了字母表，对吧？ Farhana: 嗯 Shubho : 好，你也学会了如何用字母形成一个个有意义的单词，同时，你也学会了一些语法来造句子。比如，你要维持时态，使用介词、连接词、和其他语法来造出正确的句子。比如说一个句子像下面这样。”I” (pronoun) “want” (Verb) “to” (Preposition) “learn” (Verb) “OOD” (Noun) 你看，你要让这些单词安特定的顺序组成，你也 要选取正确的词来使得这个句子有意义。 Farhana: 呃，这是什么意思？ Shubho : 这和OOP是类似的。OOP是面向对象程序设计的基本原则和核心思想。这里，OOP对应于英语语法，这些基本语法告诉你如何用单词去构造一句有意义的话，OOP告诉你使用类，封装成员变量和方法，也告诉你在代码中使用继承关系。 Farhana: 嗯，有点懂了。那么OOD对应于什么呢？ Shubho : 你马上就知道。好，现在比如说你想要就一个论题写一些文章。你也想就一些你比较精通的方面写一些书。知道如何遣词造句还不够写一篇好文章或者好书出来，对吧？你还需要学习很多，你需要知道如何用一种好的方式去解释一个东西，这样读者才能了解你到底在说什么。 Farhana: 有点趣，继续。 Shubho : 好，现在比如说你想就OOD方面写一个本书，你需要知道如何把这个主题分为小题目。然后在这些小议题上面逐章地写，你还要写前言、简介、解释、例子，还有许多其他段落。你需要知道如何从整体上把握这本书的构造，甚至需要一些写作技巧。这才能让你的书通俗易懂。在软件设计领域，OOD同样是个更上层的角度。你需要好好的设计，使得你的类和代码可以更好地模块化、复用、灵活。使用这些设计原则可以是你少重复发明轮子。懂了吗？ Farhana: Hmm，我明白了一些，但是请继续。 Shubho : 别急，一会你就知道了。我们只管讨论就是了。Why OOD? Shuboho : 这有个很重要的问题，为什么我们需要OOD，我们明明就能很快的稀里糊涂的设计一些类，赶快完成开发然后交付？这还不够么？ Shubho : 就是，我以前也不知道OOD，我仍然能开发完成项目。那这有什么问题么？ Shuboho : 好，让我来给你一个经典的引用: “Walking on water and developing software from a specification are easy if both are frozen.” - Edward V. Berard (如果水是冰冻的在上面行走很方面，如果规格书是不变的，开发软件也很方便) Shubho : 你是说软件的需求说明书一直都在变化？ Shuboho : 正确，最普遍的真理就是”你的软件注定都要变化”,为什么？因为你的软件需要解决的是现实生活中的问题，而这些都是会变化的—永远会变。你的软件按照今天需要做的，做的足够好。但是你不设计得足够好，你的软件足够灵活来应对”变化”吗？ Shubho : 好，这样，快给我介绍什么是”设计得足够灵活的软件”! Shuboho : “一个设计的灵活的软件是容易适应变化的，它能够便于扩展和复用”。而使用一种好的”面向对象设计”方式是得到这种灵活设计的关键。但是，我们有什么标准来说明我们的代码中使用了良好的OOD？ Shubho : 呃嗯，这也是我的问题。 Shuboho : 你需要做到了下面几点: 面向对象方式 可复用 修改代价最小化 不修改现有代码的基础上扩展前人已经在这方面做了许多工作，他们已经对一些通用的场景列出了一些通用的设计准则。最基本的五点可以简称为SOLID原则(Uncle BoB)。S = Single Responsibility PrincipleO = Opened Closed PrincipleL = Liscov Substitution PrincipleI = Interface Segregation PrincipleD = Dependency Inversion Principle下面我们逐一介绍上面的几个原则。Single Responsibility Principle 单一职责原则 Shubho : 先来看幅图，很形象。你能把所有的功能都集成在一个东西上，但是真的不应该。为什么？因为这为以后增加了很多额外的管理工作。我来用OO术语解释一下,”不能有多个理由去改变一个类”,或者说”一个类有且只能有单一职责”。 Farhana: 能解释一下吗？ Shubho : 让我们来看这个继承的例子，这是从Uncle Bob书上弄来的。Rectangle类做了两件事， 计算矩形的面积 在UI上画出矩形两个程序要用这个类， 一个几何计算的程序要用来计算面积 一个图形界面程序要用来在UI上画一个矩形这就违反了SRP原则。 Farhana: 怎么？ Shubho : 你看，一个矩形类包含了两个不同的动作，一个计算面积，一个画矩形，这导致了下面的问题： 在几何计算的程序中我们要包含GUI，进而又需要包含GUI所用的图形库。 任何因为图形界面而在这个类上面所做的修改将导致几何计算程序重新编译测试，相反也是。 Farhana: 变得有趣了，所以我们应该根据其功能把这个类分开，对吧？ Shubho : 正是，那么该如何做？ Farhana: 我来试试，也许该这样，根据职责分为两个类，比如： Rectangle 这个类定义方法method() RectangleUI 这个类从Rectangle继承并定义Draw()方法 Shubho : 非常好，现在两个程序分别使用两个不同的类，我们甚至可以将两个类放在不同的Dll文件里面，这样任何一个类的改动不会影响到另外一个程序。 Farhana: 谢谢，我想我理解了SRP。一方面，SRP是一种把东西分开到一些便于复用和集中管理的小模块中。那么，我们同样也能在成员函数这一级别来使用这个原则吧？我是说，如果我写了很多很多行代码在一个函数中完成几件不同的事，这也违反了SRP原则，对吧？ Shubho : 是的，你应该把这个函数分成几个小的分别做一份特定的事。这也让你只需要很小的代价来应付变化。 Open-closed Principle 开闭原则 Shubho : 这幅图是说开闭原则的。 Shubho : 先来解释一下:软件实体(类、模块、函数等等)应该对扩展开放，对修改封闭。最基本的层次，你应该能够在不修改一个类的基础上扩展它的行为。比如，我不需要在我的身体上做什么改变，就能穿上一件衣服，哈哈。 Farhana: 有趣，你能穿不同的衣服来改变的外貌，而不需要对你的身体做改变，所以你是对扩展开放的，对吧？ Shubho : 是的，在OOD里面，对扩展开放意味着我们能够扩张模块/类，对需求的变化添加一些新的东西。 Farhana: 而你的身体对修改是关闭的，我喜欢这个例子。那么核心的类和模块在扩展的时候是不能被修改的，你能具一些例子吗? Shubho : 好，我们来看这副图，这是一个违反了开闭原则的例子。 Shubho : 你看，服务端和客户端是直接连接的，这样不管是因为什么原因，当服务端实现改变了的时候，客户端也需要改变。 Farhana: 恩，懂了点。如果一个浏览器只是针对于特定的服务器(比如IIS)，如果因为什么原因我们需要换一个服务器(比如Apache),浏览器也需要改变，这真是恐怖。 Shubho : 对，下面这个设计应该要好。 那个抽象的服务器类对修改是关闭的，而具体的子类实现对扩展是开放的。 Farhana: 恩，懂了。抽象是关键，对吧？ Shubho : 对，我们应该抽象系统中那些核心的概念，如果你抽象得好，当添加新功能的时候不需要修改。比如上面服务端是个抽象概念，如果IISServer是服务器的一种实现，现在需要扩展服务端这个概念，比如说一种新的ApacheServer实现，而这些扩展对客户端程序没有任何影响。 Liskov’s Substitution Principle 里氏可替换原则 Shubho : LSP原则听起来很难理解，其实含义很简单，看下面这副图。这个原则意思就是：子类必须能够替换其继承的基类。或者换一种说法：基类能使用的方法，子类也能使用。 &lt;p&gt;&lt;a href=&quot;/images/7.jpg&quot;&gt;&lt;img class=&quot;aligncenter size-medium wp-image-431&quot; title=&quot;7&quot; src=&quot;/images/7-300x237.jpg&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;237&quot; /&gt;&lt;/a&gt;&lt;/p&gt; &lt;li&gt;Farhana: 对不起，听起来很难懂。我认为这时OOP的基本规则，这时多态，对吗？&lt;/li&gt; &lt;li&gt;Shubho : 好问题，答案是：在基本OOP里面，&quot;继承&quot;被描述成一种&quot;is-a&quot;的关系，如果&quot;开发者&quot;是一个&quot;软件职业者&quot;,那么&quot;开发者&quot;类应该继承&quot;软件职业者&quot;,这种&quot;is-a&quot;的关系在类的设计中非常重要，但是这样非常容易导致一种错误的继承设计。LSP原则是一种保证正确使用继承的方法。让我们看个例子。&lt;/li&gt; &lt;p&gt;&lt;a href=&quot;/images/8.png&quot;&gt;&lt;img class=&quot;size-full wp-image-432 aligncenter&quot; title=&quot;8&quot; src=&quot;/images/8.png&quot; alt=&quot;&quot; width=&quot;188&quot; height=&quot;176&quot; align=&quot;center&quot;&gt;&lt;/a&gt;&lt;/p&gt; KingFishera是一种能飞的鸟，它继承Bird类没问题。但是如果下面这样： 鸵鸟是一种鸟，所以它基于鸟基类。现在能飞么？不行，所以，这个设计违反了LSP。所以，即使在真实世界中看起来很自然。但在类的设计中，鸵鸟不应该继承鸟类。应该有一种不能飞的鸟类，然后鸵鸟从这个类中继承。 Farhana: 好，我懂了LSP，让我来指出为什么LSP这么重要： 如果LSP不满足，类继承关系将会混乱，如果一个子类实例被当作参数传到一个函数，奇怪的事可能会发生。 如果LSP不满足，单元测试中基类通过而子类通不过。 Shubho : 很正确，你能吧LSP原则当作一种验证工具，来测试你的继承层次是否正确。 The Interface Segregation Principle 接口分离原则 Farhana: 这是什么意思？ Shubho : 意思如下：客户代码应该不依赖他们不使用的接口。 Farhana: 解释一下。 Shubho : 当然，其意思就是，假设你要买一台电视机，现在有两台可供选择，一台有很多转换器和按钮，大部分你都不明白是用来干什么的。另一个只有少数几个按钮和转换器，对你来说很熟悉。你选哪一个？ Farhana: 当然是第二个。 Shubho : 是的，但是为什么？ Farhana: 因为我不需要那么转换器和按钮，那些我不明白，而且对我也没什么用嗄。 Shubho : 对，类似的，假设你有一些类，你要暴露一些接口给外界，这样外面的代码才能利用这个类。如果一个类的接口太多，也暴露了很多接口，这对于外界来说是比较混乱的。而且，方法太多的接口也是不利于复用的，这种”大而全”的接口导致类之间的紧耦合。这也导致一个问题，任何使用这个接口的类都需要实现那些方法，而有些对于这个类是根本没用的。所以这么做也带来了不必要的复杂性，导致维护的困难和系统的健壮性问题。接口分离原则保证接口设计得合理，他们都有自己的职责，这样简明、方便理解、利于复用。 Farhana: 哦，我懂了。你的意识是指接口只含又那些必须的方法，而不包括冗余的? Shubho : 是的，来看个例子。下面这个例子违反了ISP原则。 注意，IBird接口包含很多鸟的行为，还有Fly()行为，现在一个Bird类(鸵鸟)实现这个接口，它必须实现Fly()行为，这对于鸵鸟来说是不行的。 正确的设计是这个。鸵鸟实现IBird接口，而可以飞的鸟实现IFlyingBird接口。 The Dependency Inversion Principle 依赖倒置原则 Shubho : 是说：高层模块不依赖底层模块，两者都依赖抽象。抽象不应该依赖于细节，细节应该依赖于抽象。 让我们来看一个现实的例子，你的车子包括很多组成部分，有引擎、轮子、空调、还有其他东西，对吧？ Farhana: 是的。 Shubho : 好，每一件东西都是严格地独立地造的，而且每一样都是可以”插拔”的，所以你的引擎或者轮子坏了，你可以修它，甚至可以换掉它，但是其他部分不需要动。你换的时候需要保证配件和车子的设计是符合的，比如这车子需要1500Cc的引擎和18英尺的轮子。同时，你的车也可以使用2000CC的引擎，任何厂家的都可以。现在，想象一下如果你的车子不设计成这种可”插拔”的，会出现什么问题？ Farhana: 那真是太糟糕了！如果车子引擎坏掉你需要修理整个车子，或者卖一辆新的。 Shubho : 是的，那么”可插拔”是如何做到的? Farhana: “抽象”是关键，对吧？ Shubho : 是的。在现实中，汽车是一种更高层次的实体，它依赖于一些第层次的实体，像引擎和轮子。而车子不依赖于具体引擎和轮子，依赖于这些概念。这样，任何符合这个概念的引擎或者轮子都能放进车子让车子跑动起来。看看下面这幅图，注意这里车子类中，有两个属性，都是接口类，而不是具体类。引擎是”可插拔”的是因为它接受任何满足这个抽象的具体实现，而不改变其他部分。 Farhana: 那么如果违反了DIP原则，将会有下面的风险。 破坏高层次的代码 当底层代码改动的时候，需要大量成本改变上层代码 代码复用不好 Shubho : 完全正确！ 总结 Shubho : 除了SOLID，还有其他很多原则。 * “Composition over Inheritance”: This says about favoring composition over inheritance. * &quot;Principle of least knowledge&quot;: This says that &quot;the less your class knows, the better&quot;. * &quot;The Common Closure principle&quot; : This says that &quot;related classes should be packaged together&quot;. * &quot;The Stable Abstractions principle&quot;: This says that &quot;the more stable a class is, the more it must consist of abstract classes.&quot;&lt;/pre&gt; 设计模式是OOD的特例，DP就像是对于特定场景的特定框架，而OOD则是说明。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Backup","slug":"Backup","permalink":"http://catcoding.me/tags/Backup/"},{"name":"OOD","slug":"OOD","permalink":"http://catcoding.me/tags/OOD/"}]},{"title":"在显示器前干了什么","date":"2011-02-22T11:43:00.000Z","path":"2011/02/22/workingtime.html","text":"时间啊时间 写论文头大，翻资料找到一个以前写的小东西。有段时间在实验室，一坐就是一整天，经常在网上找找资料，找着找着就从一个链接点到另一链接，从豆瓣到Hoop，再弹出个QQ，一整个上午就过去了。天天对这显示器，于是就想我整天呆在这大部分时间在干什么了，要是有个记录就好了。就想写这么一个小程序，来记录我一天在电脑前花的时间分布。 方法 怎么实现呢。要知道现在在干什么，就应该要知道我现在在活动程序，编辑或者鼠标点击的。如何知道现在活动的程序名，如果能获得当前活动的程序的可执行文件的路径就比较好办了。于是在网上找了找，在Windows下可以这样实现。 CString getProcPath(int PID)//返回pid进程的可执行程序名称{ HANDLE hModule; MODULEENTRY32* minfo=new MODULEENTRY32; minfo-&gt;dwSize=sizeof(MODULEENTRY32); hModule=CreateToolhelp32Snapshot(TH32CS_SNAPMODULE,PID);//对系统进程进行拍照 Module32First(hModule, minfo);//返回与进程相关的第一个模块信息 CString str; str=CString(minfo-&gt;szExePath); CloseHandle(hModule); if(minfo) delete minfo; &lt;span style=&quot;color: #00bfff; font-weight: bold;&quot;&gt;return&lt;/span&gt; str; } 得到了当前活动的程序名称就比较好办了，其实经常用的就是那么几个程序，稍加分析然后分类就能统计到我的时间分布。我这里分为了四类：编程、上网、看文档、QQ。用个定时器记录下来即可。实现个托盘最小化，就可以了。 void Report::Init(){ m_Programming.push_back(_T(“devenv.exe”)); m_Programming.push_back(_T(“Microsoft Visual Studio”)); m_Programming.push_back(_T(“vim”)); m_Programming.push_back(_T(“matlab”)); m_Programming.push_back(_T(“MATLAB”)); m_OnWeb.push_back(_T(“firefox”)); m_OnWeb.push_back(_T(“Chrome”)); m_OnWeb.push_back(_T(“IEXPLORE”)); m_OnWeb.push_back(_T(“opera”)); m_QQ.push_back(_T(“QQ”)); m_QQ.push_back(_T(“Tecent”)); m_Document.push_back(_T(“WINWORD”)); m_Document.push_back(_T(“Office”)); m_Document.push_back(_T(“CAJView”)); m_Document.push_back(_T(“hh.exe”)); m_Document.push_back(_T(“FOXITR”)); } 结论是个有点无聊的东西。其实可以稍微完善一下，比如加一个定时通知休息的功能、或者是上网过久的通知、便签之类的小功能也可以呵。代码 ：Workingtime ,匈牙利命名法好难看。","tags":[{"name":"Backup","slug":"Backup","permalink":"http://catcoding.me/tags/Backup/"}]},{"title":"《先知》- 纪伯伦","date":"2010-12-29T11:43:00.000Z","path":"2010/12/29/theprophet.html","text":"《先知》，纪伯伦。这本书买了一年，看了一遍，更多的时候是听其附带的朗诵，美和哲理，很让人内心平静。左上角的“憩于理性，行于热情”也是出于这。先知讲述的真理包括爱、婚姻、孩子、施与、饮食、工作、欢乐和悲哀、房子、衣服、买卖、罪与罚、法律、自由、理性和热情、痛苦、自知、教育、友谊、谈话、时间、善恶、祈祷、快乐、美、宗教、死。 为什么说是真理，当你相信的时候就是真理，不相信的时候就是建议。正如里面所说:“不能说我找到了真理，而应该说我找到了一条真理。” 这一个月里经常去参加教会的活动，得到的多是感动和宁静，虔诚的爱可以让生活变得不一样。如一位大哥所说，在这里的是新生，以前认为很重要的东西变得不重要，以前认为很不重要的东西重要起，迷途的羔羊们都弄反了。 论爱 假如你在你的疑惧中，只寻求爱的和平与逸乐， 那不如掩盖你的裸露，而躲过爱的筛打， 而走入那没有季候的世界，在那里你将欢笑，却不是尽情的笑悦；你将哭泣，却没有流干了眼泪。 爱除自身外无施与，除自身外无接受。 爱不占有，也不被占有。 因为爱在爱中满足了。 论工作 你们也听见人说，生命是黑暗的。在你疲劳之中，你附和了那疲劳的人所说的话。 我说生命的确是黑暗的，除非是有了激励； 一切的激励都是盲目的，除非是有了知识； 一切的知识都是徒然的，除非是有了工作； 一切的工作都是空虚的，除非是有了爱。 当你仁爱地工作的时候，你便与自己、与人类、与上帝连系为一。","tags":[{"name":"Books","slug":"Books","permalink":"http://catcoding.me/tags/Books/"}]},{"title":"内存泄漏","date":"2010-12-22T11:43:00.000Z","path":"2010/12/22/c-mem-leak.html","text":"以前写的一些程序运行一段时间后占用的内存越来越多，估计是内存泄露了。服务端的程序要长时间的运行，内存泄露是个很严重的问题。于是再检查程序，很崩溃的是还有另外一个模块不是自己写的，看起来很麻烦。看了半小时后发现一些问题，但是还是不能保证是否完全解决了。同事让我用以前他们写的一些函数，对应的为MALLOC和FREE。仔细看了一下觉得很不错，其实就是把malloc和free函数封装了一下，用来记录申请空间的文件和代码位置，使用方法就是用MALLOC和FREE替代原来的函数。主要的数据结构是： typedef struct{ long pcode; //指针 char filename[128]; //申请空间的源文件名称 int line; //申请空间的代码所在的行 int ct; //内存状态: 0-未闭合,1-闭合,2-log/脚手架}mem_info;mem_info mem_in[MEM_SIZE]; //MEM_SIZE最大指针数目int mem_in_id; //数组中已经占有的mem_info数目int mem_check_statue; //是否进行内存泄露检查然后有两个函数，一个是初始化函数mem_check_init(),另一个为mem_check_write(),这样就能检查者两个函数之间的代码是否有内存泄露，mem_check_write()可以打印成一个表，所有申请了空间的代码的文件名称和代码所在的行数，以及运行到mem_check_write()这里的时候所有申请空间的状态，1表示已经释放，0表示申请未释放，2表示的是脚手架的位置（用来方便检查哪一小段代码是否有内存泄露）。#define MALLOC(size) ck_malloc(size,FILE__,LINE) //FILE 文件 LINE 代码所在行void __ck_malloc(int size,char file,int line){ void p=malloc(size); if (mem_check_statue) return p; if (mem_in_id&gt;=MEM_SIZE) return p; mem_in[mem_in_id].pcode=(long)p; strcpy(mem_in[mem_in_id].filename,file); mem_in[mem_in_id].line=line; mem_in[mem_in_id].ct=0; // 状态: 0-未闭合 mem_in_id++; return p;}那么FREE(p)，进行的操作就是现在数组中找到是否有这个p，如果有就改变状态，变为1表示闭合了，也就是释放掉了。CALLOC和MALLOC类似，是调用calloc，函数malloc()和函数calloc()的主要区别是前者不能初始化所分配的内存空间，而后者能。REALLOC有点不一样，调用void np=realloc(p,size)，这里要注意np和原来的p有可能不一样，有可能一样，比较一下进行相应处理。最后mem_check_write()遍历上上面的数组打印出来表，其顺序就是按照代码执行的顺序了，其中脚手架可以比较方便的定位于申请了没有释放的代码行，也就是查找两个2之间的0所对应的行。这是一个很不错的方法，今天用这个办法找到了好多处不易发现的内存泄露错误。但这也有其缺点，即使完全通过也不能保证就完全没内存泄露了，除非测试时运行代码的覆盖率要保证所有代码都运行到了，这也是正规的、高质量的测试所要做到的程度。我们现在没有时间来做足够好的测试，以后再好好规范一下。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"C","slug":"C","permalink":"http://catcoding.me/tags/C/"},{"name":"内存泄漏","slug":"内存泄漏","permalink":"http://catcoding.me/tags/%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F/"}]},{"title":"老罗的扯淡极致","date":"2010-12-01T11:43:00.000Z","path":"2010/12/01/luopanzi.html","text":"昨晚上正准备睡觉时手贱点随便点击了个链接，然后就在这个《老罗全国巡回演讲完结篇：海淀剧场》里一直跟着欢乐到2点钟。大学时有一段经常听老罗语录，胖子嬉笑怒骂、语言犀利、愤世嫉俗、玩世不恭、理性的愤青，听来很过瘾。那时很流行的一句是：“彪悍的人生不需要解释”。时不时我们寝室几个人吃完饭就那么瞎坐在那里，放上几段经典的来笑笑。原来我电脑上是有老罗全集的，后面硬盘毁掉了。很久没这么长时间听这罗氏语调了，酣畅淋漓。 老罗在腾讯微博上很活跃，一如既往的内心强大，就中医是否伪科学和无数人争论到底，耐心相当之好。原来听过老罗语录的人应该会知道此人为什么会如此憎恨中医。这牛还出书了，《我的奋斗》，看过几章，还是挺不错的。原来听说老罗在办个英语培训学校——老罗和他的朋友们教育科技有限公司，没想到现在已成气候，每天醒来都能闻到钱的味道。这个老罗全国巡讲应该是最好的广告了。以前的一系列我都没看到，不过看了最后这个终点站的应该不用看前面的了。演讲的题目是《一个理想主义者的创业故事》，估计是演说了很多场了，这牛已经熟练到如火纯青的地步。原来还以为ppt是别人帮忙放的，后来才发现应该是自己手里握着个遥控器，期间基本很少看自己的ppt，只有在自恋的时候转身对着花痴一下。笑过后也是有所收获，老罗分享了其创业以来的一些经历和想法。稍微总结一下。 1 企业的核心产品或服务。老罗英语培训，师资是关键，这个没办法，有的事只能钱来解决，用最好的薪资待遇请最好的老师。 2 营销策略和推广，这是最长也是最有趣的部分，都是一些有趣的案例。老罗是个偏执狂，只有偏执狂才能做出那么漂亮的宣传画和广告。小小窃喜一下，那个音乐节上的广告我也想到了那么个切入点，不过看的时候还是震撼了一把，完美，太有才了。还有一些平面广告在这里。 3 待遇、企业文化、愿景，这些东西是一个公司是否能留住人的关键，实实在在做产品或者服务的公司，即使在中国这样的创业环境下，还是有生存机会。我没上过老罗的辅导班，也没那钱力，觉得关于英语学习的任何辅导班都没什么用，学英语这事得靠自己。可这老罗英语培训机构做的确实很有个性。 4 即使是老罗这么内心强大的人也有挺不住的时候，这时候他的自恋和幻觉产生作用了。看来老罗最后居然有点哽塞，果真是讲到深处了。最后在商业机构里做一个理想主义者非常难，但赚钱不等于染铜臭。而又有“偏执狂才能生存”这么一个道理，要做一个牛逼的企业，还是需要理想主义的偏执狂。","tags":[{"name":"扯淡","slug":"扯淡","permalink":"http://catcoding.me/tags/%E6%89%AF%E6%B7%A1/"},{"name":"老罗","slug":"老罗","permalink":"http://catcoding.me/tags/%E8%80%81%E7%BD%97/"}]},{"title":"优化算法","date":"2010-11-20T11:43:00.000Z","path":"2010/11/20/gene-alg.html","text":"POJ 2714最近又在POJ上做题，碰上2714，题意是： 输入N，和N个点(x,y)，从原点开始一共可以走N步，每一步可以随机选择移动(x,y)，或者(-x,-y)。N的范围为1-100。输出最远能走到离开原点多远的地方，输出其距离。 分析一下，用迭代肯定可以，不过2^N的复杂度肯定太高了。每步有两种选择，其本质是求一个长度为N的0、1序列使得最后的值最大，为一个优化问 题。这里贪心不能求到最优解，稍微证明一下就能得出。如果不贪心，或者把贪心的范围扩大一点，求出每一步完后的凸包呢，然后再在这步的基础上继续扩展下一 些节点，再求凸包，继续如此，最后求得凸包中距离最远的。求凸包的复杂度位O(nlgn)，即最后的复杂度为O(N^2lgN)，是可以接受的。 随机搜索以前看过《集体智慧编程》这本书，这里有一章是说的优化。稍微回顾一下其中的几个算法。对于优化问题，首先得找到一个评价函数，对于其某个方案评价函数能给出某个值评估方案的优劣。至于返回值越大还是越好没有规定，对于特定的问题选择特定的评价函数。 随机搜索不是一种好的优化算法，但是却是后面的算法的根源。其基本思想是，我们随机长生一些解，看是否好，如果比当前更好，替换当前最优解，直到收敛了，或者猜测了足够的次数了。 do{ solution=rand_solution; value=eval(solution); if(value&gt;best) best=value; times++; //测试是否收敛}while(times&lt;max_iter&amp;&amp;(!limit_flag));这种盲目的猜测虽然有机会在某一次猜中最优解，但是效率肯定不怎么好。随机算法还是有一些问题可以适用，比如素数判定，如果能保证错误率很低很低也是可行的算法。 爬山法随机搜索不是一种好的优化方法，为什么？因为没有充分利用已经得出的当前最好解。对于上面这个问题，最优解可能和当前最优解有一些相近之处，可能是因为某一步当前最优解走错了，最后没有演变成最优解。其意思就是，如果把当前最优解稍微改变一下，可能会向最优解的方向靠 近。那么爬山法就是通过当前的最优解，在其附近找更好的解，知道当前没有更好的解为止。而随机搜索是跳越型的，所以没有这个优势。看下面这幅图，现实中很 多问题都会像这样，如果我们把所有解都算出来，按组合排列的顺寻作为x轴，评估函数得出的值为y轴，能得出稍微连贯的曲线。随机从某个初始点出发，沿着我们想要的方向寻找，能找到优解。 陷入局部最小 最优解为最低点 爬山法的缺点是，如过找到某个局部最优的地方，可能就被欺骗了，因为发现没有斜率了，以为是最优解。最后可能是个次优解。所以继续改进。 模拟退火爬山法总是接受当前最好解，也算是一种贪心的思想，正如贪心一样，有可能得不到最优解。如何改进呢？那就在选择的时候不止是选最好的，还要接受一些看其来不怎么好的解。模拟退火就是这样，“模拟退火”的原理也和金属退火的原理近似。其关键在于：如果新的解比当前解更优， 即换为当前最优解，如果不优，新的解仍然可能成为优解，但是要一定的概率接受。这个时候神奇的e派上用场了，这个接受的概率我们可以算 作：p=e^(-(highest-lowest)/(temprature))。刚开始的时候温度很高，所以p接近为1，后面温度开始降低，表现出来的结果就是越是到后面接受较差解的机会就越小。就是因为接受一定的较差解，模拟退火能找到最优解的概率比较大。 遗传算法换一个思路，如果我们把搜索空间中的所有解看成一个个的物种，初始化随便初始化一些物种，然后随着自然的演变，我们需要最好的最强大的最优秀的最优生命力的物种保存下来。遗传算法就是这样，符合自然规律，符合进化论。和上面几种算法一样，随机初始化。为了得出优秀的后代，需要优秀的双亲进行杂交，或者称为配对、或者交叉。别想歪了，对于简单的二进制序列，就可以选p1的一部分和p2的一部分组合成为一个新的解，当然还有其他的方式。位了避免局部最优的陷阱，我们还需要变异，正如现实中人类总是需要变异的天才一样。对于序列，简单的变异就是改变其中的某一位或者几位。然后每一轮都进行排序，选择其中%10，或者%20的优秀物种，继续上面的操作，直到解收敛或者达到一定的循环次数。这里可以改变的参数就比较多了， 最大筛选次数，生存的比率和选择的方法，变异的比率，杂交的函数选择，变异的函数选择等等。 总结上面的优化算法都是一个算法框架，如A*算法一样，最后更多的细节比如评估函数或者参数的选择对算法的效果都有影响。 另外这些优化算法最后能生效都是基于这么一个事实:很多优化问题最优解附近的解也是比较优的解，比如上面的问题，另比如旅行商问题。但有的情况，如下图，就是一个可能不被优化的问题，最优解附近并不是好的解，对于上面的算法都有随机性，也许随机优化一下能找到这个解（概率很小），也许遗传算法能产生个变异，但这都是概率问题，不能保证。 难优化的例子 最优解为最低点 说明：上面的图来自《集体智慧编程》中，这是本不错的书，在网上有代码，python写的，感兴趣的同学可以仔细看看。 我试着用遗传算法去解上面这个问题，参数调了很多次，最后还是能在一个可以接受的时间内得到所有正确的解。 代码在后面，写得很难看。gene_alg","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Algorithms","slug":"Algorithms","permalink":"http://catcoding.me/tags/Algorithms/"}]},{"title":"Emacs Muse的使用","date":"2010-11-15T11:43:00.000Z","path":"2010/11/15/emacs-muse.html","text":"Muse简介 Muse的配置 Muse中源代码高亮显示 Muse 来写主页和博客 Muse简介 Muse 是由 EmacsWiki 衍生的，为emacs下的一个扩展模式，可以方便快捷的为文档生成各种格式，包括html,pdf，latex等等。Muse的编辑规则很简单，而且支持“所见即所得”的编辑方式可以让文档编辑更轻松。我使用这个工具已经快一年了，强烈推荐。这个html文件就是从Muse调用htmlize生成的。 Muse的配置 从这里下载最新版本的Muse，比较简单的安装方法是解压后直接在目录下运行make，然后把所有的文件都拷贝到emacs的一个加载目录下面(比如~/.emacs.d/muse/)。设置.emacs加入以下几行。 ;; 加载 muse (require 'muse-mode) (require 'muse-html) 然后就可以利用Muse-mode来方便地创建文档。这里有个QuickStarted，看一遍就基本掌握了编辑规则。编辑完成以后按键C-u C-c C-t即可发布该文档。 Muse中源代码高亮显示 在Muse-mode中编辑时是所见即所得样式的显示，但是有一个问题是代码不能高亮显示，要贴代码就有点不方便，解决的方法是要下载htmlize.el,而且需要1.34以后的版本才支持这个功能，在这里下载。使用方法也有说明。 Muse 来写主页和博客 很多搞学术的同学喜欢建一个看起来很严谨的静态主页，这样的主页用Muse来维护非常方便。对于wordpress的博客或者主页，一款离线撰写工具是必须的，在windows下可以用WindowsLiveWriter,Linux下也有相应工具。不过我大部分还是在自己电脑上用Muse来写完发布成html格式，然后再发布到主页上。首先我们需要建立一个主页的工程。比如我的： ;;==新建一个wiki工程 (setq muse-project-alist '((\"MainPage\" (\"~/document/blog/Home\" :default \"index\") (:base \"html\" :path \"~/document/blog/Home_Page\")) (\"Computer\" (\"~/document/blog/Home/Computer/\" :default \"index\") (:base \"html\" :path \"~/document/blog/Home_Page/Computer\")) (\"Sport\" (\"~/document/blog/Home/Sport\" :default \"index\") (:base \"html\" :path \"~/document/blog/Home_Page/Sports\")) (\"Other\" (\"~/document/blog/Home/Other\" :defualt \"index\") (:base \"html\" :path \"~/document/blog/Home_Page/Other\")))) 然后到相应目录下撰写muse文件，快捷键C-c c-p就发布了整个工程，在Home_Page相应的目录下生成了html的文件。看起来有点复杂，其实还是很方便的，代码高亮这个程序员都喜欢的功能肯定就不用操心了，同时在本机上留有个备份。这种wiki风格的网页还是很利于浏览。不过有一个弊端，图片插入虽然在撰写过程中能直接预览的，但是上传到wordpress上路径肯定会变，所以还是要再稍微编辑一下。","tags":[{"name":"Emacs","slug":"Emacs","permalink":"http://catcoding.me/tags/Emacs/"},{"name":"Tools","slug":"Tools","permalink":"http://catcoding.me/tags/Tools/"}]},{"title":"又是一些歌","date":"2010-11-14T11:43:00.000Z","path":"2010/11/14/damien-rice.html","text":"实验室的机子要被占，要搬出来，所以得把资料整理一下。发现一个原来研一英语课上做representation的ppt,题目是介绍一位自己喜欢的歌手。那次第一次上台做英报告，呵呵。我喜欢缓慢而伤感，有些沉重的歌。在一位同学日记上看到介绍Damien Rice的，然后喜欢上了他的歌。研一那一年骑车时候基本都是这些歌，高中时最郁闷的时候经常听的是王菲和齐秦。一段时间狂听某些歌好像已经成了习惯，然后偶尔再听到的时候当时的情景自然就浮现了，音乐也是一种好的记忆载体。 Damien Rice Damien Rice is an Irish Rock singer.Two studio albums: O in 2003, and 9 in 2006.He was born and raised in Ireland,a country which is rich in country music, poets, singers. When He was young, music and drawing attract him. Rice was a member of the rock band Juniper.Having released the singles “The World Is Dead” and “Weatherman” in Ireland during 1998. Rice left the band to pursue a solo career. His Juniper band mates later became Bell X1. Rice’s first solo album is O, which was released in 2003 and a true contender for one of the best albums of 2003, won the Shotlist Music Prize.Rice’s style is simplity. The cover of this album is a beige hand painted portraits of the two small chiledren, which was drawed by himsefl. This is am simple folk album. This album contains a large number of hollow guitar chords , easy and simple percussion, drowning, backwards vocals, and low_key accompaniment . Rice is master of what critic called “the unknown tongue” — basically the musical equivalent of the “punctum” in photos, Rice’s emtional singing brings me a sad ,clean and sophisticated intimate space. Three years later, following extensive promotion of O in Ireland and further success worldwide, Rice released his second studio album 9 in 2006. 好听的专辑： 9 1. 9 crimes the animals were gone elephant rootless tree dogs coconut skins me, my yoke and i grey room accidental babies sleep don’t weep9 crimes最好听，适合半夜失眠。MV拍得很吸引人，在这里，我当时课上放的就是这个MV，非常惊艳，课后还有同学问我要这个。另有个评论感觉写得非常不错。Cold water浮躁繁杂的时候，就来听听这样一首像诗歌般的曲子，这也是电影《偷心》的片尾插曲。木吉他很有感觉，以后有时间学学，呵呵。 还有这首The Blowers Daughter非常不错。","tags":[{"name":"Notes","slug":"Notes","permalink":"http://catcoding.me/tags/Notes/"}]},{"title":"给C瓜同学吧","date":"2010-10-27T11:43:00.000Z","path":"2010/10/27/forc.html","text":"C瓜同学一直关注这个我这个小地方，下面是一些我面试中或者和同学讨论的一些不错的面试题，备份一下，也希望对你有用。 1：C++的多态是如何实现的？如果你用C如何来实现面向对象的多态？2：判断一个有向图中是否有环。上篇文章里面写的那个杯子倒水问题。给一个都是正整数的数组，和一个正整数sum，求是否存在和为sum的子数列。3：两个有大量id的集合A和B，数量上亿级，如何求出两个集合的交集，A中有的B中没有的，和B中有的A中没有的集合。4：设计实现一个管理内存的小模块，接口为void checkout(size_t size), void checkin(void ptr)。5： 设计一个数据结构，存储一副象棋子的摆放，尽量压缩空间，使得方便通过传输到另外一台机子上然后恢复棋盘。6：数组的众数问题，最长递增子序列问题。找大量数据中前k个大的数。找大量数据中第k大的数。7：一个平面中有很多点，用最快的算法找出相隔最近的两个点。8：select/poll和epoll，基本互联网公司都会提到这个东西。9：给敏感词列表，和一大段文本，考虑一个敏感词过滤的算法。10：海量数据问题，很多，一般方法就为分治、hash、位图。 很多没有标准答案，面试过程中的探讨很重要。找工作不难，找份好工作还是难的，基础知识很重要，数据结构和算法、操作系统、编程语言的掌握，数据库和网络。可以根据自己的喜好，偏向于某个方向。","tags":[{"name":"Notes","slug":"Notes","permalink":"http://catcoding.me/tags/Notes/"},{"name":"工作","slug":"工作","permalink":"http://catcoding.me/tags/%E5%B7%A5%E4%BD%9C/"}]},{"title":"有你的快乐","date":"2010-10-27T11:43:00.000Z","path":"2010/10/27/haveyourfun.html","text":"晚上睡在公司，这边除了晚上偶尔有施工的声音，一切都还不错。洗个热水澡，随便写写早点睡。嘈杂的音响放着这么王若琳的《有你的快乐》，标题就用这个吧，哈哈。关于工作：今年好像计算机专业的同学们还是非常好找工作，首先华为华赛来得非常早，然后就是腾讯，这几个公司就签了好多。成都很多同学都不想离开四川，所以进华为的很多。我开始找工作的时候也没有想法一定要留在这，只是周围一直有各种什么成都多好多好之类的言论，什么消费低，房价低，不排外，生活安逸之类的。渐渐地也不由自主地越发想留在这边。我找工作应该已经结束了，一共面了大概六个公司，一周三个公司，中间有一周觉得身体不是很舒服，就没怎么动。第一周面的华赛，前面已经说了很悲剧。然后腾讯，也很诡异，小概率事件发生了，面了终面没有给offer。现在还不知道原因，可能还是二面的问题吧，二面的面试官问我平时是不是都很自我，当时我还没反应过来，后来才觉得不对劲。大公司都会有自己的企业文化，可能会因为这些把人刷掉也是正确的。没收到offer心里多少会有点失落吧，深圳是除了成都之外我比较想去的地方，毕竟那边认识的人比较多，离家也比较近。过了一周后，已经是找工作的高潮时段，我也安奈不住了，所有公司都想去试试。上海纳拓软件，因为何师兄的内推这个公司暑假就已经开始联系然后笔试了，最后因为实习没去上海面试，所以等到他们的校园招聘。前面三面技术面，一面C++，两人一台电脑整程序。电工的校友大哥最后一个题目把我摧残了，模板类啊、嵌套类、友元类啊一看就紧张了。基本是他教我怎么改那个程序，从来没觉得自己C++那么差了，我以前也只是把C++当一个扩展了一点的C来用，所以当时备受打击。二面是师兄的算法，还是比较照顾我，给tips，算是探讨了。三面数理逻辑，面试官很nice，一点点教导，终于给那些最基本的文式图画出来了。纳拓的三个面试是我接触的最深的面试了，一路下来感觉很辛苦。联发科，据说要在成都建立分公司，去试试。面试官很多都是台湾人，感觉很有礼貌，他们要求也不是很高，还是吸引了不少想留成都的同学。另外当晚面了创新工场，感谢欧阳大哥的内推，还有Xiaoxiao同学的面试也很有水准，又有点受打击，后面的那个程序实在做得不尽如人意，最后还是让我进了二面。然后和Billy大概40分钟的聊天，交流了一些想法。创新工场到底怎么样我不是很了解，网上的看法是两个极端，要么是说很好的，要么是说一个空壳，但是我知道很多很强的同学在里面做得都非常有激情，非常有干劲，技术氛围也都不错，所以我也动心了。过了两天是纳拓那边的技术四面，刘大哥很和蔼，一起吃了个晚饭然后才面试。也是首先谈谈项目，没说多久就指出了我的东西是over design了，呵呵。然后交流了各自的看法，感觉很投机。纳拓软件虽然只有10个人左右，但肯定是个非常出色的团队。然后是他们老板的电话终面，他也没怎么太为难我，连老板都在问技术问题，呵呵。总是面完后感觉找到了中意的公司，所有后面也没有再去继续找了。在同一天收到创新工场和纳拓的offer，当天比较纠结。北京和上海，不知道去哪个了。真的也想去北方那边闯闯，创新工场那边应该是个不错的平台。还有欧阳大哥每周教会聚会的短息发到我手机上，我也会时不时想如果我在北京一定要去参加他们的聚会。最后综合各方面的意见，我应该还是签纳拓吧，因为对他们那边感觉很投机投缘，而且也很可能会过一年后在成都开branch。那么，两周的找工作日子算是过去了，没太努力，不过还是认为找到了适合自己的公司。实验室的同学们都找到了自己满意的工作，突然觉得我身边一个个是大牛啊，哈哈。今年的行情真的非常好了，国内的IT公司都在大规模扩招，外企倒还招得少，我们陶瓷国的IT虽然一直说做不到核心，但也确实在进步啊。 最近不知道为什么，非常淡定，也许在这边公司做得比较安稳。我喜欢这种一小群人做东西的感觉，大家一起讨论争论，努力想把一个东西做好的感觉。也可能是因为在这边受到了一些熏陶，所以找工作也想去小的公司或者创业型的公司。第一份工作工资不是主要考虑的，因为我想想即使一年赚20w(应该对应届生算不错的待遇了吧),除去平时花费一年能攒多少钱呢？多1k，2k对于生活也本质的提高，所以在能养活自己的情况下，找些觉得适合自己、能多锻炼、能让人有动力的公司挺好的。况且，如果把工作看严肃点，我应该找的是一群得整天相处的人，所以投机很重要，^^。感谢找工作这段时间所有给予我帮助的所有人，虽然你们不一定能看到，^^。熊师兄，两位何师兄，欧阳大哥。王骆驼，傅骆驼，yyl，寓于其中以及实验室的各位师兄师姐们，哈哈。","tags":[{"name":"Notes","slug":"Notes","permalink":"http://catcoding.me/tags/Notes/"}]},{"title":"面试：杯子倒水","date":"2010-10-14T11:43:00.000Z","path":"2010/10/14/beizidaoshui.html","text":"前些天纳拓的面试有一道题目: 给你一个3升的杯子和一个5升的(杯子是没有刻度的)，要你取4升水来(水可以无限取)，请问该如何操作。这个题目今年面试出现了很多次,不过这次变化了一些。如何抽象出一个模型,如果写程序如何解,如果要求得杯子倒水的过程如何做? 当时并没有一下想出来,看起来有点像取石子那样的游戏,想找规律。然后被提示搜索,对,搜索问题。 搜索得确定状态的表示,状态之间的转移方式,起点和终止状态，如果这些都确定那么就基本完成了。 如果我要求最快的解法,BFS。如果要求所有的解法,递归DFS。这里状态的总数目比较少,如果用一个整数来表示,10位表示A杯子的水量,个位表示B杯子的水量,这样要的空间最大也为60个整数。再想想如果用两个整数，最多64bit，也能表示出状态，能省下空间。 很久没做题了,有些生疏了,看来还得好好补一下。 代码_下载","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"工作","slug":"工作","permalink":"http://catcoding.me/tags/%E5%B7%A5%E4%BD%9C/"}]},{"title":"找工作小结","date":"2010-09-30T11:43:00.000Z","path":"2010/09/30/forjob.html","text":"又是很久没更新了，这段时间比较忙碌，各种笔试面试各种奔波，终于体会到了找工作到艰辛。而这还只是开始。国庆这些天应该要轻松一点，很多公司都是国庆后再来学校。总得来说最近这两个月还算比较充实，即将面临走出校园，还是得去考虑各种选择。另外，尝试着离开实验室后又淡定了不少，哈哈。虽然还没完全结束找工作这些事，但还是记录一下面试的感受吧，其实我面得还算少，才三个公司。 首先华赛就悲剧了，本来打算去积累点面经的，又不是特别重视，那面试官估计也看出来了，其中各种不爽，自己的交流方式也有问题，让他觉得这人有些傲吧。呵呵，本来我是个多不自信、多自我怀疑的人，硬是装作很自信的样子就出问题了。最后面试官说今天就到这里吧，你回去等通知吧。我说把我简历还给我，汗，我当时居然还说了这么句话，想起就无语呀。 TX的笔试感觉很细，做完后不怎么确定能不能有面试机会了，不过第二天就发来了短消息，笔试还是没怎么刷人。一面人山人海，岷山饭店还没个坐的地方，等了两个小时腿都酸掉了。据说王骆驼碰上个年纪比较大的，问得比较刁，自我感觉是挂掉了。最终，我碰上一个比较年轻的，一看就搞技术的，笑得很贼，哈哈。问题都中规中举，有的没答出来，不过还是说了一下自己到思路。最后讨论了前段时间自己在做到多线程的缓存，嘻嘻。这里不得不再说一下，在公司这段时间虽然比较短，但还是实在地做了一些事，对这一块至少说有一些体验，还是可以和面试官聊聊。面完后心里貌似有个底了，应该有二面机会。果然，第二天早上不到6点怎么就自然醒了，睡不着，于是就想一面时候的一个问题，觉得貌似想到了优化方法，哈哈，这时手机震动，于是下床一看果然有二面(赞一下tx的招聘人员敬业精神，早上1点半给你发短信)。二面在成都TX，第一次去了躺软件园，人挺多。TX的工作环境貌似还不错，装饰看起来比较鲜艳。走之前向何老大打听了一下，据说二面就是狂问技术，各种方面的都有，于是心里有点点发毛。等了近四十分钟，最后碰上六号面试官，很奇怪的是后面感觉一直在聊天，项目方面都是泛泛而谈，没怎么问我很深入的技术问题，气氛还可以。大概二十多分钟就结束了。等王骆驼面完一起回，他又碰上个狂刁钻的，各种效率不高，速度不行…..然后我觉得诡异了，说你机会可能更大点。 晚上去面了一下中兴移动，面C++，刚开始那年轻到面试官一副很凶很高深的样子：“学过UML吧，把你这个项目中所用到到类图和关系画出来..”。顿时很无语，在纸上边说边画，心里觉得不爽，这么累了本来是想来打打酱油的，还得慢慢回想一下那折磨了我两年的各种不感兴趣的对象。然后那人问：“你这个项目中只用了两层继承关系吗？”呃，我这正有点郁闷，突然想起哪本书说的，于是就随口说：“面向对象不是银弹，设计得好两层就够了，设计不好十层也不够”。 他居然没继续问了，原来适当地装装也能唬住人的。然后聊了聊状态模式，我说得比较清楚，因为这个模式还是有点体会的。不爽，面试过程中还换了个房间。然后再下面就是聊天了，这下感觉平等多了，聊了聊他们是做什么的，做手机终端各种底层和上层吧。然后就来了个人力资源的面试吧，比较和蔼，就说我们待遇比中兴好。完后站在电梯旁边，王骆驼要强面，两个人一副喝茶的姿势聊得很high，我在旁听了一下，觉得很无语。一个40岁左右的貌似技术人，在王骆驼各种项目忽悠了一顿后，说：“恩，UDT这个东西这么好，我在哪里找到呢？”王骆驼：“在网上下载”。然后面试官最后问了句：“在你编译的时候出现了一大堆到错误提示，你怎么解决？”，王骆驼：“我从第一个错误开始改“。面试官露出了找到知己的那种兴奋表情，最后站起来总结一番：”好，我觉得你对C语言理解很深刻，我去给你安排第二轮面试”。回来时王骆驼一副神清气爽，之前TX被问得不知所云，这会劳累全没了，反差啊，哈哈！然后第二天中兴移动就让人同学们去签就业意向了，估计很多人都不去。 继续TX，说着觉得诡异了，果然晚上王骆驼进入了三面，我就没了名字。后来想想估计还有一批，我就不相信就这么悄无声息地挂掉了，如果挂掉我真不知道原因在哪里了。晚上跑到公司睡了一觉，好久没来公司了，还有一些工作要做。另外如果还有三面，从这边过去软件园也方便。晚上9点多看到一条短信，估计是来消息了，果真自我感觉还是有点点灵验的，第二天九点三面。三面就更是聊天了，没有经历过群P，不过今天到碰上了类似的问题，例举出三个自己的缺点。呵呵，总不能继续各种老套太过追求完美吧。比较属实的三点：稍微有点害羞，作息时间不怎么好，有时候有些马虎。最后就等消息吧，感觉面试就和聊天一样，聊得好就好。另外根据王骆驼的经历，面试过程中不一定都要马上答出最好的答案，其中的讨论过程很重要，而且可能问题本来没有最好的解法，只能折中。韩sir说：“一般招人技术不是最重要的，应聘者是否是一个口味的很重要“。恩，有道理。 嗄，外面乌云一片，正考虑今天要不要回学校。","tags":[{"name":"Notes","slug":"Notes","permalink":"http://catcoding.me/tags/Notes/"},{"name":"Backup","slug":"Backup","permalink":"http://catcoding.me/tags/Backup/"}]},{"title":"Emacs自虐","date":"2010-08-21T11:43:00.000Z","path":"2010/08/21/emacs-for-fun.html","text":"无意中用了一下C#,发现VS下面有一个功能还是非常好的，就是每次按下回车键盘的时候，都可以把刚刚输入的那行代码自动排版一下， 看起来要清晰一些。比如 int a=0; ==&gt; int a = 0;struct Node p=&amp;node; ==&gt; struct Node p = &amp;node;a+=b; ==&gt; a += b;int p=&amp;a; ==&gt; int p = &amp;a;int a=b+c+d+f; ==&gt; int a = b + c + d + f;for(a=0,b=0;a&lt;10;a++) ==&gt; for(a = 0, b=0; a&lt; 10; a++)if(a==b) ==&gt; if(a == b)if(pbuf!=0) ==&gt; if(a != b)fwrite(buf,1,size,fp); ==&gt; fwrite(buf, 1, size, fp);printf(“%d %s\\n”,len,buf); ==&gt; printf(“%d %s\\n”, len, buf); //引号内的不变，引号外的”,”后面加空格if(p&gt;=allocbuf&amp;&amp;p&lt;buf+size) ==&gt; if(p &gt;= allocbuf &amp;&amp; p &lt; buf + size)return (b!=0)?gcd_ver2(b,a%b):a; ==&gt; return (b != 0) ? gcd_ver2(b, a % b) : a;同时要注意的情况，还有些情况下我不想让符号两边加空格： #include &lt;stdio.h&gt; //&lt; &gt; 两边不加 printf(“%d%d%d\\n”,n,m,k);//这个%两边不加 检测是否在引号内部a++; //不加空格int p; //不加空格return manip(this); //这个两边不加 找到前面或者后面是否为(strcpy(mode,“w+”); //引号里面的不变 检测是否在引号内部我以前写代码习惯都不加空格，感觉不加要写得快一些，可是这不是个很好的习惯。linux下有indent这样的工具，不过是针对于最后完成的源程序来排版。在写程序的过程中像赋值操作符两边加上空格会显得比较清晰，Emacs里面好像还没这么个插件，那我来折腾一下自己写了一个。原来还是比较复杂的。应该好好学学正则表达式，这就是一个正则匹配和替换的过程。呜，括号看得头都晕呼呼的，不过还好，最终有这么一个东西用起来比较顺手了。 首先定一个关键字和替换列表： (setq beautifly-line-list ‘( (“+” . “ + “) (“-“ . “ - “) (“=” . “ = “) (““ . “ “) (“/“ . “ / “) (“%” . “ % “) (“&lt;” . “ &lt; “) (“&gt;” . “ &gt; “) (“,” . “, “) (“+=” . “ += “) (“=” . “ = “) (“/=” . “ /= “) (“%=” . “ %= “) (“==” . “ == “)))一个用来测试dest是否为上面关键字的函数，后面用char-after来获取一个point的字符，对应的是asci码。 (defun test-valid(dest) (interactive) (if(or (equal dest 43) (equal dest 45) (equal dest 42) (equal dest 47) (equal dest 37) (equal dest 62) (equal dest 60)) ;;&lt; t nil)) ;;打印出当前位置的字符 调试用(defun print-pos-char () (interactive) (setq value (char-after (point))) (print value)) ;;从point-pos位置开始 到这一行的尾部，检测是否有”，即检测是否在” “内部(defun test-in-quote (point-pos) (interactive) (move-end-of-line 1) (setq end-pos (point)) (goto-char point-pos) (setq ret-value nil) (if (search-forward “\\”” end-pos t) (setq ret-value t) ) (goto-char point-pos) ret-value) ;;这个函数先调用我的排版函数，然后调用原来的new-line-and-indent(defun my-new-line-and-beautyfly () (interactive) (beautifly-line) (newline-and-indent)) ;;在my-c-mode-common-hook下面加上这么一句，表示把回车键绑定在上面那个函数上。 (define-key c-mode-base-map [(return)] ‘my-new-line-and-beautyfly)下面就剩下这两个函数了，写的太过复杂，可惜不会用高级一点的正则表达式，所以显得不好看。其想法比较简单，按照上面那个列表，一次查找，我要找一个两员操作符，其两边都是空格，在其两边加上空格，注意排除掉++,—操作。然后识别+=,-=,*=等符号，再两边加上空格。用起来还可以。逐渐写了些elisp，感觉特别适合自底向上的方式进行，通过一些小函数，逐步累积成一个功能，再最后只用一个上层函数来调用这个功能。每个小函数除了返回结果不改变函数外的其他变量(无副作用)。同时写一个小的函数可以马上写一个测试函数，保证其正确无误。 最后bueatifly_line的代码有点点长，不贴咯。","tags":[{"name":"Emacs","slug":"Emacs","permalink":"http://catcoding.me/tags/Emacs/"},{"name":"Linux","slug":"Linux","permalink":"http://catcoding.me/tags/Linux/"},{"name":"Backup","slug":"Backup","permalink":"http://catcoding.me/tags/Backup/"}]},{"title":"using automake","date":"2010-08-21T11:43:00.000Z","path":"2010/08/21/using-automake.html","text":"以前都是手写makefile,没使用automake之类的工具,今天看了一些相关资料,简单地总结一下，留个备份。 使用Makefile unix/linux下面使用相当广泛,对于简单一些的程序,手写makefile还是比较容易的,只要指定清目标文件,最后可执行文件的依赖关系。使用一些高级一点的功能更方便,比如下面这个就比较好用,稍微编辑一下就可以用于常用的小工程。这个Makefile把所有.cpp的文件编译成相应的.o文件,然后链接为Targetfile文件。 CC = g++ -O2LD = g++TARGET = TargetfileSOURCES = $(wildcard *.cpp)OBJS = $(patsubst %.cpp,%.o,$(SOURCES)) %.o:%.cpp $(CC) $(CFLAGS) -c $&lt; -o $@ Targetfile:$(OBJS) $(CC) $(OBJS) -lglut -lglui -o Targetfile clean: @/bin/rm *.o 使用automake等工具 1. 首先运行autoscan,这之后会生成一个configure.scan文件,修改为configure.in，并编辑。典型的一个文件如下,AC_CONFIG_SRCDIR,AC_CONFIG_HEADER这两项还不知道干什么用的,如果不注释掉后面automake会出现错误,那就先注释掉吧。重点修改AC_INIT，AC_INIT_AUTOMAKE。AC_CHECK那些不用管,后面提示-lglui提示要注意,这是需要链接的库文件，这里链接glui这个库。 # -- Autoconf --# Process this file with autoconf to produce a configure script. AC_PREREQ(2.61)AC_INIT(TSPdemo, 1.0, moorekang@gamil.com)AM_INIT_AUTOMAKE(TSPdemo, 1.0)#AC_CONFIG_SRCDIR([Elastic_Alg.cpp])#AC_CONFIG_HEADER([config.h]) # Checks for programs.AC_PROG_CXXAC_PROG_CC # Checks for libraries.# FIXME: Replace main&lt;span style=&quot;color: #deb887;&quot;&gt;&#39; with a function in-lglui’:AC_CHECK_LIB([glui], [main])# FIXME: Replace main&lt;span style=&quot;color: #deb887;&quot;&gt;&#39; with a function in-lglut’:AC_CHECK_LIB([glut], [main]) # Checks for header files. AC_HEADER_STDCAC_CHECK_HEADERS([stdlib.h]) # Checks for typedefs, structures, and compiler characteristics.AC_HEADER_STDBOOLAC_C_CONSTAC_C_INLINEAC_TYPE_SIZE_T # Checks for library functions. AC_CHECK_FUNCS([sqrt])#AC_CONFIG_FILES([makefile])AC_OUTPUT(Makefile) 编写Makefile.am,如下面这样。和makefile一样,写上可执行文件依赖于的源文件,_LDADD是要链接的库文件名。AUTOMAKE_OPTIONS=foreignbin_PROGRAMS=TSPdemoTSPdemo_SOURCES= Elastic_Alg.cpp MyMap.cpp mathlib.cpp \\Elastic_Alg.h MyMap.h mathlib.h \\LaoMan.cpp SOM.cpp pointdef.h \\LaoMan.h SOM.h main.cppTSPdemo_LDADD = -lglut 然后执行aclocal,和autoconf，最后automake —add-missing 生成configure文件。这就完成了,下面就是unix下编译安装软件的三个步骤了,./configure，make,makeinstall等。 写得比较粗略,详细查看这个文档。","tags":[{"name":"Linux","slug":"Linux","permalink":"http://catcoding.me/tags/Linux/"},{"name":"Backup","slug":"Backup","permalink":"http://catcoding.me/tags/Backup/"},{"name":"makefile","slug":"makefile","permalink":"http://catcoding.me/tags/makefile/"}]},{"title":"折腾记录","date":"2010-08-20T11:43:00.000Z","path":"2010/08/20/zheteng.html","text":"centos 环境变量 在配服务器web环境的时候，因为这个问题花费了不少时间。tomcat找不到java的其他开发包，开始以为是服务器是64位的问题。最后因为在/etc/profile文件里面设置为export CLASSPATH=…,这个export貌似不能少。或者是因为命令prelink -a的作用起了效果，这个命令好像只是起到加速到作用。orz，我是被ubuntu宠坏了，什么linux命令都没怎么用咯。 mysql mysql配置局域网内都能访问。 1 mysql -h localhost -u root2 mysql&gt;GRANT ALL PRIVILEGES ON . TO ‘root’@‘%’WITH GRANT OPTION3 mysql&gt;FLUSH PRIVILEGES4 mysql&gt;EXIT 这样就可以在其它任何的主机上以root登录，其他用户类似。但是连上以后速度比较慢，在my.cnf文件里面配置一下啊， 把缓存那些改大一些，加上这么一行：skip-name-resolve。 centos 双网卡路由问题 centos能ping通局域网，但是不能上外网，最后查处是因为双网卡到问题，添加一个默认的网关就可以了。使用命令： route add defualt gw 192.168.1.1netstat -nr 查看内核iP路由表。 two or more data types in declaration specifiers C编译器这个错误指向到行会不准确，有一种情况最容易出现这样的错误，那就是在你的程序里少了个”;”号，有可能在你的头文件里，也有可能在本文件中。","tags":[{"name":"Linux","slug":"Linux","permalink":"http://catcoding.me/tags/Linux/"},{"name":"Backup","slug":"Backup","permalink":"http://catcoding.me/tags/Backup/"}]},{"title":"《编程珠玑》：代码优化","date":"2010-08-05T11:43:00.000Z","path":"2010/08/05/programming-peal.html","text":"编程珠玑里面代码优化这一章。问题1 函数,宏，内联代码#define max(a,b) ((a)&gt;(b)? (a):(b))float max(float a,float b){ return a&gt;b? a:b;}inline float max(float a,float b){ return a&gt;b? a:b;}上面这个函数到底哪一个快一些？测试了一下。宏效率是高一点，但是对于加上编译器优化以后基本没什么区别了。 问题2 顺寻搜索 int search1(int v){ for(int i=0;i&lt;N;i++) if(vec[i]==v) return i; return -1;} int search2(int v){ vec[N]=v; int i; for(i=0; ;i++) if(vec[i] == v) break; if(i==N) return -1; return i;} int search3(int v){ vec[N]=v; int i; for(i=0; ;i+=8) { if(vec[i]==v) break; if(vec[i+1]==v) {i+=1; break;} if(vec[i+2]==v) {i+=2; break;} if(vec[i+3]==v) {i+=3; break;} if(vec[i+4]==v) {i+=4; break;} if(vec[i+5]==v) {i+=5; break;} if(vec[i+6]==v) {i+=6; break;} if(vec[i+7]==v) {i+=7; break;} } if(i==N) return -1; return i;} 这三个函数哪一个效率最好？据说第二个提高5%，第三个会提高10%~20%(对于老实计算机)。在我的机子上测试了一下，N=10000000。并不如书上说的能提高多少， 反而最原始的写法在优化后效率更高，确实是这样的数据。 问题三 二分查找 数组大小为1000。 单位ms。 确实第二个版本提高了一些，第四个版本甚至提高了一半的效率。测试是一个麻烦的事情，因为同一时间处理器调度了其他进程，但多次测试还是能给一个大概的印象。第二个例子的优化没起什么作用，也许现在的编译器优 化技术比以前更好的，得出的结果并不如书上所说。在一个算法复杂度确定的情况下改变一些写法会有一点提升，但是对于不同的输入规模也许就得不到什么提高， 而且编译器优化以后基本差别就更小了。为了那么一点效率的 提升增加了代码的复杂度得不偿失。原理那章也说了，不成熟的优化是大量编程的祸害，会危机程序的正确性、功能性、和可维护性。 王道还是改变数据结构或者算法,除非确定一个部分的代码会经常被调用很多次，在这里可以花一些功夫去优化。优化是把双刃剑，玩火者，小心自焚，哈哈。","tags":[{"name":"Books","slug":"Books","permalink":"http://catcoding.me/tags/Books/"}]},{"title":"A*算法与K-shortest path问题","date":"2010-08-02T11:43:00.000Z","path":"2010/08/02/astart-k-shortest-path.html","text":"那天师兄给面试，面到一道图算法题目，求图中两个点的前K短路径。当时觉得用Dijkstra+heap应该可以，不过也没想清楚。以前看到过这个，那时还没怎么仔细看图算法所以丢一边了， 今天好好看了一下。简单一点的解法是用Dijkstra+Astar。典型的题目就是POJ 2449。 A* 算法 再谈A算法。A算法中的评估函数为f(N)=cost(N)+h(N)。其中cost(N)为从源点到N点的距离，h(N)为N点到终点的的一个评估路径长度，设h(N)为实际N点到终点的路径长度。只要满足条件： h(N)&lt;=h(N)，那么用这个评估函数找到最短路径。具体证明看这篇论文A Formal Basis for the Heuristic Determination of Minimum Cost Paths。 其优势在于在选择每个路径 上的点的时候给予了h(N)这个启发，在搜索空间中尽量选择可能最有可能产生最优解的下一个状态，使得搜索的时间都相应地减少。A算法的思想也是贪心 的，Dijkstra是A的一个特例，当h(N)=0时，A*就退化成了Dijkstra算法，那么就是盲目的扩展当前最短路径了。 来个例子，下面这是一个城市的公路图网，一共有18263个点，23874条边，视为无向图。我们知道起点和终点的坐标，现在我们要求某两点之间的最短路径。 1. 用Dijkstra算法来，其中白色的点表示搜索过程中访问了的点。可以看出Dijkstra算法有点像BFS向周围扩展,做了很多无用的搜索。当然这与图的形状也有一定关系。 [Dijkstra 访问18191个点] 2. 用A算法，设S为起点，T为终点，启发函数为F(N)=Path_Dist(S-&gt;N)+Dist(N-&gt;T)。在搜索过程中Path_Dist一直维持着S-&gt;N的路径长度，Disk(N-&gt;T)的计算可以有多钟选择，这里我选择 Dist(N-&gt;T)=sqrt(|Xn-Xt||Xn-Xt|+|Yn-Yt||Yn-Yt|),这个为两点之间的理论最短路径，肯定是满足条件h(N) &lt;= h(N)的，那么能得到最优解。可以看到搜索偏向于目标点的方向。 [A* 两点之间距离为评估函数 访问4398个点] 3. 另外(x+y)/2 &lt;= sqrt(x^2+y^2)，所以也可以选择(|Xn-Xt|+|Yn-Yt|)/2作为启发函数。但为了节省这个sqrt的操作，代价就是访问了更多的点。 [A* (x+y)/2作为启发函数 访问14374个点] 4. 可以做得更好，修改启发函数。Dist(N-&gt;T)=|Xn-Xt|+|Yn-Yt|,这为曼哈顿函数，这样就不满足条件h*(N)&lt;=h(N)了。所以得不到最优解，但是速度上会快很多，搜索的点也会减少很多。 [A* 曼哈顿距离作为启发函数 访问296个点] 大概能得到一个规律，搜索效率依赖于h(N)的启发作用，当h(N) &lt;= h(N)时候，我们能得到最优解，用第二种启发函数能也满足最优解的条件，但是因为启发用少了所以访问了更多的点。当h(N)&gt;h(N)时，得到的可能是比较优的解(非最短路径)，可以认为因为得到的启发更多(多到超出了得到最优解的条件限制)，所以能取得更快的效率。这又是一个普遍的问题，在速度、精确度两者之间经常会只能二选一，对于不同的应用从中作出折中。上面那篇论文证明了，对于刚才举例的这个问题，用两点之间的直线距离最为启发函数的A算法是所有能得到最优解的算法中访问点最少的。启发函数对于特定的问题有特定的取法，那么A*作为一个搜索的算法框架用处还是挺多的。 Dijkstra＋A* 求k短路径 当然这个算法不是我想出来的，这里只是说一下看后自己的理解。在A算法中，优先队列出来的点如果扩展到了终点，那么 就得到了最短路径。如果能得到实际的评估函数(也就是h(N))，那么第二次 从优先队列里面弹出来的就是第2段的路径，依次直到k短。如何得到h(N),就是图中各个点到T的实际最短路径距离，可以从图的反向图以T为源点进行 Dijkstra算法，最后Dist[N]就可以作为h(N)。然后以cnt[N]表示N点从优先队列里面弹出来的次数。K-shortest问题还有更快的解法，不过还没看，这里有大把论文。这里还分结果路径中是否可以有环，像现实中公路网肯定是要求无环的k-shortest path。下面这个算法是可以有环的。 完整代码如下： //7040K 282MS#include &lt;iostream&gt;#include &lt;queue&gt;#include &lt;vector&gt;#include &lt;stdio.h&gt;#include &lt;cstring&gt;using namespace std;const int MAXN=1001;const int INF=(1&lt;&lt;20);int N,M; //N个点 M条边int S,T,K; //起点和终点typedef struct _Edge&#123; int v;//边顶点 int len;//边长度&#125;Edge;int dist[MAXN];int cnt[MAXN];bool mark[MAXN];struct Node&#123; int v,len; Node() &#123;&#125;; Node(int a,int b):v(a),len(b) &#123;&#125;&#125;;bool operator &lt; (const Node&amp; a,const Node&amp; b)&#123; return (a.len+dist[a.v] &gt; b.len+dist[b.v]);&#125;vector&lt;Edge&gt; Adj[MAXN];//图的邻接表表示vector&lt;Edge&gt; Rev[MAXN];//图的逆图void Init_graph()&#123; int u,v,l; Edge edge; scanf(&quot;%d%d&quot;,&amp;N,&amp;M); for(int i=0;i&lt;M;i++) &#123; scanf(&quot;%d%d%d&quot;,&amp;u,&amp;v,&amp;l); edge.v=v; edge.len=l; Adj[u].push_back(edge); edge.v=u; Rev[v].push_back(edge); &#125; scanf(&quot;%d%d%d&quot;,&amp;S,&amp;T,&amp;K);//计算S到T的第K短路径 if(S==T) K++;&#125;//Dijkstra 算法 找出各个点到T的最短距离void Dijkstra()&#123; memset(mark,false,sizeof(mark)); for(int i=1;i&lt;=N;i++) dist[i]=INF; dist[T]=0; int u,v,min; while(1) &#123; u=-1,min=INF; for(int i=1;i&lt;=N;i++) if(!mark[i] &amp;&amp; dist[i]&lt;min) &#123; min=dist[i]; u=i; &#125; if(u==-1) break; mark[u]=true; for(int k=0;k&lt;Rev[u].size();k++) &#123; v=Rev[u][k].v; if(!mark[v] &amp;&amp; dist[v]&gt;dist[u]+Rev[u][k].len) dist[v]=dist[u]+Rev[u][k].len; &#125; &#125;&#125;int Astar()&#123; if(dist[S]==INF) return -1; memset(cnt,0,sizeof(cnt)); priority_queue&lt;Node&gt; Q; Q.push(Node(S,0)); while(!Q.empty()) &#123; int len=Q.top().len; int v=Q.top().v; Q.pop(); cnt[v]++; if(cnt[T]==K) return len; if(cnt[v]&gt;K) continue; for(int i=0;i&lt;Adj[v].size();i++) Q.push(Node(Adj[v][i].v,len+Adj[v][i].len)); &#125; return -1;&#125;int main()&#123; Init_graph(); Dijkstra(); int ans=Astar(); printf(&quot;%d\\n&quot;,ans); return 0;&#125;","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"A* k-shortest","slug":"A-k-shortest","permalink":"http://catcoding.me/tags/A-k-shortest/"}]},{"title":"一个小题目","date":"2010-08-02T11:43:00.000Z","path":"2010/08/02/findsum.html","text":"前些天在班级群里看到一个笔试题： 从1到100000中任意拿掉两个数字，把剩下的99998个数顺序打乱，并且放入数组A中。要求只扫描一遍，把这两个数找出来；可以使用最多不超过5个局部变量，不能使用数组变量，并且不能改变原数组的值。也想不到什么更好的解法，原解法是顺序扫一边求得所有数的乘积(mul_res)、和(sum_res)。用(N!)/mul_res得到两个数的乘积，1到100000的和减去sum_res得到两个数之和。 解这个方程得到两个数。关键是N!太大了，C会溢出。刚开始想想乘积每次模100000，后来写了一下还是不对的，因为模100000中可能就出现了0，后面全为0了。最后想到这么一个办法，不过中间 除法和比较多。也许有更快的解法。 file:///home/heipang/document/wiki/Home_Page/Computer/笔试题.html //1到100 000 #include &lt;iostream&gt; #include &lt;math.h&gt; using namespace std; #define N 100000 typedef long long LL; LL a; LL b; LL vec[N]; int cnt; LL MAX_MUL; void Find(const LL* vec) { int sum=0; LL mul=1; LL Now=1; for(int i=0;i&lt;cnt;i++) { sum+=vec[i]; while(mul%vec[i]!=0) mul*=(++Now); mul/=vec[i]; } while(Now&lt;100000) mul*=(++Now); LL diff=((1+N)*N)/2-sum; cout&lt;&lt;diff&lt;&lt;\" \"&lt;&lt;mul&lt;&lt;endl; LL a=(diff+sqrt(diff*diff-4*mul))/2; cout&lt;&lt;a&lt;&lt;\" \"&lt;&lt;diff-a&lt;&lt;endl; } int main() { srand(time(NULL)); a=(rand()%100000)+1; b=(rand()%100000)+1; cnt=0; for(int i=1;i&lt;=N;i++) { if(i!=a&amp;&amp;i!=b) vec[cnt++]=i; } cout&lt;&lt;a&lt;&lt;\" \"&lt;&lt;b&lt;&lt;\" \"&lt;&lt;endl; cout&lt;&lt;a+b&lt;&lt;\" \"&lt;&lt;a*b&lt;&lt;endl; Find(vec); } ---------------------------------------------------------- 经熊师兄指点，上面的解法还是不对，如果vec前面刚好为比较大的素数，mul就溢出了。正确的解法应该为求x+y=B, x^2+y^2=A, 1-100000的平方和可以用double存下来，然后减去vec里面的平方和就得到x^2+y^2的值。 void Find(const LL* vec) { double sum=0; double square_sum=0; for(int i=0;i&lt;cnt;i++) { sum+=vec[i]; square_sum+=(vec[i]*vec[i]); } double diff=((1+N)*N)/2-sum; double square_sum_diff= ((double)N*(N+1)*(2*(double)N+1))/6 - square_sum; cout&lt;&lt;diff&lt;&lt;\" \"&lt;&lt;square_sum_diff&lt;&lt;endl; a=(2*(diff)+sqrt(8*square_sum_diff-4*diff*diff))/4; cout&lt;&lt;a&lt;&lt;\" \"&lt;&lt;diff-a&lt;&lt;endl; }","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"}]},{"title":"魔法书：SICP","date":"2010-07-27T11:43:00.000Z","path":"2010/07/27/sicp.html","text":"《计算机程序的构造与解释》，SICP。这本书号称魔法书，真的是本非常有趣的书。为什么要看这本书，豆瓣上面有很多推荐，书评写得都很好，在这里。我最初看的是英文版， 在网上很好找到，MIT开源课程的网站上面有很多相关资料。从80年开始MIT就是用这门课程作为计算机的入门课程的(MIT真是个神牛云集的地方,看这个神牛的博客http://blog.vgod.tw/category/divine-code/ ,神乎其乎)，不过 现在这门课程的编程语言换作Python了。所以曾经风靡一时的scheme和Lisp学的用的人就更少了。这最古老的一种编程语言之一 在慢慢要消失，不知那帮做人工智能的还用这个不？关于语言的发展参考这个牛人的一系列博文(http://blog.youxu.info/)。 这本书06年看过一点，不过那时候没怎么看懂,到前两章就没看下去了。大四的暑假进了实验室，怎么就偶然又想好好看看，学校图书馆三楼有这本英文原版的，纸张非常之好，看起来是相当舒服。有中文 版的，不过翻译有时看起来会有点点别扭。大学期间没写过很大的工程，当时也不知道这本书的内容的深度，因为之前一段时间看了Concrete Abstraction 吧，所以看起来没06年那么吃力了。 反正只是觉得好玩，正如书的前言中所说，编程应该是充满艺术性以及美感的。后来又在寝室下了MIT的课程视频，两个老师讲课都非常好，很奇怪那些老师都会用粉笔在黑板上狂写代码，或者是当时在键盘上敲代码，分析来分析去的，反正极少用ppt之类的东西。 国内的大学老师大多是不怎么用粉笔了。总之这本书的内容还是相当广泛，我花了近两个月看了四章多点，慢慢做每章后面的习题,感觉收获不少，函数、算法、面向对象、高阶函数、泛型、并发、流、惰性求值、解释器和编译器、一些编程风格和方式的解释等等。 很多高级语言里面的特性在那里都已经提及过,比如STL里面不就有高阶函数吗，现在的动态语言还支持lambda。理论支撑实现，实现很多内容看起来很高深，不过因为有具体的代码可以实现一下就比较好理解了。 当时看的时候有的地方还是没理解，后来看到一个书评说多年的编程经验才能完全理解其中的内容。虽然现在除了Elisp也很少用函数式语言，但通过看这本书和做习题来让我对编程有了更多的兴趣。以后有时间再好好看看后面两章，因为第五章还没看完。有的题目有些难， 做的时候参考了这个博客(http://eli.thegreenplace.net/)，估计这人是第一个在网上放出SICP绝大部分习题解答的吧，他用的是Lisp。下面的附件是我做习题的代码，不保证全部都正确，如果有错误或者更好的解法请给我指出来(moorekang@gmail.com)。 前面三章用的环境是PLT scheme的集成环境，后面用的是mzscheme，不过应该是没有问题的，我把一些运行结果也放到里面了。sicp(1~4)_exercise","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Books","slug":"Books","permalink":"http://catcoding.me/tags/Books/"},{"name":"Lisp","slug":"Lisp","permalink":"http://catcoding.me/tags/Lisp/"},{"name":"SICP","slug":"SICP","permalink":"http://catcoding.me/tags/SICP/"}]},{"title":"走出迷宫-路径搜索","date":"2010-07-22T11:43:00.000Z","path":"2010/07/22/maze.html","text":"上次把那个迷宫弄出来，然后想了想解法，找了些资料。再把界面上弄了一下，右边迷宫大小，然后有一个选项percent，是代表要推倒的墙占的总百分比，如果数字越小生成的迷宫就越稀疏,有可能有多条 通路从起点到终点,数字大那么生成的迷宫就越密集，但至少有一条通路。 单迷宫解法迷宫第一定律：一般而言，只要在出发点单手摸住一面墙出发，手始终不离开墙面，总可以找到迷宫的出口。对于单迷宫而言，这一种万能的破解方法，即沿着某一面墙壁走。 或者换句话说，你在走的时候，左（右）手一直摸着左（右）边的墙壁，这种方法可能费时最长，也可能会使你走遍迷宫的每一个角落和每一条死路，但你绝不会永远困在里面。 直觉上好像是可以，实现一下也确实能找到终点的，也就是靠着墙，一直靠左或者一直靠右。实现的时候甚至都不用记录哪些点已经访问过了，哪些点还没访问过。 这也是一种人能来做的算法，毕竟人不可能像计算机一样dfs、bfs。 BFS用BFS肯定也是可以的，如果是单路径的迷宫，用BFS实在是太慢了,它会把大部分的点都遍历一边。感觉就像是一颗石子掉到水中，要找岸边的终点那得等波纹波及到岸边。 非常之慢。但如果是有多条通路的迷宫，BFS是能保证找到最短路径的。也许双向BFS会好一点，不过猜想对于单迷宫，也提高不了多少。 DFS那用DFS也是可以的。不过效率还是很差，像苍蝇一般在迷宫的各个角落转悠，直到大部分点都遍历了。稍微改变一下DFS优先搜索的方向会有一些提高，比如我这个图优先走下方或者优先走左方。 AA是一种启发式搜索算法，在这里我用点与点的曼哈顿距离来作为启发函数，效果不好，因为曼哈顿距离也就大概的告诉了搜索路径现在应该往哪个方向走比较好。不过总得来说 这么一点启发得到的效果还是要比BFS和DFS要好些。评估函数选择合适也是能找到最短路径的，曼哈顿是可以的。如果墙比较稀疏(肯定有多条路径)，那么A*算法会快得许多。 用键盘走呵呵，对于小点的迷宫用键盘来移动可以比较快解决，人是有直觉和经验的，在合适复杂度上面这种直觉给的启发可比上面好，但是如果迷宫太大了就不行咯。或者还有其他算法去走出迷宫么？","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"迷宫","slug":"迷宫","permalink":"http://catcoding.me/tags/%E8%BF%B7%E5%AE%AB/"},{"name":"路径搜索","slug":"路径搜索","permalink":"http://catcoding.me/tags/%E8%B7%AF%E5%BE%84%E6%90%9C%E7%B4%A2/"}]},{"title":"《C深度探索》笔记","date":"2010-07-20T11:43:00.000Z","path":"2010/07/20/c-deep.html","text":"最名不副实的关键字 static这个关键字在C语言里面有两个作用，C++对这个关键词进行了扩展。1：修饰变量，又分为局部变量和全局变量，被修饰的变量都存储在静态的内存区域。 修饰静态变量，那么只有在这个文件内可以引用它，在其他文件里面即使使用extern也不能进行访问。所以一般是放在文件头部分。 修饰局部变量，只有在定义的函数内访问，函数外不能访问，即使是在同文件内。2：修饰函数，在函数前面添加static，那么这个函数只能在该文件内使用。这样，不同人编写的函数，如果不在同文件内，可以不用担心函数名字 相同。main.cint main()&#123; Func(); reutrn 0;&#125;Def.cstatic void Func()&#123; printf(&quot;Func called\\n&quot;);&#125;编译: gcc main.c Def.c -o main 链接错误变量的命名min-length&amp;&amp;max-information低精度数据向高精度数据扩展。被冤枉的关键字 sizeof 用法：sizeof(int), sizeof(i), sizeof i;if ,else float类型值与0值比较，定义一个很小的数，在某个范围内。同时不要在一个很大的浮点数和很小的浮点数之间进行运算。循环注意点嵌套循环中，长循环放在内，短循环放在外面，这样可以减少cpu跨切循环层的次数，利用cpu cache。 循环里面的代码尽量短，一般不超过20行。如果不行就改为循环调用函数。void主要作用在于对函数参数的限定和函数返回值的限定。不能对void进行算法操作。const修饰指针的时候的记法，就近原则。 const int p ; p可变，指向的对象不可变 int const p ; p可变，指向的对象不可变 int* const p; p不可变，指向的对象可变struct 和class的区别在C++中struct关键字与class一般可以通用，一个区别就是struct的成员默认情况下是public的，而class的是private的。union一个union只配置一个足够大的空间来容纳最大的数据成员，union的作用在于压缩空间。存储的大小端：union&#123; int i; char a[2];&#125;*p,u;int main()&#123; p=&amp;amp;u; p-&amp;gt;a[0]=0x39; p-&amp;gt;a[1]=0x38; printf(&quot;%d\\n&quot;,p-&amp;gt;i); PrintBinary(14393); PrintBinary(56); PrintBinary(57); if(CheckSystem()==1) printf(&quot;Little endian\\n&quot;); else printf(&quot;Big endian\\n&quot;); return 0;&#125;11100000111001111000111001Little endian 低字节存储在低地址指针，访问内存的钥匙前段时间听过一个面试题，就是如何读写某人地址，答案就是指针？#include &lt;stdio.h&gt;int main()&#123; int i=0; int pp=&amp;i; printf(&quot;%x\\n&quot;,pp); int p=(int)0x12ff60; printf(&quot;%x\\n&quot;,p); *p=1; printf(&quot;%d\\n&quot;,i); getchar(); return 0;&#125;这段代码在vc中编译是能够运行的，但是在gcc中不行，gcc中编译后i的地址并不是固定的，这样直接给指针赋值，写指向的地址出现访问越界。a和&amp;a的区别 int main()&#123; int a[5]=&#123;1,2,3,4,5&#125;; int* ptr=(int*)(&amp;amp;a+1); int* p=(int*)(&amp;amp;a); printf(&quot;%x\\n&quot;,ptr); printf(&quot;%x\\n&quot;,p); printf(&quot;%d,%d\\n&quot;,*(a+1),*(ptr-1)); return 0;&#125; bfeae860 bfeae84c 2,5 说明ptr和a的地址相差5*4=20个byte。 定义数组int a5; a表示的是数组中首元素的地址，&amp;a才是数组的首地址，两者的值是一样的，但是意义却不同。 数组当作函数参数传递传递的是指针，也就是数组的地址，但注意如果把指针本身传递进函数的时候进行了数组的拷贝，传递的是一个拷贝。 void func(char* p)&#123; char c=p[3]; *(p+3)=&#x27;X&#x27;; printf(&quot;%c\\n&quot;,c);&#125;int main()&#123; //char* p=&quot;abcdef&quot;; char p[]=&quot;abcdefg&quot;; func(p); printf(&quot;%s\\n&quot;,p); return 0;&#125; 注意上面的区别，如果是char* p=”abcdef”，那么p为main函数的局部变量，”abcdef”的存储空间在静态内存中，func函数中可以通过指针p去访问其内容， 但如果改变其内容会发生访问越界。而char p[]=”abcdefg”，其数组的内容是在栈上。 内存管理静态区:保存自动全局变量和 static 变量(包括 static 全局和局部变量)。静态区的内容 在总个程序的生命周期内都存在,由编译器在编译的时候分配。 栈(堆栈):保存局部变量。栈上的内容只在函数的范围内存在,当函数运行结束,这些内容 也会自动被销毁。其特点是效率高,但空间大小有限。 堆:由 malloc 系列函数或 new 操作符分配的内存。其生命周期由 free 或 delete 决定。 在没有释放之前一直存在,直到程序结束。其特点是使用灵活,空间比较大,但容易出错。","tags":[{"name":"C","slug":"C","permalink":"http://catcoding.me/tags/C/"},{"name":"Books","slug":"Books","permalink":"http://catcoding.me/tags/Books/"}]},{"title":"《Concrete Abstractions》的一些解答","date":"2010-07-20T11:43:00.000Z","path":"2010/07/20/concrete-abstractions.html","text":"这本书名中文名字叫什么呢，有本《具体数学》，那么这本书“具体抽象”，矛盾了。副标题是An Introduction to Computer Science Using Scheme。可以看出这是本引论性质的计算机理论书籍。《冒号课堂》里面说过，编程中最重要的能力是抽象的能力，这本书也在培养这么一种能力，并且能代 码实现去辅助说明。这本书是美国一个大学用的一本教材(具体哪个忘记了，可以到书的主页上去看看),貌似很多大学都使用scheme作为第一门程序设计语 言，历史悠久，属于Lisp变种。像这种函数式语言虽然效率不是很高，但是语法简单，而且功能强大，支持多种程序设计方法。在这里程序就是数据，数据就是 程序，在sicp中一段不长的scheme代码就能成为一个scheme解释器。Scheme很简单，和下棋一样，人们能很快就学会其语法，这里有个很好 的教程t-y-scheme。 貌似以前美国很多大学都是用这个作为第一门程序设计语言来教学，现在用Python的更多了，函数式语言还是在渐渐被遗忘。作为引论性质的课程，广度和高 度都达到一定程度，甚至让学生站了语言设计者的角度去思考问题。其中的主线是：过程抽象，数据抽象，和状态抽象。内容涉及:递归和推导，迭代，高阶函数， 数据结构，泛型操作，实现程序设计语言，动态规划，面向对象范型等等。SICP包含这些内容，并且思想上更深入。所以先大概看看这本书对于阅读SICP(《计算机程序的构造和解释》)有很大的帮助。大学的时候看到第五章，做了其中大部分习题，有些题目很有启发。我大四的时候做的1~5章的练习题。在这里下载。不保证所有的解法都是正确并最好的，网上这本书的相关资料比较少，而SICP的解答到是有比较多可以参考。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Scheme","slug":"Scheme","permalink":"http://catcoding.me/tags/Scheme/"}]},{"title":"指针指针","date":"2010-07-20T11:43:00.000Z","path":"2010/07/20/pointerbug.html","text":"今天由一个函数加深了对指针的理解，是这么一个函数： void BST_Delete(BITREE y) //删除节点y&#123; if (y-&gt;lch==NULL &amp;&amp; y-&gt;rch==NULL &amp;&amp; y-&gt;p) &#123; if(y==(y-&gt;p)-&gt;lch) (y-&gt;p)-&gt;lch=NULL; else (y-&gt;p)-&gt;rch=NULL; &#125; else if (y-&gt;rch==NULL &amp;&amp; y-&gt;p) &#123; if(y==y-&gt;p-&gt;lch) y-&gt;p-&gt;lch=y-&gt;lch; else y-&gt;p-&gt;rch=y-&gt;lch; &#125; else if (y-&gt;lch==NULL &amp;&amp; y-&gt;p)&#123; if(y==y-&gt;p-&gt;lch) y-&gt;p-&gt;lch=y-&gt;rch; else y-&gt;p-&gt;rch=y-&gt;rch; &#125; else &#123; BITREE t=BST_Successor(y); y-&gt;data=t-&gt;data; BST_Delete(t); y=t;//y=NULL &#125; free(y);&#125; 在最后一个else内，如果二叉搜索树中有左右孩子，那么找这个删除节点的后继，把内容互换，然后删除后继 节点，因为后继节点一定只有一个孩子或者没有孩子。最后只有一个free()操作其实是为了代码简洁,可以把前面每一个else if后面加一个free， 最后不写free()操作。但是这么写运行起来会有问题，y=t,就是所指向的地址相同，但是因为是 递归操作，t指向的地址在调用BST_Delete(t)的时候已经被free掉了，所以如果再删除一次就会 出现内存错误，修改方法是y=NULL,或者修改函数参数，用指针引用的形式 void BST_Delete( BITREE&amp; y)，然后再在free(y)后面增加一句y=NULL。以前以为两次调用free(p)是不会出现问题的，free()在释放掉p指向的内存以后，会 自动将p赋值为NULL，其实没有这部分操作。 前些天还看到一个面试题目，malloc申请的空间用delete删除会有什么问题？一般来说没有问题， 内存会释放掉，而且即使是有析构函数的对象指针，用delete删除的时候同样会调用析构函数。这说明 c++的delete操作其实是在c的基础增加了一些操作，先调用析构函数，然后释放空间。良好的编程风格 就是free/malloc，new/delete一一对应，甚至不要出现一次调用，多次释放，像上面那样的因为递归 而产生的多次释放并不是很好发现","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"C","slug":"C","permalink":"http://catcoding.me/tags/C/"}]},{"title":"The Game of Life","date":"2010-07-20T11:43:00.000Z","path":"2010/07/20/the-game-of-life.html","text":"简介 Game of Life是Princeton的一个数学家发明的游戏，这个不像一般的小游戏，有胜负，这只是一个规则很简单的模拟游戏， 规则很简单，但是过程和结果都很有趣，大三时看到一个同学实现过，去年无聊时也写了个实现，挺好玩的，最后形成的图案很有趣。 rule平面中的一个小方格分为生和死的状态，规则是： 如果一个死的细胞周围有三个细胞是活的，在下一轮中这个位置出现一个活的细胞。 如果一个活的细胞周围有两个或者三个活的细胞，在下一轮中或者，否则下轮中该细胞死掉。 其他情况该位置维持不变。这里的 周围 是指一个方格的周围8个位置。 规则很简单，结果也很完美，甚至是符合现实世界中生命的生死规律，一个群种只有在保持平衡的状态下才能实现良性循环。 不可能有一种初始状态使得活着的细胞数量一直增加,如果你找到一种，可以向原作者所要一笔钱，哈哈。不管初始状态如何，真个世界在经过一段时间的演变之后都会逐渐稳定下来。稳定的状态有很多中，分为静止的和“颤抖”的。 另外发现一些的简单规律：并不是初始或者的数目越多最后或者的数目就越多，测试表明初始或者的数目为总量的一半的时候活着的比较多。 还有很多规律在其主页上可以找到。 实现我这个是Linux下OpenGL实现的，红色代表死的细胞，蓝色代表活着的细胞，稳定以后世界","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Life Game","slug":"Life-Game","permalink":"http://catcoding.me/tags/Life-Game/"}]},{"title":"迷宫生成算法–并查集","date":"2010-07-20T11:43:00.000Z","path":"2010/07/20/union-set-maze.html","text":"好书好书 在看《数据结构与算法分析》这本书的时候看到后面的一个关于并查集的有趣应用，是个生成迷宫的算法，看起来非常有趣，所以就实现了一下。顺便把几种走迷宫的算法都整了 进去。八卦一下，这本书的作者是Mark Weiss,这牛写了几本数据结构和算法的书，各种语言版本(C,C++,Java)，原来是师出名门啊，在他的主页上一看，原来是Robert Sedgewick 的学生。Sedgewick更是师出名门，在Princeton跟高纳德神牛读的博士，也写了N本算法和数据结构的书。这两人写的书都还不错，对于初学者和中等水平来说很好，覆盖了一般的数据结构和算法，同时带有一定的理论分析还有特定的语言实现。 并查集 可能一般的大学教材上面没有说这个数据结构，这是个很有趣的东西。《算法导论》上面用这个来作为均摊分析的例子吧。在ACM/ICPC中这个数据结构经常出现，有可能是一个小题 （难点的就是要维护节点之间关系的那种），或者是有的图论算法中实现要用,比如实现Kruskar算法求最小生成树。并查集本身比较简单，主要是用来操作元素集合，支持的操作有： UnionSets(int root1,int root2), 用来合并两个根节点。 FindSet(int x) , 用来查找x所属的根节点。 一并一查，所以叫作并查集。实现时候可以通过按秩合并(union by rank)，和路径压缩(path compression)来增加效率，可以获得几乎与总操作数m成线性关系的运行时间。 int rank[MAXSIZE]; // 节点高度的上界int parent[MAXSIZE]; // 根节点void Init(void)&#123; memset(rank, 0, sizeof(rank)); for(int i=0; i &lt; MAXSIZE; ++i ) parent[i] = i;&#125;int FindSet(int x)&#123;// 查找+递归的路径压缩 if( x != parent[x] ) parent[x] = FindSet(parent[x]); return parent[x];&#125;​void UnionSet(int root1, int root2)&#123; int x = FindSet(root1), y = FindSet(root2); if( x == y ) return ; if( rank[x] &gt; rank[y] ) parent[y] = x; else&#123; parent[x] = y; if( rank[x] == rank[y] ) ++rank[y]; &#125;&#125; 迷宫的实现 上面那本书上的习题上给了提示，比如首先所有的墙都没有去掉，那么是一个一个的方格，每一个方格为并查集合的一个元素，已经连通的元素是在并查集的一个集合中，有相同的根节点。 随机的选择一个墙，在并查集中查询这两个元素是否已经连通，如果已经连通则另选一个墙，如果不连通，union两个节点的根节点，这样操作以后这两个方格已经连通。继续上面的操作， 直到入口和出口连通位置，那么这就形成了一个只有一条合法路径的迷宫，称为单迷宫。如下图所示。 左上角起点 右下角终点","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"迷宫","slug":"迷宫","permalink":"http://catcoding.me/tags/%E8%BF%B7%E5%AE%AB/"}]},{"title":"Emacs: keyboard macros","date":"2010-07-17T11:43:00.000Z","path":"2010/07/17/emacs-keyboard-macros.html","text":"宏编辑以前知道Emacs有一个keyboard macros，不过一直没认真看一下，今天算是粗略懂了一些。宏编辑很早就有了，很多编辑器都有这种功能，word好像是有的，不过没用过，格式刷算宏编辑不？甚至Emacs 的起名有一种说法就是 Edit MACroS，最初是作为一个叫作TECO编辑器上的一套宏而编写，然后就是重写了N次，现在Emacs上还有个模拟TECO的模式：）。kbd macros就是把一系列要做的动作集合成一个，然后可以执行多次。以前有时在网上拷贝代码，但是前面都加有行好，不编辑一下不能编译，这种情况 就可以用这个kbd macro一下就解决了。 先来一个例子，比如说有这么一段文字：Newton, IsaacEinstein, AlbertMaxwell, JamesTuring, Alan…现在要变成这个样子Isaac NewtonJames MaxwellAlan Turing…在Emacs下可以执行下面一系列快捷键来处理一行。如果行数不多，那么敲几下键盘就可以了，如果是很多行呢，总不可能一直这样用手动的吧。上次遇到那个几百行的代码，每 行前面都有一个表示行数目的数字，一狠心写了个C程序来处理，囧。为了不让手指报废，定义一个kbd macro是很快速的方法。也就是在我处理的一行的之前按F3(或者”C-x (“ ),在处理第一行的时候Emacs已经在记录这即个命令，结束完一行的处理就可以按F4(或者”C-x )”。这样就已经完成了定义。使用宏 定义好以后下面的很多行都可以使用这个宏去操作，只要按C-x e就是执行上一次定义的宏，C-u 20 C-x e执行20次，甚至可以选中一个区域然后执行M-x apply-macro-to-region-lines (或者 C-x C-k r)。但这个时候宏里面别加go-to-the-next-line，因为上面这个命令就已经是逐渐移动区域的每一行，执行上面的宏，如果再加goto命 令就会跳过一些行。另外还可以手动编辑这个宏，命令M-x edit-kbd-macro，会让你选择要编辑的宏，比如说选刚才保存的那个宏，得到： ;; Keyboard Macro Editor. Press C-c C-c to finish; press C-x k RET to cancel.;; Original keys: C-a M-d 2*C-d C-e SPC C-y C-nCommand: last-kbd-macroKey: noneMacro:C-a ;; move-beginning-of-lineM-d ;; kill-word2*C-d ;; delete-charC-e ;; move-end-of-lineSPC ;; self-insert-commandC-y ;; yankC-n ;; next-line 编辑完后按C-c C-c完成。 如果这个操作经常会用到(比如清楚带行号的代码)，还可以把这个操作保存下来，以后都可以用。在.emacs或者自己的配置文件中增加: (fset &#x27;foo [?\\C-a ?\\M-d delete delete ?\\C-e ? ?\\C-y ?\\C-n])","tags":[{"name":"Emacs","slug":"Emacs","permalink":"http://catcoding.me/tags/Emacs/"}]},{"title":"胡乱想想","date":"2010-07-15T11:43:00.000Z","path":"2010/07/15/thinking.html","text":"哈哈，终于还是弄了独立空间，yo2还在崩溃中，没前的还没转过来。新的空间速度不错，服务也可以，可是在教育网内不能访问，算了，教育网内能访问的就那么几个。中午下了场雨，可还是很闷，下午在看《The Practice of Programming》，不错的书。两天没去实验室了，那里闷得慌。这个月还是打算在学校待着，8月份回家一趟。昨天一个校友从上海回来，大家一起聊了会，对他们那公司挺感兴趣的，准备有机会去面试一下。这些天经常睡不着，睡着也做梦。我就是这样，在生活的链接点比较焦虑，比如说升学时，这会是找工作了。一些朋友会说，你那么当心干什么，找份工作应该不难，况且你又平常又不是懒人，还是学了点东西的。呵呵，我是天生有点悲观吧，总会忍不住去想结果。这会倒比较轻松，工作有好坏之分么，适合自己的工作才是最好的吧，做自己想做的领域才会有激情，现在工作的愿望比两年前强多了。同时我也比较能看得到自己的弱点。我很清楚自己不是想搞科研，可能也不是很适合。对于写论文，我更倾向于写代码。我不适合做市场，同人打交道好像要比同机器打交道要难。我不适合做管理，尽管有时候想改变自己的一些性格特点，现在回想起来勉强自己做的那些并没什么好的效果。总之，既然想搞所谓的挨踢行业，想走技术路线，那还是好好的坚持吧，The lyf so short, the craft so long to lerne.. 在学校还能好好看看想看的书，以后就是MOP了，珍惜珍惜！控制自己的思绪和情绪是件比较重要的事情，“憩于理性，行于热情”这是我所期望的，抓紧时间好好享受这段最后的单调的校园生活。面包会有的，哼哈。","tags":[{"name":"Notes","slug":"Notes","permalink":"http://catcoding.me/tags/Notes/"}]},{"title":"Hello world!","date":"2010-07-13T11:43:00.000Z","path":"2010/07/13/hello-world.html","text":"欢迎使用 WordPress 。这是系统自动生成的演示文章。编辑或者删除它，开始您的博客！","tags":[{"name":"Notes","slug":"Notes","permalink":"http://catcoding.me/tags/Notes/"}]}]