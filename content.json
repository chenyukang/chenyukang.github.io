[{"title":"我如何学“会”了 Rust","date":"2022-04-21T12:35:06.000Z","path":"p/my-experience-learning-rust/","text":"最近我打算把自己的小项目 Obweb 后端重新用 JavaScript 重写，之前这个项目的后端是用 Rust 写的。 重写基于以下考虑： Rust 受众少，和 Obsidian 的用户群体重合的就更少了 Rust 开发 Web 后端确实不便，虽然我也看过其他的 Rust Web Framework，但看起来都还不太成熟 在使用 Warp 的过程中有很多坑，而且代码看起来异常复杂 Web 开发这块 JavaScript 有很多现成的库 这个项目比较简单，性能不敏感，使用 Nodejs 也不会有大的差异 我想写写 JavaScript 当初用 Rust 也只是为了练手，今天聊聊自己如何跟进这门小众而、难学的编程语言，顺便谈谈这些年我对 Rust 的一些感受。 我最早关注到 Rust 是 2014 年，当时还没发布 1.0 ，但是核心的概念和设计理念已经定了，那就是不走 GC，通过编译器保证类型和内存安全，兼顾性能和安全。 接触没多久后我试着实现一个简单的 scheme 解释器，所以我就开始写这个小项目 rust-scm 。 这种几百行的项目就能很好的上手一门编程语言，因为在这个过程中会涉及输入输出、递归、测试，抽象方式等。 当时我觉得 Rust 用起来还行，但是有些部分很复杂，比如指针还有 Borrow checker，另外当然最大的问题是第三方库太少了。 那时还有一个印度程序员 ckkashyap 开了一个坑，用 Rust 写一个 Unix-like 的操作系统 rustix: Unix kernel in rust ，我看有点意思就跟着做了几个 PR。没多久他就弃坑了，转去搞一门更小众的编程语言 Nim，打算重新用 Nim 实现 xv6 nim-xv6: Translate xv6 to nim 。不过我们一直保持联系，有时候在 gtalk 上聊聊。他工作了大概有 20 年，非常喜欢折腾。后来他换工作去了微软，然后随后几年我也去了微软。最近他给我发邮件说又开了新坑 lispware/minilisp ，一起来搞啊，哈哈，我们这些 Polyglot Programmer 就是这么容易见异思迁。 后来几年我也没太关注 Rust 了，只是偶尔看看官方的一些文章之类的。在这期间国内的数据库公司 PingCap 发展起来了，国内也出现了一些 Rust 语言爱好者。 中间这些年，我有时会在 https://exercism.org 上写写简单的练习，这些上面的编程题不是算法，而是一些典型的编程挑战，包含测试用例，非常适合用来练手在学的语言。 这个网站更好的地方在于里面有一些各个语言的爱好者当导师，你可以选择让他们 review 你的代码，这样就可以从经验丰富的导师那里学一门语言的最佳实践： 最近一年我重新关注 Rust，发现热度比之前好多了，Github 上不少项目都在用 Rust 写 (当然也可能是我自己之前关注了一些开发者，他们继续在折腾)，相关的生态和工具链也发展起来了，比如 rust-analyzer 加上 VSCode 的开发体验非常好，比如 Cargo 管理包很好用。我关注到 Rust 在区块链和 WebAssembly 两个领域发展得不错。 回顾起来发现 2021 年我参与的几个项目都和 Rust 相关： gomoku containers/youki: A container runtime written in Rust wasmerio/wasmer: WebAssembly Runtime second-state/dapr-wasm 可以说我学会了 Rust，可以自己写些小项目，能在 Rust 的中大型项目中做贡献，也对 Rust 本身做贡献，但是我对一些语言细节不太清楚，比如我做 Rust Quiz 发现好多都做不出来。事实上 Rust 因为走了一条独特的路线，导致语言本身也就比较复杂。 我的学习方法就是时不时地开个坑练手，或者去参与到一些比较活跃的开源项目中。我买了一本中文版本的 Rust 书，但是感觉没时间和耐心看完。 对于大部分开发任务，我们没有必要掌握一门编程语言的所有细节。好办法是花尽量少的时间去掌握日常开发所需要的 80%，而不是花 80 % 时间去掌握平时比较少见的 20%。我觉得对于 Rust 来说，20% 包括宏、Unsafe，还有一些复杂的 Pointer、Pin 之类的东西，这些需要了解的时候再去看看就行。 前几天看到 geekplux 写的我是如何学会编程的 有类似的概括： 编程只是一个工具，学习一门技术的时候要快速掌握其最核心的部分，抛弃细枝末节，直接动手实现目标，中途遇到不会的再 Google 即可。这样才是高效快速的学习方式。 学会这个思维的好处是，我后来学什么都特别快，自我总结出一套学习方法。但坏处是知识点掌握的不牢靠，很多细节需要现学现卖，这在日常编程中好像没什么影响，随手 Google 随手写，但面试就很差了，毕竟面试是通过考察细碎的知识点来衡量你的知识面（我不苟同这个面试方式，但确实是现在最流行的）。 学习新东西从来不是线性的，所以如果你看某个人给出了一个最佳的学习路径，比如看完某本书，然后再看另外一本更深入的，然后再买个什么课…. 这种路线也许可以参考，但也别太当真，学会了的标准肯定是能拿来应用。我认为绝大部分书没有官方的文档更有价值，大部分课程还没有直接从开源项目中学习更有效。 所以我建议不管是新手还是老鸟，要学一门新技术就去看官方文档，然后自己做些小项目，如果还想继续深入就做一些更大的项目，或是参与到开源项目中去。 通常是技术不难学，但是领域知识比较难学，因为要实践某些领域知识需要相关环境和工作内容。 好了，以上乱扯写了一篇。2022 我打算好好学一下 JavaScript 😉","tags":[{"name":"编程","slug":"编程","permalink":"http://catcoding.me/tags/%E7%BC%96%E7%A8%8B/"}]},{"title":"理想中的开发者","date":"2022-04-15T18:07:05.000Z","path":"p/weekly-9/","text":"我每周会分享一下这周看到的好内容，加上自己的一些个人理解和评注，这算是一种比较轻的持续输出方式，前三期为： #6 创造者和实施者 #7 无聊的技术栈 #8 Valve，另一种公司 这是第 9 期。 理想中的开发者状态你理想中的开发者状态是什么样的？ 肯定不是无尽的会议和摧残的 996。 看到这位日本开发者的视频之后，我觉得这就是理想中的开发者状态。 这位独立开发者花了 6 年时间做了一个面向开发人员的 Markdown 编辑器，这里有个产品介绍视频： How to take notes in Markdown efficiently with Inkdrop 老实说，我已经找到了适合自己的 Markdown 编辑工具，但是我还是被他的视频深深吸引，忍不住试试他的产品。 他的视频里都没有说一句话，都是通过键盘敲打声音带出字幕，画面从东京街头随拍一直切换到自己临时租的小屋，整整 40 分钟他就在那里默默地使用自己的编辑器，偶尔伸个懒腰或者抿口茶，背景音就是一些好听的键盘声和轻音乐。 这太独特了！我们可以通过视频感受到他对自己产品的执着、自豪、和品味。 然后我接着看他其他的视频： How to build a portfolio website using Next.js, Chakra UI, Framer Motion, and Three.js How I built a software agency website with Next.js and Tailwind CSS 里面有从头到尾展示如何做一个好看的主页，跑到深山老林依着山涧泉水给朋友做网站，我想这大概就是程序员界的李子柒吧，他拍出了我理想中的开发者状态。 现实中独立开发者其实很苦，刚好我这周看到个 v2ex 上关于独立开发者的讨论，个人开发者处境是否越来越困难了 ，大家在诉苦国内 Andriod 独立开发者要上线一个产品越来越难。 这里还有些大环境的原因，这个年代已经是存量时代，几乎任何一个领域都存在多个竞品，用户似乎不缺少软件，问题是用户为什么要选择你的产品。 而作为个人开发者除了能写代码，还需要会营销和宣传，比如上面那位日本开发者的手法，品位、情怀、故事，这些都是代码之外的事，但在这个存量年代这些就很重要。 Generative Art这周我不经意间看了一些 Generative Art 相关的东西。 在我的 Ob 里一直收藏着这个介绍傅里叶的网页地址：傅里叶变换交互式入门 。这个文章写得很好，已经被翻译成多国语言，非常生动地解释了傅里叶变换是如何工作的。网页上看到的动画都是通过纯 JavaScript 在 Canvas 上画出来，所有代码都是开源的。 然后我又在 B 站看到 AnthonyFu 介绍如何实现梅花的动画，用 Canvas 做梅花生长动画 。 我之前看他的个人主页时也注意到了背景里的那个图画效果。他这在视频里介绍这也是递归的一个实现，只是中间加了一些随机性，比如长度、角度上的随机。 这两个都算是 Code Generative Art 的例子，我们通过这个关键词去搜能找到很多类似、好玩的东西。 这篇文章 Generative Art: 50 Best Examples, Tools &amp; Artists 非常全面地介绍了这个主题。 “What I enjoy the most is the complex and intricate results you can get from a set of simple rules.” — Anders Hoff 想起来我在学校的时候也做过一些简陋的类似东西，比如我这个迷宫生成器: 动画和可视化都能给观众深刻的印象，简单的规则加上随机性就能做出很多精妙的东西。 学习 ContainerLearning Containers From The Bottom Up 作者写了很多 Container 相关的文章，质量都非常高。我对这些有兴趣，打算以后如果有时间也写写这个系列。 如果要学习 Container 的原理和内部实现，不一定要盯着 runc，可以看看后来一个红帽员工用 C 实现的 crun，A fast and lightweight fully featured OCI runtime and C library for running containers 。 我参与的这个项目：Rust 实现容器 containers/youki，里面很多都是参考的 crun 的。C 代码其实比 Go、Rust 都精简。 这就是本周的分享了。 我本来打算这周离开苏州回老家待着，结果因为疫情的变化，我不敢去车站了，所以继续宅在苏州等等看吧。 大家保重！😷","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"},{"name":"周刊","slug":"周刊","permalink":"http://catcoding.me/tags/%E5%91%A8%E5%88%8A/"}]},{"title":"成为 UP 主","date":"2022-04-13T18:09:59.000Z","path":"p/be-a-creator/","text":"上周我录制了一个视频分享在 B 站，程序员使用 Obsidian 的经验 。 这算是我践行多元发展的一个尝试吧，看起来作为 UP 主我取得了一个好开头，视频发布三天已经有三千多的观看记录，播放量超过了自己公众号文章的阅读量，而且这是一个 28 分钟的视频，可比看一篇文章的几分钟要长多了。 和大家分享一下过程和收获，算是 BTS。 先谈谈动机，上次我写了一篇文章 我的 Obsidian 使用经验 ，感觉文字在这种需要演示的场景下显得无力，因此萌发了做视频的想法。 我看过一些 Obsidian 相关的视频，有的讲解得很棒，剪辑得也很好，但太多是关于 Ob 产品的介绍、插件介绍和使用，我想看的是真实的笔记场景和流程，而且我自己总结出来的这套流程好像没有人提及过。 所以我就开干了。 前期选择和试用各种录屏工具，我总共花了大概两个小时，最后的选择是 Open Broadcaster Software 。其他我觉得也不错的备选是 Zoom 和 B 站的必剪，以后我再试试。 录制的整个过程花了差不多一个小时，因为我没有经验，首次录制完了之后才发现没声音，然后又重新录制了一遍。 当然还是有诸多不满意，但我已经比较累了，我想这次就先这样吧，于是立刻发布了。随后我去 v2ex 发了个帖子宣传了一下，B 站的流量很不错，因为我发的帖子点击才 1400 多，那最终点进去看的也不到 1000 左右？所以后续的观看应该基本是 B 站本身的流量积累起来的 看数据统计时发现我的粉丝 100 % 男性，25 岁以下和 40 岁以上居多，难道就没有对 Ob 感兴趣的女生🤣? 另外 B 站果然是学习的好地方，通常都是深夜开始学习。 通过第一次实践我学到了： 不用力求完美，因为作为新手第一次就力求完美，会导致耗费太大力气，从而产生抗拒心理。如果第一次视频比较快完成，而且我也知道了一些明显的改进点，就会想着赶紧下次实践。 宣传，如果我没有在 V 站发帖，肯定是没有这么多人看的。这个朴实策略我之前也提到过：找到自己的目标受众，尽量创造出好的内容。 自信，我和大多数技术人一样，不擅长演讲。但这种录视频可以很好地规避公开演说的紧张和压力，我们可以反复练习，也可以后期修改，所以做视频分享其实适合我这种内向型的人。我也怕在录音中听到自己的声音，不太好解释这种心理，反正就是感觉不真实或者和自己想象中的不一样。这次录完后我认真听了一遍，发现普通话确实不太标准，另外有时候稍显啰嗦。但我觉得内容大于形式吧，真实也是一种特色。 创作者心态，当自己试着写些文章、做视频之后，会发现不自觉就抱有一种创作者心态，再去看文章、视频时会去关注一些很细的问题，想着哪些地方可以模仿学习。 后续更新计划，如果时间允许我会再录一些 Obsidian 相关的视频，后续我会尝试着做技术学习、代码解读分析这方面的分享，欢迎关注我的 B 站。","tags":[{"name":"视频","slug":"视频","permalink":"http://catcoding.me/tags/%E8%A7%86%E9%A2%91/"},{"name":"创作者","slug":"创作者","permalink":"http://catcoding.me/tags/%E5%88%9B%E4%BD%9C%E8%80%85/"}]},{"title":"魔幻......","date":"2022-04-10T12:13:06.000Z","path":"p/complaint/","text":"今天这篇算是一个纯吐槽，我真觉得很魔幻….. 昨天我看到一个新闻，核酸结果统计难？复旦博士生的操作火了 这位博士当然干了一件大好事，在疫情这种节骨眼上大量节省了手工操作的时间，为民解难。 给他点赞！ 接着我就觉得悲哀、难过。 现在疫情这种紧急情况中，如果这样的事还被拿国字号媒体拿来宣传，这说明这事有些罕见。 我们仍然用着最原始的数据工具和方法，人肉手工去处理大量疫情相关的数据，效率如此低下。 就在前几天，我老婆给我发了一个截图，说同学所在单位 (政府机构) 要处理一个疫情的表格，要把批注导出按照小区重新组合，数据量比较大，他们百度之后不知道如何解决，问我这个老程序员能不能解决： 我纳闷了一会儿，这个对于稍微熟悉 Excel 的人应该不难吧，毕竟 Excel 有效率极高的宏操作…. 而且发给我这个外人会不会涉及到隐私信息。 我说发给我试试吧，我老婆把我的号码给了那位同学，不过后来他也没发给我了。 所以，我昨天看到那个新闻后不禁感叹，复旦这还算是上海，还在人才济济的高校，能有博士出来随手解困，像我老家那种小地方呢？ 全国有多少我老家那种小地方，而上海只有一个。 即使是做疫情的 IT 系统，技术方式仍然采用的是上世纪的。以前 VeryCD 的老大 Dash 最近在网上吐槽上海核酸检测： 我上个月在深圳的时候，发现也是这样的分了多个入口： 难道做这些系统的人还不知道负载均衡为何物….. 后来我看一些网友分析的，可能原因是： 外行领导内行，领导觉得这样能解决问题 每个入口是一个承包商【虽然我觉得不太可能】 最后看到这个解释，我释然了…… 再想想西安「一码通」的那事，唉。 疫情已经两年多了，我们可以看到各地的流调报告仍然是在用 Word，Excel 之类的东西人肉管理，没有接口，没有系统互联，相关的信息化、数字化建设还没跟上。 而另一面，我们称自己是人工智能强国，我们互联网技术已经数一数二。 这就很魔幻….. 我们并不缺计算机人才，每年毕业几百万的应届生，其中往计算机行业转的人几乎有 1/3？每年也有大量经验丰富的 35 岁技术人员从互联网公司退下，这些都是马老师所说的为社会输送人才。… 人才输送到哪里呢？ 公务员考试超过 35 岁都不行…. 而这些机构单位要是稍微多招几个懂点计算机的，也不至于项目外包的时候被人坑，也不至于这么多民生相关的系统仍然只能用 IE，也不至于数据处理还需要博士使用“黑科技”来解救。 当然，我知道这很难，也很复杂，很多不能言说…… 最近看了些上海疫情相关的事，心情低落，权当吐槽吧。","tags":[{"name":"吐槽","slug":"吐槽","permalink":"http://catcoding.me/tags/%E5%90%90%E6%A7%BD/"}]},{"title":"Valve，另一种公司","date":"2022-04-09T10:49:05.000Z","path":"p/weekly-8/","text":"我每周会分享一下这周看到的好内容，加上自己的一些个人理解和评注，这算是一种比较轻的持续输出方式，前三期为： #5 财富的三个车道 #6 创造者和实施者 #7 无聊的技术栈 这是第 8 期。 Faster sorting with Go genericsEli Bendersky 的技术文章可以作为技术写作的典范，他写这个博客已经 20 年了。 最近他写了一篇关于 Go 泛型的文章，通过排序算法来探索 Go 的泛型实现： Faster sorting with Go generics - Eli Bendersky’s website 文中作者实现了两个版本的冒泡排序算法，第一个版本是通过 Interface 实现，第二个版本是用泛型实现的，通过 Benchmark 发现泛型版本要快 20%。 Go 团队核心成员 Russ Cox 之前写到过： When a language decides on whether to have generics and how to implement them, it faces the following decision: do you want slow programmers, slow compilers and bloated binaries, or slow execution times? 不支持泛型就是 slow programmers，但是目前主流的泛型实现各有各的问题： Slow compilers and bloated binaries 是指 C++ 那种 full monomorphization 的方式，编译器为每一处实际的泛型函数调用生成对应的函数代码，导致编译时间过长。写过 C++ 的程序员都有些体会，我以前那个公司的代码量也不至于很大，但是编译一遍得差不多一个小时。 Slow execution times 是指 Java 那种 dynamic dispatch，调用的时候会动态分发，导致运行时开销。 Go 团队采用了介于这两种之间的方法，像 int、string 这些原子型的类型就通过 full monomorphization 而其他复合类型使用 dynamic dispatch。 作者继续通过性能分析，对比反汇编后的指令来看这两者之间的差别。基于以上原理，上面的例子程序因为要排序的是 string 所以用的是 full monomorphization，这样对比 interface 版本少了 method dispatch 的时间，而且利用了编译器的另一个叫做 bounds-check elimination 的优化，这样 string 对比的时候没有 bound index 的检查。 不过既然 Go 采用的是混合的方式，也可能某些情况使用泛型的代码比 Interface 更慢，参考这篇文章： Generics can make your Go code slower 看起来 Eli Bendersky 的这篇文章也写了三周左右！他写博文通常会有完整的示例程序，非常严谨。 180 天，每天做个简单网页After 180 Websites, I’m Ready to Start the Rest of My Life as a Coder Jennifer Dewalt 这位女生学习编程的方式非常独特： 连续 180 天 每天都完成一个虽然简单但足够完整的网页，写对应的博文 所有的代码都是开源在 Github 上 她是学美术出身的，但是对互联网很感兴趣，所以想自己试着做一些东西来分享美术。我随便选了一些她完成的网页，感觉有些想法和设计不错。 比如这个 窗户应用 的效果，看起来非常逼真，而且关闭窗户的时候声音也会跟着变。 在这个过程中她学到的最重要的是： “Start Small. Keep Building.” 这个女生的学习编程的方法非常好！ 我虽然编程很多年，但是前端开发很少涉及，去年我想做一些东西所以自学了些前端技能。自学时我发现最有用的是这个 Github 代码仓库 Mini projects built with HTML5, CSS, JavaScript ，如果一个前端新手，能把这些例子都看一遍，基本就能上手了。 有的人在学习编程的时候，会有一种学生思维，比如等我先学 HTML，然后再看完这本 css 的书，然后就可以继续学 JavaScript ，然后再学 Vue 之类的。 这样很可能会磨灭学习兴趣，特别是对学习偏实际应用的前端技术而言，更好的学习路线就是想一个应用，做出来，然后再接着做更复杂的，在这个过程中边学边做，不懂的时候去补。我们要掌握的是能力，而不是知识。 Valve 的员工手册Publications - Valve Corporation 这个员工手册有各种语言的版本，手册里面还配有漫画，写得也很简洁，非常用心。 Valve 的这种企业几乎是独一无二的，这是他们的组织架构随着人数的变化演变： 可以看到里面完全是自由组织的一些项目组，员工自己决定做什么，加入哪个小组，手册里还说明了如何快速移动办公桌，这样你就可以随意搬到自己喜欢的项目组🤣。 每个组都有一个组长一样的角色，但主要是承担沟通枢纽的职责，而不是纯粹的管理，Valve 认为完全按照等级制度来构建公司会有严重弊端： 等级制度会通过招募更多适合这一制度的人从而实现自我强化，让更多的人来充当下属的角色。最后，原先为客户服务的单纯目的将逐渐被成员利用体制谋求私利的欲望和行动所取代和吞噬。 员工的成长不是等级的攀升，而是能力和收入的提升，Valve 鼓励员工向各个方面多元发展自己的能力。 这样看起来每个人都在掌握方向盘： 那这样组建公司的前提是什么？ 就是要招聘到能力强而又协作、沟通足够好的人，所以他们的第一任务是招聘。 看完他们的员工手册后，引起了我的一些思考，Valve 看起来像是构建了一个乌托邦，居然还运行得如此好。 等级制度的弊端我们很容易体会到，比如员工为了晋升可能会做一些短期就有成果的事，虽然员工晋升了，但是这些事对公司而言真的是有价值的么？比如我们看到，很多公司的中层管理肆意招聘，因为手下的人多往往意味着 visibility，这在很多快速扩张的公司并不少见，而当危机真正来临的时候，大量裁员就出现了。 为什么世界上绝大部分公司是按照等级的架构来组织的，我想这几乎是刻在人类基因里的，我们可以看到在动物世界里，大猩猩、猴子、狼群等都有类似的组织形式。 另一个原因大概是，大量的优秀而又善协作的人才太少了，等级制度可以认为是精英治理，最基层的员工做的活都是单一而细分的，这样员工都是可以随意替换。 而且世界上大部分公司，所需要做的事大量是实施类工作，而 Valve 这样的游戏公司需要的是很多创意，公司性质的不同也决定了不同的组织模式。 当然，世界上有 Valve 这样的公司真是太好了！我顺便看了看这篇文章： 关于 Steam、Valve 和 G 胖 你可能不知道的二三事","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"},{"name":"周刊","slug":"周刊","permalink":"http://catcoding.me/tags/%E5%91%A8%E5%88%8A/"}]},{"title":"写作 12 年，我的经验和技巧","date":"2022-04-06T12:58:06.000Z","path":"p/writing-for-joy/","text":"多年以后，如果我还沉浸在写作的乐趣中，一定还记得 2019 年那位给了我鼓励和帮助的陌生读者，他帮我完整地润色了一篇长文，并给了我些提高写作的建议。 这让我赚到了第一笔稿费，当我提出用稿费感谢他时，他回复说你以后也帮助别人就好了。 最近我写文章更多了，收到一些积极的反馈，有的人也想开始写作，咨询我如何持续写作，希望我这篇文章也能帮助到这些朋友。 为何而写大部分人高中毕业之后就再也没有尝试过写文章，没几个人天生喜欢写作，应试作文是很多人上学时所恐惧的事。 写作当然有很多实际的好处，比如赚钱，卖货，建立个人品牌等。Basecamp 的创始人 Jason Fried 曾经写到，如果你在一堆差不多的候选人中不知道选谁，那就选写作好的那个人；现在网络上也充斥着各种写作培训的广告，可见写作算是个稀缺技能。 我从 2010 年开始写博客，一直是想起来就写点，大多是随手记录技术心得，我觉得在互联网上有个自留地就很好。 直到 2019 我才开始学着如何写好，因为我想搞个长期副业。我看到了一些人的分享和经历，他们说写作改变了自己的人生，会让人更丰富，比如 Why I Do What I Do ，所以我也开始尝试英文写作。 为了赚钱去学习写作也挺好，起码有个目标和动力。但如果赚钱是唯一目标时，结果往往容易失望和放弃，因为这是一个投入周期如此漫长的事，短期上看也是投入产出比非常低的事，这条路上赚钱往往是副产物。 通过更密集的写作，我倒没赚多少钱，但得到了一些成长和乐趣，回想起来也是我当时解决焦虑的一个办法。现在要问我为什么写作，我认为有以下几点： 我们常说写作即思考，并不是写作让人更丰富，而是思考让人更丰富。即使一个看似简单的主题，写起来之后发现好像还没想清楚，想写得好也得思考得深入和透彻。 每写完一个主题，意味着我对这个主题完成了阶段性的思考，分享之后会有畅快感，技术、非技术文章写完后都有这样的感受，我为了写而进行思考和总结，写完之后理解就更为深入了。 另一个原因是社交，年纪越大，家庭、工作所占时间更多，通常除去同事我们很难结交到更多人，这也是为什么人的年纪越大越容易孤独。 而写作是高质量社交，是和这个世界产生更多连接的方式。文字是行走的名片，读者和作者之间虽然未曾谋面，偶尔的交流就足够，通过公开写作很容易结识到兴趣相同的人。 写作和分享是有乐趣的，能对抗生活中的焦虑和无聊，有闲暇安静下来写些东西分享出去，大概是最好的精神生活了。 总之，我认为写作是个长期有价值的事，所以我会继续写。 写些什么不要怕写出来的东西太简单而被人嘲笑，不要怕没人关注，恐惧是糟糕作品的根源。刚开始就当写作是记录自己的学习和心得，是 Learn In Public 的最直接方式。 作为技术人员，我们通常最容易开始写的就是技术。 有的人会建议只写某个细分领域，这是个好办法，也有利于品牌建设，比如 Go 语言设计与实现 这本书就是由一些列博文组成的，类似的还有用 Python 编程 13 年后，我把经验写成了 400 页的书 。如果以后找到有持续热情的主题，我也会这样试试。 我最近喜欢写一些非技术类的主题，比如个人成长，理念，经验分享等。我曾是个技术宅，我的技术兴趣广泛， 30 岁以后我逐渐觉得技术不是最重要的，技术是工具，职位只是人生中的一个角色，而人的观念、思维、视野、家庭、健康、甚至运气等决定人生上限和幸福与否。既然有相关的思考我就会写一些相关的文章。 所以，刚开始写作就随着自己的兴趣和热情。如果还没找到特定的主题，就从轻分享开始，像我的周刊那样就写写最近看到什么好内容、我的想法是什么。这类文章看似简单，要写好也不容易，可以通过这类文章锻炼起来。 如何持久写作固然有益，但是很多人坚持不到发现写作益处的阶段，尝试写几篇，没有什么反馈和收获，而后不了了之。 不得不说刚开始确实比较难熬。作为普通人我们只能多读多写，不断练习，写了一定数量的文章后才会获得那种乐趣。我在写了二十多篇英文长篇后才慢慢体会到心流状态。 那如何才能坚持写下去？ 可以适当地给自己定一些计划，比如我今年一月份没有上班，我给自己定的目标非常大，每天一篇，最终我完成 3/4 目标，这比没有计划要好了很多。 如果你给自己定排期，自然会有一些输出的压力。应对这个压力的办法是超前一些，我一直有一些文章在同时写，预计这周发的上周基本写好了，这样留有空间就能从容应对。 另外重要的是反馈，因为如果你写的东西没有任何反馈，自然就难以坚持。 反馈的另一个好处是获得写作主题，比如这篇文章就是来自读者的问题，虽然我觉得自己并未在写作上取得好的成就，但有人问也就意味着我的经验也许能给他人启发。这样就犹如一个正向反馈的轮子，转动起来之后才不容易停下来。 数据可以用来追踪结果，比如阅读量、订阅数等，这些都可以用来量化自己。但一直盯着数据容易陷入自我怀疑，为什么这篇阅读量不好，为什么关注的人少。看数据要把周期拉长，比如一个月左右回顾一次，不和别人比较，因为每个人的节奏和风格都不同，比较会带来压力。 要持续写作必须培养出习惯，得有持续输入。阅读、思考、听播客都是输入，有输入输出的正向循环后才会有习惯。 有了习惯后，写的过程无非是把平时所想记录了下来。我觉得并没有花太多时间，思考即写作，而想的过程很多是在思绪乱飞的空余时间。 写作技巧没几个人天生写得好，要写好需要刻意练习。虽然我说自己写了 12 年，但是 2019 年之前我没有认真琢磨过如何写出好文章，我所写的无非是随手记录而已。 2019 年开始，我写了接近两年的英文技术类文章，有的被人翻译为中文，比如这篇 学会所有的编程语言 ，我看后觉得如果直接写中文我不一定写得这么细致。再看我以前的博文发现有很多地方可以提高，在写作这方面我这两年的成长超过之前十年。 究其原因，我认为是学写英文的时候我写得很慢、很细，结果这样摸索了一段时间后更有韧性了，这是刻意练习的结果。 最基本的，是要有一次写一个词的耐心，直至达到所需的长度。太多人缺乏这种耐心了。一旦你习惯了，写起来就会毫无困难 – 黑泽明 提高的另一个原因是我从 Medium 上看了很多文章，学习文章排版和段落逻辑。 纯技术类的文章相对好写，因为内容和范围都在那里，我们只管写清楚就好。当然我们看到很多技术类文章质量不够好，说明主动琢磨过技术写作的人不多。我推荐看看 Technical Writing ，陈皓翻译过一个中文版本 Google 技术写作 ，中英文写作有很多共同点，好的观点，通顺的逻辑都是相通的。 非技术写作更难一些，因为自由度太高，比如讲好一个故事，讲明白一个道理，我认为最有用的写作技巧是诚实和自然。 我曾不够自信，因为我不会使用丰富华丽的修饰，也没有文彩，文章读起来没有快感，犹如白开水。 我向朋友请教如何提高文彩，朋友说你写的不是小说，大部分是干货而已，直白点就很好。 确实如此，那些我印象深刻的文章大多是对我有所启发，而不是阅读快感。好的故事和观点、真诚表达、简洁的格式，组合起来其实就能超过很多人。斯蒂芬·金在《写作这回事》中写道： 简洁是写作风格的第一要素。尽量简洁，少用副词修饰。 不要卖弄，不要自我陶醉，最重要的是准确描述一个故事。 公开写作需要在一定程度上保持同理心和读者视角，不能完全自嗨，但也不能完全丢掉自我。 有段时间我经常琢磨 SEO 技巧，怎样选择关键词，怎么找热门主题，如何才能让文章排名更高 —— 我犹如一个生产同质内容的机器，这样就没了乐趣。 后来看到 flaviocopes 的作者写到 SEO trick number 1: do not worry about SEO，write things that help people ，我深受启发，如果完全为了钱和流量而写，最终就会因为没趣而无法长久地写下去，写出来的也不够好。所以，更好的心态是把写作当成倾诉和分享。 写完后自己读读，看是否顺口，逻辑上是否有问题，哪些地方不对再改改。 对于特别想写好的主题，我会长时间修改。也许我今天写了主要内容，在接下来的半个月里，我的思绪可能还会在这个主题上，也许散步、看相关资料时有了新的想法，再去修改这篇文章，文章在发布之前经过了断断续续的多次修改。 如果你写的文字，你自己看都像吃了黄连一样苦憋的表情，那就不要指望别人看的时候能够津津有味。 – 村上春树 获得读者人们经常说内容为王，你只管写，写得好了自然就会有人看。 这话放到以前是对的，在如今资讯爆炸的年代，能静下来好好读完一篇文章的人也越来越少了，不推广就根本没人关注到你。 为了获得反馈，我们就需要稍微做一些自我推广。很多人讨厌推广，这是人之常情，之前我也害羞推广自己。我最近倒发现把自己写的发给朋友看看，或是去自己平时晃悠的社区推广一下也没什么，迈过心里那道坎就无所谓了。 如果要推广自己的文章，那就推自己非常满意的内容，人们通常不会反感被推销高质量或是对自己有用的东西。 不用每篇文章都很高质量，但是得有一小部分好内容让人记住，建立起信任感。有了一些固定读者就会有驱动力，最难的是初期滚雪球阶段。 所谓高质量通常有两种： 阐述了一个很好的理念和想法，或者分享了一个很好的故事比如我经常提 Learn In Public，我自然会把流量推到最初阐述这个理念的站点。 很好、很全面地给出了某个 Evergreen 主题的总结和答案Evergreen 译为常绿，就是不会随着时间流失而失去热度的主题，例如 coolshell 的我做系统架构的一些原则 ，这种是算是常绿主题；而 2022 年十大科技新闻，Rust 社区闹分离了，这些就不算是常绿，因为过一段时间大家就不关注了。 这叫作红杉策略，红杉树可以生长上千年，可以长到一百多米高，引人注目，犹如我们说的常绿内容。根据二八原则，少部分高质量的内容会不断带来流量。创作出少部分高质量的内容，不断保持更新，不断地推广，形成口碑效应 。 如果是写英文，我们还能期望能通过 Google 带来有些自然流量，如果是中文就不要期望百度能带来多少自然流量。 初期主要靠自己的主动推广和口碑，对于技术类文章我没发现特别好的中文社区，如果想自我推广在 v2ex、知乎试试，也可以向大号投搞，比如我就往 ruanyifeng 的周刊投过稿获得了我新域名的第一波较大的流量。 每个人获取流量的方式都不同，而且也存在偶然因素，有的人可能写了一两篇爆款就火了，有的人可能是因为被某个大 V 推了一下就成了。但我认为比较靠谱的方式就是，找到你的目标读者可能出现的地方，然后创造出好内容。 写作工具如果是想短期试试手，不想折腾工具，那就选择现有的平台： 中文：知乎，InfoQ，掘金 英文：Medium ，hashnode ，dev. to 虽然平台各有各的问题，到好处在于不必折腾，自带流量。 如果要长期写下去那就不要依赖平台，我的博客经历过好几次平台倒闭，没有建立起固定读者。 内容最好是可以完全自己离线管理，本地编辑器撰写效率最好，文本和图片都通过 Git 管理版本，数据存储在 Github，参考 People Die, but Long Live GitHub 。域名用 Github Pages 之类的就行，Github Pages 也可以绑定自己的域名。 编辑工具我推荐使用带有双链支持的软件，比如 Obsidian、Logseq。我使用网页标注工具 Hypothesis 来把自己看过的东西同步到 Obsidian，写完后使用一些小脚本来自动化发布内容，具体参考：我的 Obsidian 使用经验 和 如何无痛苦更新公众号 。 国外大家喜欢使用 newsletter，国内习惯用公众号，公众号这种关注关系很弱，还有可能被封掉一下子就失去了读者，通过 RSS 也算是维持比较稳定的订阅关系。如果用我的自动同步的办法就把个人站点和公众号兼容了。 英文写作我还是推荐 Medium ，即使现在没那么火了，但是有流量还有认真的编辑和读者。中文技术社区我看得不多，但我看一些人在 CSDN 之类的地方写得风生水起，关键还是需要持续输出。 以上是我的一些经验之谈，如果你能得到一些启发或有了写作的想法，那就很好。我相信认真写作一段时间会让你体会到丰富。 欢迎点赞、分享这篇文章，也欢迎和我交流。","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"},{"name":"副业","slug":"副业","permalink":"http://catcoding.me/tags/%E5%89%AF%E4%B8%9A/"}]},{"title":"Lex Fridman 播客 -- 高德纳","date":"2022-04-03T19:54:06.000Z","path":"p/knuth-interview/","text":"Donald Knuth: Algorithms, Complexity, and The Art of Computer Programming 我最近比较迷 Lex Fridman 的播客，发现他早期还做了很多期技术方面的访谈，而且请到的嘉宾都是些祖师爷级别的人物，比如 Donald Knuth、Bjarne Stroustrup、James Gosling、Brian Kernighan。 Donald Knuth 是有中文名字的：高德纳，1977 年访问中国前所取。 高德纳参加了两次 Lex Fridman 的录播，我看的这期是第一次，在他自己的书房里录的。这个采访非常长，我当作英语听力练习来听，断断续续听完了。 早期经历高德纳回忆了 1957 年开始编程时候使用 IBM 650 的情景，这机器尺寸巨大，但是内存只有 4000 bytes，需要打孔纸卡 Punched card。这算是第一个量产的计算机，IBM 当时只是租给大学使用。高德纳那时候刚好是大学新生，他在这台计算机上熏陶了自己的计算思维。 计算思维接着聊计算思维 (或是 Geek 思维)，他曾经提到根据经验推算只有 2% 的人有类似自己的计算思维 ，而他的书就是为这些人准备的。 I always try to keep a potential reader in mind – basically somebody who is reading my book because they want to, not because they must, and somebody who has a natural ability to do computer programming. Only about 2 per cent of the population really “resonates” with programming the way I do; but somebody ought to write books for that 2%, and I try to be one of the authors who does so. Instead of trying to impress the reader with what I know, I try to explain why the things I’ve learned impress me. 高德纳解释了一所说的计算思维，认为自己特别擅长两件事： 能在不同的抽象层之间自由切换，既能把大的问题拆分为小问题，也能在写程序的时候知道下一条指令是什么，知道寄存器里面存的是什么。所以他的书《计算机程序艺术》还是以指令级的 MIX 语言描述算法实现。 处理复杂逻辑和系统的能力，比如一个很复杂的算法有 10 来个 case，而每个 case 都在处理不同的逻辑，很多数学问题是基于一两个很通用的规则的，所以他比纯的数学家善于处理更复杂的系统。 我上学的时候买过他的《具体数学》，工作后也买过《计算机程序设计艺术》，都是潦草看了几章就吃灰了。看来我可能不属于这 2% 😭，面壁中….. 我看汇编和复杂的数学公式就有点头晕。最近无聊时测试了一下 MBTI，我属于 INTP，这还算是很适合做程序员这类职业的性格特征。也许我对细节和数学抽象都达不到某个深度，但是并不妨碍我做一个应用层的程序员。 高德纳也谈到虽然大家都为了鼓励新手说人人都能学会编程，但是从自己的经验来说，他有一些领域自己非常感兴趣，而且也按照合适的方法练习，但始终都不能达到某种程度，很多领域要达到精通确实需要天分。 文学编程在文学方面，高德纳喜欢托尔斯泰，比如《安娜卡列尼娜》这本书不仅讲述了好的故事也带有一些哲学讨论。 他于 1980 年左右提出了文学编程的概念，用近乎自然语言的形式来实现程序。他认为文学编程像是一种 informal 的方式写程序，而使用编程语言是 formal 的方式，同时用两种方式思考对于技术写作非常有用。 My life is a convex combination of english and mathematics 机器学习机器学习使用数据来训练模型，数据和算法都非常重要，高德纳说这看起来是非极客的方式，他很难完全相信这些算法，因为即使是搞机器学习的人，有时候也不确定算法到底从数据中学到了什么，但机器学习的方法确实扩大了算法的适用范围。 写作流程接着高德纳描述了自己典型的写作流程，他会先在纸上把初步的想法和算法写出来： 然后站起来在屏幕前修改初稿，平均每周会写 5 个左右的程序，他会看目前该领域新的算法和论文，还会尝试自己去写程序，因为只有通过写程序验证了之后才算是彻底理解，完成算法实现后就开始写最终版本的初稿，顺便出一些数学习题给他那些数学好的朋友们做，把那些他们能完成的当作书本的习题。 插个八卦，我以前的老板是 Formal Verification 方面的研究者，他说有一次他收到了高德纳的邮件，咨询他论文里的一些细节问题。高德纳写的《计算机程序设计艺术》可以说是计算机算法领域的百科全书了。 P = NP高德纳倾向于相信 P = NP，但认为即使是成立也可能没有现实意义。额，这段他解释了很多，但是我有的没太听懂细节，以后再学习一下 NP 相关知识。 人工智能高德纳坦诚自己对人工智能可能不像该领域里的人那么乐观，他觉得现在这些人工智能都是假装有“理解”，和真正智能存在巨大的鸿沟。他有些担心，人们如果真的相信自己制造了的人工智能 — 假装的东西真到一定程度就会让人产生这种幻觉，那就是危险。 面对死亡其中有一段感觉谈起如何面对死亡，听起来有些伤感，高德纳在 2006 年被诊断出患有癌症，后来做了手术，最初的一段时间内他无法正常工作。 然后他觉得自己应该抓紧时间了却自己一直想做的事。年轻时高德纳就非常热爱音乐，曾经还纠结过是否选音乐专业，如今还有个愿望就是自己作曲，所以他抓紧时间成了这个夙愿，还在 80 岁左右开了音乐会。 高德纳觉得自己整个人生非常幸运，一直在做自己喜欢的事，而且也已经完成了人生中的大部分目标，剩下的愿望就是继续完成已经写了 50 年的《计算机程序设计艺术》。 Fex 最后一个问题：当你到了天堂碰到上帝，你会问什么问题？ 他回答到： What kind of browser do you have up there…. I hope we have a good Internet.. 这个访谈还有很多其他细节，有时间各位去看看也挺好。","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"},{"name":"算法","slug":"算法","permalink":"http://catcoding.me/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"无聊的技术栈","date":"2022-04-02T10:16:17.000Z","path":"p/weekly-7/","text":"我每周会分享一下我这周看到的好内容，加上我自己的一些个人理解和评注，这算是一种比较轻的持续输出方式，前三期为： #4 你对世界足够了解吗 #5 财富的三个车道 #6 创造者和实施者 这是第 7 期。 使用无聊的技术栈On Choosing Boring TechnologyChoose Boring Technology 我们很多人都非常热衷学习新东西，讨论、实践新的框架、语言、工具也算是一些技术人员的爱好。 而这些文章阐述了这么一个道理：很多时候，技术爱好和情怀不能当饭吃，选择无聊的技术栈大多数时候是对的。 比如说做一个创业公司，更重要的问题是解决什么问题，产品能否达到要求，而选择什么数据库则属于更次要和细节的问题。人的注意力有限，这种情况下选择那些已经验证过的、无聊的、自己熟练掌握的技术栈。 新的、小众的技术栈通常有一些 unknown unknowns，就是你不知道自己会碰到什么问题，而且碰到这些问题时需要花时间去埋坑，而长时间被大量采用过的技术，该踩的坑通常被人踩过了。 Boring is less surprising 当然这也并不意味着我们不用去学习新东西： You try to maximize your expected gain by taking advantage of what worked well in the past, while sometimes exploring new things to avoid missing out on a possible goldmine. 这方面我有些个人体会，我曾经在的中等规模的独角兽公司。2013 年左右，公司在做一些互联网产品时使用了 Ruby on Rails，RoR 在那时候算是新潮的工具。我 2014 年加入也觉得挺少见，感觉 RoR 适合那种几个人的创业团队。 后来了解到，对公司来说并没有刻意选择，可以解释为偶然因素。因为有喜欢 Ruby 的技术 Leader，然后就继续招了更多的 Ruby 程序员，代码越来越多，人也越来越多。 而这么些年后，他们就要换技术栈了，一是因为 Ruby 程序员太少了，很多人也不愿意学，毕竟人家会考虑进来干段时间之后好不好跳槽的问题，内卷的人才市场大家考虑的就是这么实际；二是一些技术问题，比如性能、社区支持等，到了如今和 Java 的开发效率也没有本质区别。 如果把时间拨回到 2013 年，更理性的选择应该还是主流的 Java？RoR 也许那个时候确实算先进生产力工具，但没经过长时间验证。 从公司 (大部分公司) 角度来说，要解决的完全是个业务问题，技术人的品味和偏好可能导致额外的技术成本。而对于很多创业公司来说，创业成功与否与所选技术栈关系不大，关键还是做的事和做事的人。 也有一些创业公司使用小众技术，比如 PingCap 采用 Rust 写存储部分，JaneStreet 大量使用 OCaml ，WhatsApp 使用 Erlang，Roam Research / Logseq 使用 Clojure 等等。 他们使用小众技术栈有其他方面的因素： 通过小众技术栈吸引到强的开发者，因为这些人更多比例是 polyglot programming 有技术上的原因，比如是性能、正确性、可扩展性和灵活性 对所选技术有信心和十足把握 小众技术栈不适合绝大部分创业公司，更不适合大公司，因为大公司体量大，小众技术栈并不容易大量招人，而且大量投入资源到小众技术栈投入产出比太大。大公司使用小众技术只是局限在某些组，比如 Facebook 用 Haskell 写代码重构工具，那是因为 FP 之类的语言非常适合干这个。 还有另外一些场景，某些大公司的技术 Leader，他们要做出新的业绩或者抢眼的项目，但在一个稳定的大公司要做出这些事不容易，一种群众喜闻乐见的做法就是引入新的技术栈，或者是用新的编程语言重写某些系统，我听闻在 AWS 现在一些中层的口头禅是 “Why not rewrite in Rust”. Adding the technology is easy, living with it is hard. 没有银弹！ 焦虑的人焦虑的人 作者：弗雷德里克·巴克曼，2021 年出版。 我在微信读书上偶然碰到这本小说，我看评分非常高所以就读了起来。 这个故事非常精妙而温暖，还充满了荒诞的喜剧效果。作者的写作手法也很独特，不断地切换视角和时间点。 故事中的每个人物都是不完美的普通人，他们有各自的背景、伤痛和焦虑，而在这场莫名其妙的人质事件中，他们用一些人类公有的同情心拯救了彼此，也接受了自己。 太喜欢这句话了： 即使知道世界明天就要毁灭，我们今天也要种下一颗小苹果树。 非常期待哪天这个故事能被拍成电影。 其他资源Operating Systems: Three Easy Pieces 操作系统相关论文，适合操作系统入门。 CS 自学指南 一个北大学生写的计算机科学自学指南，目录分类很好，粗看里面列的书有很多好的书籍推荐和公开课，非常适合在校学生。","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"},{"name":"周刊","slug":"周刊","permalink":"http://catcoding.me/tags/%E5%91%A8%E5%88%8A/"}]},{"title":"优化自己的信息源","date":"2022-03-31T12:43:06.000Z","path":"p/get-better-info/","text":"我有个年纪比较大的同事，他的特点就是淡定、从容，还有些单纯。 你和他一聊，发现他对很多现在的新闻不了解，甚至不知道很多影星、歌手、网络红人。但是他并不是对什么都不感兴趣，他有自己喜欢的主题，只是除了自己喜欢的这些其他的都不关心。 可以说他的获取信息的方式是经过刻意选择的。 这有什么坏处么？我没想到，很多热闹的新闻看起来都是关我屁事，比如 xx 明星离婚了这类顶流新闻，不知道也没什么损失。 而刻意缩小自己的信息源好处显而易见，我们时间和注意力很宝贵，优化自己的信息源、甚至是获取资讯的习惯，让自己获取高质量的信息。 可以看到目前很多 App 和网站已经全面退化，如果不优化自己的信息源，我们将被垃圾包围。 下面我要开启吐槽模式，先拿知乎来举例。 我曾是知乎的深度用户，从知乎 2011 年创建后的几个月开始使用，那时候知乎社区的整体氛围非常好。但是这么多年后的今天，我已经基本把这个 App 当作中文搜索引擎来使用了。市面上很多 App 都在学习推荐算法，而推荐算法恰恰不利于获取高质量信息。 就拿知乎来说，它的推荐栏放在了首要位置，而推荐的内容里面质量极其低下，内容里面夹杂广告不说，还非常粗暴。你看我回趟老家一路打开的就是这些，就把地点给换了一下套进了模板吧？ 难道做推荐算法都不建一个用户画像么，我在知乎上搜过很多次育儿相关信息，这算法蠢到认为我还没谈恋爱？ 另外这些广告点了“不感兴趣”也是没用的，大概是因为他们的广告主数量太少，反正就是不断弹出。知乎的推荐连内容去重都没做，比如一个刷存在感的推广用户，不断在各个主题下发送同样的文本内容，但是我居然能在推荐页的连续三屏都能看到相同回答。 知乎的另外一个做法是让自己的付费内容推荐给用户，让你看个开头，剩下的需要会员看才行。 行，我付费，只要是高质量的内容我付点钱我也愿意。然后我用了几天，在看电子书的时候就发现这么个鬼玩意儿： 我想到自己是尊贵的付费会员，立马打开“盐选会员专属客服”报告问题，客服说这确实不能关闭，他们正在搞个活动，然后给了我这么一个表情表示歉意： 还有很多知乎的细节问题我就懒得吐槽了，我不反对 App 为了流量整这些玩意，我想要的是干净的、清净的界面、高质量的内容，即使这需要付费也可以。 推荐系统的目标是流量，不是让我们获取好的内容，比如今日头条这种 App，我曾经试着去上面发点东西，发现他们的编辑后台居然还有标题生成器，能自动生成一些备用标题，这些标题大多是看起来更吸引人的。我作为老古董看了后有些震惊，居然还能这么玩。 头条上的内容很多都是同质化的标题党，质量低下。知乎的另外一个趋势是抖音化，而抖音…… 我觉得是毒品。 以前我觉得这东西放在手机角落里，想搜个什么再拿出来看看就可以。但是我低估了抖音的设计，每当我搜了一个什么之后就会花更多时间去看其他的，然后就形成了每天看的习惯。抖音利用了人性中的三毒“贪、嗔、痴“，还有很多人共有的猎奇这个弱点，能极大的抓住人的注意力，让用户成瘾。 所以这东西绝对不能留在手机里，不要高估自己的自制力。 现在大部分人都已经被这个 App 降伏，每当我坐地铁、坐火车，附近的人开起来外放之后，那种背景音乐和嘎嘎嘎的笑声随之而来，我整个人都会不好。 如何优化吐槽了这么多，那如何优化自己的信息源和习惯？ 获取信息的方式最好是主动的，摆脱算法和机器的喂养，自己去挖掘有价值的信息，而我长期关注的信息来源一定是自己认可和刻意筛选的。 主动和被动有明显的区别。比如我的四岁女儿，我发现她这段时间过多地接触视频类东西，比如动画片和网课，结果就是不能自己静下来好好看会儿书，或者玩玩具。 当一个人习惯了被动的方式之后，会排斥主动的方式。对于她来说看着这些东西就能乐呵，而自己看书和玩明显感受不同。我不想让她变成等待喂养的小萌鸡，所以想办法尽量减少她看视频的时间。 主动阅读仍然是最好的获取知识和信息的方式。而看视频就得分情况，比如我想了解一个主题所以搜索一些相关视频看，或者是欣赏一个高质量的纪录片，这些都是主动的；而因为无聊刷抖音这则是被动的，这是在让低质量内容填充自己。 当我主动找到了足够多的好的资讯、书籍需要消化时，就没时间去看那些为了流量而写的东西了。目前我的主要信息来源有以下几个方式： 个人订阅Rss 订阅现在看起来已经有点复古了，我认为这是保持个人信息源精简的好方式。 我通过 RSS 订阅了很多个人博客和 newsletter，我们发现那些质量好的内容大多来自真正的领域热爱者。 newsletter 国外用得很多，近些年 Substack 兴起，而 Substack 是绝对没有推荐机制的，完全是基于读者和创作者的订阅关系。 我们也可以使用 kill-the-newsletter.com 来把 newsletter 转化为 Rss feed，这样就只使用一个 App 来阅读，我这篇文章 打造自己的工具 - Obweb 介绍了自己的这个小工具： 虽然我自己写公众号，但是其他公众号我看得不太多，新加的推荐算法影响了公众号整体内容的质量，弱化了订阅的关系。 主流网站中文社区相对来说知乎用得最多，我也偶尔逛逛 v2ex 之类的。 英文 Twitter，Medium，Dev. to，Quora，Github，HackerNews 等等。 微博偶尔看，像 Twitter 、微博这类社交应用，我认为是一个扩展自己信息源的渠道，比如看其他人发的一些有趣的和好的东西。 很多中文网站我尽量控制在搜索 (还得排除百度) 指向的时候看看，因为 中文互联网的产出在渐渐枯萎 ，可以说现在整个互联网正在充斥着流量内容，而我们得学会如何从垃圾中找到金子。 主动学习某个主题看维基百科非常不错。 视频播客YouTube 和小宇宙，YouTube 上很多高质量计算机类课程视频，播客也是一个很好的信息源，关键是在抱娃时、开车时候也能听。 书籍我之前主要用 Kindle，最近使用微信读书比较多。 关于如何获取更多、更好的信息，欢迎评论交流。","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"},{"name":"阅读","slug":"阅读","permalink":"http://catcoding.me/tags/%E9%98%85%E8%AF%BB/"}]},{"title":"创造者和实施者","date":"2022-03-26T10:07:05.000Z","path":"p/weekly-6/","text":"我每周会分享一下我这周看到的好内容，加上我自己的一些个人理解和评注，这算是一种比较轻的持续输出方式，前三期为： #3 Basecamp 的小而美 #4 你对世界足够了解吗 #5 财富的三个车道 这是第 6 期。 创造者和实施者创造者和实施者的差别 这篇文章讲述了这两个角色之间的差别。 作者认为演员是实施者，作家是创造者；类比起来开发工程师是创造者，而支持工程师算实施者；工程师是创造者，而程序员是实施者。 虽然工程师需要具备一些开发者的技能，比如写代码，但从根本上，工程师的能力，和代码无关，而是创造一个脑子中的世界的能力。当然，这种划分并非完全分开，每个人每天都会同时做一些工程师和程序员的工作。 … 画家，作曲家，作家，建筑师，工程师，企业家，甚至一些精神领袖，都像创造者。对于精神世界里面创造一些东西，他们游刃有余。对于现实世界里面的实现，他们却未必擅长。 … 世界需要那些在思维世界不受现实羁绊而翱翔的人，也需要把这些想法变成现实的人。或许我们并没有如此幸运在自己一个人身上在两种能力都无比优秀，或许他们的思维方式本身就是互斥的。理解这种差异，才能知道自己最强的领域，并且和自己互补的人相互欣赏，组成团队达成合作，一起拼出一幅图景。 我仔细想了想，工作内容决定了身份和角色，也许还有一个维度是深度，上限决定了有的事成与不成。 比如同样是演员，好的演员表演出来有自己的理解和风格。 所以，我认为关键点在于独创性？比如你做的事情另一个人也能做出来，那大概率是实施者。画家，作曲家，作家，建筑师，工程师，企业家这些人做的事情换一个人也许不能复制，那就是创造者。 这个世界不缺实施者，但是缺创造者。 思考一下自己的两种属性的比例，我认为自己在工作上基本还属于实施者，但在写作的过程中我也算个创造者，暂且不论写出来的东西如何，至少这是一种有独创性的活动 :) 一个 Linux 漏洞The Dirty Pipe Vulnerability — The Dirty Pipe Vulnerability documentation 这个文档详细描述了一个 Linux 内核漏洞的发现过程。 作者的应用出现了一个诡异的 Bug，这个 Bug 有个很诡异的现象，每当月底的时候，他们的日志文件压缩后都有几位校验码不对，这导致解压软件就无法解压，作者时不时被这个 Bug 所困扰。 但是这种偶发性的问题其实很难问题根源，光是发现那个出现日期的规律就已经过去了几个月。 作者先查遍了应用层的代码，使用排除法一层层分析，最终怀疑到是内核的问题。然后写了一个简单的 C 程序去验证果然是内核 Bug： 文中还详细解释了内核中 Pipe 和 page cache 的关联，对比内核版本之间的改动发现是由于一个很简单的 C 语言结构体里变量未初始化造成的，当然修复也就是两行代码： 作者最后尝试写 POC，可以利用这个漏洞可以去覆盖一个没有读权限的文件，这甚至会影响到 Andriod 设备，不过 Google 也已经合并了这个修复。 判断程序员水平的一个很好方法就是给个隐藏的 Bug，看他的分析方法和思路、如何使用各种工具，这比考八股算法靠谱多了。 看完这篇 Bug 分析我感觉像是看完了一篇侦探小说！🤣 写博客 10 年得到的经验ferrucc.io | Everything I’ve learned in 10 years of Blogging 这篇文章很长，这第一句就把人吓唬住： I’m 21, but I’ve been blogging for almost 10 years. I grew up doing this. 我完整地看完了这篇文章，不得不说这个小伙写作很好，行文流畅。里面写的很多确实和我的经验是一致的： 很多人自己建博客，在样式和设计上花了很多时间，折腾完之后就没写几篇，而最难的是长期持续地写出好内容。 好文章是修改出来的，他这里说 50 % 花费在写上面，其他时间做润色、画图、重写，这些是重要的细节。 这篇文章虽然长，但是读起来比较容易读，因为作者是意大利人，所以不会用那种俚语之类的，非母语写作有时反而能写出受众范围更大的文章；另外一个原因是每段都相对短，可能就一两句话，这也是现在很多人写长文所采用的方式。","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"},{"name":"周刊","slug":"周刊","permalink":"http://catcoding.me/tags/%E5%91%A8%E5%88%8A/"}]},{"title":"远离内卷和无趣，我选择多元","date":"2022-03-21T20:47:06.000Z","path":"p/diversity/","text":"罗素曾写到：Diversity is essential to happiness，王小波在《思维的乐趣》中引用了这句话，翻译为 参差多态，乃是幸福的本源。 下面结合我自己的一些经验来谈谈，为什么我认为大家应该去尝试拥抱多元。这里的多元指两个方面，组织里的多元，和个人选择、生活里的多元。 公司里的多元公司的多元意思是愿意招聘、包容不同族裔、性别、年龄、背景和性格的人。我这些年经历了两个极端，所以感受特别明显。 2011 年我在上海的一个创业公司，我们办公室只有 13 个研发人员，因为销售都在美国。我们都是理工男、大多比较宅。因为都是男生，我们可以光着膀子在办公室换衣服，吃晚饭的时候开上投影放上一段蜡笔小新或维多利亚的秘密。公司很小，只有这么多人，人员单一是没办法的。 2014 年我加入了深圳某公司，这个公司并不小，但公司有个特点就是只想要一类人，这类人的标签是工作追求极致、极其勤奋。说实话这种人当然每个公司都想要，因为这些词里的每一个都是一种稀缺性。但当一个公司大部分人都是这种行事方式，他们努力加班时，其他人也会跟着节奏跳舞，有时候做的是布朗运动，结果就是有些内卷。 后来我换工作去了微软，刚开始我不太理解公司为什么一直强调 diversity，渐渐地我体会到公司包容不同的人会对工作环境产生巨大影响。 入职培训主要是说如何高效沟通，如何消除无意识歧视，如何认清自己的现状以更好地获得职业发展，没有打鸡血。 在多元化的组织里面，会有各种不同履历背景、性格志向的人。多元必然意味着包容，允许你有不同的看法，也鼓励你说出自己的真实想法，不用担心被质疑提的问题是否是高水平，允许员工在合理范围内自由安排时间，不用和同事比拼加班，没人关注你在公司待了多久时间。 简而言之，公司认为你是个成年人，并相信你对自己的行为和选择负责。没有人告诉你应该向谁谁学习，没人催着你要往上爬。当然，如果想做得更突出升职更快，也可以努力加班做到 120 % 的突出成果，如果想照顾家庭没那么多精力突出，做好本职工作也没人批判。 员工乐于展现自己的兴趣，有的人早上爬起来骑车去绕个阳澄湖，有的人热爱飞行所以带来模拟设备和大家分享，有的人对绿植感兴趣就在办公室种水培蔬菜，有的人沉迷于桌上足球，当然也有人下班不回家继续努力工作。同事中有 00 后也有 70 后，虽然个性和背景不同，工作起来并没有不顺畅。 我觉得这就很好，即使以后我不在这工作了，我还是会认为这是个正常的、舒服的，让人自由发展的工作环境。 有人会说，这是因为微软处于垄断地位，处于软件行业上端，所以才提供这样的轻松包容的氛围。但微软并不是一直都这样，有段时间也出现过狼文化的阶段，只是狼文化并不能解决公司的疲软，反而会导致人员流失。 纳德拉上位 CEO 逐渐改变了公司文化，参考纳德拉出任 CEO 三年，靠改变“狗咬狗”狼性文化来重塑微软 在盖茨和鲍尔默的领导下，微软形成了一种竞争之上的狼性文化。在严苛的绩效管理系统下，团队中的其中一部分人被贴上了优秀的标签，升值、加薪随之而来；而另一群人的表现无论多么优秀，只要在其所在团队中是落后的一方，就会被视为是“老鼠屎”，面临被解雇的窘境。 而在纳德拉的领导下，“一个微软”的公司文化加速在微软扎根。他认为员工应该专注于合作，而不是在竞争中诚惶诚恐：“我们的态度应该从‘什么都懂’转为‘什么都学’。 我想给员工减减负并传达这样的信息：他们不需要摆出一副‘我什么都懂’的样子，以确保自己的安全地位。他们可以犯错，但我希望他们保持好奇心，不断地学习新事物。” 奥布莱恩说：“纳德拉成为 CEO 后，管理混乱和勾心斗角的现象都在逐渐减少。员工之间开始建立信任、互相分享新想法并展开真正的合作——他们不再时时刻刻想着竞争、绩效和奖金。” 微软的公司文化改变之后，一些之前离职了多年的老员工又重新回来了，他们有时候还会感叹公司那段时间真是很混蛋。 同样验证了这一点的是百度，有段时间百度只要狼不要小白兔，结果无法避免公司沦为计量单位。可以看到很多时候对于公司而言，更重要的是决策和方向上的把握。时代要抛弃一个公司，与这个公司员工是否勤奋没有太大关系。 当然多元与否也与各个国家的具体情况相关，对于很多欧美公司来说，多元是一种政治正确，特别是美国本身是一个移民国家。 我不反对公司只想招某一个类型的员工，如果公司处于中小规模时，频道相同的人可能会减少沟通成本，执行力上更为高效。我反感某些公司只招一类员工，比如年轻皮实的，在环境上构造内卷的氛围，让无意义加班来缓解公司策略上失败和管理上的焦虑，而这样的公司并不少。 希望更多公司像对待成年人一样对待员工，容忍不同人的生活态度和工作节奏。 生活中的多元启发我写这一段的是因为这篇文章：Diversify your life If your existence is all about work, and work goes to shit, then life goes to shit too. If you live for your hobby, and your hobby hits the wall, then your life crashes too. If everything else is waiting until you hang with your mates, and your mates fade away, then you fade too. Betting your drive to get up in the morning on a single path will leave you completely stuck if that one road is blocked. Don’t bet all your happiness and purpose on a single square. 我认同这点，不管是从生活角度、还是技术角度，过于单一往往意味着狭隘和无趣。我现在也在尝试用拥抱多元的态度去生活，多元意味着让自己的生活有更多选择，不排斥可能性。 几年前我和基友爬深圳的梧桐山，我们沿着大路慢悠悠走到电视塔那个点，然后我们打算下山。这时我想沿着原路返回有点无聊，毕竟风景已经看过了，然后我俩就沿着山间小路往下走，其中还迷路了两次，最终耗时两个小时才走到山底，整个过程又累又饿，但却是我在深圳爬了这么多次山印象最深刻的一次。 大多数人过着受变幻莫测的命运所掌控的随遇而安的生活。很多人受迫于其出生的境遇和生活的必需而保持一条笔直且狭窄的生活道路，在这条路上，没有向左转或者向右转的可能。 – 毛姆 人的每个选择犹如计算机中的每一步判断，在算法设计中贪心算法就可能会有这个缺陷，掉入局部最优解，而最后没法找到全局最优解。 如果自己没有刻意做过更多尝试，人生就会陷入路径依赖：所有当前的选择都是最优的，但是最后的结果趋于平庸。一个解决的办法就是模拟退火，引入一些随机的选择，即多元化自己的选择。 当然我并不是说随机的引入其他选项，比如我现在就不做程序员了，我去干销售。引入选项得利用现在已有的优势，结合自己的兴趣和爱好，在可能的范围内找更多可能性。 多年来我一直都是纯的技术理工男，近些年来业余时间我更多关注一些非技术的领域，多读一些技术无关的书籍。逐渐地我觉得自己一些看问题角度变了，甚至有些后悔自己曾经过于执着于技术。 我还尝试让自己的收入来源多样化，至少我体会到一个好处在于最大化满足感，比如我通过写作赚上 1 万元，成就感和满足感大于我通过上班赚上 5 万元，要是哪天我钓鱼赚上 1 千元，成就感抵得过我上班赚上 5 万元。 即使是在技术上，保持多元的态度也意味着更理性。 我从 2006 年一直用 Emacs，曾经我以为自己会用上一辈子，毕竟这是最高效、最适合自己的编辑器，但是 2020 年我换了工作之后我开始用 VsCode 了。然后我发现 Emacs 并不是不可抛弃的，因为一直死守 Emacs 失去了很多体验新东西的机会，VsCode 在很多方面是非常好的，而且我并不需要花什么时间去配置它，使用 VsCode 的群体更大，我可以获得更多人的经验和分享。 我从 2005 年开始一直用 Linux，工作后我也基本用 MacOS，我曾经以为 Mac 必须是更先进的，然而 2020 年后我开始使用 Windows 工作，我发现也可以很高效，用 WSL 并没有失去使用命令行的乐趣。 在技术这行存在着各种各样的鄙视链，编辑器、编程语言、操作系统，框架等等，我们往往自认为自己的选择是最好的。 不同的选择某种程度上代表着不同的世界观，有的人认为开发效率更重要，而有的人认为性能更重要，有的人认为正确性更重要。这个世界本来就是多态的，每个人的世界观、需求、品味都会有差别，自然就会有不同的技术选择，说服和比较都没多大意义。 经历过数次的反转后，我开始反思那些我曾经坚信的想法不一定正确，而人都有一个倾向那就是把自己局限在某个角色、领域、自己最熟悉的区域里，并把自己成功的经验到处复制。 更好的态度是保持多元的心态，技术都是工具，不必太过于狭隘和执着。XX 最牛、最强，这种态度是一种拒绝的、封闭的心态，而用一种不断探索、自我怀疑、包容异己的态度来看待技术会更好。 以上就是我的一些个人体验和想法，最后推荐一些启发我的文章： 思维的乐趣 程序算法与人生选择","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"},{"name":"成长","slug":"成长","permalink":"http://catcoding.me/tags/%E6%88%90%E9%95%BF/"},{"name":"职场","slug":"职场","permalink":"http://catcoding.me/tags/%E8%81%8C%E5%9C%BA/"}]},{"title":"财富的三个车道","date":"2022-03-17T22:55:06.000Z","path":"p/weekly-5/","text":"我每周会分享一下我这周看到的好内容，加上我自己的一些个人理解和评注，这算是一种比较轻的持续输出方式，前三期为： #2 好的抽象和设计就像积木 #3 Basecamp 的小而美 #4 你对世界足够了解吗 这是第 5 期。 百万富翁快车道这本书名比较俗气，看起来是教人快速致富的。我看到有些人推荐了，所以也找来看看。读完后感觉有些鸡血，可能是因为一些观念我之前已经接受过了，所以并没有大受启发之感。 我觉得这本书的比喻很贴合，把人的财富道路分成三种： 人行道：他们忽视金钱，对钱没有管理，没有计划和储蓄，被欲望驱使，花的钱永远比赚得多，缺乏财务自律，牺牲明天享乐今天。典型的是那些消费主义的奴隶，背上高额债务的人。 慢车道：绝大部分人都处于这个车道，兢兢业业工作，每月可能会留有部分积蓄，不至于出现生活窘迫，但需要一直工作到退休。他们大部分情况下是消费者，人生中的财富积累是线性的。 快车道：这小部分人是生产者、企业家、发明家和创造者，他们发明新东西或者是利用规律，去创业并承担责任，通过商业系统来积累财富，财富增长是指数级的。因为承担了更大的风险和责任，所以可能获得巨大的财富。 他们的认知如下： ·对债务的看法：如果允许我建立和发展我的系统，债务是有用的。·对时间的看法：时间是我所拥有的最重要的资产，远远超过金钱。·对教育的看法：当你停止学习的那一刻，你就停止了成长。不断扩充我的知识和认识，对我的旅程至关重要。·对金钱的看法：金钱无处不在，而且非常充裕。金钱是我影响了多少人的真实反映，也反映了我创造价值的能力。·对财富的看法：建立现金流和资产评估的业务系统。·财富公式：财富=净利润 + 资产价值。·策略：我付出越多，我在时间、金钱和个人满足感方面就越富有。·目的地：终身获得被动收入，既通过生意，也通过投资。 虽然整本书主要在谈论如何赚钱和积累财富，但是到了后来又说： 财富不是由物质财产、金钱或“东西”成就的，而是由我所说的 3 个基本的“f”组成，即家庭（family）或人际关系、健康（fitness）和自由（freedom）。在这个财富三位一体中，你会找到真正的财富和幸福。 这倒是个政治正确的关于财富的定义。 这本书的写作语气和论据我倒不是很喜欢。大概是因为作者早年经历过悲惨窘境，后来通过互联网发财致富，这本书即使是翻译过来了还是有那么点戾气，比如把走在慢车道的人描述得很悲惨，认为必须上班 5 天这种生活不值得一过，如此等等。 尽管如此，这整本书的内容还行，推荐大家试着去读读，不一定要去创业，树立正确的财富观和财务管理概念也很重要。 Rails 核心贡献者的分离Rails 社区这段时间在闹分离，一些核心开发者把自己的名字从列表中移除。 很多人都是懵逼的，不知道具体发生了什么。我以前写过几年 Rails，虽然现在早已经不碰了，我还是花了点时间看看到底是怎么回事。 事件的开头是因为 DHH 于 2022.03.03 发表了一篇文章：No RailsConf ，其中列举了自己 2021 年对 Rails 所做的所有贡献，然后晒出了一封 RailsConf 组织者的邮件： _Hi David, Hope you’ve been well. With you having been mostly offline the last year, the program committee has decided it would be valuable for the community to start sharing the opening keynote stage with other contributors. We have a few in mind but if you have any suggestions of people who have been impactful this year, please share them. If you have any questions, please let me know. 邮件开头那句：With you having been mostly offline the last year 直接让 DHH 爆了，他认为这是对政治、意识形态差异的报复。 因为我订阅了 DHH 的博客，所以第一时间我也阅读到了这篇文章，我当时觉得他是不是稍微有那么点敏感了，依照我的理解 RailsConf 组织者是想让他和其他人一起做 Opening Keynote，这好像也不是过分的要求，现在很多技术类 Conf 都是这样的。 这个组织者写出这么一句话大概是因为 DHH 之前在两件事上惹起的争议： Basecamp 禁止员工讨论政治敏感话题，导致一半员工离职 DHH 之前站队加密货币 根据这个 Reddit 帖子里的描述 Dhh is cancelled from RailsConf: Won’t Give Keynote : rails , 也验证了我的感受。DHH 一直都是桀骜不驯，心直口快的人，这个特点容易引发争论，特别是现在意识形态的分裂越来越严重的情况下，更容易造成社区的割裂。 Facebook 技术主管的经验42 things I learned from building a production database 2017 年，Mahesh 从耶鲁大学的教职岗位上休假去了 Facebook。他创建了一个基础架构团队，在 Facebook 打造了一个名为 Delos 的分布式存储系统 (Facebook 版的 Chubby)。他们用了不到一年的时间里完成了初版 ( 3 人的初始团队)，然后团队规模扩大到 30 多名工程师。这个项目的四年中都没有严重的事故。 在这篇文章里作者分享了从用户、项目管理、设计、团队文化、策略、可观测性等各个维度的思考，这里面包含一些技术、管理方面的经验，非常值得一读。 做 Infra 的好处在于技术挑战比较大，而且面对的客户通常来自自己公司，相对来说沟通起来会容易点。这里面谈到的一些技术点，通常也是分布式系统的挑战，比如系统时间在分布式系统中是非常容易出问题的： Avoid using real-time for correctness guarantees or comparing clocks across machines unless you have (and understand) error bounds on the clock. 存储系统应该优先考虑一致性和持久性，因为这两个更难衡量，出现问题也更难修复： For storage systems, bias heavily in the beginning towards consistency and durability rather than availability; these are harder to measure and harder to fix if broken. Because availability is easier to measure, there will be external pressure to prioritize it first; push back. 在大厂做好技术管理不容易，既要懂技术又要懂得管理，还要争取到好的项目，给团队足够的存在感。基本上作为工程师，一个在大公司的工作体验与直接主管最挂钩。管理他人意味着用了杠杆，所以管理者的好和坏都会被放大。","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"},{"name":"周刊","slug":"周刊","permalink":"http://catcoding.me/tags/%E5%91%A8%E5%88%8A/"}]},{"title":"我如何写出一万元的文章","date":"2022-03-13T15:09:05.000Z","path":"p/my-writing-story-on-medium/","text":"当我开始练习写作时，他人的故事、技巧分享激励了我。希望我的经历也会帮助到其他人，这篇案例分享的文章是我 2020 写的，原文是 How I Wrote a $500 Article in My First 3 Months on Medium ，我改过来加上一些后续。 一万元并不是一笔巨款，但是算是我赚的时薪很高的一笔收入，因为我写当时那篇文章只花了 30 分钟。 如何写出来的我作为一名软件工程师已经工作了近十年。我喜欢阅读，但没有写过太多文章。2019 年我开始练习英语写作，我在网上看到东西都会想想这篇文章怎么样，哪些地方值得学习。 某天，我看到了一篇关于 Linux 好玩的命令的中文文章，觉得这有点意思，我们在日常工作中并不使用这些命令，但它们是程序员和 Linux 系统里的一种小幽默。我想可以写一篇 Medium 风格的文章，我在学习这种风格，反正也需要练习。 我之前看过一些营销类的资料，诡异的心理学说标题中的奇数会吸引更多注意力，所以我得凑够 7 个命令，这感觉是在配制神秘药水。我读的那篇文章是针对极客的，我想把受众扩大到新手或非技术领域的读者，所以加入了一些如何安装这些命令的详细说明。 我在 Mac 上尝试了每个命令，如果在 Mac 上没有我就在 Linux 虚拟机上试试，然后给每个命令都配了一张截图。 我大概用了 30 分钟完成了，然后就提交到专栏 Better Programming 。这是一个面向 IT 专业人士的专栏，我之前在这里已经投递成功过一些技术文，但这篇不是硬核技术文，所以有可能不会被接收。我当时想，如果没有被接受我就发布在个人页面好了，反正也没没付出太多时间，随手一试吧。 幸好 Better Programming 的编辑 Zack Shapiro 很快接收并发表了这篇文章：7 Terminal Commands That Will Just Make You Smile 。 他们还配了一张可爱的图片和带点幽默感的副标题： These tutorials don’t always have to be practical 我估计是 Medium 在一些相关主题中推荐了这篇文章，阅读和点赞数开始滚雪球地增加，这算是我学习写作 3 个月里写出的表现最好的文章了。 如何继续完善大约两天后，我看到数据不错就开始思考如何改进这篇文章。 文章本身不长，只有 300 字。Medium 是看吸引了多少付费用户的阅读时间来计算稿费的，那如何提高平均阅读时间？ 我的想法是让它更有吸引力😏 首先想到的是光有截图不够，应该为这些命令制作 GIF，因为 GIF 能更好地展示这些命令的有趣性。我以前没有在 Mac 上制作过 GIF，我在 Google 上搜索发现一个叫 LICEcap 的小工具，用这个工具很快就完成了 GIF。我甚至在页面上内嵌了一个 Youtube 视频，我要做的就是使这篇文章活泼生动，让读者很快得到乐趣并盯着文章看。 最终这篇文章虽然很短，平均阅读时间为 2 分半钟，阅读量是 10 w，挣了 1300 多美金： 疫情的那段时间，我每天看着这篇文章赚上几百元的被动收入，感觉很好。 我学到了什么这篇文章的想法并非完全原创，也很简单。我所做的是分享点趣味，并且扩大受众面，为目标受众做出一篇完美的文章。 我在很短的时间内完成了初稿，发布之后如果数据好就继续雕琢到完美，这是一个可行的节省时间的策略。 那如何重现这一切呢？说实话，我不知道，谁也不能保证根据这个策略就能再写出一篇。我还写了一些其他文章，所花费的时间比这篇更多却没得到这么多阅读量。写作中就会出现这样一些惊喜，那些不经意间写出来的反而火了。我想这篇能很快传播开来，一个原因是优秀的配图和幽默感容易引起病毒式传播。 这篇文章确实是一个好的开始，因为我感觉这个经历有点靠边 Marketing，所以我又能写下这篇案例分享的文章。初稿我写得并不好，Better Marketing 的编辑 Niklas Göke 回复说噪音太多，能不能专注于写出来的过程，你当时的想法和思考等，写得越详细越好。我按照他的思路重写了这篇文章，最后也获得不错的结果： 给靠谱的 Meidum 专栏投稿的好处在于，作者提交后他们的编辑还会继续修改，我估计是因为编辑看我是非英语母语写作，所以会帮忙润色。我则可以看他们的修改来学习英语和写作。 对于写作赚钱这件事来说，没有一个必定成功的公式，我们需要做的就是写得更多、更好，写完给行家看，根据反馈修改，这就是最好的提高途径。对于新手来说，投稿是个不错的办法，这样即能赚钱又能锻炼自己。 最后提一下，我知道一些人也想参与 Medium 的合作伙伴项目 (因为只有参加了这个才能通收稿费)，一个门槛是 Medium 现在还不支持中国的银行卡，所以就比较麻烦。我的解决办法就是找了个朋友，用他的卡帮我收😂。 我还是很推荐想学习英语或者写作的朋友多去 Medium 写写，不止有靠谱的编辑，也有很认真阅读的读者，即使不是为了赚钱也值得一试。","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"},{"name":"英语","slug":"英语","permalink":"http://catcoding.me/tags/%E8%8B%B1%E8%AF%AD/"}]},{"title":"你对世界足够了解吗","date":"2022-03-08T22:40:05.000Z","path":"p/weekly-4/","text":"我每周会分享一下我这周看到的好内容，加上我自己的一些个人理解和评注，这算是一种比较轻的持续输出方式。 #1 你可以创造运气 #2 好的抽象和设计就像积木 # 3 Basecamp 的小而美 这是第 4 期。 避免偏见这两周我看了一些非技术类的书籍和视频，我最推荐的是这本《事实》，可以说一定程度上改变了我的认知。 这本书是 2019 年出版的，书的开头有 13 个测试题，全都是关于这个世界的人口、卫生、收入、教育、环境等方面的认知测试，我的结果是做对了 3 个，这和大猩猩的测试结果一样。 很多人都是这样的测试结果，甚至包括那些专业人士和国家领袖。可以说我们很多人对世界的认识还停留在十多年前，和现实有着巨大的认知差异。 在很多方面，这个世界其实并没有那么糟，而是在变好的。 书中提到： 我最担心的五大全球性问题包括：全球性传染病、金融崩溃、世界大战、气候变化以及极度贫穷。 没想到才不到三年，全球性传染病这点应验了，而俄罗斯和乌克兰正在打战。可以看到网络上、现实中很多人都在为战争争论不止，很多人只相信自己所看到的。我在 Twitter 上看到有个人和儿子对此争论，因为儿子持有不同的立场就觉得永远地失去了儿子。 我推荐大家也读读这本书，在下结论判断对错之前，思考一下自己是否足够全面了解乌克兰、俄罗斯的历史，我们从媒体看到的是否是片面的。 这本书列举了一些方法来避免自己陷入偏见。为了让自己能够更好的理解这个世界，我们应该保持谦卑和好奇心： 保持谦卑，意味着要认识到我们的本能通常会妨碍我们认识到事实的真相。它意味着我们要认识到自己知识的局限性。它意味着我们应当很坦然地说“我不知道”。它还意味着，等你形成了一个观点之后，要随时准备接受新的事实来改变你的观点。 保持好奇心，意味着你应当对新的知识和信息保持开放的心态，并且积极地寻找新的信息。它意味着你能够拥抱和你世界观不符的事实，并且可以努力去理解它们背后的含义。 主要作者汉斯·罗斯林在该书接近尾声时因病去世，遗憾。 帝国的兴衰这周我还看了《原则》作者 Ray Dalio 的一个非常好的视频：Principles for Dealing with the Changing World Order，详细地讲述了帝国兴衰地规律。 也许我们真快到了一个历史节点： 一个 L5 自动驾驶的赌局2030 年自动驾驶 L5 能达到大规模商用么？ 这里有一个赌局 The 2030 Self-Driving Car Bet，参与者是 Stack Overflow 的创始人 Jeff Atwood 和游戏编程的大神 John Carmack By January 1st, 2030, completely autonomous self-driving cars meeting SAE J3016 level 5 will be commercially available for passenger use in major cities. Jeff Atwood 认为这个目标达不到，而 John Carmack 认为是可以的。这里 L5 的标准是驾驶者上车后除了指定目的地，驾驶的全程不用进行任何人工干预 (自然灾害情况除外)。 L4 标准：基本上驾驶就是车辆的事情，驾驶员只有在极端情况下才需要介入。目前已经有一些公司几乎达到了 L4 标准，但是没有出现大范围的商用，而现在更多的是辅助驾驶，像特斯拉这种。 经过这么些年在自动驾驶上的研究，目前看来完全解决自动驾驶比预期得要更难，比如Waymo’s Self-Driving Cars Are 99% of the Way There. The Last 1% Is the Hardest，这最后的 1% 解决谁也不敢大范围投入吧。 辞掉年薪 45 万美金的工作Why I Quit My Engineering Job (at Netflix) | Medium Michael Lin 是一个华人，他在 Netflix 工作了接近 4 年。大家都知道 Netflix 的工程师岗位只有 Senior Software Engineer 这个职级，但是拿的却是行业内的顶尖薪酬。 这位作者在 Netflix 工作了一年半以后，渐渐地对工程性的工作失去了兴趣。从他的描述看来，有很多复制粘贴的工作。看来架构太稳定就会出现这样的问题，什么东西拿之前的过来改改就可以了，工程师没有成就感😂。 里面有个细节，他爸妈是 70 年代去的美国，听到儿子要放弃高薪工作，感觉是浪费了他们那代的努力，看来这确实是非常典型的中国式家长： “Just keep your head down and do the work!” they said.“Don’t be ungrateful for what you have!” they said. 作者本身对产品方面的事更感兴趣，因此他尝试过转到 PM 的角色，但这在 Netflix 没有先例。如果对工作没有认同感，那自然就绩效越来越差。而且疫情的原因，导致只能在家办公，这样也没了办公室社交： And all you were left with was the work itself. So if you didn’t like the work, and that was all you had, COVID magnified this fact 10x more. 另外因为看到很多人死于新冠，这让他更加焦虑，觉得自己守着高薪浪费青春： I realized what the real cost to golden handcuffs was. The cost is your youth, your time, and your life. People don’t accurately judge these costs, because a salary is a hard number, whereas the value of your youth is more intangible. But just because something is hard to measure doesn’t make it any less valuable than something countable like money. It’s hard to measure the value of a brand, mental health, or love, but we know it matters. golden handcuffs 这个词很形象，一份高薪而不喜欢的工作就如金手铐。 不得不说，只有思考过死亡才会更加有决心追求真心想要的。钱确实很重要，但也不是最重要的。如果做一份工作确实难受，那就辞了吧。 辞职之后作者自己工作，做了一些视频相关的工具，还有在 Medium 上写作，兼职做 career coaching，这个活大部分来自这几篇文章。不得不说，写作真是非常重要！ 这篇文章写得非常棒，不管从写作技巧还还是内容本身都值得学习，推荐你读一下。","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"},{"name":"周刊","slug":"周刊","permalink":"http://catcoding.me/tags/%E5%91%A8%E5%88%8A/"}]},{"title":"谈谈工作中的犯错","date":"2022-03-06T20:08:05.000Z","path":"p/avoid-mistake/","text":"想到这个题目是因为最近我们组出现了一个严重的线上问题，某小哥在进行线上操作的时候传错了一个参数。这种问题在程序员这行很常见，所谓常在河边走，哪有不湿鞋。 工作这么多年我自己犯过错，也看到过身边的删库跑路案例，更有甚者因为泄露敏感信息而锒铛入狱。这里分享一些自己所见的真实案例，以及如何在编程上、工作习惯上避免犯错。 案例分享信息泄露大疆前员工泄露公司源代码，被罚 20 万、获刑半年，这个安全事故完全是因为员工的安全意识不足造成的。 这类问题非常多，不信你可以在 Github 上用 password、private key 之类的关键词搜索，很多人会无意识把这些敏感信息推送到 Github 上，而公司又没法完全禁止 Github，只能不断加强安全培训和监控。 从这个案例来看公司的损失非常非常大，单人力成本这块就难以估计，我也因为这个事故参与到了安全建设中，后面在这里领域工作了两三年左右。真是一人挖坑，无数人救火。 退款接口我在做支付、物流相关的系统时，曾经因为一个诡异的接口造成了直接上的金钱损失。 我们的支付是通过第三方支付系统做的对接，比如用户通过支付系统向我们预支付了 100 美金，等他收货后第三方把钱给我们。第三方支付有个退款接口，假设他不想要货了于是发起退单，我们的系统就会调用第三方的支付接口去退款。 因为接口有时候调用失败或者返回不及时，我在写代码的时候默认既然对方预支付了 100 美金，多次发起退款接口自然也没问题，所以我有一些重试的机制来确保退款成功。过了一段时间后发现账目上有点差别，后来经过排查是因为重复调用了退款接口，这个接口如果两次调用就会退给客户退 200 美金！ 最后我们只能发邮件给一些客户，说多退了钱，麻烦能退回来么，有的客户很好心就直接返回了钱。我记得有个客户回复说：我认为这是上帝给我的恩赐，对不起我已经花完了。 额，我就是那个可怜的上帝好么。 并发问题我前公司所在的部门曾经有个发货系统，当多进程跑起来的时候，有个并发问题没处理好，最终导致用户收到多份相同的货物。 当程序员经验不足的时候这种错误就很容易出现。代码中哪些部分是可以重入的，哪些部分需要加锁，都需要仔细考虑。但是在业务快速发展，快速堆代码的时候，我们可能不一定有足够的时间把所有细节都考虑清楚。 配置错误我之前出现过的一个最大的错误是因为配置错误。这件事我一直都记得，因为印象实在是深刻，现在对正则表达式都有所恐惧。 那天我正准备下班回家，我配置了一些安全上的防护规则。然后我的 Leader 说拦截的页面不够好看，我们要不统一个拦截页面。我想了一下觉得很简单，就准备在我们自己定制的网关 (Kong) 上配置一条全局规则，我想通过正则表达式把所有拦截页面 redirect 到订制的错误页面。 我通过后台 Admin 页面，在一个全局插件上写下了一条正则表达式，提交生效。然后立马就收到了报警，大量系统同时报警！因为有公司很多域名的请求都通过这个网关，而我配置的正则表达式嵌入到 Lua 代码中后有语法错误，导致所有系统的路由处理时都报错。 最要命的是我们的 Admin 页面也会经过这个网关，所以 Admin 页面也没法访问了，意味着我无法通过页面去回滚配置！我当时已经手心发汗，如热锅上的蚂蚁了。强迫自己镇静下来，马上修改插件的代码，赶紧让运维一起迅速地更新服务器上网关代码。 整个过程大概花费了 20 分钟，这期间整个公司估计有一半的系统都是不能访问的，包括那些官网、商城等。 经验总结犯错并不可怕，只要是个人就可能会犯错。出现错误往往也不止是个人的问题，也意味着团队有问题，比如对代码质量要求不够，系统设计不够容错，权限划分不够好，安全机制不健全，没有 代码 Review 等等。错误是个人和团队最好的学习、提高的机会，而且我们已经交了学费。 但是随着我们成长，最好避免个人犯一些低级的错误，特别是安全类的问题。写程序、做系统设计的时候就做好防御，把犯错的概率降低到最小。 防御编程 面包落地的时候，永远是抹黄油的一面着地。 上面配置的问题，我在做网关的时候其实意识到了潜在风险， Admin 路由也经过自己控制那出问题不就嗝屁了吗？当时我自我安慰只要不对这个路由开有问题的全局插件就可以了，所以没有及时处理这个风险，最终导致自己掉入坑里。 当系统中存在潜在问题时，时间一拉长出现的概率就大了。因此我们编程的时候总要有意识想最坏的情况是什么，哪些是危险操作，比如写数据如果没写入成功会怎样，如果并发运行了会怎样，如果文件错误会怎样，这就是防御式编程。 做系统设计时，要考虑敏感的业务逻辑如何测试，如何在系统层面规避错误。对于敏感的资源一定要再从统计的角度进行复查。像我那个退款的问题就是对潜在的风险意识不够，想当然地对接口进行了错误的假设，而对方这个接口不是幂等的。后来我们在系统中加了很多检查，确保及时代码有问题也能尽早发现问题。 如果系统对正确性要求高，必须加大量单元测试和集成测试，并且每修复一个 Bug 都引入对应的测试，因为随着代码的不断演进，没人能保证新加的代码不会破坏掉原来的代码。测试能最大程度自动化地帮我们发现一些潜在问题。 我工作的第一家公司是做 EDA 相关软件的，因为 EDA 软件不像互联网这样的系统，crash 了就是发生在客户的机器上，很多时候都没法 debug，因此公司对代码质量要求极高，他们在自动化测试这块就做得非常棒，测试覆盖率几乎 100%，还有很多 fuzzy testing。 代码上的问题没法完全避免，那如何减少风险？微软有个实践就是大量运用 killswitch，本质上就是开关，每个新加的功能和代码，建议都是加上类似这样一个嵌套： if(!killswitch-active(uuid)) &#123; // your new code ...&#125; else &#123; // old code ...&#125; 这样的好处在于如果新的代码出现了问题，可以迅速把对应的 killswitch 打开，这样老的代码就继续跑了，也就是不用发新版本就能快速回滚。不得不说这个办法虽然有点土和笨，但是非常有用，因为这也救过我，而且让人发代码压力不至于那么大。坏处也很明显，当 killswitch 多了之后代码就很难读，所以要去定期清理那些老的开关。 工作经验丰富一些了之后 (掉入坑里足够多次)，自然会对容易出现问题的部分有风险意识，这需要不断积累和总结。 工作习惯安全是第一位的，我们在工作中对敏感信息、公司资产要有一定的安全意识。完全按照公司的安全准则来工作，否则提桶跑路可能是小事，被追究法律责任就麻烦了。 任何线上操作都是危险的，如非必要不要进行手动的线上操作。操作的时候尽量慢，然后想清楚如果错了如何恢复。比如删东西尽量软删除，把要删的东西移动目录或者设置状态。 如果一个动作是有危险的，应该思考如何把这动作自动化，如果是必须有人给输入，那需要一定的流程来进行 Review 和批准。 微软还有个好实践就是所有的线上命令，如果是写入型的命令默认不能运行，需要手动地运行命令提升权限。 运维方面，如果有条件和时间尽量往 Infrastructure as Code 方向上靠，减少人工进行操作。 写到最后，觉得写得不够系统和全面，这个题目范围太大，开发、运维、规范、安全等很多方面都涉及到，而且有很多细节问题。 一句话建议是：保持对工作的敬畏之心，特别是你的代码和工作会影响到很多用户时，即使一个小的错误也会造成大量损失。 先这样吧👻。","tags":[{"name":"编程","slug":"编程","permalink":"http://catcoding.me/tags/%E7%BC%96%E7%A8%8B/"},{"name":"经验分享","slug":"经验分享","permalink":"http://catcoding.me/tags/%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB/"}]},{"title":"Basecamp 的小而美","date":"2022-03-02T22:45:08.000Z","path":"p/weekly-3/","text":"我每周会分享一下我这周看到的好内容，加上我自己的一些个人理解和评注，这算是一种比较轻的持续输出方式。 #1 你可以创造运气 #2 好的抽象和设计就像积木 这是第 3 期。 Basecamp 的经验10 Things I’ve Learned | Jason Fried at BIG Omaha - YouTube Basecamp (37signals）为人所知主要是因为《重来》这些书籍，Ruby on Rails 的创造者 dhh 是这公司的主要布道者，而 Basecamp 的创始人就是 Jason Fried。 这是个独特的小公司，刻意地慢慢发展，在产品做少做精，每周工作 4 天，居然滋润地活了 23 年了，2014 年就创造了高达 300 万美金的年人均营收（同期 Google 为 123 万美金）。 在这个视频中 Jason Fried 谈到他做公司和产品的一些经验，这些很多内容和《重来》有些重复，不过这个演讲还是很值得看看，Jason Fried 的演讲能力非常出色。他主要分享了这么几点： Bootstrapping company : bootstrapping 是编译里的自启动，作为公司来说最好从一开始就考虑如何挣钱，如何养活自己，而拿投资意味着从一开始想着的就是如何花钱，拿投资是为了快速发展，公司太快有很多事情会想不清楚，而且后面会有被资本控制的风险。 Price : 现在免费的东西太多了，不要总是免费，收费会让紧紧盯住自己的核心业务，而且收费后反而从用户那里获取到更有价值的反馈，因为用户付了钱，所以会在意。 Innovation is overrated, useful is underrated ： 做产品不能总是追求时髦和创新，很多时候可用性才更重要。 Focus on what won’t change in your business ：对于 Basecamp 来说，简单、快速、可靠这些是最重要的，这些也许并不新潮，但从长远来看这些才是能得到回报的。 DIY ： 自己理解不够的岗位不要盲目招聘。如果想招人，先自己尝试做一段时间这个岗位，比如 dhh 兼职做了两年的系统管理员。只有自己做了才知道如何面试，以及如何衡量这个岗位的工作成果。 Draw a line on the sand ：公司不能什么都做，要对很多事情说“不”。 Sell something, listen to the customer what they care： 这里演讲中举了他自己卖球鞋的经历，非常贴切。永远关注用户的需求和用户的在意点，做产品不能自嗨。 Do less thing, do something really good : less is always the option, less feature, less people。一个产品有很多功能，但是每个功能都不出色，这会很难卖，而且工作量也会大。少做，但是做精。 同样的道理，公司并不是人越多越好，人少就会少很多管理工作。37signals 成立于 1999 年，到 2009 年即使用户规模扩大了很多倍，员工人数在 10 个左右。 小而美的公司曾经是个热潮，国内也出现过类似做 Basecamp 这类产品的公司，只是发展到后来都逃不过被收购的命运，比如 Teambition 2018 年被阿里收购，Tower 2020 年被收购。 我认为用户付费意识是个方面，还有些其他复杂的原因。Basecamp 的经营理念在国内就不一定行，至少在 SaaS 这个领域国内的用户不那么信任小公司。 小而美的公司不止输出产品，更会输出不一样的理念和想法，比如两个人的公司 flomo，大家可以看看 flomo 的经营理念。这种独特的声音会吸引认同这种理念的用户。 如何找到你真正想要的工作How to land the job you really want (hey.com) 还是 Jason Fried 的博客文章。Jason Fried 基本每周左右会写篇博客，而 dhh 基本每两天写一篇。Jason Fried 的博文相对好读很多，而 dhh 的文章涉及面很宽泛，有的读起来会难懂一些。 最近的这篇文章中介绍了 Basecamp 从 400 多个应聘者中招了一位 Email Marketing Manager 。这位应聘者特别用心，做了一个非常好、独特的求职信和简历 Meet your new Email Marketing Manager。这封信和简历几乎让人无法拒绝这位候选人。 这真是个非常好的思路，好的工作通常竞争激烈，我们想要脱颖而出可以详细地说明对这个岗位的理解，对公司文化、产品的理解，以及自己已经为这个岗位做了哪些努力和成果。 求职信在国内很少见，一份用心写的求职信我觉得还是能加分不少的。 Lisp 生产环境运用Running Lisp in Production | Grammarly Engineering Blog Grammarly 使用了很多种编程语言，比如 Java、Go、Erlang，在一个公司使用多种编程语言可能是一个技术债，最好使用语言无关的基础工具 (language-agnostic infrastructure tools)，比如 StatsD、Graylog2。 我倒是没看出来 Grammarly 的 core grammar engine 为什么非用 Lisp 。后面提到了 Lisp 提供了一些非常独特的开发和调试体验，用 SLIME 这样的工具可以在远程起一个 console 来进行任何代码上的操作，trace 可以很好的帮助调试。 这种体验在 Clojure 上开发也有，REPL (Read–Eval–Print Loop) 确实是那种很不同的编程体验，想了解更多可以看看这篇文章：Val on Programming: What makes a good REPL? 另外，我也才知道 Grammarly 是一个乌克兰公司。 其他Things that used to be hard and are now easy 这些事几年以前很难，现在已经变得很简单了。 💻📖对开发人员有用的定律、理论、原则和模式","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"},{"name":"周刊","slug":"周刊","permalink":"http://catcoding.me/tags/%E5%91%A8%E5%88%8A/"}]},{"title":"程序员如何做副业","date":"2022-02-27T19:28:05.000Z","path":"p/side-hustle-for-programmer/","text":"有些人问我程序员如何做副业。我有一些经验，但是并不算很多，因为我自己也在摸索中。我做过的副业包括： -【一年】自建英文站点-【两年】在 Medium 上写作-【半年】写开源代码 下面我谈谈自己的一些思考和理解。 为什么做副业我认为主要有以下几个好处： 副业是一个备用选项，可以让我们尝试如何能不依赖组织，自己创造价值、自己摸索出一条业务。 副业可以多方面发展自己，因为在公司做可能只是涉及某一方面，做副业可能涉及到如何找需求，如何营销，如何谈价，如何保持收支平衡等等各方面。这也许是创业之前的尝试。 如果想多赚钱，给公司打工明显是一个慢车道，在慢车道上你不容易撞车，也很不能很快到达财富自由这个目的地。注意，这里的财富自由不单指赚很多钱，还包含那种被动收入能满足所需，这样也算自由了，有的人想搞些副业也是为了追求这种自由。 兴趣，很多人发展副业完全是因为兴趣爱好，愿意投入时间在自己感兴趣上的事上。 总而言之，副业是一种相对小成本的方式来做各种可能性尝试。 副业不是刚需副业听起来很美好，那是否所有人都应该去做副业？特别是疫情这样的灰天鹅事件出现以后，人们发现工作是很没有保障的，有些人甚至喊出了刚需副业，副业比主业更重要这样的口号。 我们网络上看到的教你月入多少、保证你能做成的 99% 是收割智商税，一定能挣钱、好挣钱的事谁还拿出来教别人？ 实际上很多人也不适合做副业。 如果你处于刚毕业没多久，事业处于爬坡期，那就好好拼一把主业，不管是从专业技能还是业务方面，多投入时间提高自己，副业也可以关注，但是不要花太多精力，因为这可能会影响主业。 任何行业都需要一定时间的积累，如果还没做好积累就花时间做积累，副业以后再考虑。 另外，如果主业工作已经很忙很累，这种情况做副业只会更累，对身体不好，而且更多的结果可能是两方面都没做好。如果真想做副业，那就得先换工作或者用其他办法让自己有空余时间。我上一次换工作，有一部分原因就是我需要把主业所占的精力和时间降低。 如何做副业所以，副业的前提是： 有时间和精力来折腾 自己的主业进入了瓶颈期和疲劳期 有些想法，有感兴趣的领域，想做点尝试 下面我们谈谈一些可能的副业，以及我自己的思考。我没法告诉你一个具体能做成的副业，或许能给你一些启发。 个人品牌现在有了个人品牌才可能得到流量和注意力，这是很多事情的开端。当然你也可以一开始就买流量，这就需要金钱上的投入，也很难保证转化率。长期来说，个人品牌的经营绝对是有益的，本质上是你需要通过互联网建立起和他人的信任感。 现实中很多副业不是自己找到的，而是别人通过你的个人品牌找到的。因为现在大家在网络上的时间太多了，个人品牌就如同你逛街看到的广告牌。有了个人品牌别人会向你发问，你只要能帮忙解决掉别人的问题，就会有收入。 有非凡成就的人自带个人品牌，而如果是平凡人，可能需要常年累月的积累和主动输出。 我在知乎上混了 10 年 (回答问题不多🤣)，才积累几千关注者，我在 Medium 上写了两年才积累 2 K 左右读者，爆火的公众号仙人 JUMP，写公众号之前已经写了 10 多年网文。 虽然如此难，但是个人品牌的建立任何时候都不晚，因为大多数人都不会去输出，而做了的大部分人都不会坚持。 我最近半年经常看一个推主 @coolXiao 的推文和文章，他也是中年突发想做点新的尝试，我觉得这点说得很有道理： 想通了这点，就可以解决一些困惑，比如现在公众号已经是红海了，还有必要投入吗？ 市场上大多数人都是信息的贩卖者，原创者很少。所以如果是打算做原创，并且要创造出比其他人更好的同类内容，那什么时候进场都不是事。如果是打算学着做，红海不红海更没有关系。 当然，网络上的爆红也有些偶然因素，但不去尝试那是更没有可能性。 提供服务给他人提供技术咨询，这类活也通常需要一定人脉积累和个人品牌。如果你做到某个领域优秀或者顶尖，就不缺这类机会。 还有其他类的服务，比如内推这类事情就是顺手一做的事情。现在内推这行也很卷了，比如有的人做个网站，上面全是各公司的面试题，然后顺带内推。内推说白了是兼职 HR 和猎头，是一个投入可大可小的事情。 去接平台接项目也算是一种服务，接项目不是一种好的副业，因为通常你接到的项目还抵不过公司给的时薪，而且更大的问题是不够稳定。除非是极少的个别项目，但这种项目投入的精力和时间也多，这里面还得涉及谈价，收款等麻烦事。所以如果你的技术能力在市场上都拿不到稳定的薪水，去做这类外包就更难应对，不如提高能力先拿到市面上的较高薪。 国内的那些外包平台我不看，国外也有一些平台接外包项目，一上去就可以看到一群印度人和你竞争，而且你可能并不占优势，因为人家英语溜、开价低廉。 接项目这事终究还是出卖劳动力，和在公司编码一样的，一次性投入一次性产出。我也还做了点在 Github 上做收费开源的这类活，因为我刚好对那个领域有些兴趣，比如我帮公司做的 second-state/dapr-wasm 。 提供服务不一定是技术范围内的事，我有个前同事得副业是做咨询教练，为此去考了相关的教练资格证。 数字资产创造个人的数字资产，这是一个不错的方向。写个软件，做个网站，制作课程，拍个视频，写些文章，都可以称之为数字资产，这些也是通常我们程序员最容易想到的方向。 数字资产的好处是可以多次销售和贩卖，也不像传统产品有囤货的压力，同时也可以顺带做个人品牌。 现在随便做个网站、APP 就能发财的事越来越少了，需求越来越细分，做的事情越来越垂直。作为程序员在这块我们有优势，我们有开发技能，有领域内知识，但领域外知识和技能需要自己补充，比如发现需求、推广能力、写作能力等，所以能做成稳定副业的少之又少。 我们可以看看思否的关于独立开发者的统计数据，2020 中国独立开发者生存现状调研报告 ，我不确定这数据是否真实： 程序员做开源也可以算作是数字资产，如果你的代码被足够多人用到，就有机会获得赞助，比如这位中国开发者 egoist 。 我认为自己在线公开写作创造的也是数字资产，还有一定复利效应，参考 我如何写出一万元的文章。 发现机会我之前大疆的一个同事，从外表看起来他是最老实的工程师，每天兢兢业业完成工作，看起来无欲无求的那种。 突然某天他要离职了。我后来才知道，他在大疆工作时就开始通过网络做无人机的返利推广。 大疆有一个类似推广返利的项目，别人通过他的链接购买了商品，他就可以拿到一定比例的返利。他做的事情就是把自己的推广链接放到百度问答，一些论坛之类的地方，当大疆发布新机的时候，一个月可以赚上近十万。他边工作边筹划着副业，顺便做个小网站。具体故事请参考我是如何凭借大疆无人机的风口开上特斯拉的？ 后来他离职自己做无人机自媒体，然后开始接货卖货，完全成了自由职业者。最近和他聊了一下近况： 要发现机会需要平时多观察、琢磨和积累，我在大疆的时候写这个推广者联盟的代码，但是我并不太懂网络营销，对无人机也没什么太大的兴趣，所以即使我知道这东西能赚钱，但是我没捞上一分钱。 程序员通常最容易出现的问题是被技术视野限制，很多时候了解行业外的人和事，不要总是局限于技术，也许会有更多机会。 被动收入这是一种很好的模式，因为这可能会让我们从无尽的工作中逃离出来。被动收入虽然听起来美好，但非常难，因为正常社会需要绝大部分人来搬砖保持运行，如果大家都被动收入了谁来不断创造？ 投资是常见的制造被动收入的方式，用钱来挣钱。但是投资也有风险，还依赖本金的大小等因素。 还有一些是半被动式收入，比如写作，我写的时候收入高一些，我不写的时候之前的作品也还在被浏览，只是会少很多。 我们如果用英文 Passive Income 去搜索，发现很多人在做的是刚才我说的返利，就是 Affiliate Marketing，这是世界上很好的一种模式，谷歌加上亚马逊返利项目，养活了世界上无数的中小网站。 很简单，亚马逊返利就是别人通过你的链接购买了东西，亚马逊给你一定比率的返利。Google 可以给高质量内容带去流量，所以很多人做 Google SEO 优化，很多人做内容优化，争取到 Google 的第一页。这种模式对用户、Google、亚马逊都好，用户获得高质量内容和返利，Google 获得用户信任和高质量内容，亚马逊获得流量和营业额。但是在国内为什么中小站点无法获取流量呢？因为国内某搜索引擎作恶了。 我自己也很快地走通了这个模式，比如在 Google 上搜索这个关键词，我的页面排在第三位，我的文章里就有亚马逊链接。 我放的链接不多，而且我的网站流量也不算多，但我已经可以每个月收到一笔钱，而我的这个网站的投入是多少呢，日常就是五美金一年，我的内容放在了 Github Pages，所以不要服务器的费用。 Affiliate Marketing 难的是如何找到合适的利基 (Niche，细分领域)，并在这个领域把这一套打通。 当然，做 SEO 这些早些年可能更流行，现在这行很卷，要通过高质量内容拿到 Google 排名不容易。Google 还是非常的强大，可以判断出低劣的、抄袭的内容。目前我们看到很多计算机类的技术网站，其实是印度人做的，我和 Reactgo 的作者之前交流过，他说 geeksforgeeks 这类站点非常赚钱，印度人还是有些人在以 blogging 为生。 Affiliate 如果在某个垂直领域做好了，这就是一个造钱机器，深圳就有一些以这种模式作为主要收入方式的人，只是具体别人做哪个垂直领域，细节方面不会分享出来。中国人在这块天然处于劣势，因为英语会阻拦掉很多人。 另外一种被动收入就是把数字资产和流量结合起来，比如我之前分享过的亚马逊工程师写 AWS 电子书，自己贩卖。 制造被动收入的关键是把整个流程打通，这样当你睡觉，吃饭，带娃的时候，整个系统都在运行和赚钱，不用一直投入时间和精力。 当然整个过程会很漫长，而且拿到流量，建立信任，制作内容每一个都是不简单，如果一个人能做好，活该他赚钱和获得自由。 总结也许还有其他副业，比如投资之类的，我没有谈及，因为这些我不太了解。 我认为好的副业不是再次出卖劳动力。好的副业需要类似创业者的某些素质，这包括： 某领域内的顶尖，多个领域的知识和能力 对某领域的兴趣和爱好，长久的坚持 发现机会，发现真实问题和需求，提出解决办法 技术通常不是最重要的，重要是有效地解决问题和满足真实世界的需求。 如果还不清楚自己想做什么，可以先从建立个人品牌着手，或者其他任何有复利效应、能复用自己的优势和资源、或者能提高自己的事情，很多事做起来了才能有些新想法。 副业可能是为了挣钱，自由，探路，兴趣等等。做得不好也不必焦虑，上班低头做事，副业抬头看路，带着一种探索的心态来做副业就很好。","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"},{"name":"副业","slug":"副业","permalink":"http://catcoding.me/tags/%E5%89%AF%E4%B8%9A/"}]},{"title":"好的抽象和设计就像积木","date":"2022-02-24T10:38:06.000Z","path":"p/weekly-2/","text":"这是我的 Newsletter 第 2 篇。 我很喜欢玩乐高，我发现很多好的抽象、设计的使用体验就像玩积木，比如现在这些迅猛发展的云服务、比如 Notion。每个组件都不复杂，掌握规律后很容易组合成我们想要的作品。 云服务架构节省成本 以不到 400 美元处理每月 80TB 和 500 万的访问量 How we handle 80TB and 5M page views a month for under $400 – Poly Haven Blog 云服务这些东西用起来虽然方便，但是很容易出现资源浪费。我之前的公司一直使用 AWS，后来管理层觉得钱花得实在有点多，后来我们部门稍微优化一段时间，成本降下 1/3。 这篇文章详细讲述了 Poly haven 如何通过各种云服务来应对大量数据请求。 Poly haven 是一个专门用来让游戏开发者共享资源的网站，比如模型、纹理等等。这个组织非常透明，他们接受捐赠，然后把所有的花费都显示在个页面上：Finance Reports • Poly Haven。 节省成本的方法简而言之就是缓存一切能缓存的东西，让缓存的命中率尽量地高。 缓存主要使用 Cloudflare 当 CDN，Cloudflare 和用来替代 S3 的 Backblaze 之间有流量联盟，一起用的话存储就不要钱了。 Google Firestore 用来作 Database，Vercel 用来跑 Web Server，系统中还有个 Vultr 服务器专门跑 API。我觉得这个 Vultr 跑的 API 是不是可以换成 AWS Lambda 一类的东西？至少没有单点问题，不过费用上不知道会不会更贵点。 顺便分享一下，我最近把自己的站点从 Vultr 迁移了出来，因为我的服务器跑了很久了，一个偶然的因素我重启了一下服务器，然后就 …… 再也起不来了，我的网站也处于停服状态。 我立马给 Vultr 发个 Ticket，这是我得到的回复： 我看了头大，一狠心就往 Github Pages 上移。过了不到一个小时他们客服问我解决了么，我回答说：Yes, What I’m doing is migrating to Github Pages, and I’m almost done. 原本我认为搞什么 ssl 证书会麻烦点，没想到 Github Pages 已经和 Let’s encrypt 集成了，不用管服务器真是香！ 未来做业务的大部分公司，可能更需要的是对各种云服务非常了解的架构师，这种架构就有点类似自由式乐高，我们需要对组件了如指掌才能搭出节省成本的作品。 Notion 创始人的一个访谈Notion CEO Ivan 专访：即使不会编程，人人都可以成为工作达人 - Linmi Notion 的“积木感”在于页面无限嵌套，也在于一个简单的 ‘/‘ 让你选择下一个零件。 Notion 是由华人 Ivan 创建的，好像很多人都不知道这点，毕竟大家都还在吐槽 Notion 的中文支持得不够好和国内访问都不稳定。 这是创始人 Ivan 两年前接受韩国媒体的访谈，如果你对 Notion 感兴趣应该去看看。其中谈到了 Notion 的设计原则： Q：有人说 Notion 简洁和直观性和苹果公司很像。 A：简洁是 Notion 的重要价值。用户们应该感到轻松和易于操作。品牌也是如此，我们希望用户想到 Notion 的话就能想到‘铅笔’。要像身体的一部分一样，成为自然而熟悉的工具。即使不会编程，也要让每个人都能直观地用鼠标解决所有问题。我们觉得自己是制作工艺品（craft）等工具的艺术家。 Q：Notion 的简洁感的哲学基础是什么？ A：我出生在中国，儿时移居加拿大。所以很熟悉东亚的儒学。Notion 的设计和开发哲学也与‘中庸’的概念有着深刻的共鸣。比起过分强调功能或追求变化，更保守地包含了克制。比起华丽，我们更愿意把注意力集中在本质问题上，我们提供有需要的东西用在很多人遇到的共同问题上。 2013 年，曾是 Zhao 的朋友的 Simon Last 在美国旧金山创立了 Notion 公司。最初开发的项目是‘代码制作应用’，但最终还是失败了。他回忆道：“当时只集中于想展现给世人的东西，但并不知道世界想要什么”。之后，他于 2015 年和 Last 一起来到日本东京并在那里停留了 1 年，构想了现在的 Notion。他在解释选择日本的理由时说：”需要一个语言不通的地方来一整天的集中精力去编程。” 我的感受是，很多好的产品都是非科班出生的人创造出来的，他们可能是学艺术、设计、心理学的等等，而经过了科班训练的人似乎更难找到世界的真实需求，大概是因为很多时候大家在拿着锤子找钉子。 这让我想到吴军地浪潮之巅里描述到的 ： 一个进入了麻省理工学院的高中毕业生很明确是为了学习理工的，而他们周围的同学也是如此。这些年轻人在一起不断交流，彼此在技术上越来越精深，内境逾宽、外延逾窄。 我和麻省理工学院的一些博士生谈论过各种浏览器的好坏，他们不和你谈微软的 IE 或者 Mozilla 的火狐，而是 Unix 用户更常用的字处理器 Emacs 下一个很小的浏览网页的功能，这个东西不仅不好用，而且在全世界用它的网民连万分之一都不到。他们和你谈的是里面技术上谁实现的好。 这些人以后可以是很好的科学家和工程师，但是很难创业。 Linux 复杂么 Why is Linux so complicated? - quora.com Linux 为什么如此复杂？这个 Quora 回答得很好，Linux 对比起来可能没有大多数用户熟悉的 GUI，命令行需要一段时间来学习如何使用。 但这只是表面的复杂，在内核设计上 Linux 相比 Windows 更简单。这是 2008 年某个安全人员绘制的 Windows 上运行 MS web-server (IIS) 和 Linux 上运行 Apache 的函数调用图： 如果这是积木说明书，我当然更愿意玩第二个！ 其他huacnlee/autocorrect: 我的文档里中英文之间必须加空格，如果你也有这种偏执的话就试试这个工具。我把这个工具加到了 CI 里，这样我发布的文章都没有空格问题了。 Tailwind CSS Tutorial - YouTube: 学习 Tailwind CSS，这周我看完了这系列视频。在这个视频里作者从开始如何安装介绍，做了一个食谱的前端页面，过程非常详细。我理解 TailwindCss 主要还是一个更好用的原子化 CSS，感觉用起来很方便，借助 VSCode 的补全，用熟了会很有效率。 程序员做饭指南 | HowToCook : 偶然发现我司这位同事维护了一个程序员做菜指南，这段时间突然就火了。去年我去玩过他放在办公室的微软模拟飞行器，他还给我好好上了一节飞行课。他对飞行了解好多，讲解非常非常详细，他还考了一些飞行相关的证书，没想到对做菜也这么痴迷。这个 Github Repo 真是程序员居家办公，解决日常饮食的好手册🤣。","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"},{"name":"周刊","slug":"周刊","permalink":"http://catcoding.me/tags/%E5%91%A8%E5%88%8A/"}]},{"title":"深圳 WLB 的 IT 公司","date":"2022-02-20T22:18:06.000Z","path":"p/wlb-shenzhen/","text":"我之前在深圳待了 6 年，前两年打算换工作的时候居然找不到什么 WLB 的企业。 后来通过一些朋友介绍、自己平时的关注了解到深圳还是有一些工作不累的公司。不过从数量上来说比北京、上海少很多，主要是 IT 类的外企相对较少。 下面这些公司我有认识的朋友在里面，如果你对这些职位感兴趣请联系我，我帮你对接内推！ NvidiaNvidia 是老牌外企了，这些年随着 AI 的发展势头也不错。 我之前不知道 Nvidia 在深圳有个分部，前一年有个学弟进去了。里面做基础设施、Web、或者 AI 方面的职位都有。 Nvidia 是典型的外企，肯定是不怎么加班。我那个学弟通常一周两天去办公室，其余时间在家，据他说工作氛围很好，可以安心做做技术。 Nvidia 职位列表 crypto.comhttp://Crypto.com 成立于 2016 年，总部在香港，全球各地都有员工。这公司的愿景是希望能加速全球经济对加密货币的转型。主要产品包括：以加密货币购买、出售和支付的平台钱包，以及没有年费的金属卡 MCO Visa 信用卡，现在也在做一个公链。 看起来这个公司近些年发展挺快，crypto 不缺钱，去年年底拿下湖人队球馆 20 年冠名权！ 有个朋友在里面，据说不卷，而且可以远程办公。 crypto 职位列表 ，目前在招的有后端开发 Go/Java/Ruby/C/C++/Rust 等。 Shopee我有很多前同事跳槽去了 Shopee。 Shopee 是否卷得看组，现在据说腾讯去的管理者很多，有些部门也比较卷。所以如果想进去得看准部门和领导，可以通过内部的员工了解一下。 深圳虾皮信息科技有限公司 - 社会招聘 (mokahr.com) AfterShipAfterShip 是做全球物流 SaaS 的公司，除了物流他们也在拓展其他相关业务。我最初知道这个公司是因为左耳朵耗子的一个朋友圈介绍，据说里面工程师氛围比较浓厚。 AfterShip 严谨实施敏捷的那套开发流程，不至于卷。去年 Go 夜话的组织者也加入了 AfterShip。 AfterShip 招聘/社招/校招 - we’re hiring 以上就是我目前了解到的一些 WLB 深圳公司。 也许还有其他的公司，比如微软在深圳只有少部分硬件部门，Apple 据说在深圳有部门，SnapChat 在有个深圳小分队，Flexport 等，但我不太清楚这些公司的具体情况。当然还有一些大公司，里面有一些组氛围好，工作也不累。如果你知道更多深圳 WLB 公司麻烦告知我一声！ 在深圳虽然工作压力比较大、大家都挺忙这两点外，我还是很喜欢深圳的，气候宜人，城市年轻有活力。","tags":[{"name":"职业","slug":"职业","permalink":"http://catcoding.me/tags/%E8%81%8C%E4%B8%9A/"}]},{"title":"你可以创造运气","date":"2022-02-17T14:04:05.000Z","path":"p/weekly-1/","text":"我在之前的更新计划里提到过想尝试周刊这种方式创作。大概就是每周会分享一下我这周看到的值得分享的内容，加上我自己的一些个人理解和评注。这算是一种比较轻的持续输出方式，我自己平常也会阅读一些这类文章，我觉得有收获，所以我要试试。 好吧，这是第一次周刊型文章。 创造运气How to Create Luck (swyx.io) 2016 年左右我在深圳一个饭局上，某大佬给我们介绍比特币和以太坊，我们那桌 10 个左右同事只有 1 个人买了点，而且他在大涨之前又卖掉了。有时候我想，运气虽然称之为运气，也与个人有很大关系。我们大多数人好像对新鲜事物的好奇心还不够，或者是没有去实践，去折腾。 Shawn 的这篇文章解释了关于运气的各种理论和行动指导，还真有一些人严肃地做了一些关于运气的研究： Binary Luck： 二元性运气，比如有的人就生在罗马，含着金钥匙出生。这种没法改变，有就是有，没有就接受。 Luck Surface Area： 运气表面积？这个理论阐述的是运气对每个人是公平的，只有扩大自己的运气横截面积，才能让自己运气更好。简而言之，我们需要做更多，并且把自己做的事分享出来。 这幅图是不是很好理解： 更细化地我们可以培养这些习惯，使用这些策略来创造运气： 探索、尝试、折腾、模仿 精通某领域 经营个人品牌和人脉 保持好奇心和观察 花 3 个月破解硬件找回 200 万美金How I hacked a hardware crypto wallet and recovered $2 million - YouTube 这个幸运的男子几年前买了一些数字货币，后来这个币大涨，价值 200 万美金，他的私钥存在一个移动数字钱包里，要命是他不记得 PIN 码了。 眼睁睁看着这么一个小小的硬件里存了 200 万美金，而不能拿出来花是什么感受？ 如果输入密码错误次数太多，钱包会自动删除里面的内容。 幸好硬件黑客大神 Joe Grand 花了近 3 个月时间，外接线路、反复启动钱包、制造噪音 (glitch)、让钱包进入 Debug 模式、然后从 RAM 里读出所有信息、找到密码👏。 这个 Youtube 视频的观看次数已经达到 400 万次，扶墙推荐你去看看。 这位独立开发者几乎做错了所有事8 万变 80 万 - V2EX 原文表达不太好，可以大致浏览看看。 任何人的努力和梦想都值得鼓励和尊敬，但是当我看到这个人的创业历程后，我真觉得他几乎做错了所有事，除了坚持。 另一个感受是，如果初入一个行业需要敬畏之心，不要太过自信，觉得什么都看起来容易。 这位开发者之前教书的，有些开发经验，但没有 IT 行业从业经验，他竟然从学习各种技术栈、设计、一直实践到了去注册美国公司运营，而做出来的东西质量上是半成品…… 关键是在 35 到 40 的这个年龄段这样折腾了 5 年，让家庭生活在困难之中…… 创业不要冲动，尽早做出 MVP 版本，小步快跑，在没找到确定的盈利模式之前节省开支。这位推友总结得非常好：十个错误 白宦成： 在 V2ex 看到一个独立开发的哥们，只能说，读书少确实害了他自己，做错了几乎所有事情。得亏是有个好的老婆和岳父，能坚持到现在。 独立开发并非毫无指南，多读书，多看报，会少踩很多坑。不要踩别人踩过的坑。","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"},{"name":"周刊","slug":"周刊","permalink":"http://catcoding.me/tags/%E5%91%A8%E5%88%8A/"}]},{"title":"我的 Obsidian 使用经验","date":"2022-02-15T10:58:30.000Z","path":"p/obsidian-for-programmer/","text":"今天给大家分享一下我如何使用 Obsidian 来管理笔记和提高效率。 Obsidian 是什么Obsidian 是一个笔记软件，可能很多人还不知道这个工具，因为相对来说比较新，2020.5 才出第一个 Beta 版本。 创始人是一对小情侣 Shida Li 和 Erica Xu，还有一对可爱的猫咪。 我有点八卦啊，所以随便查了一下两位小朋友的背景，应该都是从小在加拿大成长的华人，上的大学都是 University of Waterloo。这大学的计算机非常有名，以培养学生动手能力著名，本科毕业前两年可以去很多大公司实习，所以对学生找工作非常有帮助。他们俩做出 Obsidian 之前已经折腾过了 10 来个副业项目，都是类似笔记、工具类的东西。所以，成功不是随便就能达成的。 Obsidian 的特点现在笔记软件满天飞，为什么我选择 Obsidian。我认为 Obsidian 是特别适合程序员的笔记工具，可以称之为笔记 IDE，其特点是： Local-first and plain text Link as first-class citizen Make it super extensible 这三个特点使得 Obsidian 变得独特，Notion 之类的不是本地化的，Roam Research 也不是本地化的，唯一和 Obsidian 有些类似的是 Logseq，而 Logseq 的插件系统应该是还在打磨，并没有形成 Obsidian 这样的生态。 我的主要使用场景基本编辑Obsidian 用来编辑 Markdown 非常舒服，目前也支持了 Typora 那种实时预览的编辑方式。代码高亮没问题，贴图没问题，公式也可以支持，这些基本的东西默认已经足够好用。 通过一些插件的协助效率更高。我自己比较喜欢的插件是这些： obsidian-various-complements-plugin，这个插件用来自动补全很多东西，这是一个日本人在维护的插件，issue 反馈很快。我在使用过程中也对这个插件做了一些贡献：自动补全算法。 cMenu-Plugin，在编辑页面加一些常见的 Markdown 格式按钮。 obsidian-excalidraw-plugin，可以用来在 Obsidian 上画 excalidraw 格式的图，这是我最喜欢的画图工具，因为可以画出手绘风格的图。 还有些其他的辅助编辑的插件，大家可以自己去摸索。 Daily Notes打开核心插件 Daily notes，绑定快捷键 Ctrl-D 到 Open today&#39;s daily notes，即可快速打开或者创建今天的日志，存放在一个自己设定的目录。 为什么一定要快捷键打开今天的日记页，因为我需要随手记录一点东西的时，这是个很好的选择，只有快才能不打断思维，并且形成习惯。 我使用双链和 Tag 来把记录的内容和我已有的记录关联起来，这样以后我在打开我的某个主题节点时，所记录的东西自然能找到。 自动同步我的所有笔记自动同步到 Github 上的私有库，通过插件 obsidian-git 自动定时 2 分钟同步一次，我经常工作的设备是 1 个 PC ，两台笔记本，一个手机。 虽然 Obsidian 有移动端 App，但我已经习惯自己做的 obweb，我在自己的服务器上部署这个应用，然后通过微信悬浮打开应用的网页。 虽然有几个设备上，因为同一时间我只在一个设备上工作，定时拉取这种粗暴同步方式的体验甚至好过了 OneNote。即使是偶然出现了一些冲突之类，也就只是解决一下 Git 冲突的小事。 QuickAddQuickAdd 的概念应该是借鉴于 Emacs 的 org-mode。 简而言之就是我们可以预设一些文件格式、动作，让我们通过命令就可以快速创建文件，或者按某种格式记录内容，比如我设定了这些预设动作，通过命令运行某个命令，我就可以快速的记录一个 Todo，或者输入一个标题则开始写文章，或者是记录一个单词，或者是记录一个代码片段： TodoTodo 的格式就是 Markdown 的 - [ ]，我用 Obsidian 管理 Todo 的好处在于每个 todo 都有上下文，我可能是 Daily 里面记录了 Todo，也可能是网页浏览时留下了一些 Todo，这些 Todo 散落在各个文件，但是我可以通过一条 obsidian-tasks 语句生成一个 Task 视角，而在这个 Task 视角上编辑就等于编辑了散落在各个文件里的 Todo，真是绝妙！ not donesort by due descdescription includes #write 在 Obsidian 里显示为： 这种工作方式也是来自 Emacs 的 org-mode，我觉得 Obsidian 的这些插件都做得更容易使用，毕竟不是谁都有心思去学习 elisp 来配置 Emacs 。 网页标注网页标注是非常好的概念，这是我打通输入输出的必要工具。很多人喜欢收藏东西，用浏览器书签、知乎收藏夹之类的。因为收藏的时候没有自己写上标注和自己的理解，而且和自己的输入是隔离的，这样导致收藏的东西基本吃灰。 所以我们可以使用网页标注这种概念来把自己平时所看的东西变成输入。 网页标注我使用 开源、可定制的网页批注工具 Hypothesis，通过 Hypothesis 我可以在浏览网页的时候把某些内容高亮或者添加注释，然后通过插件 obsidian-hypothesis-plugin 自动同步到我的知识库，这样我就可以在 Obsidian 里面看到我的记录。 比如我在浏览这个网页的时候，如果我觉得内容不错就写一点自己的评论，加上 #write 标签标识以后可能分享一下。 然后我的这个目录里面就会多出这么一条 Todo 记录，包含了网页的链接，我自己的备注等等信息： 这样的好处在于，我能通过上面类似的 obsidian-tasks 语句筛选出来我的写作备选想法。 我积累了好多平时冒出来的想法，以及浏览网页时觉得想分享的东西，有了这些输入我就一直有输出的材料，这也是为什么我最近写文章更多了。 我贡献了这个插件的自动同步功能 ，记得用得时候想起我😊 写了这么多，我觉得好多东西估计没讲明白，而且我还有好多好玩有用 Obsidian 的玩意，但是我已经写累了。 我逐渐意识到只有通过视频才能比较好阐明和演示，也许我以后会学着做一些视频，但是目前就先这样吧！","tags":[{"name":"工具","slug":"工具","permalink":"http://catcoding.me/tags/%E5%B7%A5%E5%85%B7/"},{"name":"Obsidian","slug":"Obsidian","permalink":"http://catcoding.me/tags/Obsidian/"}]},{"title":"一个小的里程碑","date":"2022-02-12T20:12:37.000Z","path":"p/small-milestone/","text":"我从元旦开始一直在休陪产假，所以在空余时间写了十多篇文章。今天是一个小的里程碑，因为读者数达到了 550 左右，感谢大家。 公众号超过 500 就可以开流量主了，可我不打算开了。我知道这赚不了几块钱，另一个原因是我认为这很影响阅读体验，我觉得阅读体验最好的是 Medium. com，干净的排版能让人静下来阅读长文。目前我还比较理想化，认为自己也是在构建一个数字花园 ，不能忍受丑陋和不协调。 所有可量化的东西都是可以被管理和设定目标的，因为有反馈和量化，能让自己更有创作和分享的动力。如果你觉得内容对你有帮助和启发，欢迎转发、打赏。 在这段时间里，我的主业是帮老婆带孩子，这真的比上班还辛苦。我终于理解了我司有的人下班了还不回家，在公司多磨蹭磨蹭。当然更辛苦的是妈妈们，带孩子一直是她们的主业，而这个任务真的是不分昼夜，时时刻刻都得上心，很艰辛。所以各位程序员也对老婆们好点吧😉 下面谈谈我以后的更新计划和想法。 为什么写写点东西也是有乐趣的，我之前也分享过这是抵抗焦虑的一个好方式。 我写博客也有十年了，但是之前大部分都是自己想怎么写就怎么写，我的个人域名丢了两次，所以中文博客并没有固定的读者。我经历过中文互联网开放分享的好年代，那时候大家可以通过博客交换链接，可以认识一些人。那时候很多人在开放的地方讨论问题。 而现在互联网的中文环境显然没那么好了，我认为主要有几个原因： 移动互联网崛起，大家都在用各种 App 了，而这些 App 的内容是不能够被搜索到的，比如微信群，公众号，知识星球。 对质量有要求的作者会自己建站，百度的堕落导致中小站点基本没有流量，没有流量会让很多人没了分享的欲望。 所以当我 2019 年想要好好写些内容时，我选择了写英文，顺便锻炼自己的英文写作能力。从 2019 年开始到 2021 年间，我写了一百多篇英文文章，有的发到 Medium 上，这样能赚到一些钱，虽然不是那么多，但是通过英文撰写的练习大大提高了我写作的韧性。 我写的时候心态不同了，我会想着目标读者是谁，写的东西别人能否有收获，如何排版，如何用图等等，而这些都是中英文写作通用的。 2022 年我又开始写中文内容，大概是因为年纪大了有一些表达欲，而写英文终究还没达到情感表达的境界。因为受 Learn In Public 的启发，我会让周围的人知道我在写东西，也会去尝试推广一下自己的内容。 后续内容我还是会围绕自己想的编程技术，英语，写作，个人成长之类的主题写。现在技术类的公众号风评很不好，大家都说正经的技术人谁写公众号啊。我自己也不想做出一个自己讨厌的公号，所以我这里没有告诉你入职大厂的秘籍，我也不擅长那种面试，哈哈。 写作很重要的是真诚，如果我分享给你读者一定是我觉得好的东西。 我想做的是那种 NewsLetter 形式，口语化表达也可以。个人经历，体验，故事，所思，所想都是可以分享的，我自己也受到了很多人的个人分享的启发。 关于风格我在写这段时间也在摸索和尝试，甚至我的领导老婆大人会这样指导我如何取标题： 我觉得这不是程序员风格，标题党看多了会让人生厌。所以我的标题估计大多还是直白的描述，排版也就是现在这样看起来简单即可，都是脚本程序自动生成的。 可以看到我的号是没有评论的，这是因为 2018 年后开的都是没有，需要花 3000 多去买一个有留言功能的公号，然后再迁移过来。 这是我觉得匪夷所思的事，如果想留言可以选择阅读原文到我的博客上留言，或者加我微信沟通。 更新节奏现在我已经恢复上班了，除工作之外还得照顾两个孩子，所以时间上我大概只能每周更新两篇，计划一篇是纯自己写的分享，一篇是集合我一周所看的好的文章和资料加上自己的见解。 我不知道自己能这样写多久，看起来经过一段时间的刻意培养，我现在已经形成了习惯，有时候我抱着娃的时候可能是在写腹稿，有时候睡觉突然觉得某个话题有些意思，所以这些就积累记录下来了。阅读、写作算是性价比很高的精神食粮了。 好吧，今天就写到这里，这些是我陪孩子在游乐园玩耍的时候敲出来🙌。 欢迎点赞，打赏，分享，你的激励是最好的反馈。","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"},{"name":"公众号","slug":"公众号","permalink":"http://catcoding.me/tags/%E5%85%AC%E4%BC%97%E5%8F%B7/"}]},{"title":"你想编程到 60 岁么？","date":"2022-02-09T18:25:08.000Z","path":"p/coding-to-60/","text":"今天看了篇文章关于大龄程序员的： Software engineer and hitting 40, how to set up for another 20 years of coding 不只是中国，其实整个世界的 IT 行业都有年龄焦虑，奔四的程序员算是稀有物种。这篇文章写了几个建议给那些打算编程到 60 岁的人。 到了一定年龄很多人的想法是转管理岗，并不是所有人都能转到管理岗位。这不只是因为管理岗位更少，管理岗位的职位核心要求和工程师不同，很多人不适合管理，也有很多人不能忍受管理的工作内容。 文中提到管理岗位的一个核心能力是： Thinking about abstract problems and discussing them in endless meetings with non-tech people requires something nobody told us in school or university: suffer endlessly without complaining. 这点不管是国内还是国外都是大同小异的。 作为大龄程序员我们的优势是经验： Being 20 years in software engineering gives you the super power of seeing patterns. 作者的一个建议是维护历史遗留代码也是个好的选择。我看评论里面有很多人喷这一点，但我倒觉得这确实算个选项，不过前提是： 所在的公司稳定，通常是大公司 在有长久生命力的产品线 比如在微软我就见过一些 60 岁左右的老工程师，他们的职业生涯几乎就在做一个产品，像 SharePoint 这样的产品已经 20 年了，他们从青年到老头，是对这个系统最了解的人，只要产品还在运行，他们就是不可替代的。 另外，年纪大了之后不容易被打鸡血、也不容易被画饼，所以如果上班就得找那种和自己三观贴合的公司，否则不适合长待。 文中的另外两个建议就是保持健康，包括身体和精神上的健康。 年纪大了，首要的健康问题通常是体重，程序员的肩膀、颈椎也容易出问题。我们可能不适合激烈的体育运动，不适合熬夜刷剧之类的，需要找到适合自己的放松方式。我年轻的时候很喜欢打蓝球，现在居然没什么很大兴趣了，我现在喜欢游泳，这对缓解肩膀酸疼很有效。 另外一方面，找一些能让自己精神上保持充沛的事情： You need to challenge your mind constantly. Otherwise it gets fat and lazy too. Don’t always go the easy way. Try building stuff, try coding stuff and get your hands dirty with real hardware. Ask questions online, document your journey and talk to friends about it. It is that easy to get execited again about the things that brought you into software engineering in the first place. 对我来说，写些文章是个兼有放松和自我提高的事情，所以我要一直写下去。40 岁之后家庭生活会占据很多时间，特别是孩子。养孩子是痛并快乐着吧，有时候觉得带孩子很耗费时间和精力，但陪孩子也是一种另类的放松。 在评论里有很多年纪大的工程师留言，大多是描述自己还乐于其中吧。 那些到 60+ 还在编程的人，我不知道国内有多少这样的程序员，看起来硅谷还是有一些，而且这些人不缺钱、也不缺机会： 很多人说 IT 行业很累，35 岁就要淘汰了。做什么工作都有累的方面，我身边一些亲戚朋友有在医院，有创业的，有做生意的，聊下来我觉得他们很累。相对来说，在 IT 行业如果不去卷的地方也不至于很累。 想要编程到 60 岁么？看完文章和评论，我的感受是：除非你能找到这行的乐趣，还得注意健康，不然绝对坚持不到 60 岁，甚至很难坚持到 40 岁。","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"},{"name":"编程","slug":"编程","permalink":"http://catcoding.me/tags/%E7%BC%96%E7%A8%8B/"},{"name":"职业发展","slug":"职业发展","permalink":"http://catcoding.me/tags/%E8%81%8C%E4%B8%9A%E5%8F%91%E5%B1%95/"}]},{"title":"如何高效阅读源代码","date":"2022-02-07T16:43:08.000Z","path":"p/learn-from-source-code/","text":"这篇文章最初是我 2019 年写的英文版本：Learn from Source Code (an Effective Way to Grow for Beginners) 后来陆续到一些读者的积极反馈，所以我最近把这篇翻译为中文，在翻译的过程中我又顺便重写和简化了一部分。 为什么要读代码工作多年后，我觉得自己很多时间花费在了阅读代码上。能高效地理解代码是一个程序员的核心技能，这种能力与具体的技术栈没有关系，而是一种通用的、可迁移的能力。 我们教编程的方式注重在写代码的技能，而不是如何读代码。这里的“读代码”指的是刻意地、有目的地去阅读源代码。 编程和写作有很多共同点，我们通过文字或代码表达想法，Donald Knuth 之前还倡导过文学编程的编程范式。 还记得我们在学校是如何学习写作的吗？从小学开始开始，我们需要阅读各种优秀作家的文章，并从中学习各种写作技巧。读书破万卷，下笔如有神。 和看书一样，有目的地阅读代码会帮助程序员更快地成长 (尤其是对于初中级程序员)。 刻意读代码至少有三个好处： 站在巨人的肩膀上读史使人明智，读诗使人灵透。 好的源代码就像一部文学杰作，不仅仅包含信息和知识，也是好的启蒙。在 Linux Kernel、Redis、Nginx、Rails 这些伟大的开源项目中，可以找到无数优秀的编程技巧、范式选择、设计架构，阅读这些代码你可以汲取全球顶级程序员的技巧和智慧。 读源码的另一个好处是能够避免常见的陷阱，因为软件开发中的大多数错误已经被其他人犯过。 解决难题在你的整个编程生涯中，肯定会遇到无法通过谷歌搜索解决的问题，阅读源代码通常是解决这类问题的好方法，这也是学习新东西的好机会。 拓展见识大多数程序员只是工作在几个特定领域。一般来说，如果你不持续地逼迫自己拓展知识面，你的编程能力将趋于同事的平均水平。 作为程序员，如果要持续成长就要不断尝试自己感兴趣的新领域，从深度和广度拓展对编程的理解。 读什么代码现在有这么多优秀的开源代码可供选择，我们应该阅读什么样的源代码？ 我们通常是带着目的去阅读源码的，那么有以下是几个典型场景： 要学习一门新的编程语言时学习一门新的编程语言不仅仅意味着学习语法，更需要学习如何完成一些常见的编程任务。这需要读一些小型项目，比如 Learn xxx By Examples 之类的。 我从 rust-rosetta 项目中学到了很多关于 Rust 的知识，Rosetta Code 收集各种编程语言中常见任务的示例代码，这是学习新编程语言的有用资源。 要理解具体技术的实现时我们都使用了标准库中的 sort 函数，你有没有想过它是如何实现的？或者说你需要在 Redis 中使用 Set 数据结构，它的实现中用到了哪些数据结构？ 那你需要读标准库的源码或者 Redis 的源码，通常我们关注的是几个文件或函数。 当你比较熟练使用某个框架后，可以尝试去阅读框架某些组件的源代码，这样可以加深对框架的理解。 要学习一个新领域时这时候适合阅读该领域的经典项目，不要选择太大的项目，可以从优秀的开源课程开始。 假设你想学习分布式系统，MIT 的分布式课程是很好的课程，里面也有几个经典的大作业。如果你了解 Golang，那么 etcd 可能是个不错选择。 你想深入了解操作系统的内部实现吗？直接读现在的 Linux Kernel 版本肯定会让新手摸不着北，那么 Xv6 或者 Linux Kernel 的早期版本会是一个好的开始。 想学编译器实现？也许可以看看 rui314/9cc。 在 Github 上拥有许多好的的教学性质的开源项目，也有一些重造轮子类的项目，可以尝试 “tiny + 关键词” 或者 “make your own + 关键词” 这样来搜索。 根据你当前的技能和知识水平选择项目。如果你选择的项目远高于你当前的技能水平，结果会迷失在源码中而受到打击，那么先阅读一些较小的项目，然后继续读较大的项目。 如果你花了一段时间都无法理解代码，这通常意味着你欠缺背景知识，那么先把代码放在一边，试着阅读一些书籍、论文或相关文档，等有信心了再回来。 比如我如果一股脑直接去看 Raft 的代码就会很吃力，所以我得先看 Raft 配套的文档和论文。 真正的成长，是始终游走在“舒适区边缘”。我们总是以这样的模式取得进步：阅读（代码、书籍、论文）、写代码、读更多、写更多。 如何阅读源代码 阅读代码并不容易，我们得试图理解代码中的设计和思想，需要比较长时间的精神专注。为了有效地阅读代码，最好准备以下这些技能和工具： 前置准备能够高效地使用编辑器，例如快速搜索关键字、查找变量和函数的相关引用。最好能对编辑器熟悉到仅使用键盘来操作，这将使你专注于代码而不会中断思维。 基本掌握 Git 或其他版本控制工具，比如比较不同版本之间的差异。 找到所有源码相关的文档，尤其是设计文档、代码约定等。 对所用编程语言有所了解，如果是阅读大型项目，需要了解设计模式。 当然，这些也需要在常年地读写代码中积累经验，保持耐心。 流程和技巧读代码的过程和读书有些差别，读书我们通常按照章节的线性顺序去读，如果读代码也是这样从头读到尾则容易瞌睡，而且效果也不好。 大多数时候我们根据项目的组织，自顶向下、或者自底向上地读代码，很多时候我们的注意力只是专注在少数源文件上。 以下是一些更有效地阅读代码的技巧： 带着问题阅读代码 当你开始阅读代码时，可以尝试抛出一些问题。例如，一个应用程序有一个缓存策略，一个很好的问题是如果缓存失效会发生什么，缓存中的值是如何更新的？ 这样就能在心中确定一个目标，你也可以对自己问题做出一些猜想，然后根据代码验证猜想，这有点像侦探：你想理解代码的真相和逻辑，这就像是找一个故事的真相。 读代码的经验多了，就能不断抛出各种问题，引导自己不断地挖掘代码，最终的阅读顺序倒不重要了，因为我们是随着自己的好奇心读懂了整个项目。 运行和调试代码写代码的过程有点像搭积木，而已经完成的代码就像一个组装好的乐高。 如果你想了解它是如何组合在一起的，一个好的办法是沿着提交记录来理解，这时候版本控制工具就很有用了。 假设我想看某个特定功能是如何实现的，我可以根据提交日志，尝试读 Git 的提交记录。我发现 Lua 的第一个版本要简单得多，这有助于我理解作者最初的设计思想。 调试是另一种理解代码的方式，可以尝试在代码中添加一些断点（或打印语句），把代码运行起来。如果对代码有足够的了解，我们也可以尝试进行一些修改，最简单的是尝试调整配置看看效果，然后逐步尝试添加一些小的功能，如果结果对其他人也有用，可以顺便做些开源贡献。 画出代码里的关系 “糟糕的程序员担心代码，优秀的程序员会担心数据结构和他们的关系。” – Linus Torvalds 在读代码的过程中，用笔或任何工具画出数据结构、模块之间的关系、主要的流程图等。这就像是源代码的地图，在阅读过程中你可能需要经常参考这些地图和索引。 scitools 等一些工具可用于自动生成 UML 图，我最喜欢的画图工具是 Excalidraw，ProcessOn。 注意模块和边界大型项目中通常包含多个模块，在设计良好的项目中一个模块通常具有单一职责，它的变量和函数以一种可读的风格命名，这也使得代码更容易维护。 模块的接口是抽象边界，我们可以忽略掉那些我们暂时不关心的模块。和《如何阅读一本书》中介绍的精读和泛读一样，自己感兴趣的部分精读，其他部分则泛读，这将大大节省整体时间。 模块也不止是按照目录来组织的，如果你正在阅读使用 GNU Make 构建的 C/C++ 项目，Makefile 将是了解模块组织方式的一个很好的入口。 使用测试用例测试用例也是理解代码的一个很好的补充，我认为测试用例也是一种文档。像 Rust 就很好，测试和实现通常在一块。 如果读一个类，试着读一下相关的测试代码，这可以让你弄清楚一个类的接口以以及它的典型用法。集成的测试用例对于调试带有某些特定输入的代码也很有用，它可以让你跟踪程序的整体流程。 回顾和总结花了很长时间读一个项目，为什么不写篇文章阐述一下自己的理解？ 这就像在写读书的读后感，你可以写下源代码中的好坏，以及你从中学到的新东西。教授别人是一种最好的学习方式，写这样的文章会加深你的理解，也有助于其他人阅读源代码。 我当初在花了好一段时间阅读 Kong 的源码后，写了一系列关于 Kong 的文章：Kong 源码分析 总结写了这么多，我发现代码阅读比想象的要复杂得多，没有标准的、系统的方法来训练这项技能。总而言之，不断练习读代码，找到适合自己的方法和工具，读得越多就会越快、越高效。 最后推荐两本提高读代码能力的好书： 设计模式 架构整洁之道 如果喜欢这篇文章，记得分享、点赞 👻","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"},{"name":"编程","slug":"编程","permalink":"http://catcoding.me/tags/%E7%BC%96%E7%A8%8B/"}]},{"title":"AlphaCode ，技术奇点要到来了？","date":"2022-02-04T09:49:57.000Z","path":"p/on-alphacode/","text":"今天看到一个新闻，DeepMind 的 AlphaCode 发布：Competitive programming with AlphaCode，并且在 Codeforces 的编程比赛中模拟参加比赛，居然能达到中等竞赛者水平。 我对此有些震惊，因为编程竞赛绝对是有创造性的智慧活动，现在 AI 竟然已经发展到了程序能自动生成一些有意义的完整程序。 当我们谈到人工智能的创造性时，通常会想到人工智能来创造艺术作品，比如下面这副 AI 画出来的： 因为在艺术上，很难有一个绝对的标准来衡量这东西到底是好还是坏。但是 AI 生成程序是有绝对的衡量标准，就是生成的程序是否是对的。 AlphaCode 和以前的 AlphaGo 也不同，围棋的规则简单而确定，只是在下棋过程中搜索空间巨大，AlphaGo 做的事是从巨大的搜索空间中尽量选择合理的下一步。 你可以说生成代码也是一个搜索问题，在生成每一个字符串时我们都要从 52 个字母加符号中选择下一个字符，其目标是生成一个可以编译运行、解决问题的程序。 其中的细微差别是，在围棋的中间步骤中，我们都可以通过评估函数来衡量当前局势对于目标的距离，就是判断当前局势对谁更有利。 而在代码自动生成中，这种评估函数并不存在，目前已经生成的代码片段即使包含部分错误，也可以在后续代码片段中修复，所以不到整个程序生成完整，我们没法知道目前做的是对还是错。 这看起来是一个 Copilot 的更强本版，因为 Copilot 是根据目前写的代码片段和注释，补充新的代码片段，但是 AlphaCode 的输入完全是问题的描述，输出是解决问题的完整代码。 比如例子中的这个编程问题，上面是输入，下面是输出： 另外 Copilot 可能是会生成训练集里面的某些代码片段，简单说就是 AI 之前看过某个代码片段，所以在某些场景下背出了这个代码。而从 DeepMind 发布的论文看，AlphaCode 不会完全重复生成训练集中的训练代码。 那这种工具如果更完善后是否会彻底改变编程？难道我们已经快到技术奇点了么？ 技术奇点（英语：Technological Singularity），出自奇点理论；根据技术发展史总结出的观点，认为人类正在接近一个使得现有技术被完全抛弃或者人类文明被完全颠覆的事件点。例如，意识上传技术可能使人类的意识摆脱有机体的约束，或者人来开发出可以自我进化、有自由意识的人工智能，在这个奇点之后的人类文明将发展到当今完全无法理解的水准。 之所以被称为奇点，因为它是一个临界点。当我们越来越接近这个临界点，它会对人类的事物产生越来越大的影响，直到它成为人类的共识。但当它最终来临的时候，也许仍会出人意料并且难以想象。 我仔细思考了好一会儿，我的结论是这种工具也许能极大的拓展编程的范围，也可能会改变程序员的工作内容，但离自动编程还差很远。 首先，AlphaCode 也许会提高程序员的工作效率，改变人类学习编程的过程。 我之前对 Copilot 之类的工具持悲观的态度，甚至认为除了酷炫估计对日常开发没什么帮助，参考我关于 Copilot 的知乎回答。 后来我感觉自己被打脸。收到 Copilot 试用邀请后，我在实际开发中使用了大概半年，结果是超乎我的意料。Copilot 和之前我用的代码补全类工具有一些差别，它看起来能猜测我的编码意图，从而进行有意义的补全。 特别是当我使用一个不是很熟悉的编程语言时，我敲一些关键词 Copilot 可以帮我补全剩下的代码，这节省了我自己去 Google 搜索的时间。即使这没有从根本上解决编程的难点，也能很大程度上让编程变得更愉悦。 如果有完美的 AlphaCode，它就是一个 Transformer，输入是英语，输出是程序。 作为程序员我们的日常工作可能会变成向这个 Transformer 表述我们的意图，所以一个会说英文的人，也许就能生成一些有意义的程序，这就是为什么我说编程的范围扩大了，或者我们学习编程的方式改变了。 比如 OpenAI Codex ，我们只需要输入想要的 HTML 效果，Codex 自动生成对应的 JavaScript 代码。 但是，它也终究只是一个输入不同的、人造的 Transformer，我们现在的编译器或者解释器也可以理解为 Transformer，只是输入的是某个编程语言的源代码，这个源代码是程序员按照编程语言的语法写出来的，程序员是个智能的 Transformer。 自然语言是比编程语言更大的一个集合和维度，所以同样目的的代码，如果从自然语言角度来直接生成，会变得更为繁琐，而且不精准。 在 DeepMind 的论文中也提到了，AlphaCode 的一个问题就是： Sensitivity to problem descriptions….solve rate goes down dramatically when given related but different problems, and is not very affected by different ways of describing the same the problem. 现有的代码生成技术，我们通常会限制输入语言的范围或者规则，这样就是一个领域特定语言 : DSL。恕我直言，现在这些鼓吹的低代码，无非就是套壳的领域特定语言。 作为一个程序员，我也许会使用这种自然语言生成代码的技术来辅助编程，但不可能完全使用这个写代码，我还不担心自己会失业。","tags":[{"name":"技术","slug":"技术","permalink":"http://catcoding.me/tags/%E6%8A%80%E6%9C%AF/"},{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"}]},{"title":"Elon Musk 的飞行路线","date":"2022-02-02T19:12:56.000Z","path":"p/musks-jet/","text":"你想知道 Elon Musk 的实时位置么？ 关注 Elon Musk’s Jet (@ElonJet) / Twitter 就行了，这个 Twitter 账号每天都会发布 Elon Musk 的每一次私人飞机的行踪，详细到每次飞行的起飞时间、落地时间、和降落机场。 这不，Musk 最近降落在 Brownsville，Texas。 这个 Twitter 账户是一个名叫作 Jack Sweeney 的 19 岁大学生维护的。他不止维护了 Musk 的飞行跟踪数据，也维护了 Bill Gates’ Jets (@GatesJets) / Twitter 和 Jeff Bezos’ Jets (@BezosJets) / Twitter 等其他富豪的数据。 不过 Musk 的数据是人们最感兴趣的，这个 Twitter 账户的粉丝数已经接近 30 万。作为亿万富豪，自然不想让自己的隐私暴露在公开场合。Musk 去年也关注到了这个 Twitter，然后直接给 Jack Sweeney 发消息： Musk: Can you take this down? It is a security risk. I don’t love the idea of being shot by a nutcase, Jack: Yes I can but it’ll cost you a Model 3 only joking unless?……… Musk：Ok, how about $5K for this account and generally helping make it slightly harder for crazy people to track me? Jack: Any chance to up that to $50k? It would be great support in college and would possibly allow me to get a car maybe even a Model 3. Musk: I’d think about it 中间 Jack 解释了如何获取这些数据的，如果不要钱给个实习机会也是可以的。 虽然 5w 美金对于 Musk 也是九牛一毛吧，不过估计是感觉自己被敲诈了，他最后回复说 “Doesn’t feel right to pay to shut this down”，然后把 Jack 同学拉黑了。 我就比较好奇 Jack 是如何获取这些信息的，于是搜索了一把。 Jack 的父亲在航空行业工作，所以从小耳濡目染，他对这些也很感兴趣，喜欢识别飞机型号和跟踪飞机轨迹。他刚刚高中毕业，大学选择的专业也是航空航天工程。因此他对这些了如指掌。 美国联邦航空管理局提供LADD (匿名化的飞机数据显示)，这些数据是公开的，只是富豪们的个人信息是被脱敏的，Jack 需要根据更多信息来交叉验证。 目前他主要使用 ADS-B (Automatic dependent surveillance – broadcast), 飞机通过卫星导航系统确定其位置，并进行定期广播，使得飞机可以可被追踪。数据来源这两个网站： ADS-B Exchange data：Serving the Flight Tracking Enthusiast - ADS-B Exchange，社区维护的飞行跟踪数据平台，非盈利。 OpenSky ： The OpenSky Network - Free ADS-B and Mode S data for Research，2012 年开始，由几个大学、政府组织联合创建的飞行数据收集平台，主要用于优化和改进飞行管控和研究。 甚至他的代码也是公开的，感兴趣的可以看看这个代码项目：Jxck-S/plane-notify。 有的人指责 Jack 同学干的事情不地道，侵犯他人隐私。 Jack 反驳到他获取数据的途径都是合法的，并且这些数据也是可以被公开分享，该指责的是 ADS-B 不够安全。 这个事情虽然有点小八卦，我觉得可以从事件学到两点。 个人兴趣是最好的老师，Jack 说自己通过这个项目来学习编程，而且目前自己也乐于其中，这里面的满足感超过 5w 美金。 数据公开程度超过很多人想象，个人隐私是个难以解决的问题。","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"}]},{"title":"如何无痛苦更新公众号","date":"2022-01-30T22:57:42.000Z","path":"p/publish-to-wechat/","text":"这个月我刚好完成自己设置的 30 天写作挑战，从结果上看，我达成了 3/4 每日更新的目标。 这其中有几天，我实在是厌烦了公众号编辑和发布流程。 和很多技术人员一样，我习惯使用本地的 Markdown 编辑器编辑文档，在发布到公众号之前我已经有一套自己的 Github 流程来自动发布文章到我的博客。 这个流程实现的效果是每次我本地编辑完文章，Github Action 都会触发我写的脚本生成静态的 HTML，发布到 Github Pages。 但是在尝试更新公众号这段时间，我一度非常挣扎。我看大家的做法都是使用mdnice 一类的在线排版工具，复制粘贴到公众号的后台编辑器。 最痛苦的是图片！因为目前市面上也没什么免费的图床，即使拷贝了排版好的内容，图片还需要一张一张再上传到公众号， 在持续更新了十多篇文章之后，我就觉得非常琐碎而无聊，刚好那几天有很多其他杂事，因此我断更了几天。 后来我搜索了一把，发现有个 Python 包 WeRoBot 可以通过 API 上传文章和图片到公众号的资源库，所以我花了点时间自己写了一个 Python 脚本 markdown-to-wechat，在我自己的服务器上定时拉取我的 Github repo，如果有新文章则自动同步到公号。 这个代码写得很丑，因为我硬编码了很多 HTML css ，不过真的是太实用了。现在我的写作流程是这样： 整个过程中除了本地写文章，其他都是自动化实现的。 公众号是一个封闭的系统，还有诸多限制，比如外链嵌入，比如发布后修改只能一次，这些都是违反互联网开放精神。我目前做的就是任何我发布到公众号的文章，在 catcoding.me 上都有原版，如果后续我修改了文章会自动更新到网页版本。 我在 知识管理工具和经验 提过，最适合自己的工具永远是自己私人定制的，只有工具和流程做到完美配合，才能达到最好的效率。 懒惰是程序员最好的美德，我们要把琐碎的、重复的事情自动化，这样才能把精力放在需要创意的地方。 这不，这样折腾好之后，我现在每天写点什么的习惯都养成了😉。","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"},{"name":"公众号","slug":"公众号","permalink":"http://catcoding.me/tags/%E5%85%AC%E4%BC%97%E5%8F%B7/"}]},{"title":"学习编程难？先解决量的问题","date":"2022-01-29T11:24:27.000Z","path":"p/entry-for-learning-programming/","text":"今天分享一下自己这些年来学习编程的一些体会，来阐述一个朴素的道理和原则。而好多初学者并不太明白这个道理，所以在学习过程中会有迷茫感。 我是 2004 年上的大学，当时读的是信息安全专业。在上大学之前我没怎么用过计算机，可以说是完全的小白，而且我觉得自己的数学一般，算是一个资质平平的小白。 当年我们学校还规定大一新生不准自己带电脑进宿舍，所以大学第一年我也没怎么写过代码。我记得当时我们上 C 语言的课，每周大概有一两次去学校机房敲代码，机房里装的是 Turbo C，至今印象深刻。 因为我完全是小白，键盘都不太熟悉，所以我是完全照着书上面的例子敲的。 而后的三四年里，我买了自己的台式机，平时也写了一些简单程序，但我花费了更多的时间去折腾 Linux 系统。那时候 Linux 发行版本 ubuntu 会免费给学生邮寄光盘，我每年都申请一个新版本，所以毕业时一袋子 Linux 系统光盘。 我本科期间因为各种原因蹉跎了很多时间，可以说编程并未入门。那是什么感觉呢？就是看起来都好像懂点，自己写起程序来就没底。比如数据结构和算法，我虽然知道很重要，但就是没太学懂，考试过了却不知道实际应用。看相关的书籍，如果没有现成的代码我就总感觉少了点什么，有些困难。 后来我就考研了，当时我也没太想明白为什么要读研，算是还没准备好参加工作，还想在学校待两年。读研期间我在实验室跟着做一些科研项目，编程做得也不算多。 2009 年一次偶然的事情改变了我。那天我大概是看到了一个介绍 PKU JudgeOnline - POJ 的网页，然后想起自己 2006 年注册过账号，我就重新登录了进去，没想到从此的一年多时间里，我基本天天泡在上面写程序。 我不是为了参加比赛，而只是偶然陷入了进去，然后就变得沉迷。我基本从早上九点到实验室，到晚上十一点左右离开实验室。我从一些简单的算法开始写，有时候是按照某些分类去做，实在想不出来就去评论区和别人的博客看解题报告。 现在回想起来那一年算是自己最专注的学习编程的一段时间，我记得有一次神奇的体验，有次我一直在想一个算法问题，然后在梦里还在做，第二天醒来后居然能回忆起梦里的方法，最后实现出来居然是对的。 这种忘我的、愉悦的心流体验非常难得，以至于在十年之后，当我遭遇焦虑时仍用这种办法来解决。 在这一年多的时间里，我基本刷完了 500 道题目。其实每个程序通常都比较短，算 100 行每道题的话我也就写了 5 万行代码。 就是这 5 万行代码彻底提高了我的编程能力，感觉就好像就是突然上道了。我对算法和数据结构没有了恐惧感，变得更有耐心，我看其他技术书籍也没任何困难，学习编程语言，框架类的东西快多了。 在 POJ 上做编程题和自己学习数据结构、算法有什么区别呢？后来我明白，其实我经过了一年多刻意的有效练习，这种在线编程的练习有几个好处： 可以获得即时反馈，一个程序是否通过都是确定的，到底是 Wrong Answer、Memory Limit Exceeded、还是 Time Limit Exceeded 可以跟踪和量化，我学会了哪些，比如 DFS、BFS、DP、Tree、Graph 等都是可以追踪和量化的 可以和其他人交流 在这种练习中，我通过写获得了编程的“语感”，也提高了阅读源码的能力。写代码和写作差不多，编程无非是通过代码来表述自己的想法，需要不断地练习。 关于这一点我后来看到硅谷王川的表述非常好： 所有的我们以为的质量问题，大多本质是数量问题。因为数量不够，差几个数量级而已。 数量就是最重要的质量。大部分质量问题，在微观上看，就是某个地方的数量不够。 最大的误区是，明明是数量不够的问题，因为错误地以为瓶颈在于质量，幻想在不增加数量的前提下，用某种奇技淫巧，偷工减料达到目的。这时候玄学，迷信和各种无病呻吟就出现了。数量不够，底子不够厚时，很多事情时做不到的。即使有时看似有捷径，欠的账迟早是要还的。 有的初学者在量没达到的情况下，怀疑自己的学习方法有问题，然后再怀疑是不是编程语言没选对，试其他的办法又没法长久坚持，最终导致自己好像一直没上道。如果没有写到足够的量，任何方法都是无法阶段性提高自己。 这个量就像是一个门槛。 任何复杂技艺的学习都是有门槛的，通过这个门意味着构建了做这行的韧性和耐心，也可以说是找到了里面的乐趣和成就感，这些是深入下去的基础。 在纪录片寿司之神中有一个片段： 在小野二郎的店里做学徒，先要学会的是拧毛巾。毛巾是刚从开水中蒸出来的，温度骇人，食客使用都需要晾凉。而在这之前，学徒要将其捞出，并拧至全干。 这种训练非常辛苦，但如果学不会的话，就不能去碰鱼。接着，学徒要学会用刀料理鱼，10 年后才会被允许去煎蛋。 资深学徒苦修 4 个多月，失败 200 多次，终于做出了人生第一个“合格”的玉子烧。 训练和衡量一个飞行员，我们说他累计飞行时间多长；训练长跑运动员，衡量标准是每天跑多少公里；那衡量一个编程初学者，有效编程行数就是一个很好的指标。 编程中的有效练习不是拷贝粘贴代码，也不只是读代码，而是自己从头到尾去思考，去写出来，然后出了问题自己去调试。 在 LeetCode 上写也很不错，你可能对算法不感兴趣，那可以去做游戏、 Web 应用开发、后台开发等等项目，找到自己感兴趣的方向作为突破口，然后持续积累到一定程度的代码量，比如三万行代码，那编程自然就入门了。 就编程来说，三万行代码这么明确的一个指标，实际上大部分人做不到。以大多数人的努力程度之低，根本轮不到拼天赋。不信你可以问问，即使是大学计算机专业的学生，很多人毕业的时候并未完成过 3 万行有效编程的这个量。 有了这种体验，我培养出了作为普通人学习掌握技能的耐心。类似编程，那些难以获得、需要不断锤炼的技能，例如写作、英语、钢琴、绘画等，前期都需要一定量的积累，我们要做的是找到有效练习的方式，持续投入再阶段性回顾。 这个月我在锻炼写作能力，因此我一个月写了接近 15 篇文章，自我感觉确实有提高了不少，而且在这段时间里我克服了心理问题，解决了写作的流程、和工具的问题，所以我也不感觉到迷茫。 总而言之，编程初学者不要想着捷径。每个人的方法都可能会有所差别，他人的路径不一定适合你。唯一的共同点是得有量的积累，先在键盘前敲起来，敲几万行代码后你就没有入门学习这类的疑问了，下一阶段是如何写得更好，如何用编程解决现实问题了。","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"},{"name":"编程","slug":"编程","permalink":"http://catcoding.me/tags/%E7%BC%96%E7%A8%8B/"}]},{"title":"微软内推","date":"2022-01-27T20:47:03.000Z","path":"p/ms-refer/","text":"关注我的很多读者是想找份能兼顾生活的工作的，我觉得微软是个很好的选择。微软员工内推入职的比例比较高，因为没和猎头合作，这钱就给员工赚了也挺好。 微软苏州即将启用第二栋办公楼，又要开启招招招的模式，各个部门目前开放的岗位超过 200+， 并且之后会持续开放新的岗位。 所以对微软有兴趣的同学们，不要错过加入微软的最好机会！ 内推职位不限于苏州，北京、上海也有职位，麻烦你在官网找自己感兴趣的职位。 https://careers.microsoft.com/professionals/us/en/ 个人工作感受在微软工作，工程师可以大多数时间专注在自己的项目上，没有那么多汇报和扯皮的事情。 日常接触的技术栈大多是微软自己的那套 (不过也看部门)。这个我认为没什么问题，其实工作到一定年限，成熟的做法就是不对技术保有什么偏执。微软近些年在开源方面也做得挺好。 另一方面的感受是包容、平等和尊重。这里不会有年龄歧视，我们团队有小孩上高中的，也有 96 年左右的同事，其他部门也能看到预计 50 多岁的员工。做管理和不做管理也主要是在于个人志趣。 下面是一些 FAQ: Q1: 申请微软需要什么样的学历门槛？ A: 学历更好可能会占一些优势，但面试主要还是看能力和经验。如果是技术岗位，前几轮都是编程能力考察。学历在应届生中很重要，如果是社招就没那么重要，例如你有一线大厂有经验，或者是好的项目经验，学历​通常只要是本科就可以，名校和非名校没那么大的差别。我甚至也见到过没有本科学历的同事，但是他技术和工作经验都没问题。 Q2: 微软的面试流程是什么样的，简历投递之后流程如何？ A: 我这里投递简历之后，HR 初步沟通意向，可能会和你讨论哪个组比较合适你。然后一轮技术面试（现在一般是远程面试)。通过之后大概 4-5 轮连续的面试，HR 会尽量安排在一到两天内。面完之后就是等结果和谈 Offer 的过程了。 Q3: 针对面试需要做哪些准备？ A: 社招主要是编程能力、系统设计、表达能力、英语能力。其中编程能力的考察方式是在线编程。 我建议刷一下 LeetCode easy/medium 难度。系统设计通常是给一个具体的场景，一起讨论如何设计实现，或者讲一下自己之前做的一些项目，难点和挑战。英语能力要求能简单表述自己，发音和流畅度不要求太高。 Q4: 微软的职级是怎样的，我应该申请什么级别？ A: 本科生和研究生校招进入微软都是 59 级，这是你在微软的 level，除了 level 之外，微软制定了不同角色的 title 体系，以多数人申请的 IC(个人研发) 岗位为例，一个 title 往往对应 2~3 个 level，大概的对应关系和工作年限要求如下： Title Level 工作年限要求 SDE 59~60 3 年以下工作经验 SDE2 61~62 3 年到 6 年 Senior SDE 63~64 7 年到 10 年 Principal SDE 65~67 10 年 + 当然工作年限和职级的对应关系不是严格对应的，需要自己争取。 Q5: 英文不好的我是不是和微软无缘了？ A: 如果是技术岗位对英语的要求没那么高，只要能听懂和简单表达自己即可。当然面试之前准备好英文的自我介绍比较好。 Q6: 微软需要 996 福报嘛？ A: 不会，我的感受是大家都真的在自由安排时间，上下班不打卡，没人关注你什么时候下班，也没有拼加班的风气。有的有孩子的同事回家比较早，通常 5、6 点开始有人下班了。 据说有个别组有点卷，这些私聊我会告知你我所知道的。 Q7: 和外界迥异的技术栈，进入微软水土不服怎么办？ A: 入职后会有比较长时间去给你适应，内部好多文档、书籍、视频资料可以学习。我最近发现公司还给员工买了 Oreilly 的会员，还有 Linkedin 上的各种学习资料，只要保持学习心态这些不是问题。 Q8: 带着想要肉身翻墙，去接受美帝资本主义腐蚀的思想也可以加入微软嘛？ A: 这个时期还有勇气去美帝么？真的勇士！ 据我所知以前去美帝的很多，疫情期间暂停了一段时间。现在据说又有同事开始过去了，不过都是疫情之前已经拿到那边的 Offer 的同事。 真想要翻墙可以进来再观望，估计以后还是有机会的。 Q9: 目前开放的岗位有哪些，岗位太多难以抉择怎么办？ A: 找我或者和 HR 小姐姐沟通。我当时也是抱着随便投投攒点面试经历的想法投了简历。没想到 HR 特别耐心和我沟通了半个多小时。然后就稀里糊涂的面了好几轮。 Q10: 微软可以远程办公吗？ A: 如果是不超过 50% 时间在家办公，和组里口头说一下即可，我经常一周在家一两天。如果是想长期永久在家办公，需要走流程让上面审批，我们隔壁组有同事长久在家办公。 有意向的读者请将简历微信发我 (公号回复 0)，或者邮箱 moorekang#gmail.com。我会全程跟进大家的面试流程，为大家解答问题和提供面试的意见。","tags":[{"name":"微软","slug":"微软","permalink":"http://catcoding.me/tags/%E5%BE%AE%E8%BD%AF/"}]},{"title":"John Carmack 的编程学习建议","date":"2022-01-27T00:15:54.000Z","path":"p/adivces-from-john-carmack/","text":"John Carmack 是游戏编程祖师爷级别的人物，id Software 的创始人之一。代表作有《德军总部 3D》（Wolfenstein 3D）、《毁灭战士》（Doom）和《雷神之锤》（Quake）等等，这些游戏和它们的后续版本都获取了巨大的成功。 《Doom 启示录》这本书可以说是很多游戏创作者的启蒙书。 他更是创造了游戏编程和图形学中的一些经典技术，比如他在 Doom 上第一次使用了二叉树分割技术，表面缓存技术则在 Quake 中第一次出现。 前段时间看到个说法： 衡量一职业是否越老越吃香，就看能不能在前面加上德高望重四字。例如：德高望重的医生，德高望重的老师，德高望重的鉴定师…… 我想 John Carmack 是不是可以配得上这四个字？但是总感觉哪里不对，原来是年纪，其实 John Carmack 今年不过才 51 岁。 就是这样的大神，仍然对编程保持着好奇心和学习的心态，从他的 Twitter @ID_AA_Carmack 可以偶尔看到一些关于编程学习的心得和体会。 比如前几年他对函数式编程感兴趣了，所以做了一个 Scheme 脚本语言来进行 VR 开发。 他提倡的学习方式是实际动手去做一些小东西，这两年他在学一些 AI 相关的东西 : My advice to people wanting to get into game programming has been to write small games completely from scratch while also working on commercial game mods and with unity or unreal. I’m following that myself for AI — I have some C++ backprop-from-scratch projects while also learning python / pytorch / jupyter and experimenting with pretrained models. I had to give myself a bit of a kick to not dwell too much in the lowest levels, but now I am enjoying the new world quite a bit. You can do a remarkable amount with very little code, but when I actually write a loop in python because I don’t know the correct way to do something with tensor ops I get reminded just how slow python is relative to C++. Carmark 甚至还会使用这种静修式的方式来找回编程的乐趣，完整地花费一周时间来自己实现神经网络的小项目，顺便玩一些自己用得比较少的工具： I’m not a Unix geek. I get around ok, but I am most comfortable developing in Visual Studio on Windows. I thought a week of full immersion work in the old school Unix style would be interesting, even if it meant working at a slower pace. It was sort of an adventure in retro computing — this was fvwm and vi. Not vim, actual BSD vi.…..Maybe next time I do this I will try to go full emacs, another major culture that I don’t have much exposure to. 你看，当一个喜欢编程的程序员财富自由了之后，最有乐趣的事还是编程。 那大佬对学习编程有什么建议么？ 简而言之还是那句话：多看，多写！ 2005 年有个 14 岁的小朋友发邮件问 John Carmack 如何学习编程，他当年给了一个回复，2018 年的时候又被翻出来，虽然十多年过去了，技术变得越来越复杂，但是这仍然是学习编程的好建议： John Carmack on Twitter: “This is still generally good advice.” / Twitter 这里完整地分享一下，顺便一起学学英语 🙌 When I started, computers couldn’t do much more than simple arithmetic and if statements – my first computer had 4k of memory. How I learned probably isn’t very relevant, because there are so much better resources available today. Don’t expect it to be easy, you will have to work at it. Get a few more books from the library that cover beginning programming to go with the ones you have – sometimes a different author explaining the same thing will help a concept click. Go through all of them at least twice. Try to do every problem and exercise, don’t just read them and think you get it. Lots of people that want to program will talk a lot about programming, but not actually write that many programs. You should write hundreds of programs If you want to get good at something you need to focus on it, which means choosing to exclude some other things from your life. Keep a little journal of what you are working on each day, you may find that you aren’t applying yourself all that hard. Learn something new every single day. Avoid “cookbook programming”, where you copy and paste bits of code that you have found to make something work. Make sure you fully understand what everything it actually doing, and that you are comfortable applying the techniques in other situations. It isn’t a bad idea to start in an environment that give you more exciting feedback, like visual basic, flash, or javascript, but you should try and “find the excitement” in even the most simple data processing tasks. There are layers and layers of things going on in just compiling and running the simplest program that are worth investigating. Pay attention in school to the math classes. It is more important to be able to do basic algebra and trigonometry extremely well than to sort of get by in higher math classes. You should be able to ace all the tests and teach other people if you truly have a complete understanding of the subjects. John Carmack","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"}]},{"title":"培养习惯，程序员学英语没那么难","date":"2022-01-24T13:30:47.000Z","path":"p/learn-english-as-programmer/","text":"接着上一篇，我们谈谈程序员如何能从各个维度来提高自己的英语能力。 首先声明，我自己的英语水平也没那么好，技术类的阅读没有问题，自己还在提高英语写作和口语，我的目标是在专业方向上完全无障碍的英语表达。 这是我自己日常工作生活中总结出来的一些小经验吧，每个人的学习习惯不同，这些仅作参考。 PS：等我开始写这篇的时候，我发现有的事情不能写，比如怎么科学上网之类的 ，那么我们假设这个你已经搞定了🤣 阅读作为 IT 从业人员，我们日常生活中其实会接触很多英文内容，书籍、文档、参考资料等等。如果一个英文不够好的人会优先选择中文内容。 如果你想提高自己的英文能力，就得改变这个默认倾向。否则这就是一个怪圈，你一直看中文的就不可能打破这个循环。 首先，编程的时候参考文档换成优先看英文版本，比如假设你是前端开发，平时需要看 vue 文档，那就换成英文的，而且英文的内容更及时更新。 我建议默认也把操作系统的语言设置为英文的，这样很多软件默认语言也自动成为英文。 关闭浏览器的自动翻译功能，因为这会干扰阅读，也会让你放弃掉自己先阅读英文的机会。 在浏览英文网页的时候，可以使用一些辅助查询插件，比如我用的这个 Chrome 插件 Saladict 沙拉查词 就提供各种辅助查询，也可以把自己不认识的生词保存在线上以便以后回顾。 在用互联网上搜索的时候，也尽量换成使用英文关键词。如果能用 Google 最好，不能的话换成 Bing 、DuckDuckGo 搜英文也比百度好很多。 除了文档，另一个不错的英语阅读来源是 Medium.com，这上面除了技术类的文章也有很多其他方向上的内容，这些文章并不是很长，而且排版都非常好，容易让人沉下心来阅读。欢迎关注我的账号：Medium 👻 如果是在校学生，你也许需要看很多计算机相关的书籍，如果能看英文原版的最好。不要恐惧去拿起整本的英文书，因为只要坚持读完第一本，后面自然就会读起来越来越快。 我在学校的时候借过《Introduction to Algorithms》和《Structure and Interpretation of Computer Programs》。 学校图书馆的英文书相对更容易借到，因为看的人少很多，从书本的新旧程度看这些书基本没人借过。所以，选择少有人走的路，有时候反而更轻松。 还有不少其他计算机的经典书籍，我认为计算机相关专业的最好在学校阶段看一遍，比如： The Pragmatic Programmer: From Journeyman to Master The C Programming Language The UNIX Programming Environment The Art of Unix Programming Clean Code Refactoring: Improving the Design of Existing Code Computer Systems: A Programmer’s Perspective Code Complete Programming Pearls 这些书中的任何两本认真看完，技术类的阅读不成问题了。 写作英语写作更难一些，因为相对来说如果不是在外企工作，使用英文写作的场景会少很多。 很多时候越是难的事才越有价值，我在之前公司工作的时候需要写英文的技术文档，懂技术的英文不好，懂英文的技术不好，所以把这两种稀缺能力叠加一起就很好地提高自己的价值。 我们也可以刻意地改变一些习惯培养技术写作，比如使用英文来写 Readme 和代码中的注释，使用英文来写平时的记录和博客之类的。 建立一个自己的英文 Blog 是非常好的方式，我在自己的英文站点 http://coderscat.com 上总共写了 150 多篇技术相关的英语文章，有的是平时工作中的一些记录，有的是解题报告，有的是刻意练习写作的。 在写的过程中需要反馈才能提高，因为有很多中式表达如果没有人指出来自己是意识不到的。 为了得到一些反馈，反馈也会激励我们继续写下去，所以我们需要把自己的内容让更多人看到。 在 StackOverflow, Quora 上回答问题是锻炼写作能力的好平台。我有段时间就经常在 Quora 上回答问题，因为这里有很多英语母语者在浏览。如果他们发现问题可能会乐于帮我指出来。 我有时候会把文章同步到 dev.to，比如我这篇文章曾经是 dev.to 上的爆款：How To Learn Data Structures And Algorithms 后来我把自己写的文章同步到 Medium.com 上，然后投稿到一些大的技术类专栏，比如 Better Programming，Level Up Coding。 为什么要投稿呢，因为可以来判断自己是否写得足够好，而且像 Better Programming 这样对质量要求比较高的专栏，他们能看出我不是英语母语者，但是如果我的内容还不错，也会让自己的编辑去帮我润色，这就是最好的得到反馈的机会。 专业的编辑会从标题的选取、排版、英语写作的用法等等角度去改进文章。我在这个过程中就学会了很多东西。 在 Medium 写作的另一好处是可以赚钱，可以参考一下我写的这篇：How I Wrote a $500 Article in My First 3 Months on Medium，文中提到的那篇文章一直都还有阅读，后来累计了 1300 $。 在 Medium 上写作赚钱的红利期也过了，除了我上面的那篇爆款，我其他写的文章如果专栏接收大概也只是在 500 元左右的收益。 关于如何建一个盈利的英文站以及如何通过英文写作赚钱，这是另一个比较大的话题，这些也以后再分享 🙌 沟通听力和口语这是两项英语沟通的必备技能，最好在学校阶段就注重这方面的培养，因为工作之后时间和精力都会少很多。 如果是锻炼听力，轻松的办法是看美剧，比如 Friends 系列。我现在用得更多的是听 Podcast 、看 Youtube 之类的。这里推荐两个 IT 类的 Podcast： Behind the Tech Podcast with Kevin Scott - Microsoft 微软 CTO 关于科技方面的播客。 Hanselminutes Technology Podcast Scott Hanselman 在 Youtube 上也很活跃，技术介绍通俗易懂。 在口语这块，我自己在学校阶段没刻意提高，所以虽然阅读、写作相对好些，口语一直都一般。 如果有练习口语的环境，逼得你日常就用英语交流，这就会提高很快。2013 年我在硅谷待过一段时间，每天至少会和印度同事交流一下，感受是听力好了很多。 然而后面脱离了那个环境就又退化了。我两年前曾经付费使用过 Cambly 来练习口语，每天花 30 分钟和英语母语者聊天，自我感觉提高了一些，其实主要是克服了那种不敢说的恐惧。我的发音不太准，以后再花时间改进。 工作后的人大多没有很多时间来学习英语，我见过同事花了 2 万多去报名培训班，上了几次后之后就坚持不了的。提高英语能力不是一朝一夕的事情，没什么捷径，每天花 20 分钟专门阅读，20 分钟锻炼口语或者写作就是很好的习惯。 如果你想不知不觉地提高自己的英语，好好培养一些习惯，然后一直坚持就够了。如果要刻意提高，在校的学生可以尝试先把四六级过了，然后如果有时间和精力去考雅思托福之类的。 以上就是我自己的一些经验之谈。道理很简单：不管是读写听说，多用英语，用得多了日积月累就会提高，摸索出一些适合自己的习惯才能持久。","tags":[{"name":"英语","slug":"英语","permalink":"http://catcoding.me/tags/%E8%8B%B1%E8%AF%AD/"},{"name":"自我成长","slug":"自我成长","permalink":"http://catcoding.me/tags/%E8%87%AA%E6%88%91%E6%88%90%E9%95%BF/"}]},{"title":"世界很大，一定要学好英语","date":"2022-01-18T00:10:31.000Z","path":"p/learn-english-for-big-world/","text":"今天再分享一下自己作为程序员学习英语的一些经验，我计划分几篇写成一个系列。 首先我们谈谈作为程序员，我们为什么要学好英语。英语对程序员的重要性主要体现在以下几个方面： 更好的输入毋庸置疑，英语已经是世界上科技和学术交流的通用语言，这是我们无法改变的事实，而且可以预见我们有生之年仍然是这样。在 IT 领域更是这样，这个世界上最新的、最全的、最好的编程学习资料大多是英文的。 比如我前几天介绍的 Crafting Interpreters 这本书，如果等到国内翻译出来说不定几年都过去了。而且国内很多技术书的翻译质量很差，因为翻译的收入并不高，有能力把技术翻译做好的人，大多不愿意投入时间到这上面。 我知道一些出版社找的是国内高校的老师，然后让一些实验室的几个研究生来翻译，这些研究生因为缺乏从业经验，翻译出来的东西质量低下。有的经典技术书籍被翻译成烂的中文版，让人痛心。 比如《人月神话》中文版里有一句话是 “大拇指的规则就是 …..”，你看的时候会不会困惑不已，大拇指规则是什么？ 如果你去看英文版本，其实这句是: The rule of thumb，其实是指”经验法则”。 其实不止是英文资料的问题，很多软件的中文告示也是不够准确的，甚至有的计算机术语是没有公认得中文翻译的。 比如编译器 Gcc 的一个中文警告： 提领类型双关的指针将破坏强重叠规则。 这到底写个啥？但如果你去看英文，就容易理解得多： warning: dereferencing type-punned pointer will break strict-aliasing rules 如果我们一直用这些学习资料，容易被误导、浪费自己的时间，更是可能是达到一定瓶颈无法提高自己，所以直接看原版的英文书收益更多。比如我就基本没买计算机的书了，我用公司的 OReilly 账号，基本能看所有好的原版计算机书籍： 更广的交流如果你在 Github 上做开源，免不了和其他国家程序员沟通。要在一个顶级的开源项目做贡献，一个 Pull Request 来来回回几十个讨论也是很正常的。 能否在英语世界中传播对于一个开源项目至关重要。 Ruby 创始人松本行弘 1995 年开始创建 Ruby，前面好几年其实 Ruby 大多是在日本圈子里用用，可以看看 Ruby 的早期版本里很多注释都是日文的。一直到 2005 年 Rails 发布，出现了很多英文的 Rails 书籍和介绍，Ruby 才开始风靡全球。 那些做出著名开源项目的国人中，英语交流肯定是没有任何问题的，例如 OpenResty 作者章亦春，Vue 创始人尤雨溪等。反观国内某些大厂的某些开源项目，例如腾讯的 polarismesh/polaris，这文档、代码注释都是只有中文，这如何能在世界范围内流行开了呢。 有的国内开发者编程中的变量名用拼音，可以想象如果一个开发者写的代码是： def denglu(yonghu): ... 这代码只有中国人有可能读懂，那如何让中国之外的开发者协作？ 同样的原因，我认为中文编程可能为英语不好的初学者稍微拉低一下学习门槛，除此之外毫无益处。 更多机会国内年轻人多，2021 年应届生加上海归总人数达到 900 万。 而其他行业相对不好找工作、工资低，导致很多人转向 IT 行业，结果就是国内 IT 职位内卷得要命。 另一方面，现在因为疫情、贸易战等原因，世界各国的人员流动减缓，但是线上协作更多了。疫情加速了全球数字化进程，其实各个国家都很缺软件工程师。 所以如果你想做这行但又不想内卷，就别一直盯着国内大厂，多看看外面的机会，比如国内外企，远程职位，或者其他国家的职位。 德国就为工程师提供欧盟蓝卡，比如《精通正则表达式》的译者余晟就在德国生活得很舒服啊。 当然是否出国定居涉及到很多因素，如果不出国也可以试着找国内的外企，比如微软在国内大量招聘 (找我内推)，还有 Paypal、AMD、NVIDIA、Amazon、Hulu 等等。有人会说外企在国内正在衰退啊，我的理解是传统外企确实岗位少了很多，而 IT 类的外企还是有很多职位在招人，只是对比 BAT 招聘名额少很多，所以显得没有多少存在感。 应聘这些职位对英语有一定要求，但这个要求其实又没有你想象的那么高，通常只要能达到日常交流水平就可以了，因为编程工作中的交流相对来说是比较简单的。 这篇已经比较长了，后一篇再接着谈作为工程师如何提高英语能力。我的经验是不用专门为了提高英语而刻意去学，更多是日常工作学习中做一些习惯上的改变，达到日渐提高英语的目的。 待续。","tags":[{"name":"英语","slug":"英语","permalink":"http://catcoding.me/tags/%E8%8B%B1%E8%AF%AD/"},{"name":"自我成长","slug":"自我成长","permalink":"http://catcoding.me/tags/%E8%87%AA%E6%88%91%E6%88%90%E9%95%BF/"}]},{"title":"国内远程 IT 职位","date":"2022-01-15T00:09:24.000Z","path":"p/remote-jobs-in-cn/","text":"我最近在做一个提供国内远程职位的公司列表，可能对你有帮助。 可以看出这些公司通常不是那些行业巨头，反而是一些小而美的创业公司。他们能提供的薪资也许比不上 996 的大公司，但是也不会那么卷和累，而且如果远程工作你可以居住在二三线城市，这样也能做到一定程度兼顾家庭。 所以我认为这是逃离内卷的一种方式。 为什么说愿意让员工远程的公司通常不那么卷？ 因为远程职位通常要求员工的自驱力比较强，并且公司相信员工能够按约定交付，所以也不太关心你什么时候上下班，每天工作多少时间。对员工信任的公司，不会内卷。 这些公司提供的职位大多是偏技术的，毕竟编程的工作是比较适合远程的。如果你有感兴趣的职位，可以找我内推，也许我认识这里面的一些朋友。另外，微软也支持远程，如果远程时间小于 50% 经理批准就可以，如果全职远程必须部门大老板批准 (我也看到有人在全职远程了)。感兴趣的也可以让我内推。 这个列表的链接是：remote-jobs-cn。 公众号重新编辑不便，所以如果后续有新增我会更新到 Github 上。 平凯星辰 | PingCAP 职位： Careers | PingCAP 行业：分布式数据库 技术：Golang, Rust，前端，数据库，DevOps，运维 PingCAP 的 5 年远程办公实践 - 知乎 (zhihu.com) 涛思数据 | TDengine 职位： 招贤纳士 | 涛思数据 (taosdata.com) 行业：时序数据库 技术：C/C++, 前端 关于 | 涛思数据 (taosdata.com) 开源 —— “这是最好的时代，这是最坏的时代”｜陶建辉 MegaEase 职位：Hiring@MegaEase.com 行业： 云原生开源软件、微服务开发框架、中间件等 技术：Golang, C/C++ MegaEase 的远程工作文化 | 酷 壳 - CoolShell 秘猿科技 | cryptape 职位：cryptape 行业：区块链 技术：Rust，C/C++ 等 秘猿科技 招聘区块链开发工程师/Rust 开发工程师/全栈开发 FydeOS - 面向未来的操作系统 职位：操作系统底层工程师、Android 底层工程师、C/C++ 底层软件工程师、前端 行业：操作系统 [北京/武汉/深圳/远程] FydeOS - V2EX VMware 职位：数据库内核开发 行业： 虚拟化 技术：C, k8s 、网络、存储、虚拟化 [北京][955]VMware 招聘 Greenplum 数据库内核开发 - V2EX RustDesk 职位：Contact (rustdesk.com) 行业：远程桌面 技术：Rust 、Flutter 、React/Javascript RustDesk 招聘远程 - Rust 语言中文社区 (rustcc.cn) Databend 职位：数据库内核、Cloud 平台开发工程师、社区运营 行业：开源云原生数仓库 技术：Rust Databend 招聘中，期待你能全职加入开源项目 - Rust 语言中文社区 (rustcc.cn) 极狐 (GitLab) 职位：Ruby 测试/研发/全栈工程师等多个职位 行业：开源代码托管 极狐 (GitLab) 招聘 Ruby 测试/研发/全栈工程师等多个职位 · Ruby China (ruby-china.org) Logseq 职位：开发工程师 行业：笔记软件 技术： Clojure(Script) 职位不多，也许招满了。Logseq 远程招聘一位开发工程师 [40k ~ 65k] - V2EX 欧若数网分布分布式图数据库 招聘岗位 | 欧若数网，开源分布式图数据库 Nebula Graph 研发商 (vesoft.com)","tags":[{"name":"工作","slug":"工作","permalink":"http://catcoding.me/tags/%E5%B7%A5%E4%BD%9C/"},{"name":"远程","slug":"远程","permalink":"http://catcoding.me/tags/%E8%BF%9C%E7%A8%8B/"}]},{"title":"大家都在用我的代码，所以我就该富有吗？","date":"2022-01-12T20:11:48.000Z","path":"p/fakerjs-is-deleted/","text":"这些天因为 faker.js 开源作者 Marak 删除代码事件让开源出圈了，好多非 IT 的自媒体都跟风写上了。我花了些时间查找资料，也说说自己的理解。 首先我们回顾一下整个事件： 8 年前 Marak 的 JavaScript 库 Faker.js 完成 1.0.0 版本，该库可以制造非常多不同类型的假数据，用于开发调试。使用的是 MIT License ，这个 License 简而言之你可以随意用我的代码，但是风险你自己承担，我也不会收费。 Marak 曾在 2020 年 10 月 25 日的时候在推特发帖声称自己在公寓火灾中丢失了所有东西，几乎无家可归，在申请外界支援，从回复上看很多人已经伸出了援手。 2020 年底开始，Marak 一直在寻求一些方式来通过 Faker.js 赚钱，众筹或者寻求大公司赞助，甚至是希望被收购。这过程中收到了一些拒绝。 从 2021 年左右开始，Marak 开始关注币圈了，说要卖掉房子来投资 NFT。可以看出这时候他应该从火灾的窘境中脱离了？ 也许是因为通过 faker.js 筹钱不顺，前几天 Marak 强制把代码仓库清空，并写上了句关于 Aaron Swartz 的话。 Aaron Swartz 被称为互联网之子，作为开放获取运动的长期支持者，因为大规模系统性地下载JSTOR上的学术期刊] 而被判非法入侵罪，他拒绝认罪并随后自杀。Aaron Swartz 倡导的开发和平等的互联网思想深深的影响了一代 IT 从业人员，使得越来越多人愿意将自己的软件授权、技术书籍、平台信息选择对外开放。 所以 Marak 的做法也许在拷问，这个世界怎么了，我们分享精神得不到应该得到的回报？ 如果作者不想再继续维护开源软件，通常的做法是不做更新、或者转移项目所有权给其他人。但是 Marak 的做法是清空代码库，这导致一大波公司不能使用。最后，作者还因为向自己开源项目提交恶意代码，使得 GitHub 账户被暂停使用，从而在技术圈引发热议。 这里我再加一些具体的细节。这个库虽然有用，但是并不是什么高深技术。即使没有他这个东西，一个资深的前端程序员完全可以自己搞出来一个。在开源的世界一个东西流行，其实有很多因素，可能出现的时机对了，当然也可能确实有些独特好用的地方。这样功能的一个库，往往只要一个火了，其使用量就会很大，排第二的可能就没多少人知道了。 另外作者来开始的时候，也是不知道这东西这么多人用的，选择的 License 就很随意，要是选择 GPL 在道义上就没问题。所以十年后，用的人多了的情况下，他就形成了这样一种心理：世界上这么多人用我的代码，但我却这么穷，这不公平。 大家都用我的代码，所以我就该富有吗？ 理论上确实是如此，你创造了一个大家都在用的东西，理应收到物质上的回馈。但现实中就很复杂，你这东西如果从开始就说要收费，可能根本没这么多人用。所以这就是一个鸡生蛋还是蛋生鸡的问题，而且这库也不是一个必需品，事实上这是开发过程中的辅助库，基本不会发布到生产环境，替换起来又没到伤筋动骨的程度。 所以 Marak 在尝试通过这个库来赚钱的时候会很困难。即使这样，faker.js 并不是没融到钱，只是可能没达到最近玩币圈的 Marak 的胃口。参考faker.js - Open Collective ： 真正能赚钱的通常不是基础库，而是直接面向用户的成品，比如 Obsidian 这个产品，我作为愿意付费，但是我没捐赠给他用的那些开源库。而给基础开源库捐赠的企业太少了，参考之前的 OpenSSL 事件。 个人为什么开源实际上，能通过开源软件直接赚钱的个人开发者少之又少。如果这样，作为个人开发者，为什么我们要开源？ 开源运动始于早期黑客的反抗精神和分享精神，Unix 不是闭源么，所以早期黑客把代码印成书来分发，这是一种对商业软件的反抗。随着互联网和 Linux 的发展，开源已成为软件开发的常态，甚至是开发者的自豪。可以说开源和 Wikipedia 是目前人类两项最大的集体智慧活动，无数人在无偿地、自愿地付出时间和精力去做共享。 大多开源是为了交流和单纯的分享，想给其他人看看怎么样，也许社区会有反馈，也去其他人可以帮忙完善一部分等等。 另一部分原因是为了名声，如果一个开源作品得到很多关注，可以给自己增光不少。如果一个开源项目被大公司用了，通常会怎样？作者会把大公司的名称列到 README 的用户列表中。开发者可能内心会希望大公司多少能捐赠些，但其实大公司白嫖也能给项目带来曝光度和知名度。 公司为什么要开源公司是否开源是个很复杂的问题。很多公司开源是为了形成社区和生态，比如 VSCode，要是不开放源肯定没有现在的几乎垄断的态势。比如 TiDB、TDEngine ，他们巴不得各位来学习、研究他们的代码，这样会渐渐形成开发生态。用户一看关注度这么高，用的信心也增强了。但你说这源码都给用户了，该怎么挣钱啊。事实上他们总会有付费的功能不会在社区版本，然后用户中只要有一小部分能赚钱就可以了。 我理解这是行业发展到一定程度必然出现的结果，就是先让大家用起来，然后再通过技术支持和付费功能收费。开源软件的商业化也不好走，比如 Docker 影响力这么大的开源项目也难以找到合适的盈利模式。 开源是否拉低了行业门槛半佛仙人提到其他行业的聪明人，比如律师、医生都在提高行业门槛，为什么 IT 行业的傻傻程序员在免费分享，降低行业门槛？ 现实确实如此，现在学习编程的资料多如牛毛、唾手可得，任何想学编程的都可以面对电脑开始学。开源的、可复用的代码太多，任何人稍微学学可能就能弄出一个产品。比如搭网站，在二十年前可能需要一个专业的程序员，耗费好几天才可以搞定。现在既然有了这么多代码可以参考，这么多现有的框架可以用，可能一个学了一个月的初级程序员花上一天就能搞定。 那这到底是门槛低了还是生产率提高了？ 我认为都有。但我不认为这是这个行业内卷的原因，内卷化的本质是生存与发展问题，国内很多人涌进来学 IT 本身因为这个行业相对好找工作、工资高点。开源提高了程序员生产力，同时也加速了各行各业的数字化进程，蛋糕越来越大了。中国 IT 行业内卷是因为年轻人多，而公司做的都是业务型工作多，导致老人容易被新人替代。你看腐朽的资本主义国家，IT 行业还是处于极度缺人状态，行业从业人员也不用 996。 有人说：开源软件是程序员的自媒体。 我觉得这种说法很恰当，作为开发者你可以开个自媒体，也可以不跟这个风气。现状是有小部分人因为自媒体富了起来，绝大部分在用爱发电。 假如，作为一个自媒体的作者，我一直说我的东西是免费的，结果 10 年后进入币圈觉得自己穷，高呼你们这些粉丝和读者都是白嫖党，看了我的文章的都该给我钱，没多少人给钱我就把老文章给删了。 这，就很诡异！ 所以我觉得这事件的结论是：币圈容易让人黑化。","tags":[{"name":"技术","slug":"技术","permalink":"http://catcoding.me/tags/%E6%8A%80%E6%9C%AF/"},{"name":"开源","slug":"开源","permalink":"http://catcoding.me/tags/%E5%BC%80%E6%BA%90/"}]},{"title":"花 10 年写一本编程语言实现的书","date":"2022-01-12T00:10:31.000Z","path":"p/a-book-on-programming-language/","text":"Robert Nystrom 是一位拥有 20 年工作经验的软件工程师，之前在 EA 做了 9 年多，2010 年入职 Google ，目前工作在 Dart 项目。 2009 年开始写一本设计模式方面的书，叫 Game Programming Patterns，写到一半发现自己对编程语言实现很感兴趣。强忍着兴奋继续写第一本，直到 2014 年第一本书完成.。这本书收获很高的评价，建议想学习设计模式的同学看看这本书，电子版本的完全公开。 而后就开始了第二本关于编程语言实现的书，断断续续写了这么多年，直到 2020 年完成了：Crafting Interpreters，整个过程居然花费了接近 10 年时间。 在这篇 Crafting “Crafting Interpreters” 中，作者详细记录了完成这本书的过程。反正我看完后很震惊，一本技术书籍可以按照这种制作工艺和水准，最后的成书是我见过的质量最高的技术书籍，而且成书和代码可以完全免费阅读！ 其实写技术书是投入产出比很低的事情，只有纯粹的热情才能让一个人花这么多年去写这种书。为了完成这本书，作者看了这么多关于语言实现的书： 里面的插图是自己手画的，配文是手写的 ，完成之后再通过扫描机扫描成电子版本： 所有想深入学习编程的人都应该去理解一个编程语言是如何实现的，因为： 克服对语言的恐惧，解释器、编译器不过是另外一个程序。我们可以自己去实现一些常见的语法和特性，编程语言对我们是可以改变和理解的工具，而不是黑盒。 这是一个绝佳的提升编程技能的方式。 工作中会接触到各种小语言和 DSL (Domain-specific language)，parser 或者编译相关的技能可能会有用。 我大学本科的时候挂了一门课叫做形式语言和自动机，这门课当然是对 Parser 很重要的，但是我觉得枯燥之极，我记得需要手画状态机。 后来我工作之后，找了一些具体的代码来看，才能理解状态机这些东西如何应用在实际中。所以，我认为在学习编程中最重要的还是读代码和写代码。我通过读 Essentials of programming languages 学到了很多编程语言相关的东西，在这里面可以实现好多小解释器。 理解编程语言的过程中，Parser 只是其中第一步，而且也是不重要的一步。Parser 如何做已经有了很成熟和规范的做法，一门编程语言更重要的是语法、语义和实现。编译部分又涉及到更多底层和高深的东西，现在 LLVM 是常用的编译后端。所以要理解一门编程语言的实现，一个小语言的解释器就是很好的方向。 在这本书里，作者详细讲解了一个解释器的两遍实现，第一遍用 Java 实现，注重主要概念和原理；第二遍用 C 实现，bytecode、VM 、GC，注重优化和底层实现。 这些主题对于非编译器从业人员来说已经足够了。编程语言的实现比很多日常项目难，但这值得一个想更深入学习编程的人锻炼： 长跑运动员有时在脚踝上绑上重物，或者在空气稀薄的高海拔地区进行训练。然后卸下包袱时，相对轻松的四肢和富含氧气的空气使它们跑得更远更快。 另外这本书中有一些英语俚语，不过不会对阅读造成干扰。相比较 EOPL，我更推荐这本书来学习编程语言原理，因为 EOPL 偏函数式一些，相对更小众。","tags":[{"name":"技术","slug":"技术","permalink":"http://catcoding.me/tags/%E6%8A%80%E6%9C%AF/"},{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"}]},{"title":"深刻启发我的 3 篇文章","date":"2022-01-10T22:07:55.000Z","path":"p/share-3-articles/","text":"这些年读过很多的文章，绝大部分看了就忘记了，其中这三篇对我启发很大，这里分享给大家。 十年学会编程 Teach Yourself Programming in Ten Years 十年学会编程 这篇文章是 Peter Norvig 发表于二十年前。现在和二十年前都一样，很多人学习编程都会浮躁，渴望 21 天甚至是 7 天 就能学会编程，这篇文章很好的解释了为什么不行。甚至是，初学者理解的编程和一个高手理解的编程可能都不是一回事。 对我的启发是，永远不要妄想有什么捷径，不要浮躁，编程不是一门科学，更像是一种技艺，如同绘画、音乐一样的技能，只有通过长时间的砺练才会有所成。 另外不要拘泥于单一技术，因为技术可能会过时，这样年纪越大越容易被淘汰。需要不断加基础知识和核心能力，因为技术原理相通，无论适应学习新技术、还是发挥经验优势，都是比年轻人强很多的。 学习编程这么多年后，反而更加觉得自己渺小和无知，看着那些后浪做出的漂亮东西有时候会感叹，这十年可荒废了不少，想再上一台阶再花十年吧。 Learn in Public Learn In Public 当众学习 - 最快的学习方式 我之前写了 10 来年的博客，但我基本是当作自己的一个私人记录在写，我甚至不希望身边的朋友、同事发现我写的东西，因为我会觉得不舒服，后来我才知道这其实就是冒名顶替综合症。我的域名也丢了两次，所以最终导致我写的东西除了自己看没有什么很多人看过。 这会有什么问题？ 其实也没什么大问题，只是我丧失了很多提高自己的机会。 写出来的东西并没有其他人看，就相当于我只是在消费，实际并没有产出。因为没有得到太多的反馈、激励，即使我写了 10 年，这也是断断续续写的，兴致来了写上一篇，通常每年十篇左右，这样没有形成写作的习惯，而且我丧失了启发他人，以及从他人学习的机会。 我认为 Learn In Public 是费曼学习法的加强版，能在公共场合传授我们所学，这是更高的标准。 具体执行起来可能是在 Github 上通过做贡献，或者是建立一个持久的开源的知识库，或者去做公开的技术分享等等。长久来说，人们会注意到真正的学习者和生产者，然后会向其提供帮助或者寻求帮助，这个过程就能产生价值。 我正在实践这个理念，比如我正在写的这个公众号，我想让自己变得更自信和开放，推广自己的想法，让自己成为生产者，同时还能和更多人交流。 别让自己“墙”了自己 别让自己“墙”了自己 CoolShell 上有很多不错的文章，其中这篇我会时不时再看。 偏见和不开放，对一个人的限制是真正有毁灭性的。 持有强烈偏见是技术人员经常会出现的问题，大概是因为我们在编程的时候其实是在构建一个简单的世界，所以自认为一切都可控，自己擅长的就是最好的。 比如有的人认为 C++ 是最强的，所以鄙视其他语言；比如我之前认为 Emacs 是最好的，所以排斥一些现代先进的编辑器；比如自认为是后端开发，所以前端的东西不想碰。行业里这样的偏见到处可见，能形成各种鄙视链。这种不开放的心态就是作茧自缚。 这篇文章还谈了很多其他的方面： 站在更高维度上思考和学习 整天在焦虑那些低维度的事（比如自己的薪水、工作的地点、稳不稳定、有没有户口……），只会让你变得越来越平庸，只要你站在更高的维度（比如： 眼界有没有扩大、可能性是不是更多、竞争力是不是更强、能不能解决更大更难的问题、能创造多大的价值……），时间会让你明白那些低维度的东西全都不是事儿。 技术学习上也一样，站在学习编程语法特性的维度和站在学习编程范式、设计模式的维度是两种完全不一样的学习方式。 扩大眼界 英文语言能力对你能不能融入世界是起决定性的作用，所以我也还在提高英语写作和口语。","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"},{"name":"个人成长","slug":"个人成长","permalink":"http://catcoding.me/tags/%E4%B8%AA%E4%BA%BA%E6%88%90%E9%95%BF/"}]},{"title":"35 岁，我用这三种方法克服焦虑","date":"2022-01-07T00:10:33.000Z","path":"p/how-to-beat-anxiety/","text":"去年我刚好满 35 岁。 我 2011 年研究生毕业后参加工作，一直工作在 IT 领域，这些年发展也算比较顺利。毕业后我待了一个创业团队三年，后面六年一直待在深圳一个独角兽企业。这十年算是赶上了行业红利和房产红利，经济上没什么大的压力。 但是在 2019 年开始我开始焦虑。 主要压力来自家庭，亲人查出严重疾病，幸好手术后渐渐恢复。另一方面压力来自工作，因为在同一公司工作六年后我感觉到了瓶颈，对自己的工作内容也提不起兴趣。还有一方面来自自己的身体，因为经常晚上睡不好觉导致出了一些肠胃方面的慢性疾病。有段时间我不敢去医院检查，因为怕是什么绝症之类的。后来鼓起勇气去做了比较彻底的检查，医生说这病只能慢慢养，心情要放松才行。 总之，人生进入后半场不如意十之八九，家庭、工作、健康，突然各方面都需要应对，而精力又大不如前。 经过一年多的调整，我感觉现在基本摆脱了焦虑，自认为算是迈过了这道坎。总的来说我用了三种方法： 做让自己进入心流的事 换工作和城市 找到自己的长期驱动力，做 PlanB 分别再详细阐述一下。 当一个人焦虑的时候，就很容易东想西想、瞻前顾后，这样会加重精神内耗，反过来加重焦虑。如何避免自己想得太多从而进入恶性循环？ 一个好办法是让自己进去心流状态，尝试找自己感兴趣的、喜欢做的事情，留出较长一段时间来做。这就好像是躲避，但是是一种安全的躲避方式。 我喜欢编程，有段时间我就也没想到写什么代码，回想起读研时曾经花了很多业余时间在 POJ 上刷题，那段时间经常能获得心流的体验，所以我就又在 LeetCode 上刷题写代码。 后来有一段时间我又热衷于乐高，所以买了一些夜深人静的时候自己玩。后来发现写作也能让自己静下心来，所以那段时间我每天写一篇技术类的英文文章，然后发布到 Medium 上。我发现这样还能赚些钱，所以就动机就更大，投入了更多时间在这上面。 总之，兴趣和爱好可以让自己从工作、生活中暂时逃离，这样可以应对心理、精神上的疲劳。 2020 年中，因为一次偶然的面试，我拿了一个苏州微软的 Offer。然后大概经过了一个多月的考虑，我决定举家从深圳搬迁到苏州。这需要很大的勇气，我甚至让女儿来抽签决定是否离开已经定居的深圳。 最终做出换工作的决定还是因为我想多一些不同的体验和尝试，李笑来曾说七年就是一辈子，我已经在深圳待了 6 年。就像是优化算法进入了一个局部最优解，我需要趁还不那么老的时候去做一个更大的改变。 在苏州待了一年之后，我有些庆幸自己当时做了那个决定。人焦虑很多时候是因为所处的环境。苏州整个城市都是有一种养老的气质，稍晚点街上就没什么人，路上没什么车，完全没有奋斗的氛围。 如果要在一个公司长待，那么公司企业文化是否和自己贴合特别重要。外企工作节奏和氛围轻松多了，我工作上时间投入少很多，基本是上午十点上班晚上六点下班。更重要的是成熟的公司管理方式反而更简单些，上班做事下班闪人。 人到中年有时候得把工作别看得太重，这需要做取舍。在纪伯伦的《先知》中谈论到工作时写道： 所有知识都是无用的，除非有了工作，所有工作都是空洞的，除非有了爱； 毕竟工作也还是为了家，工作相对轻松了我可以每天晚上回家吃饭，陪女儿玩耍，看书，给她洗漱哄她睡觉。这些陪伴对她的成长很重要，从长远来看这也许比赚钱还重要。在陪小孩的过程中，自己也像是在重新过一个童年，玩积木和拼图都很有趣。 另外苏州的风景和天气都很不错，所以这一年我经常周末开车出去逛，太湖、阳澄湖、古镇等等，风景好的地方太多了。当一个人整个心态慢下来，漫步在风景优美的自然环境里，就会觉得人间美好，我没心情焦虑，肠胃方面的问题也渐渐地就没什么症状了。 说了这么多，有的人可能就说这不就是躺平么？ 我认为不是。我是在调整工作和生活，更好地应对衰老这个自然规律。职场上的中年危机，本质上就是一种对不确定性的恐惧和焦虑。 如果是作为工薪阶层，年纪大了还一直还是只盯着职位和工资看，难免为失望，因为命运掌握在公司手里就会有不确定性。 即使到了 35 岁，后面的路还有很长，不要自己局限在公司和职场上。作为个体来说，我认为需要花时间思考自己的后路，如何能不断保持自己能力的提高，如何能不依赖公司或者机构创造自己的价值，如何找到自己的内在驱动力，如何做复利和时间的朋友。 这需要不断尝试，找到自己的激情所在，并且需要保持一种开放，终生学习成长的心态。比如我通过摸索，现在能通过写作赚钱，这一年我花了更多时间在开源上，对技术反而有了更大的兴趣，也能通过做开源软件赚钱。即使这两样加起来目前都不足以养活家庭，但是这是我自己的兴趣和爱好。 最坏的情况下我失业了，我还可以用此谋生，而且我相信如果投入更多时间，这两块都能做得更好。总之，PlanB 能让人自信和安宁，只要还在学习和进步就不算躺平。 经过了这个焦虑的阶段，回忆起来焦虑也会让人更深入的认识自己。经过毕业后这么些年，我们如果还不确定自己所求，但肯定知道哪些是自己不要的。 在某个阶段必须做取舍，就需要不断问自己想要的生活和人生是什么样的，想清楚之后去做决定然后执行，焦虑就少了。 如果按照中国平均寿命 70 多岁来算，35 岁刚好是一个分界点，在人生四季中算是进入秋季。前段时间在东太湖生态公园看到一排排的红杉树，觉得特别美。 正如人生的每一个年龄段自有其痛苦和动人之处，努力学会适应和享受，就能克服中年危机。","tags":[{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"}]},{"title":"那些年，我们终将碰上的 Bug","date":"2022-01-05T15:12:02.000Z","path":"p/those-bugs-will-always-happen/","text":"2022 年的新年钟声刚敲响，时钟从 2021 年 12 月 31 日跳转到 2022 年 1 月 1 日，微软 Exchange 准时给大家带来了第一个世界范围内的 Bug。人们写好的新年祝福等邮件，突然发不出去了！大量用户在 Reddit 、Twitter 上亮出新年第一骂。 那些正准备休假的倒霉的 IT 管理员，被紧急电话呼进公司，排查后发现邮件队列卡住了，日志里显示的是： 随后微软官方确认了这个 Bug。 这些错误是由 Microsoft Exchange Server 检查 FIP-FS 防病毒扫描引擎的版本，并试图将日期存储在带符号的 int32 变量中引起的。 在这个变量中使用了 yymmddHHMM 这种格式的约定，我们知道 int32 能表示的最大值是 2,147,483,647，但是到了 2020.01.01 这个值将是 2,201,010,001，所以就溢出了！ 这是一个典型的类似千年虫 问题，即由于时间的数据格式不对导致溢出或者日期逻辑错误，进而导致大量软件出现 Bug。千年虫的问题很多是因为很多老程序使用了两位来表示年份，比如 99 代表 1999 年，那 2000 年只能用 00 来表示了，但是 00 在程序里本意指的是 1900。 可能现在的新生代程序员会感叹，这些老古董为什么会犯这样低级的错误？ 这就牵扯到一些更复杂的问题： 一个是约定习俗，1931 年后很多人在写年份的时候，自然就开始用两位来代表年份，因为 1931 年后年和日已经不重合了，例如写成 35 ，任何人看了都是理解为 1935 年。 另一个原因是内存曾经又贵又稀缺，早期核心内存的价格是每比特 1 美元，老一辈程序员在写代码的时候都是按 bit 抠的。 前美联储主席 Alan Greenspan 曾经也写过程序： 我是造成这个问题的罪魁祸首之一。我曾在 20 世纪 60 年代和 70 年代编写过这些程序，我为自己能够在程序中挤出一些空格元素而感到自豪，因为我不需要在年份前加上一个 19。 在当时，这是非常重要的。在我们开始编写程序之前，我们曾经花了很多时间进行各种数学练习，这样它们就可以很清楚地根据空间和容量的使用进行划分。 我们从来没有想到，这些项目会持续几年以上。 “过早优化是万恶之源”，高老头真是诚不我欺： 这种类型的 Bug 是可以预测的，比如千年虫问题，其实在 1985 年左右就已经有计算机专家发现了。问题是代码已经写好并且运行了，甚至因为早期的系统和软件通用性不高，有很多固化在芯片内部的程序，所以要解决也是大费周折。而且日期的问题与各个地方的不同习俗也有关系，比如台湾某些程序在 2011 年出现了日期溢出问题，大家考虑一下为什么😉？ 总而言之，这些 Bug 就很神奇，我们知道在某些年份这类 Bug 必然会发生，但是我们无法完全消除，我们可以简称为 那些年，我们终将碰上的 Bug。 我们可以列举一下今后会碰到 Bug 的重要年份： GPS 星期技术归零GPS(全球定位系统) 广播时采用周计数 (WN) + 周内时 (TOW) 的方式组合发布，早期的 GPS 采用 10bits 存储 WN，所以当计数达到 1024 时会翻转为 0。因此每 1024 周 (也就是 19.6 年) 会轮回一次。 最近几年发生是 1999，2019，下一次预计就是 2038 年。 2019 年的这次看起来没有发生特别严重的事故，霍尼韦尔的飞行管理和导航软件因为没有及时打上补丁导致航班延误。一些 2012 年之前生产的 iPhone 和 iPad 可能因此连不上网络。 为了解决这一问题，现代化的 GPS 导航消息使用 13 位字段，该字段重复周期变成了 8,192 周（157 岁），也就是说会直到 2137 年附近才清零。 Unix 系统 time 溢出 2038 年将是软件历史上史诗级别的灾难年。 因为 Unix 系统最初实现的时候采用的是有符号整数 int 来保存时间，而时间系统是由 Epoch 开始计算起，单位为秒，Epoch 则是指定为 1970 年 1 月 1 日凌晨 00:00:00，格林威治时间。 很多古老的 UNIX 系统都是用 32 位元来记录时间，正值表示为 1970 以后，负值则表示 1970 年以前。也就是说最大为 0xFFFFFFFF 的一半，除以一天 86400 秒的话，就是 68 年。1970 年往后延 68 年刚好是 2038 年。 2038 年问题比 2000 的千年虫问题更麻烦。虽然目前很多 OS 和硬件已经升级到 64 位系统，32 位的嵌入式系统仍然大量运行。另外因为这涉及到系统层面的改动，如果我们直接修改 time_t 的定义，则会出现兼容性问题。 乐观情况，在还剩下不到 20 年的时间里，这些 32 位的系统逐渐被 64 位替换掉，这样就不会出现大问题。有可能导致严重问题的是那些无法升级的嵌入式系统，运行这些系统的设备寿命通常比较长，例如交通系统、汽车的稳定控制系统等。 2106 年很多文件格式、通讯协议采用的是类似 Unix 的日期格式，差别是把时间存储在无符号 32 bit 整数里。按照这个范围计算，日期将在 2106 年溢出。 4501 年Microsoft Outlook 使用 4501 年 1 月 1 日作为“none”或“empty”的占位符，不知道那天会出现什么神奇的 Bug，反正我们已经不在了。 这种类型的 Bug 其实还有很多，时间和日期是程序和系统中非常重要的一个概念，在分布式系统中时间也很容易造成 Bug。我们作为程序员在写代码的时候，尽量眼光放远一点，多想想自己的程序一千年以后还在跑🤣，这样大概就没这类问题了。 不过一千年后还在运行的代码，得多伟大。这时候我脑海里回想起来那首歌： 别等到 一千年以后所有人都遗忘了我那时红色黄昏的沙漠能有谁 解开缠绕千年的寂寞","tags":[{"name":"技术","slug":"技术","permalink":"http://catcoding.me/tags/%E6%8A%80%E6%9C%AF/"},{"name":"写作","slug":"写作","permalink":"http://catcoding.me/tags/%E5%86%99%E4%BD%9C/"}]},{"title":"什么是 Web3","date":"2022-01-03T10:30:46.000Z","path":"p/what-is-web3/","text":"2021 年 Web3 彻底火了，突然感觉很多人都在讨论，这看起来是在一个大的变革前夕。Web3 被路透社评为今年的科技热词之一，然而马斯克和一些科技大佬直呼没见过 Web3 这东西。 我花时间来理解了一下这个东西，从非技术角度探讨一下。。 对于 Web 1.0 和 2.0 的区分，业界似乎是达成了比较一致的共识，但是对 Web3 这个术语其实是有些困惑的，我来解释一下。 Web 1.0 时代 年份： 1991 - 2004 在这个时代，作为互联网的普通用户，我们主要是从互联网获取信息和内容。内容是由那些互联网门户，例如搜狐、网易、新浪、腾讯等四大门户网站。这个时代的最大赢家是 Yahoo！这是一种单向的信息分享，信息提供商提供新闻、咨询等，我们上网读取。 这个阶段社交网络还没有真正成型，大多是还是以企业以及组织机构为主的门户网站。本质上就是单向的信息分享——我通过网络查看我需要的资料。 活化石一样的互联网公司——Yahoo！是这个时期的大赢家。国内比较有代表性的是搜狐、网易、新浪、腾讯为代表的四大门户。 Web 2.0 时代 年份：2004 - 2020 大概从 03 年开始，O’Reilly Media 的副总裁戴尔·杜赫蒂（Dale Dougherty）首先提出 Web2.0 这个词，随后 Web2.0 的浪潮席卷全球。 Facebook 于 2004 年创办，而后成为社交网络巨头。可以说社交网络定义了 Web 2.0，移动设备比如手机联入互联网，极大地加速了 Web 2.0 的发展。 在 2. 0 时代，互联网就把人与内容的关系变成了人与人的关系。在短短十年的时间里，Web2.0 完全重新定义了市场营销和业务运营。Web2.0 包含大量目前我们熟悉的产品和服务，例如 RSS、博客、播客、维基、P2P 下载、SNS、社区、分享服务等等。 互联网用户也参与了生产内容，比如你上网发表个博客，发一个照片，发个餐厅的评论等等，大量的数据从普通用户那里产生。 人对于互联网的影响力与日俱增，以往网站给用户投喂信息的时代已经过去。有影响的网红只需要发一个视频就可以让一个餐馆排满长队，也可以用一句话让一家网店差评如潮。公众号、微博等本质上是把个体做成了品牌。 在 Web 2.0 时代，少数超级强大的公司拥有的封闭式平台上进行大量的通信和商业，全球的谷歌，Facebook，亚马逊，国内的腾讯，新浪微博等。 Web 3.0 时代 年份：2021 ~ …. 有的狂热的支持者可能只认可 Web3 这种说法，但是业界目前有的人用 Web 3.0 ，有的人用 Web3，并且他们讨论的可能不是一个东西。Web3 看起来就是一个箩筐，大家都在往里面扔不同的东西，其定义还在不断地改变。里面保罗万象，有物联网、人工智能、区块链等等。我从一些资料梳理了一下，总结发现 Web3 主要是指下面这两个： 语义互联网以 2014 年为分割点，之前大家在讨论 Web 3.0 的时候，更多的是在讨论语义互联网 (Semantic Web)。语义互联网的概念是 W3C 发起的，目标是改善互联网现状。通过给万维网上的文档（如：HTML文档）添加能够被计算机所理解的语义元数据，使得人们能够更方便快捷地找到网络信息。这些元数据描述语言包括 RDF/RDFS 等。 但这条路其实发展缓慢，或者其实基于关键词的搜索满足了绝大部分场景。有的公司使用自然语言处理 (Natural Language Process) 继续在朝着让机器理解内容的方向前进。在知识理解这块我觉得 WolframAlpha 让人耳目一新，WolframAlpha 对自然语言的识别和逻辑感觉比较强大，这更像知识引擎 。 去中心化2009 年比特币发明，其底层技术区块链于 2014 年开始越来越热。以太坊 (Ethereum) 联合创始人 Gavin Wood 于 2014 年重新定义了 Web 3.0。 在新的概念中，Web3 的特点是去中心化。这也等于要革这些中心化巨头的命，师出有名很重要，Web 3.0 可是个好名称，用来营销再适合不过了。 区块链信徒相信未来互联网是一个运行在“区块链”技术上面的“去中心化”的互联网。在这种模式下，用户将拥有平台和应用程序的所有权。一些爱好者还将游戏、元世界、增强现实和虚拟现实与 Web3 联系在一起，因为一些虚拟世界依赖于基于区块链的数字资产。 为什么要去中心化？这得从中心化的弊端开始讨论。所谓中心，即在一个体系中，如果一个节点要和另外的节点产生关联，都要通过特定的一个节点，这个特定的节点就是一个中心。比如阿里的淘宝，我要买东西需要在淘宝下单，然后付钱，对方发货我确认后，对方在淘宝收钱。对于交易来说，淘宝就是一个中心。同理，银行、微信、微博、Facebook 都是中心。 中心化的弊端是风险和隐私。 中心拥有所有用户的数据，可以操纵用户的情况下是非常危险的，比如 Facebook 可以通过给不同政见的人群推送不同类型的广告，这样可以用来引导选民。川普那么多粉丝，Twitter 说杀就杀，这就是平台的权力。再比如我们的隐私被电商收集，大数据杀熟成为常规操作。我们的交易产生的数据被第三方平台无偿利用，我们却得不到任何报酬，它往往涉及用户的隐私。如果管理不当，也极易造成隐私的泄露。 在 Web3 里，用户不仅是创造内容，还需要拥有自己的数据。 目前已经出现了一批去中心化的应用，DApp 是 D+App，D 为英文单词 Decentralization 的首字母，中文翻译为去中心化，即 DApp 为去中心化应用。DApp 是在区块链公链上开发并结合智能合约，其数据加密后存储在区块链，难以篡改。从现在有的运行模式看，DApp 更像是众筹模式。先有发起人写好白皮书明确了共识机制和 Token(通证) 分配与激励，以包括智能合约等区块链技术开发好应用，其中持有 Token 的用户都是股东，持有的 Token 也可以在支持的交易所交易。 前段时间出现了一个典型的案例，一个区块链爱好者在网上发起来了一个通过区块链筹款来竞拍美国宪法的古董品，最终竟然筹集 4700 万美元。虽然最终没有竞拍成功，但是依然创造了历史，证明基于区块链的集资是可行的。 目前这些 DApp 都还比较小众，比如下面这些区中心化的应用，你用过多少？ 我看了看其中的这个 Brave 浏览器，它在用户安全和隐私上做了很多优化，特别是去掉了一些可以追踪用户的功能。代码全部开源，同样使用 Chrome 的内核，支持跨平台使用，它是基于区块链技术的无广告纯净 Web 浏览器。 Brave 利用区块链技术集成 Token BAT 来让用户可以直接支持投给自己喜欢的文章，视频等创造者。并且用户也可以通过自身加入区块链为基础的数字广告平台，通过推广而获得奖励。这大概就是用户 own 的意思吧。 虽然目前区块链除了比特币之类的数字货币外，并没有出现另一个现象级应用，资本还是在不断投入到这些初创公司中。如果一个投资公司在某些区块链应用中占大部分股份，那这本质上还是一个中心化的实体。这也是为什么 Twitter 的创始人多西吐槽说，投资机构拥有这些 Web3。 我不知道 Web3 到底是真的未来互联网方向，还是一个泡沫似的营销术语。但我认为去中心化的大势是好的，去中心化的互联网一个更能促进人与人平等、人与 Web 相处更友好的互联网。","tags":[{"name":"Web","slug":"Web","permalink":"http://catcoding.me/tags/Web/"},{"name":"互联网","slug":"互联网","permalink":"http://catcoding.me/tags/%E4%BA%92%E8%81%94%E7%BD%91/"}]},{"title":"我欣赏的英文技术站","date":"2021-12-28T10:32:58.000Z","path":"p/best-english-tech-sites/","text":"做技术这么多年，我订阅了很多英文技术站点。这里介绍一些我认为非常值得关注、学习的技术站点。 我推荐的标准是： 持续多年更新 质量非常高，或者某些文章深刻地启发了我 后面我会长期更新这个列表： Joel on Software Essays (paulgraham.com) 有太多经典的技术文章。分别有中文的《Joel 谈软件》和《黑客与画家》。 Eli Bendersky’s website (thegreenplace.net) 这个博客已经有十多年了。我记得最初搜索到这个站点是自己在 2008 年做 SICP 的习题时，我发现这里有几乎 SICP 所有的习题答案，附带自己详细的解释。 难能可贵的是，作者 Eli Bendersky 一直坚持记录自己技术上的心得，这个博客持续在更新。而且他写的内容质量都非常高，既有理论又有实践和代码。例如他写的 Raft 系列： Implementing Raft: Part 0 - Introduction，简直就是技术写作的典范。 Flavio Copes 这个博客是一个意大利开发者维护的，内容偏向于前端和 Web 开发之类的。我欣赏这个站点是因为他在几年内几乎做到了每天都日更写博客。有时候我想写又懒癌发作的时候，就会想到这位作者。他写的东西也许并不高深，但对很多人来说有用。我之前用 SEO 工具看过这个网站的数据，Google 给他带来的自然流量非常高。 Every developer should have a blog. Here’s why, and how to stick with it I wrote 1 blog post every day for 2 years. Here’s 5 things I learned about SEO Julia Evans (jvns.ca) 这个博客也是持续更新了近 10 年，涉及的领域及其广泛。这个作者深刻启发了我的观点是，通过搞懂内部原理来学习编程：Get better at programming by learning how things work。 当然还有很多其他类的技术类文章如：Diving into concurrency: trying out mutexes and atomics 而且作者做了很多技术相关的电子书，用漫画的方式讲解技术，图文并茂：wizard zines journal.stuffwithstuff.com 花 6 年时间，用工匠精神写一本编程语言实现的书是怎样一种体验？Crafting “Crafting Interpreters” 在这里所有的图片都是用手画出来的，字体、颜色、对齐等，所有这些细节几乎都做到完美，最终成书可以称之为艺术品。一个技术书籍竟然能做到如此优美！ swyx’s site 主要内容涉及开发、个人成长等。其中 Learn In Public (swyx.io) 这个概念对我有很大触动，这个博客还有很多 podcast 。","tags":[{"name":"编程","slug":"编程","permalink":"http://catcoding.me/tags/%E7%BC%96%E7%A8%8B/"}]},{"title":"百度是如何死掉的","date":"2021-12-27T07:02:34.000Z","path":"p/baidu-die-for-reason/","text":"“百度已死” 几年前就已经被广泛讨论过，好像现在大家都不怎么讨论了。即使百度仍是最大的中文搜索引擎，但已沦为互联网度量单位，短短数年间的变化不由让人唏嘘。 今天让我重新思考这个问题的是两件小事。 事件一我有一个英文小站点，断断续续写了一些技术类的文章。这一年来已经有一些稳定的流量，大部分都是从 Google 来的自然流量。我曾经学了点 Amazon 推广的东西，当时把几篇文章的链接换成了亚马逊的推广链接，然后现在隔段时间就能从亚马逊收到一笔小钱，平均每个月大概 10 来块美金吧。 这个数额很小，但是这种模式确实就是很多小网站的盈利模式。这是已经被验证可行的创造被动收入的可靠方式，有的站点能做到几万美金一个月。 事件二我老婆想找一个房屋出租合同模板，结果她在百度上花了十来分钟，我看她已经开始在注册某下载网站的账号，她说要下载就得付费。我大为震惊！这个年代这种免费中文信息居然如此难以获取。 然后我打开 Google 输入关键词立马解决。 从这两件小事上，我分别从内容创作者、互联网普通用户两个角色体验到了百度为什么会死。 百度这些年来渐渐的沦为互联网公司的度量单位，一个原因是没有拿到移动互联网的门票，另一个更根本的原因就是丢掉了用户信任。 其结果不只是一个公司发展不好，甚至可以说是阻碍了中文信息的分享，并且让很多初创企业无法生存。 不知道大家有没有体会，现在互联网上的免费的、好的中文信息越来越少。曾经流行过一段时间独立站点，但是你看现在活下来的，还在好好创作内容的中小站点还有多少？ 但是英文就完全不同，我们可以通过 Google 搜索到的很多结果来自中小站点，而且内容质量很高。 因为用户相信在 Google 上能找到可靠的、高质量的内容，内容创作者相信高质量的内容可以通过 Google 吸引到用户，有流量就可以通过各种方式来变现。所以创作者就会不断创造高质量的内容，争取能做到 Google 的搜索排名靠前。还衍生了 SEO (Search Engine Optimization ) 这样的行业，有提供咨询和服务的，有提供工具的，有提供数据的等等。 这样就形成了一个正向闭环。这种的商业模式对于用户、创作者、Google 三方有益的。可以说 Google 通过搜索打造了一个超级印钞机。 但是百度选择另外一条路，因为过于短视，竭泽而渔去做竞价排名，最终破坏了这种用户、内容创作者对百度的信任。反正写得好也没流量，结果就是整个开放的互联网上，中文的高质量内容越来越少。而一些高质量的站点，比如 CoolShell 从来不期望百度能带流量，而且做了 anti-baidu 插件来提醒读者不要使用百度。 用户搜索行为被分流到了各个垂直领域的 App，这些 App 很多都是对搜索引擎是封闭的，比如微信公众号，整个就是一个大的封闭生态，这样百度可以使用的信息也越来越少。 2010 年的时候，我的一个师兄在成都创业，做的是房产相关的网站。我当时快毕业了，跟着在里面实习打杂。 我印象比较深的一点是，我隔壁座位的师兄时不时叹息：百度账号上的钱又快没了。实际上我们的业务都还没跑上正轨，但是百度已经开始收割了。很多人可能没开过做过初创公司，不信你可以试试，以公司的名义上线一个网站，要不了几个礼拜百度的销售会联系过来，问你要不要充钱。那你说我们可以不充钱啊，不充的结果就是几乎没有任何自然增长的机会 。 一个公平有效的互联网搜索引擎，应当会给这些中小企业生存机会，而不是一味的凭借自己手握流量来抢夺和豪取，吃自己的饭让别人没饭可吃。 理想情况下，如果一个初创企业或个人能够提供好的信息和服务，那就应该被人们搜索到，然后逐渐成长起来。比如 Flavio Copes，这是一个意大利开发者的个人站点，写的东西简单明了，Google 每天给他带来几万的自然流量，这样他可以开始自己卖电子书，逐渐摸索出了自己的业务。 当一个公司掌握了流量分发大权时，有太多的手段可以立马来钱，所以抵抗这种诱惑需要克制和智慧。 在 Google 2004 年首次公开募股的招股说明书中，包含了这几个字：“不作恶，我们坚信，从长远来看，即使我们放弃一些短期收益，作为股东，以及在其他方面，作为一家为世界做好事的公司，我们也会得到更好的服务“。 很遗憾，百度在我看来就是在作恶。从我上面的第二个例子可以看出百度已经把免费的信息拿来换钱了，其他的恶还有把卖百度贴吧，百度全家桶等等，罄竹难书。 我想如果没有百度也许我们会有一个更好的中文互联网环境。 除了百度的核心高管，外界估计无法知晓为什么百度这么多年都坚持做竞价排名。也许这东西就像是毒品一般，用上了之后就在资本的压力下再也无法回头。百度这些年来转头做 AI，作为普通用户我也是不抱任何期待。魏则西事件后大众对百度口诛笔伐，但是现在还是原来那个卵样。你要是想在百度上查个什么病，看几页搜索结果就会觉得自己命不久矣。 所以，百度的产品能绕开就建议不用，少给自己添麻烦。","tags":[{"name":"胡写","slug":"胡写","permalink":"http://catcoding.me/tags/%E8%83%A1%E5%86%99/"}]},{"title":"编译 WebAssembly 模块","date":"2021-12-16T07:02:23.000Z","path":"p/compiling-to-wasm/","text":"最近一年经常接触了 WebAssembly , 我把一些老的 C/C++ 代码通过 emcc 编译为 wasm 模块，也可以把 Rust 代码编译为 wasm。 这里做一个简单的总结，以及我在编译过程中碰到的问题。 WebAssembly 的优势 WebAsembly 定义了一个可移植、体积小、加载快的二进制格式作为编译结果。通过充分发挥通用硬件的能力（包括移动设备以及物联网），使其在大多数平台上能达到原生的执行效率。借助 wasi，WebAssembly 还可能运行在服务端。WebAssembly 的目标包括： 现有的 Web 平台完美结合并在其中运行： 维护无版本、特性可测试、向后兼容的 Web 演变过程； 和 JavaScript 执行在相同的语意环境中； 允许和 JavaScript 相互的同步调用； 严格遵守同源策略以及浏览器安全策略； 和 JavaScript 一样，可以访问相同的 Web API 去调用浏览器的功能；以及 定义一个可与二进制格式相互转化的人类可编辑的文本格式，并且支持查看源码的功能。 被设计为也可以支持非浏览器嵌入的运行形式，这样就可能在某些场景下替代 Docker。 C/C++ =&gt; wasm首先需要安装 Emscripten SDK:https://emscripten.org/docs/getting_started/downloads.html 移植一个 C/C++ 项目到 WebAssembly , 最简单的办法是把类似 gcc 命令换成 emcc，难点在于动态链接的第三方库，我们需要改成静态链接。一些常用的库已经被移植了，例如libc, libc++ and SDL，这些我们不需要手动处理。不在 emcc 预装里的库，我们只需要在编译的过程中加一些额外的参数，例如我下面这个项目就用到了 PNG，JPEG 这些库： emcc -c dbgutil.c -o dbgutil.oemcc -c qrtest.c -o qrtest.oemcc -c decode.c -o decode.oemcc -c identify.c -o identify.oemcc -c quirc.c -o quirc.oemcc -c version_db.c -o version_db.oemcc -g -Oz --llvm-lto 1 -s STANDALONE_WASM *.o -o qrtest.wasm -lm -s USE_LIBJPEG -s USE_LIBPNG 另外 emcc 编译出来的 wasm 模块默认只能做纯计算，没有网络、系统文件等。如果有系统调用则需要运行在浏览器中，用浏览器的接口来模拟某些 C 函数调用，例如 C 语言中的系统调用 time 在 emcc 中被替成为了 JavaScript 代码： clock: function() &#123; if (_clock.start === undefined) _clock.start = Date.now(); return ((Date.now() - _clock.start) * (&#123;&#123;&#123; cDefine(&#x27;CLOCKS_PER_SEC&#x27;) &#125;&#125;&#125; / 1000))|0; &#125; Rust =&gt; wasmRust 是对 WebAssembly 支持得特别好的编程语言。我们可以使用 wasm-pack，或者安装 target: rustup target add wasm32-wasi 然后在编译命令后面加参数：cargo build --target wasm32-wasi 系统函数同样是个问题，有的第三方库可能会支持 wasm 格式，例如 getrandom - Rust (docs.rs)。 参考Main — Emscripten 3.0.1-git (dev) documentationWASM Tutorial (marcoselvatici.github.io)Introduction - Rust and WebAssembly (rustwasm.github.io)","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"WebAssembly","slug":"WebAssembly","permalink":"http://catcoding.me/tags/WebAssembly/"}]},{"title":"为什么要开源","date":"2021-12-14T07:02:45.000Z","path":"p/why-open-source/","text":"这篇源于知乎上的一个问题：为什么程序员们愿意在 GitHub 上开源自己的成果给别人免费使用和学习？ 最近越发觉得，分享越多就会有更多的可能性，这里谈谈自己这些年的收获和想法。 我 2010 年开始在 Github 上分享自己的代码。在 push 代码之前我根本没想过为什么，只是因我当时学了 Git，而且又觉得 Github 很方便，可以用来备份自己的代码。 而后我就参加工作了，在工作之余我还会写一些感兴趣的代码分享到 Github，没事也经常在上面瞎逛，找一些自己感兴趣的资料和代码来学习。没想到这么多年下来，在 Github 上玩开源已经成为自己的一种习惯、爱好和生活方式。 最近一年工作轻松些了，所以有更多时间投入在这上面 (忽略最近两个月的大量提交数据，因为有个自动脚本每天在同步笔记 😁) 自我提高我建议任何在学编程、想提高开发技能的人参与到开源中来。 现在的软件开发已经过了刀耕火种，徒手编码的年代。很多开发需要复用大量已有的库和工具，大型软件开发是一种社会化的、集体性的智慧活动。 在 Github 上分享代码，给其他开源项目做贡献，是最好的、最直接的方式来练习这种编程能力、协作能力和复用已有代码的能力。在 Github 上混久了，就形成一种自然而然做贡献的习惯，在这里我们不只是使用者，也可以是贡献者，例如： 我想学学 WebAssembly，所以找来一个 Runtime wasmerio/wasmer 实现看看，顺便修复一些自己发现的问题 。 我在使用这个 Obsidian 补全插件碰到些缺陷，提了个 PR 修一下然后和作者讨论一下怎么更完善。 在使用 Rust 开发的时候，我看到了一些重复的警告，在 Github 上一搜索发现别人也碰到过，所以我花了一些时间提 PR 修复。 我想看看 container 是怎么实现的，所以找来开源代码 containers/youki 来学习，然后顺便修复自己发现的问题，后来还成了 maintainer。 在开发中，使用者和贡献者是完全不同的态度，使用者在碰到问题的时候可能会放弃掉，而贡献者会去尝试发现原因、找到解决办法，在这个过程中我们可以学到很多。而且为开源做贡献属于 Working in Public，也是 Learn in Public。Working in Public 的好处在于我们做的贡献可以算作能力的证明，参考刘未鹏十年前的怎样花两年时间去面试一个人, Github 主页是最直观的开发人员简历。这些年我换工作就碰到过认可我开源贡献的公司，面试的时候就不考八股的问题了。 创造价值实际上绝大多数代码不值钱。纯代码不值钱，业务才能赚钱，所以代码得运行起来、或者是交流起来。如果我分享出来的代码对别人有用，就能产生价值，能产生价值就附带可以赚钱。 举个例子，我在自己看书《Enssential of Programming Language》的时候，一边学习一边把课后习题用代码实现了：my solutions to EOPL3 。 这个代码如果一直留在我硬盘的某个角落，估计就是分文不值，我总不能把它当作传家宝留给我的后代。但是开源之后居然每年都会收到一些邮件咨询这方面的问题。因为这本书是国外一些大学的教材，他们学编程语言相关的课程就需要做这些编程题，还有一些项目之类的，有的同学就付费让我咨询。所以有的时候赚钱是结果的副产物。 更多可能前段时间我看到 React 核心开发 Dan Abramov 的十年总结 My Decade in Review — Overreacted, Dan Abramov 在几年里就从一个 17 岁的编程小白成为行业大牛。从总结里面看好多关键节点都是因为开源和分享，开源让一个人能成长如此快。 当然每个人的故事都是独一无二无法复制的。我想分享一下自己的小例子，在学习数据结构和算法时我实现了一个生成迷宫程序，还写了一些 A* 路径规划算法相关的文章。 后来上海大学有个搞生物的教授看到我的文章，问我能不能帮他们看个程序，他们需要在多个节点里计算 k-th shortest 路径。我花了一些业余时间帮他们把核心算法用 C 实现了，他们后来把文章发表了出来，还把我的名字署上了。 我可从来没想过自己会发表一篇分子生物类的文章。最近我也开始另一种副业，在 Github 上收费帮有的公司做开源。这些就是分享的奇妙之处，我不知道自己的分享什么时候就帮助了别人，同时创造了更多的可能性。 无数人的分享让开源改变了整个软件行业，这些如今牛逼的开源项目都是从最开始一个小的分享举动开始的，Linus 在分享自己的小 Kernel 时估计未曾想过整个 IT 行业被自己改变了，尤大在分享自己的前端成果时也未料到 Vue 会被这么多企业使用。 最后，特别推荐这两期播客 : 和 Vue.js 的创造者尤雨溪聊开源软件 跟 Anthony Fu 聊聊全职开源和他的故事 这些开发者已经实现了全职做开源这种工作形态。另外现在国内开始出现了一波用开源软件赚钱的公司，比如 PingCap，TDengine 等。我认为这是个很好的趋势，让我们这些本身喜欢写代码的除了 996 之外有了更多选择。 这是开发人员最好的时代了，一起学习和贡献吧。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"OpenSource","slug":"OpenSource","permalink":"http://catcoding.me/tags/OpenSource/"}]},{"title":"为什么印度人占领了硅谷","date":"2021-12-12T07:02:34.000Z","path":"p/why-indian-lead-silicon-valley/","text":"前段时间 Twitter 也换了 CEO，还是一个印度裔。目前，硅谷的很多大的 IT 公司 CEO 位置都被印度裔占了，包括 Google，Microsoft，IBM，Adobe, Palo Alto Network , VMWare 等等，如今硅谷的印度裔高管已经数不过来了。这种现象逐渐成为西方媒体也在讨论的 The Indian CEO Phenomenon。 从我个人的经历来说，我毕业后所工作的第一家公司 (模式是国内研发美国销售)，在创业六年后被印度人的公司收购了。我目前所在的公司也是印度裔 CEO，工作中接触不少印度同事。 对于这个现象，有时候会和身边的朋友同事交流。综合下来，我认为主要原因有这些： 能力很多印度裔技术人员早年都在印度上完大学。因为印度有种姓制度，社会阶层明显。能在印度上大学的大多家庭条件和阶层都不错。我 2015 年在硅谷出差时，有段时间经常蹭印度同事的车，所以我们会聊一些日常。他吐槽说跑到美国后更累了，因为在印度家里有好几个佣人，过得可是饭来张口的生活😃。 印度的 STEM 氛围比较重，工程师算得上是一个受人尊重的职位。看过《三傻大闹宝莱坞》的可能对此有些印象。从目前印度高考情况来看，理工科是最热门的、入学门槛最高的学科。像印度理工学院这种顶尖学校，入学难度堪比麻省理工。印度好的理工学校，很多学生毕业后就去美国继续上学、工作。 所以，我们看到的去美国的印度工程师，其实也和中国类似，经过了好几轮教育体制的筛选，智力、学习能力大多都是不输中国人的。 在人数众多的 IT 公司中，领导岗位犹如部队的率领，也许枪法不是最好的，更重要的是能带队伍，做正确决策等综合能力。印度是一个非常注重商业管理教育的国家，很多印度人出于职业发展上的考虑，喜欢上商业类的双学位课程，或者像 MBA 这类的项目。 技术能力对于做 Leader 岗位来说，只是其中一个维度。当大部分都是技术上出众的时候，那么同时具备商业嗅觉、宏观判断力的人就容易突出。Google CEO 的 Sundar Pichai ，当年作为 PM 领导了 Google Chrome ，Google Drive 等明星产品。 沟通在公司能踏实做事固然很重要，但如果要走向管理岗，不太会表达就是个大问题。 在 IT 行业工作的印度程序员，基本都能很流利地用英语表达。日常搜索中我们经常碰到的 geekforgeeks 这种网站都是印度人做的。 很多印度人说出来的口语口音很重（部分阶层更高的印度人从小接受英语教育，所以口音更纯正一些）。典型的印度口音就像是这个视频 里一样。但是这不是一个大问题，欧洲的、俄罗斯的、世界各地的非英语母语国家的人说英语都是由口音的。对于母语是英语的听众来说，有口音大多不影响理解。就像是国内北京人来听带山东、湖南口音的普通话，这完全是没有什么障碍的。在英语这块，中国的技术人员很多是应试教育的受害者，高考后荒废几年，英语日常沟通交流并不顺畅。这种现象在我这种 80 后的年龄段中还比较突出。公司最近有一些毕业生入职，总体感觉 90、00 后相对来说口语会好很多。 文化InfoQ 曾有一篇文章对比了华人与印度裔的领导力：华人是典型的技术型领导者，主张内心修为，务实低调，倾向于个人奋斗，喜欢在技术方向上深钻；印度裔则是典型的商业型领导者，他们更关注传递价值观，注重培养沟通能力、管理能力、影响力及对商业的理解，这更贴近西方文化中领导力的内涵。 通常中国人相对内敛，表达方式含蓄，东西方这种表达方式上的偏差会在职场上造成巨大影响。所以实际上，韩国、日本能在欧美企业中做到顶尖的也相对较少。 东方文化中推崇“凡事不做出头鸟”，中国人工程师大多比含蓄和谦虚，自己做了 120 分可能才敢说出 100 分。中国传统文化中，我们推崇那种扫地僧，默默地做技术大牛，在技艺上做到顶尖，而在很多公司决策上、公共事务上成为”沉默的大多数“。这对于美国人是比较陌生的，美国人沟通倾向于直接明、强势自信的。在印度被英国统治多年，印度人的思想、文化、体质几乎都彻底被西方化，所以自然容易同美国人打交道。I 文化差异的另一方面是团结。传说“公司来了一个印度人，过段时间就是一群”。硅谷的印度人对自己族裔相互提携，非常抱团，部分原因是因为印度的种姓制度，同阶层和种姓的群体容易相互帮助。而华人圈曾经流行过一句话：“一个中国人是条龙，一群中国人是条虫” ，辛辣地批评了中国人的劣根性。北京大学著名学者钱理群先生说：今天大学所培养的，不过是一群精致的“利己主义者”。 在美国工作了三十年的前老板跟我提到过，华人里面其实暗地里相互的较劲很多，特别是同级别之间。文人相轻自古以来都有，千军万马独木桥走过的做题家，在狭窄的职场上容易引起竞争。攀比、嫉妒等会造成很大内耗，最终影响华人整体发展。 国情中国和印度两国的巨大国情差异也是一个原因，这导致了两国留在美国发展的人的追求就不同。 近二十年来，因为中国人口基数红利，中国基础设施的完善，互联网对中国各个行业的渗透，国内 IT 行业迅速崛起。机会和资本都不缺，这些年来对于顶尖人才的待遇不输美国，职场天花板更高。在美国的中国技术人员大都犹豫过是否回国。现实也是，很多优秀的、有大抱负的中国人放弃了在美国职场闯荡的路径，选择回国创业或加入国内大公司。另外我发现很多程序员出去是为了逃避内卷，或者是为了孩子教育，他们追求的是工作之余“种竹浇花酿酒”。 对于印度人而言，在一个好的理工学校毕业，然后去美国赚钱、发展，这是非常理想的，几乎是唯一好的出路。因为印度本土发展落后太多，生活形态和质量也差很多。选择少反而成了优势，留下来扎根的人，自然有些渐渐就爬上去了。 以上纯是些个人感受和理解，或许和实际情况存在一些偏差。 其实我们也没必要过于纠结在这点上。总体而言，我认为这些年来中国在 IT 领域取得了全球最快的发展速度，我们有自己的成功 IT 企业，也有很华人创办了成功的创业公司，例如 Zoom、Notion 等等。 但这事也值得大家思考，职场发展其实不管哪个国家都有一些共性的东西。多向别人学习，发觉自己的不足，这样才能成长和进步。共勉！","tags":[{"name":"瞎写","slug":"瞎写","permalink":"http://catcoding.me/tags/%E7%9E%8E%E5%86%99/"}]},{"title":"什么是好的技术面试","date":"2021-12-08T09:11:49.000Z","path":"p/the-good-tech-interview/","text":"今天正好看到两个技术面试相关的分享。结合自己这十年来的面试或者被面试经历，谈谈自己的想法。 难得的面试分享首先我们来看看 ReactJs 核心开发 Dan Abramov 的面试视频。这不算是正式的面试，是一个 Youtube 主播和 Dan 进行的模拟面试。Coding Interview with Dan Abramov - YouTube 这个面试将近持续了一个小时，但是主要是后面的那个算法题耗费时间，前面几个问题都是很八股的前端面试题： let 和 const 区别 什么时候使用 redux dangerouslySetInnerHTML 是什么，该怎么用 把一个 div 居中 把一个 binaryTree 镜像翻转 Bonus Q: 一个找兔子的算法题，兔子出现在数组的某个位置，但是每次可以跳向相邻的位置，用最快的办法找到兔子的位置。 这里面有意思的点是： Ben: There is a library called ‘redux’ Dan: “Hmmmm heard about it” Redux 最初版本是 Dan 2015 年发布的…….. 面试官小哥羞涩地笑了 🤣 然后，把 div 居中算是前端中的经典梗了，Dan 花了好一会时间在面试官的提示下才把一个 div 居中。如果对方不是 React 核心开发，手熟的前端可能就会开始鄙视这位“初级前端”了。这让我这种一直觉得 css 很难的前端学习者觉得信心大增。 反转二叉树问题 Dan 很快就答出来了，但是从面试过程中可以看到他对怎么尽量少代码 swap 两个变量还想了一会儿。我后来看他的十年总结的博文中，职业生涯初期的一次面试也提到了这个点： At one point I freaked out and panicked because I couldn’t write three lines of code that swap two items in an array. I asked Jing to look away for a few seconds. She said “I know you can swap two items”, and that gave me the confidence to finish the answer and make it through the interview. I probably didn’t pass with flying colors, but I got the offer. 最后一个算法题比较新颖，这不算红黑树式的八股算法题，倒像是一个 IQ 测试题目。可以看出 dan 也很少碰这类算法题。他花费了近半个小时在面试官的提示下，按照自己的直觉一步一步推出了答案。但是他最后写的代码是有点小问题的 (没有用 2 来递增 index)，面试者看他思路是对的也没有指出来了。这里可以看到，其实结果可能并不重要，而是在解决这问题中所展现出来的思维方式方法很重要。 除去 Bonus Question，可以说这轮面试的题目大多比较常规，难度小于很多国内外大厂的面试。Dan 作为前端大咖，愿意参加这样的直播分享很难得。我感觉看到的是一个真实的工程师，在未做过八股训练下的真实表现。 这是今晚看到的另外一个面试分享， 经历了人生体验最棒的一次面试 · Issue #228 · yihong0618/gitblog (github.com)： 我觉得比较难得的是第一面面试官的面试方式，选择一个面试者的开源项目，然后提一个小需求让他实现。这得很花面试官的心思和时间，也确实能很好地考察应聘者的编程能力和工程能力。国内这种认真面试的公司太少太少，而且一线大厂几乎不可能出现这种面试方式。 我的一些经历在我十年的职业生涯中，经历过多次技术面试，作为应聘者被面试或者面试他人。 我经历过的最差的面试体验是在 2014 年。面试官没怎么看我的简历，首先让我挑两个主题，然后我能看到他在屏幕前点了点鼠标，从题库中挑选了几个题甩给我。这种感觉就是高中时候的考试体验，我需要在纸上写程序和公式。面试官全程严肃无表情，即使我主动需求交流也无果。这次面试可以说是深深地伤害了我，并给了我很大的心理阴影，导致我后来面试就会忍不住祈祷千万别再碰到这类面试官。 一些小而美的技术公司倒是更尊重应聘者。前两年我参加过一个新加坡小外企的招聘。首先第一轮面试是双方自我介绍，对方会和我聊他们公司的主要业务和技术栈，以及目前这个岗位的工作内容和职责，确定我感兴趣之后才会约第一轮技术面试。第一轮面试就是一个小的项目，需求都写清楚，但其中也留了一下自由发挥的空间。我一周的时间来完成，然后把代码发过去。第二轮技术面试首先是从那个小项目聊，为什么这么写等等，然后会引出一些技术问题，但是会从深度和广度不断地追问下去。这就有些像是平时工作中，两个同事探讨问题的状态。 算法有什么用面试的难点在于，很难在短时间内了解这个人的全部技能和特点。这些包括编程能力，工程能力，技术视野，沟通能力，应对挑战的能力等。 刘未鹏曾经在怎样花两年时间去面试一个人中提到，用 Github 和书单的方法来面试。这当然是一个不错的面试方法。而大公司采用比较标准的面试，主要是为了节省时间。因为应聘者多，面试的场次多，不可能让面试官在工作之余花大时间主动了解应聘者，通常情况是面试官在面试之前匆匆扫上一眼简历。而且八股文式的面试很容易让面试官得出结论，即使这个结论包含了不少偶然性因素。 面试造火箭，入职后拧螺丝是行业常态。这也说明，我们工作中极少极少去碰这些基础算法类的东西。工作久了，我能看到很多面试官拿出一个公司的面试题，在不看答案的情况下自己也做不出来。 算法又是很多程序员所惧怕和不擅长的部分。Programming Pearls(《编程珠玑》) 一书的作者 Jon Bentley 曾经说过：“90% 的程序员无法正确实现二分查找算法...”。2014 年我在广州参加一个技术聚会上，因为一个一时兴起的赌局验证过这点。当时我们那个会议室 20 多个程序员，其中有工作多年的，也有刚毕业没多久的，能在规定时间写出一个无 bug 的二分查找的确实寥寥无几。 那面试出这种题目有何意义？ 算法当然对程序员很重要，特别是某些特定的领域，比如图形学、机器学习、高性能计算等等。另外如果一个程序员啃过算法这个硬骨头后，会觉得学其他都不算太难。在学习编程阶段，大量地实现数据结构和算法就是一种很好的提高编程能力的方法。我在学校最后一年刷了 POJ 500 道算法题，自我感觉编程能力大幅提高。 但我认为面试中的算法题可以当作一个下限标准，使用相对基础的、简单的编程题，会有助于筛选出编程能力不适合的应聘者。另外来自实际工作中的一些算法问题也是很好的面试题，比如上次我碰到的输入自动补全算法。这种问题没有唯一解，而且也很容易理解实现，通常有一定编程经验的程序员都可以实现出自己的版本。 对于绝大部分岗位来说，算法题测试不适合当作上限标准，因为专门训练过的应聘者和没训练过的差别太大。较难的、八股式的算法题对于初步筛选不太有用。一个应聘者如果能很快答这种题，可能是他刷 LeetCode 比较多，或者是刚好之前碰到过这个题。对于资深的应聘者，往往只能通过以往的项目来考察深度和广度。我认为深度比广度重要，因为如果一个人能把某个领域做得很深，如果他花时间换个领域很可能会做得好，反之则不然。 总而言之，很多大公司的面试看起来八股，也有一定道理。作为应聘者，专门针对这类面试做一些针对性训练结果就会好很多。 我认为好的技术面试有如下特点： 对应聘者尊重、真诚，面试是一种平等的沟通和交流 拒绝八股，更多考察实际解决问题的能力","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"面试","slug":"面试","permalink":"http://catcoding.me/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"Obsidian 插件开发","date":"2021-12-02T07:17:37.000Z","path":"p/obsidian-plugin-dev/","text":"昨天花了点时间下学习 Obsidian 的插件开发。我想了一下目前自己有点不爽的是图片插入的时候，图片的名称中间有空格，这虽然也不是什么大问题，只是在 Linux 环境下显示的时候看起来特别别扭。而且这看起来也是一个很好的入门小插件，可以接触 Obsidian 里面的文件管理和编辑操作，我需要把图片在文件系统里的名称改掉，也要修改 markdown 里的路径。 所有代码都在这里了： chenyukang/obsidian-rename-image (github.com)。 开发步骤 从 plugin sample repo 克隆一个仓库 修改其中的 manifest.json 文件，其中 plugin id 是最重要的。 修改主文件 main.ts，使用 npm install 安装依赖库 使用命令 npm run dev 编译出 main.js 在 Obsidian 的 vault 目录 .obsidian/plugins/ 创建一个插件名称的文件夹，拷贝 manifest.json 和 main.js 到该目录，有的插件可能还有 style.css 等文件。 在 settings 页面加载插件 在开发过程中，可以通过 Ctrl-Shift-i 来打开调试页面，在代码中加入调试信息。 API 相关在插件项目里执行了 npm install 之后，文件 node_modules/obsidian/obsidian.d.ts 就是 Obsidian 的 API ，里面有很详细的注释。 作为补充可以看看 Obsidian API - Liam Cain。API 分为这几个主要部分。 其中文件编辑部分使用了这个CodeMirror。 其他之前有那么一会我会想，Obsidian 这样一个软件为什么不开源？如果开源我们是不是可以做更多的自由探索。通过折腾插件这么一段体验，我认为不开源问题也不大，其实通过插件我们其实可以在插件里面跑任何自己的代码。这里面的可扩展性对于绝大部分用户来说绰绰有余。 一个技巧是多看看已有的插件是如何实现的。打开 Settings 页面的 community plugins，选择某个感兴趣的插件看看里面的代码： Obsidian 模块化做得很好，而且 API 的粒度很细。在 VsCode 中写 TypeScript 插件体验比在 Emacs 中写 elisp 开发插件好很多，并且 JavaScript 的相关文档可太丰富了。 所以，真没必要抱着上古时代的软件不放 😁","tags":[{"name":"工具","slug":"工具","permalink":"http://catcoding.me/tags/%E5%B7%A5%E5%85%B7/"},{"name":"obsidian","slug":"obsidian","permalink":"http://catcoding.me/tags/obsidian/"},{"name":"TypeScript","slug":"TypeScript","permalink":"http://catcoding.me/tags/TypeScript/"}]},{"title":"Sidecar 架构模式","date":"2021-12-01T07:17:38.000Z","path":"p/sidecar-design-pattern/","text":"如果你最近看一些容器相关的技术文章，可能会看到这个技术名词：Sidecar 模式。中文译名为：挎斗模式。这个名字为直译，挎斗就是这样的一种摩托车： 如果理解了这种模式，就会明白这个名字其实取得特别好。Sidecar 模式就是指在原来的业务逻辑上再新加一个抽象层。这种模式很好的印证了那个计算机的名言： “计算机科学领域的任何问题都可以通过增加一个简介的中间层来解决。” “Any problem in computer science can be solved by another layer of indirection.” 如果一个抽象层不够，那来两个。这种模式也不是近些年新发明的，我们可以理解 Nginx 的反向代理其实也算一种 sidecar 模式，应用前面的 Nginx 可以实现一些常用的流量功能、鉴权、静态文件访问等基础功能。只是近些年，随着微服务和容器化在实践中越来越多，这种模式的使用范围也更广、粒度更细了。在非容器的环境下，一个 Nginx 可能会服务多个物理机 (或者虚拟机)，在容器环境下我们可以单独起 Nginx 容器来服务单个应用。 场景在微服务架构中，如果应用多了就会形成一些共有的需求。特别是流量控制方面，包括限流、流量分发和监控、灰度等等。通常我们对一类需求可以实现一个抽象层，然后在这个抽象层上实现具体的业务逻辑。比如很多公司都有服务网关，然后使用各种语言的 SDK 来集成到应用中。 这是通常我们会选择的一种方式，这过程中会有这样的一些问题需要考虑： SDK 的维护成本是很高 SDK 集成到代码中，其中一个组件发生故障就可能会影响到其他组件，SDK 和应用程序之间是保持着相互依赖的关系的。 在应用层和基础服务没有解耦的情况下，我们对基础服务做改动会增加很多风险和复杂度。例如，我之前所在的部门整个电商的应用做灰度改造，所有应用都需要做对应的改动。 sidecar 架构那我们是否可以提供一个统一的抽象层来做这些基础的重复工作？将基础服务抽象、解耦到应用层都感知不到的程度？ 这是现在的趋势，特别是现在很多架构都跑在容器这样的环境了，统一的抽象层能大大减少架构上的复杂度。 sidecar 模式在不改变主应用的情况下，会起来一个辅助应用，来辅助主应用做一些基础性的甚至是额外的工作。这个 sidecar 通常是和主应用部署在一起，所以在同样的运行环境下。这其中还有一些性能上的考虑，sidecar 如果和主程序网络通信上有延迟就会造成性能问题。例如在 K8s 下一个 pod 里的所有子应用共享一个 sidecar 服务。 这个辅助应用不一定属于应用程序的一部分，而只是与应用相连接。这就像是挎斗摩托车，每个摩托车都有自己独立的辅助部分，它随着主应用启动或停止。因为 sidecar 其实是一个独立的服务，我们可以在上面做很多东西，例如 sidecar 之间相互通信、或者通过统一的节点控制 sidecar ，从而达到 Service Mesh。 这样的好处在于： 应用层和基础服务层解耦 基础服务统一维护，SDK 统一集成，减少复杂度，减少应用服务中的重复部分 可以在不改变原有应用的情况下，为应用扩展新的功能 案例分析我们可以来看看业界典型的使用 sidecar 模式的框架。 DAPRDapr: Distributed Application Runtime 是微软开源的一套分布式程序开发框架，其目标是：“Build distributed applications with any language, any framework, run anywhere”。既然任何编程语言，任何框架都要支持，sidercar 是一个必然的选择。DAPR 把很多常见的分布式程序的公共组件抽象出来成为’building blocks’，然后通过 gRPC 或者 HTTP 统一出接口。应用程序通过 sidecar 来访问。 这样多了一层抽象之后，即使是某个 Component 做了一些改变，应用层也是无感知的。除了在容器化的环境下运行，用户也可以在非容器化环境以 sidecar 模式启动任何应用，例如我们启动一个图片接口服务 image-api-service，该服务会监听端口 8080，而 sidecar 会通过 3500 端口来代理该服务接受请求： dapr run --app-id image-api \\ --app-protocol http \\ --app-port 8080 \\ --dapr-http-port 3500 \\ --components-path ../config \\ --log-level debug \\ ./image-api-service 其他服务组件可以通过 sidecar 去请求该服务： // Dapr api format: http://localhost:&lt;daprPort&gt;/v1.0/invoke/&lt;appId&gt;/method/&lt;method-uri = &quot;http://localhost:3500/v1.0/invoke/image-api/method/api/image&quot;req, err := http.NewRequest(&quot;POST&quot;, uri, bytes.NewBuffer(image)) lstioIstio 服务网格 是一个开源的服务网格，提供了统一的方式来实现连接、监控、负载均衡等公共服务和流量管理。单个服务的所有传入和传出网络流量均通过 Sidecar 代理，完成微服务之间的流量管理、遥测数据收集以及策略的执行等。 在 lstio 中，我们需要了解 Data Plane 和 Control Plane 两个概念—— Data Plane 的作用是处理网格内服务间的通信，并完成服务发现、负载均衡、流量管理、健康检查等功能；数据平面的作用是处理网格内服务之间的通信，并负责实现服务发现、负载平衡、流量管理、健康检查等功能； Control Plane 的作用是管理和配置 Sidecar 来执行策略并收集遥测 lstio 中使用了 Lyft 开源的 Envoy 来做流量代理，Envoy 和应用程序一起在一个独立的进程中运行，应用与 localhost 收发信息，对网络的拓扑结构无感知。 其他考虑 更适合在容器化的环境使用 简单系统就没有必要使用这种重型武器了 哪些部分可以放到 sidercar 里面需要慎重考虑","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"架构","slug":"架构","permalink":"http://catcoding.me/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"在 Github Action 使用 Git","date":"2021-11-30T07:17:46.000Z","path":"p/using-git-in-github-action/","text":"最近我把自己的一些自动化脚本移到了 Github Action。因为考虑到 Github Action 有下面几个优势： 自动化脚本是代码的一部分 (Infrastructure as Code)，而不是限定在某个服务器上。这样长久来说更为通用，如果我迁移到其他服务器根本不用做什么修改，因为我们在写 Github Action 的脚本的时候就不假定在哪台服务器上运行。 配置更为方便，想要修改一下只需要提交配置文件就可以了，不用登录到服务器上。 基于以上几点考虑，我花了一些时间来把之前的一些 Ruby、Shell 脚本变成 Github Action 配置。有的脚本做的事情是定时拉去某个 repo，如果有改动则会根据规则生成新的内容，然后自动提交到远程仓库。所以我需要在 Github Action 中使用 Git 提交数据。要达到这个目的得在 Github 中配置 Git 的权限和账户信息。有以下两种方式： 使用 Github Access token首先需要在 Settings 页面生成一个 Access Token. 然后添加到要配置 Github Action 的仓库的 Settings 页面中，假设我的 token 取名为PAT，在 Action 中我们可以通过 secrets.PAT 获取和使用该 Token。 jobs: sync-to-sites: runs-on: ubuntu-latest steps: - name: Git Clone and Global Config run: | # Git setup export GITHUB_USER=yukang echo &quot;GITHUB_USER=$GITHUB_USER&quot; &gt;&gt; $GITHUB_ENV echo &quot;GITHUB_TOKEN=$&#123;&#123; secrets.PAT &#125;&#125;&quot; &gt;&gt; $GITHUB_ENV git config --global user.email &quot;moorekang@gmail.com&quot; git config --global user.name $GITHUB_USER 然后通过如下方式 clone 要修改的 repo 到跑 action 的服务器目录上。 - name: checkout blog uses: actions/checkout@master with: repository: chenyukang/blog-source token: $&#123;&#123; secrets.PAT &#125;&#125; path: blog-source 这种通过 Access Token 的方式 clone repo，用的是 HTTPS 的方式。通过 git remote -v 查看可以看到 remote 的地址。 使用 SSH另外一种方式是通过 ssh key。我们首先在任何一个服务器生成一个 ssh key，把这个 ssh 的 public key 加入到 Github settings 里。 ssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot; 然后把私钥拷贝到要配置 Action 的 repo 的 secrets 里。 通过如下方式在 action 中配置 ssh： - name: Install SSH Key uses: shimataro/ssh-key-action@v2 with: key: $&#123;&#123; secrets.SSH_KEY &#125;&#125; known_hosts: &#x27;just-a-placeholder&#x27; 这样之后就可以在 Action 的后续步骤中像在本地一样使用 SSH 的方式来 clone repo 和提交代码了。通过 ssh key 的方式我们也可以在 Github Action 中通过远程的方式来在其他服务器上执行命令，这对于要部署到服务器上的脚本来说是非常有用。 具体可以参考这篇文章： Deploying to a server via SSH and Rsync in a Github Action | Zell Liew (zellwk.com)","tags":[{"name":"工具","slug":"工具","permalink":"http://catcoding.me/tags/%E5%B7%A5%E5%85%B7/"},{"name":"Github","slug":"Github","permalink":"http://catcoding.me/tags/Github/"}]},{"title":"自动补全算法","date":"2021-11-29T08:34:43.000Z","path":"p/input-complement-algorithm/","text":"周末在和一个日本小伙一直讨论一个 Obsidian 的 补全插件，经过一个周末的努力，最终这个插件完善了不少。我主要想用这个插件来补全英文输入，这个插件目前没有自带的词典。我在互联网上搜索了一圈，最终在 Github 上找了这个 Google 10000 English，也就是最长使用的搜索单词。 实际上，前 7000 个英语单词覆盖了日常的 90% 使用场景。 中文输入首先我碰到的问题是，输入中文的时候插件也在补全英文。然后我提了第一个 issue。作者很快就回复了，给了我一个开发版本尝试，很完美的修复了这个问题。然后在使用过程中发现另一个小问题，比如我的字典里面有 apple，但是如果我是在句子头部输入 Ap ，这个单词并没有出现在补全列表。我们当然可以把字典的单词都进行首字母大写的处理，但是这就会让字典翻倍。 我看了看源码，果然如自己猜想的那样，匹配的时候没有考虑首字母大写的问题。我花了一些时间做了一个 PR：fix issue #30, take care of uppercase 。 性能优化在我做上个修复的时候，也顺便修复了一个性能上的问题，看这个补全插件的核心算法如下： function suggestWords(words: Word[], query: string, max: number): Word[] &#123; return Array.from(words) .filter((x) =&gt; x.value !== query) .map((x) =&gt; &#123; if (caseIncludesWithoutSpace(x.value, query)) &#123; return &#123; word: x, value: x.value, alias: false &#125;; &#125; const matchedAlias = x.aliases?.find((a) =&gt; caseIncludesWithoutSpace(a, query) ); if (matchedAlias) &#123; return &#123; word: x, value: matchedAlias, alias: true &#125;; &#125; return &#123; word: x, alias: false &#125;; &#125;) .filter((x) =&gt; x.value !== undefined) .sort((a, b) =&gt; &#123; const aliasP = (Number(a.alias) - Number(b.alias)) * 10000; const startP = (Number(lowerStartsWith(b.value!, query)) - Number(lowerStartsWith(a.value!, query))) * 1000; const lengthP = a.value!.length - b.value!.length; return aliasP + startP + lengthP; &#125;) .map((x) =&gt; x.word) .slice(0, max);&#125; 在这个函数中如果词典列表很长，这里的 filter, map, filter 会遍历列表三次，是很耗时的操作。我把第一个 filter 干掉了。然后在匹配逻辑里面增加了首字母大写的相关的 处理。除了自定义的单词词典，这里补全的候选词来源包括当前文件内容、Obsidian 的内部链接。而链接需要进行部分匹配进行补全。 后续在使用过程中我又觉得补全有些慢，甚至会影响输入的体验，在 Obsidian 里面通过 Ctrl+Shift+I 可以打开调试面板，我们可以看到补全的耗时： 这里的主要问题还是因为每次输入一个字母，算法都在遍历单词列表两边。优化思路有两条： 使用类似桶排序的思路，把单词按照首字母进行分割，分成 26 个子列表，这样查找的时候就先根据首字母找到子列表，然后进行遍历搜索。 使用类似 Trie Tree 的数据结构进行前缀匹配。 后来那个作者按照第一种思路进行了 优化，很快将补全时间优化到了 0~5 ms。果然粗暴的算法其实很多时候就够了。 中文分词在日常使用过程中，我又发现了还存在这个 问题。如果我尝试去修改中文句子的某个部分，这个插件会补全当前句子，就像这样：这当然是完全没有意义的。我看了一下代码发现是没有进行中文分词，所以现在的补全把这个中文句子当作一个连续的字符串在补全。 我自己尝试这想做一个 PR，但是没找到合适的中文分割 JavaScript 库。Obsidian 不能使用 Node 的库（移动端方面的考虑），所以也就不能使用这个 NodeJieba。虽然还没完成这个分词功能，不过我也在这个过程中学着写了点 TypeScript。 一些感想这个看似简单的功能，如果要做到日常可用其实有很多细节需要完善。这个算法问题看起来不难，很适合用来进行面试，因为这是日常中很常见的一个需求场景，而且优化这个算法思路也可以很开放。 TypeScript 真强，虽然我只是简单用了一下，一些常见的 JavaScript 错误比如 enum 忘记补全之类的问题都能找出来。Electron 真猛，VSCode、Obsidian、Slack 这类工具都是 Electron 开发的。 开源软件的好处在于很多代码的作者对自己的成果有一种成就感，所以会想办法来完善，而用户也可以帮着来想办法。在这个过程中，不仅可以让其他人受益，自己也得到了一些学习和提高😘。","tags":[{"name":"Tools","slug":"Tools","permalink":"http://catcoding.me/tags/Tools/"},{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Obsidian","slug":"Obsidian","permalink":"http://catcoding.me/tags/Obsidian/"}]},{"title":"打造自己的工具 - Obweb","date":"2021-11-28T07:00:04.000Z","path":"p/intro-to-obweb/","text":"在文章我的知识管理工具和经验中我介绍了自己开发的 Obsidian 配合 Web 应用 obweb。 下面详细介绍一下自己对每个功能的使用场景，以及其中的一点技术细节。后端使用 Rust 开发的，因为后端逻辑并不复杂，所以使用什么语言区别不大。我最近在练手 Rust，所以就用了 Warp 这个框架来实现。 我是一个前端新手，顺便借这个项目在学习一些 JavaScript 和 Svelte 相关的技能。第一次实现的时候是纯 HTML 加 JQuery，后来又加上了 Svelte 。Svelte 这个前端框架对新手来说也不难，我是边看教程边照着做的。 Obweb 是一个典型的前后端分离的 Web 应用，没什么技术上的难度。可忽略我直男的 UI 设计 (貌似根本无设计😂)，我们着重看看我日常用的这些功能。 记录想法这是我做 Obweb 的初衷，我想在手机端把一些想法和灵感记录下来。之前一直使用 [[flomo]] 这款应用，这个应用功能很少，就是让你打开迅速记录自己所想，使用标签来把这些想法串联起立。随着我使用 Obsidian 的时间越来越多，我就想把这些数据同步到自己的 Obsidian 中。 于是就开始用自己蹩脚的前端能力搞了这么一个界面。 这个界面很简单，就是一个输入框，可以加入标签或者 Link。但是这里面隐藏了一些逻辑： 如果 Link 为空，这个记录则为一个每日的想法，会追加在每天的 Daily 文件后 如果 Link 是 Todo，则会在我的 Todo.md 在文件头部增加一个记录。 如果 Link 是一个其他的文件名，如果数据中没有这个文件则会创建，否则就会在现有的文件后追加这条记录。这种使用场景是我在手机上看 Kindle，有的摘抄就会记录下来，最终每一本书阅读后摘抄就会在一个文件里面。这也是为什么这个 Link 除非手动清除，否则会一直记录在 localStorage 里面。因为一段时间内我看的都是一本书。如果要清除缓存则可以使用 Reset 按钮。 可以在想法中加上图片，但是限制只能加一张。因为我习惯了使用这个记录页面之后，我也想在 PC 端使用。因此增加了从剪切板中存储图片的功能，以方便我在 PC 端想同步一些内容到手机上以备后续查看。 每日回顾想法中记录的内容，可以使用 Day 来回顾，目前只有按照日期每日来回地切换。如果要大量地查阅内容我肯定使用 PC 端。这里也可以进行一些轻度编辑。 搜索和编辑我在手机端使用场景主要记录想法，但也有一定的查阅需求。比如我在外面办事可能需要看公司的保险需要哪些材料，这些我都会截图或者记录下来。所以，搜索是刚需。 目前搜索使用的就是粗暴的关键词匹配，我感觉已经够用了。后续可能可以增加分词等复杂一些的逻辑。作为程序员，文件中的代码高亮肯定是需要支持的，使用 highlight.js 就好了。 TodoTodo 也是一个 Markdown 格式的文件，而且这个文件只有记录了创建这个 todo 项的时间。我养成习惯每天早上都会看一看然后选择一些 todo 干掉。虽然目前很简陋，看起来就像是一个备忘录而已。对我来说也是足够了，我没有很多细小的事情需要赶 deadline。 RSS 阅读我已经有一段时间没有使用 RSS 阅读器了，其中一个原因是 Google Reader 之后我一直没找到特别满意的客户端 (可能 IOS 上能找到一些精美的 RSS 阅读器)。感觉越来越多的人对 RSS 阅读不感兴趣了，国内的很多人使用公众号，知乎，或者抖音。 国外很多人继续使用 Newsletter 的形式来订阅，内容创作者也喜欢让你通过邮件订阅，因为邮件订阅是一种双向的关系，他也可以通过邮件联系你，这样后续就可以推广产品之类的。所以说 RSS 是反商业的模式，通过 Feed 订阅似乎成为怀旧行为。 互联网上还是有很多独立博客，他们不是为了商业利益，纯粹是为了自己的爱好和分享精神，坚持写一些高质量的内容。所以我自己实现了一个简单的 RSS 爬虫和这个 RSS 阅读界面。爬虫部署在我的服务器上，每隔几十分钟就会遍历我的订阅列表，抓取内容推送到 Github 私人仓库。服务端的爬虫使用的数据库是 SQLite 来存储文章的其他一些元数据。 有的作者 RSS feed 里面只提供摘要，为了营造沉入式的阅读感受，我尝试把文章的内容都抓取过来，包括图片也会拷贝一份到我自己的服务器上。这样每一篇文章打开都是全文，而不是摘要，我也可以在手机上方便地阅读。 我最近发现一个新的使用场景，这种里面带有 Podcast 的语音内容，在开车时候打开听很方便。 后续改进因为现在使用 RSS 阅读的时间越来越多了，后面可能会继续优化 RSS 阅读的一些细节。另外前端代码现在比较乱，后面会继续学习一些前端技能，把代码优化得更优雅简洁。","tags":[{"name":"工具","slug":"工具","permalink":"http://catcoding.me/tags/%E5%B7%A5%E5%85%B7/"},{"name":"Obweb","slug":"Obweb","permalink":"http://catcoding.me/tags/Obweb/"}]},{"title":"我的知识管理工具和经验","date":"2021-11-23T00:21:58.000Z","path":"p/my-notes-taking-tools-and-experience/","text":"知识管理是近些年出来的逼格称呼，通俗点说就是写笔记或者写作，讲究一点可以说成“打造第二大脑”，英文中可以诗意地称之为 “Digital Garden”。看看，同样一个事怎么说出来格局完全不同了。 近两年笔记软件这个领域出现了两个很重要的创新： 一个是双向链接，开山鼻祖是 Roam Research ，一个是一切皆对象和可无限嵌套的设计，也就是 Notion。 因为这两个大方向上的微创新，现在笔记类软件和系统百发齐放，这是真是最好的时代了。 作为程序员我分享一下自己在这类工具上的使用经验、感受以及建议。 大概十多年前，还在学校的时候，博客文化刚兴起，所以很多记录类的东西我都写在博客里了。那些常见的博客系统我基本都用过，后来很多都倒闭了。当然 Wordpress 现在在非程序员中都非常流行。 后来很长一段时间我都是用 Evernote ，国内版本叫做印象笔记。用的人多了各种周边的工具也非常多，比如浏览器插件之类的。这类笔记软件也非常多。 三四年后我又渐渐不使用印象笔记了，因为我用了很多年 Emacs，所以偶然尝试了 org-mode。这东西结合 GTD 可玩的方式可太多了。 org-mode 日程管理，日志，文档都在本地，一切都是纯文本的 org 格式，我通过 Github 来做数据存储。一切都是文本并且本地化就可以自动化，我可以自己写一些脚本，自己定义各种模板等等。虽然是纯文本的格式，我也可以很方便地到导出成 PDF , 甚至是做演示。很多人是为了使用 org-mode 才一直用 Emacs，我也曾经认为自己找到了以后一直用的记录工具和方式。 在这段时间，我养成的一个很好的习惯是使用 Github 来存储自己的数据。Github 已经成为最基础的互联网设施，我信任这个平台胜过其他服务。Joe Armstrong 在去世前一年，把自己的文章迁移到 Github，感兴趣的可以看看这篇不错的文章 People Die, but Long Live GitHub。 后来，我因为换工作的原因不怎么使用 Emacs 了。最近一年工作内容变了，自己日常开发和业务时间使用 Windows 更多。业余时间基本是用的 WSL ，配合 VsCode 日常开发体验很棒。 而 Emacs 在 Windows 上使用体验很不好，我也没找到合适的移动端解决方案。虽然最近 WSL 也支持 Linux Gui 了，但我已经懒得折腾，因为我已经离不开 VS Code 。 我需要重新找一个笔记类工具，我的需求是： 本地存储文件 足够的自定义 支持 Markdown 支持双向链接 这个需求其实满足了绝大部分程序员用户，一个文件夹加 Typora 估计都差不多了，但是我觉得双链这个设计确实有一些价值，所以也变成刚需了。 在摸索的过程中我试过 Notion，Wolai，Logseq，Obsidian。 Notion 确实有耳目一新的感觉，而且 UI 的审美很好，用户做出来的笔记可以很美观整洁。而内嵌 Database 可以打造出来很多好玩的东西，甚至可以用来做站点。缺点是服务器在国外，不太稳定。 Wolai 提供 Notion 类似的块编辑以及大部分功能，而且很早就有双链接，服务器在国内所以速度上也很快。版本更新很快，有很多针对中文用户的细节优化。如果不想折腾用 Wolai 也挺好的。Wolai 和 Notion 是比较重的工具，已经超过了通常我们理解的笔记管理软件的范畴。 Logseq 是 Roam Research 的模仿品，但是提供本地存储的方式，也有桌面版软件。很多人赞赏 Roam Research ，不过我没有觉得这种方式完全适合我。 Roam Research 的正常方式是每天都在日志页面记录，然后写的过程中加上适合的链接，这样你的文档渐渐构成一个网络。如果你日常中经常用到的概念，自然就会经常被链接，那么就会是网络中的一个密集点。所以即使你不建文件目录，这种文档之间的关系也会自然而然形成，并且比目录这种单线的关系更符合直觉。 最终我一直保持使用的是 Obsidian。Obsidian 支持本地存储数据的方式（也可选择付费远程同步）。我使用一个 Git 的插件自动同步到 Github。 Obsidian 的客户端做得如此出色，而且扩张性极好，已经形成很成熟的插件生态。这是我的记录汇成的网状。 在使用 Obsidian 一段时间后我又体验了 Flomo，这是一个不错的软件让我们迅速把日常的想法记录下来。我想如果 Flomo 的数据能够同步到 Obsidian 就好了。 看了一下 Flomo 的接口，我觉得干脆还不如自己动手重新实现来练练手。我就动手自己实现了一个 Web 单页应用 obweb，然后部署在自己的服务器上。这个应用提供一个简单的页面来记录日常的想法，文字或者图片都能迅速提交。数据提交后同步到 GitHub。这个 SPA 页面可以内嵌在微信浏览器，所以使用体验和一个小程序差不多。 而后我又增加了搜索的接口，这样我所有 Obsidian 的数据都可以在手机端检索和查看，而且我也能做一些简单的编辑。实际使用下来这真的比一个独立的手机应用更方便。 最近我又新增了一个 Rss 阅读的功能，后台会自动根据我的订阅列表抓取 Feed，甚至会尝试把网页和图片都下载下来，这样即使是一些”内网”不能直接访问的文章也可以在手机端无障碍阅读。 在这个过程中我学会了 svelte 这个前端框架和 Rust 写服务端接口这些东西。虽然我的 UI 设计和前端技能简直就是渣渣，但是这就是完全贴合我的使用习惯的软件，我可以做到所有细节的定制化。 这是一种渐进式的开发体验，每隔一段时间我会在使用过程中摸索一个需求，然后我会稍微等一等，如果这个需求还是存在并且我考虑好了如何实现，我就会加上去。 折腾这么多年这类软件后，我的感受是工具的使用都是非常私人化的选择，作为程序员我们有能力使用自己的技术来定制化工具来提高效率。最近看到这篇文章 You’re Allowed To Make Your Own Tools 很好的阐述了这个观念。这就像是住房子一样，如果你自己是设计师，估计不会满足房地产商提供的统一装修，而是根据自己的喜好和习惯来重新设计。房子也不是越富丽堂皇就越好，简单但实用即可。 所以在文档和写作这块，数据本地纯文本的方式是对程序员更好的方式，你可以自己写程序来处理这些数据，而不是完全依靠软件或者第三方的功能。比如这篇文章就是我在陪小孩上课的过程中，用手机在 obweb 上敲出来，服务器上的脚本会自动转成 Hexo 里的 Markdown 文件，提交发布到我的博客。 最后，我们现在有很多华丽的工具来用，也要避免让自己变成一个纯粹信息的收藏者。 ‘数字花园’不是一股脑地往后院搬东西就行，需要花时间精心打理和修剪。工具并不能本质地解决问题，难的是日复一日坚持记录自己的想法和理解，整理知识。柳比歇夫使用纸和笔记录了自己奇特的一生，并且完成大量研究工作。 记录的过程并不是学习本身，而是思考。通过记录这种形式，把自己的理解写下来促进思考，才能产生最大的价值。 更多参考： 打造自己的工具 - Obweb 如何无痛苦更新公众号 题外画： 一个有趣的事是，除了 Roam Research 和大厂的传统产品，目前兴起的这些笔记类软件和服务大多是中国人开发的，包括 Notion、Obsidian、Logseq 等。我们可能真的比较喜欢这类东西，“好记性不如烂笔头” 乃民族真传。 另一个事实，Roam Research，Logseq，以及另外一个开源的类似产品 Athens Research 都使用了 Clojure 这门编程语言来实现。Clojure 作为一门 JVM 上的 Lisp，其热度还没进过前 30 吧。这门语言对于数据处理这样的项目是比较合适的，只是不太适合大团队使用。","tags":[{"name":"工具","slug":"工具","permalink":"http://catcoding.me/tags/%E5%B7%A5%E5%85%B7/"},{"name":"开发","slug":"开发","permalink":"http://catcoding.me/tags/%E5%BC%80%E5%8F%91/"}]},{"title":"最好的学习是输出","date":"2021-09-07T21:49:24.000Z","path":"p/learning-by-contribute/","text":"之前我设想如果有了足够多时间，会做这些事：到处逛逛，锻炼英文写作，​投入到开源社区中。最近一年有了一些空余时间来做这些。我通常是十点到公司，下午五点半左右到六点之间离开公司。晚上陪小孩，洗漱哄睡完毕之后大概是九点钟。所以每天早上、晚上，加上周末，我都有一段时间可以用来自己安排。 ​这半年时间我参与了好几个开源项目，基本是顺着自己感兴趣的领域来的： 3 月左右，微软有个 FHL(Fix/Hack/Learning) 活动，基本有两周左右时间可以做自己感兴趣的项目，或者是学习点什么技术。那段时间我在琢磨怎么下好五子棋，因为和老婆经常比赛赌输赢。所以我写了个程序来下五子棋 gomoku，顺便学了一些技术相关的，比如 Rust，WebAssembly，Azure function，monte carlo，minimax 算法等。可能是我很久没从头到尾写个项目的原因，这个项目写得很来劲，顺便掉入 WebAssembly 的坑里。 接触到了 WebAssembly 发现有些意思，所以看了很多相关的内容。然后我参与到了 wamser.io。这是一个 Rust 写的 WebAssembly Runtime，还包括各种语言的 SDK 之类的。我开始从一些简单的 PR 到一些 Bug 修复。通过这些投入我大概也熟悉了这个项目的代码。这个项目 Star 数目虽然有 1W+，但是其实日常维护者已经只有两位了，其背后是一个公司在支撑。这公司之前是在 YC 孵化的，但是据我观察是没找到合适的商业化途径。当年 Docker 是找不到合适的盈利方式，所以最终选择开源。不过短短几年，现在这些技术型创业公司，基本都是默认开始干开源的，比如那些开源数据库之类的项目。 帮 WasmEdge 做了一些和 Dapr 的集成 Demo，花了大概两周的业余时间来学习 Dapr 和 WasmEdge 相关的技术，最终完成项目 dapr-wasm。这也是我第一次尝试收费帮人做开源，虽然不多但是也算是个不错的开头。既能赚钱又能学点新东西，何乐不为。 玩了一段时间 K8S 和 Linkerd 之后，我对容器相关技术又有一些兴趣。仍然记得 2014 年刚接触到 Docker 时的震撼，所以我想看看容器到底是怎么做的。后来找到了 Rust 实现的 Container Runtime youki。这个项目主要是一群日本年轻人在开发，项目发起人还是 96 年的。真是后生可畏！我陆陆续续大概提交了十来个 PR，主要是改进一些测试脚本、参考 runc 来实现一些功能，通过容器的基准测试等。在 discord 偶尔和项目发起者聊聊天，交流一些中日的 IT 相关感受也挺有意思。贡献了几个 PR 之后，他邀请我成为项目的 maintainer。我觉得这是一个很好的锻炼、提高自己的机会，所以就欣然接受了。其实容器底层都是一些什么权限管理，namespace，cgroup，file system 等基于操作系统的抽象层做了隔离，跑起来就是进程而已。在开发容器的过程中，有时候会把自己的 Host OS 搞跪，所以最好是在 wsl 或者 VM 里面开发。 最近在使用 Rust 过程中，发现 lint 会重复报告某些提示。经过搜索发现已经有人提出了同样的问题。我曾经好几次尝试过看看 Rust 的源码，但一直没沉下心有所得。这个 Bug 看起来并不难排查，也许是一个很好的契机。我花了大概几个小时时间从理解 lint 相关的逻辑，到复现这个 Bug，找到代码里的问题，然后做出一个初步修复。这个过程中，感觉比较困难的是编译一次 Rust 代码库大概需要半个小时，跑测试则需要更久。另外通过 gdb 虽然可以调试代码，但是还是有某些限制。提交了 PR 之后才只是开始，后来又经过了一周多时间和子模块维护者讨论更细节的问题，来回 20 多 comments 才最终完成了修复。 从 2011 年开始使用 Github，这些年一直在 Github 上做一些自己的开源小项目。只有最近大半年才比较多地参与到一些大的开源项目。这个过程收获很多。 最好的学习方式是贡献和输出。不管是在公司、或者是在开源社区做出贡献才是技术的价值。看书、看资料能学会一些，但是只有实践才能提高自己的能力。比如我学 Rust，肯定不花时间去看 Rust quiz 之类的东西，因为日常开发中常用到的语言特性并不是那些细节。很多领域更重要或者更有价值的是领域知识，编程语言在使用过程中不懂再去看就行了。 有了足够的业余时间，以及纯粹的爱好，才静下心来持续投入到免费的开源中。996 肯定是不行的。做开源很多人都是在 “用爱发电”。很多开发者大多是有一份本职工作，做开源也算是眼望星空吧。但是确实因为热爱，所以代码质量反而比公司代码高。工作中看多了十多年的历史代码，看点优秀的开源代码有洗眼效果。 Github 现在开始在某些国家支持 Sponsor 项目，可是中国不在试用范围内。我认为这是一个很好的趋势，做开源的程序员如果创造出来价值，应该得到一些资金上的支持。这使得有些程序员可以为了自己的项目，依赖这些资金全职投入到开发中，比如 Bevy 的作者，来不及等到筹集 7000 美金一个月的筹款就辞职投入了。 在投入到开源的过程中，除了自己能力的提升，也可以获得精神上的满足感。即使修复是一个小问题，其他人也会因为自己的投入而受益。而因为开源以及其带来的共同协作模式，程序员的学习、生产资料都极大丰富。这真是个好时代。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Rust","slug":"Rust","permalink":"http://catcoding.me/tags/Rust/"}]},{"title":"程序员如何站着每年赚 30w 美金","date":"2020-10-27T21:57:00.000Z","path":"p/programmer-out-of-normal-job/","text":"Daniel Vassallo 是我最近一年都在关注的一个推特用户，我几乎看了他发的所有 Twitter 和文章。 这位程序员去年离开了亚马逊的一份轻松而多金的工作。他在亚马逊干了 8 年，尽管不断获得晋升、薪酬、表彰和表扬等奖励，薪水从 7.5w 刀一路涨到 50w 刀，但他没有足够的动力再干一年。 至于为什么离开亚马逊，他写了一篇很好的文章来解释：只有内在动力才能持续. 主要原因是随着级别的提高，工作的自由度减少了，得平衡各方利益，说服其他人来完成特定的目标。这很正常，在大公司工作有很多固有的限制，关于如何做工作，做什么工作，设定什么目标，以及什么业务值得追求。很多时候会迫使我们去做不想做的事情，而想做的可能也无法施展。 总之，在公司赚钱肯定是比较稳定，收入也不错。只是时间、精神上谈不上自由。 为大公司工作是一种稳定的状态，就像是围城一样。 如何站着把钱挣了？ 完全靠自己得有动力，而且是持久动力才能坚持下来。 什么是持久动力动力分为外部动力和内部动力： 外部动力可以称之为棒子或者萝卜。举例来说，缴税是棒子，虽然我们不想做，但是必须得完成。为了买一辆豪车，努力加班加点赚钱，这就是萝卜。两者都是外在因素迫使我们不断地有『动力』去执行。 内部动力是持久动力，就是自己心甘情愿去做，并且乐于其中。这位程序员的兴趣在于写代码，卖自己的作品。而互联网时代就是最好的舞台，个人可以专注于自己专业领域，完成自己的作品，并获取关注和收入。 当然最重要的是作品的质量，以及推销的手法。 找到自己的切入点通过自己的作品来赚钱，听起来很简单，但实现起来难度其实是巨大的。 辞职后开始做的一个项目叫做 Userbase， 为静态网站增加持久化存储。另外开始和朋友做的是一本电子书：The Good Parts of AWS。售价 25 美金一份。10 个月总共花费 3w 多美金推广，收入 25w 美金。 这本电子书包含一些经验性的东西，对基于 AWS 做技术架构的人挺有用的。对于在 AWS 上工作了 10 多年的人写出这样一本小册子肯定是不难的，但是难的是如何做推广。 这也是作者做得挺好的一点，在 Twitter 上经营固定的读者。他每天都会发一些作为 Indie 的一些感想，关于工作、生活、经济、创业方面的。14 个月时间从 150 的 follower 涨到了 49000 多。他经常会把一些自己项目的数据贴出来给大家分享，这样显得特别真实、真诚。这种推广套路营造出一种类似《楚门的世界》的观感效果，读者看着他从第一天辞职，然后不断经营自己的项目，就会有动力一直去关注后面的进展。 然后作者把自己最近一年左右的 Twitter 推广实践经验又录成了视频： Everyone Can Build a Twitter Audience， 售价 50 美金。这一连贯手法真是越来越溜了。这是他今天才发的 2021 年收入情况 当然，除了营销外之外能力是最重要的，这位同志的写作能力一流。可以从第一篇辞职撰文可以看出，用词、表达清晰有据。 总结有人可能认为，这赚得看起来还没他自己上班多啊！ 但是，为自己工作的自由度、成就感、安全感是完全不同的，而且这还只是一个开始。 很多人丢掉了自己的全职工作之后，完全不知道如何打造自己的另外一份收入，陷入等米下锅的状态。总结起来都是很简单的道理，只是做到的人很少： 跳出自己的舒适区，向自己期望的生活方式改变 找到自己的兴趣点和优势，寻找自己能满足的实际需求 相信复利效应，做有积累的事情 不可否认英文环境的付费意识相对来说会更好一些 营销太重要了，社交营销是现在非常重要的一种营销能力 写作太重要了，电子书、营销都离不开","tags":[{"name":"副业","slug":"副业","permalink":"http://catcoding.me/tags/%E5%89%AF%E4%B8%9A/"}]},{"title":"DHH - 关于软件开发的少数派","date":"2020-10-10T22:50:38.000Z","path":"p/dhh-on-software-dev/","text":"David Heinemeier Hansson, Software Contrarian 是 Podcast 频道 corecursive 在 2020.2.1 发布的一个 DHH 关于软件开发相关的访谈。 DHH 不用介绍了，Rails 创始人。 可以说之前 Ruby 的流行很大程度上依赖于 Rails 的兴起。Rails 确实影响了很多后来的 Web 框架的设计和实现，并给软件开发带了一些全新的理念。 这期是我之前当作练习英语的材料来听的。DHH 的口音非常清晰，表达方式也是非常直接。因此这期听起来有一种类似 Rap 的快感。 为什么 Rails 成功了Rails 的出现改变了软件开发，至少在 2006 年，当 Java，C# 大行其道的年代。Rails 以其优异的开发效率震惊了不少开发者。Rails 的成功无非是在恰好的时机做了恰当的事情。 DHH 总结了从 Java、PHP 的开发经验。Java 阵营里都是聪明人，有很多好想法，但是他们却在一个糟糕的开发环境里工作，不容易让新人轻易上手。而 PHP 却很简单明了，你直接把一个文件拖入特定的文件夹，就可以生成对应的网页。Rails 的第三个元素就是 Ruby，Ruby 是极其容易安装，容易上手而直接的编程语言。DHH 当时正在写 Basecamp，所以一切都是从实际使用出发的，自己构建工具，然后再用这个工具构建 Basecamp。 而且 DHH 当时也是一个 Ruby 新手 (那时的 Ruby 老手估计也没几个？) 新手的好处在于，他不知道 Ruby 的极限在哪里，哪里可能面临挑战。这样可以随着自己的性子，满足自己的期望来构建 Rails 了。在写 Rails 的过程中，DHH 更关注的是作为用户的感受是什么？编程就像是做菜一样，厨子需要关注的色香味俱全。 Ruby 最大的洞见是：程序员不仅仅是程序员，同时也是人。 依据这个原则，在设计 Ruby 中最重要的事情和设计标准就是：编程语言使程序员更快乐。 最开始如何开始接触 RubyRuby 是日本人 Matz 于 1995。但是直到 2003，这门编程语言仍然是非常小众而神秘的。DHH 也是那段时间在看到些 Martin Fowler 和 Dave Thomas 写的技术文章，他们俩个都选择了 Ruby 作为编程语言介绍一些概念。这引起了 DHH 的兴趣，所以开始关注 Ruby，并去参加了 Ruby 2004 Conf。 那届 Conf 大约也就 42 人吧…. 但是随后几年的 Rails Conf 就开始有 2500 人了。 关于编程语言的选择很多程序员因为喜欢上编程，就是刚好碰到了符合自己口味的编程语言，并激发对编程的巨大乐趣。所以，语言的选择说不重要也不对。如果你还没找到自己的最爱，继续尝试吧。 但并不意味着，在一个小众的编程语言过多投资可能会带来其他的回报。语言的流行有很多其他的因素。Rails 的初衷并不是完全用来满足自己的创造轮子的快感的，而是依据自己的实际项目出发的。 这给我们的不错启示：从实际的需求出发，使用新的工具造轮子。 关于微服务的吐槽DHH 对微服务保持否定态度，认为业界这么流行微服务其实是有害的。 大多数情况下，一个人可以完全理解、部署的单一应用，比微服务更容易维护。 微服务的优势在于，如果团队足够地大，我们需要给开发者一些界限。 不要盲目地沿用大公司的套路，因为解决的问题不同！ 关于 TDDTDD 也是 Rails 社区很流行和推崇的，但是 DHH 其实对此并不太感冒。并不是 TDD 就能写出更好的，更健壮的软件。 事先写测试用例还是事后写并不重要，重要的是自动化测试。","tags":[]},{"title":"网络相关","date":"2020-09-08T20:59:08.000Z","path":"p/networking-notes/","text":"DNS 域名解析分为递归解析和迭代解析 https://blog.csdn.net/lycb_gz/article/details/11720247 APR 欺骗ARP 欺骗是一种在局域网中常用的攻击手段，目的是让局域网中指定的（或全部）的目标机器的数据包都通过攻击者主机进行转发，是实现中间人攻击的常用手段，从而实现数据监听、篡改、重放、钓鱼等攻击方式。 TCP/IP 报文长度和格式IP 头部信息：头部长度：通常 20 字节，有选项时更长，总共不超过 60 字节。IP 数据报长度：65535 字节。 TCP 协议，在传输层。特点：可靠性。通过连接管理（三握四挥），序列号，确认号，拥塞控制，重传控制来保证可靠性。头部长度：一般为 20 字节，选项最多 40 字节，限制 60 字节。 TCP 最大报文长度 (MSS)https://blog.csdn.net/codejoker/article/details/5437141 TCP 提供的是一种面向连接的，可靠的字节流服务，TCP 提供可靠性的一种重要的方式就是 MSS。通过 MSS，应用数据被分割成 TCP 认为最适合发送的数 据块，由 TCP 传递给 IP 的信息单位称为报文段或段 (segment)。代表一个 TCP socket 的结构体 struct tcp_sock 中有多个成员用于确定应用数据被分割成最大为多大的数据块较为合适 (最大报文段长度 MSS)。我们不难联想到，跟最大报文段长度最为相关的一个参数是网络设备接口的 MTU，以太网的 MTU 是 1500，基本 IP 首部长度为 20，TCP 首部是 20，所 以 MSS 的值可达 1460(MSS 不包括协议首部，只包含应用数据)。 本地以太网中 MSS 为 1460 的说法并不正确，它还会动态变化，如果 IP 首部和 TCP 首部中出现选项，则 MSS 要相应的减小，一般 TCP 首部中会 有 12 字节的时间戳选项 (外加两字节的填充选项)，这时的 MSS 就等于 1448。MSS 的主要作用是限制另一端主机发送的数据的长度，同时，主机本身也控制自己发送数据报的长度，这将使以较小 MTU 连接到一个网络上的主机避免分段。 如果使用 TCP 希望传输一个复杂的对象应该怎么传输？TCP 中的流是指流入进程或者从进程中流出的字节序列。所以向 Java/golang 等高级语言在进行 TCP 通信是都需要将相应的实体序列化才能进行传输。 TCP/IP 中如何解决粘包问题？如果一直传输数据怎么拆包？应用层协议，不管是标准的还是自己定义的。“粘包”问题是伪问题。 http://www.hchstudio.cn/article/2018/d5b3/ https://img.hchstudio.cn/TCP.gif TCP 连接和断开的状态图connect: disconnect: 为什么 TCP 连接断开的时候要进行四次握手： TCP 四次挥手的 TIME_WAIT时间段长为 2MSL（报文段最大生存时间） TIME_WAIT 存在的理由之一是尽可能护送最后的 ACK 达到对端，保证可靠地终止 TCP 链接。 假设 tcp 连接是： A(1.2.3.4:8888)——B(6.7.8.9:9999), 这就是一个 tcp 四元组。当 tcp 连接关闭后， 四元组释放。TIME_WAIT 存在的理由之二是新旧四元组互不干扰。 RPCRPC（Remote Procedure Call）—远程过程调用 ，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。RPC 协议假定某些传输协议的存在，如 TCP 或 UDP，为通信程序之间携带信息数据。在 OSI 网络通信模型中，RPC 跨越了传输层和应用层。RPC 使得开发分布式程序就像开发本地程序一样简单。","tags":[]},{"title":"程序员如何提高英文写作","date":"2019-11-07T08:45:53.000Z","path":"p/improve-english-writing-as-progammer/","text":"最近几个月坚持了一段时间英文写作，兴趣和自信心都大为增强。为什么突然想锻炼自己的英文写作能力呢，是因为工作中要写个什么英文的白皮书，然后发现懂技术的不太会写，会写英文的不太懂技术。最后找了团队中的一个留学生帮忙，大家跌跌撞撞把工作完成了。仔细想想这就是稀缺能力啊，按照刻意练习的套路，我应该好好提高一下自己的英文写作能力。 然后，我就开始在一些社区，比如 dev.to 写技术文章，在 Quora 上回答问题等，这些坚持了两个月左右，自我感觉收获不少。至少，现在让我写一篇英文类的长文，我是好无压力并且有些享受的 (可能还处于自我感觉良好的时期的缘故)。 下面总结一下关于英文写作的一些自我心得。 抛去恐惧心理这是很多人要克服的第一关，想着中文都写不溜，英文如何写？写作这个东西就是需要不断练习的，即使文笔不行，首先要做到的是写出来，并且简明扼要。文章最重要的目的是表达自己，并且让人易懂，更高的要求才是让人产生读的乐趣。对于绝大部分科技类的写作来说，准确是第一要素。 如何抛去恐惧心理？唯一的办法就是多读、多写，并且让大家看，收集反馈然后不断改进。 在哪里写像我刚才说的，有很多不错的技术社区，比如 Github、StackOverflow、Quora，这些都是英文表达的场所，也是一个很好的锻炼自己英文写作的平台。从小处开始，可以写一个英文的 README，代码中使用良好的英文注释？在 Quora 上回答问题是更好的方式，因为这是一个互动的平台，你的回答会被多个人看到，这样可能会有一些反馈。 比如这个找 Quora 里的回答，题主问的是学习编程是否需要很多数据技巧？这对于我们这样的多年程序员来说，自然是有一些心得的，然后我就写了一些自己的想法作为回答。后面有一位朋友写了另外一个回答： “题主，数学技能是次要的，你应该好好学学英文写作，这样至少不会让你像上面这位回答者这一样犯一些低级的错误。” 没多久我就看到了这条回答，然后看了看自己真的是犯了一些很明显的语法错误，修正后再回复了一下这位朋友，他表示自己也有点刻薄了，哈哈。其实大家对这种“助人助己”的学习方法是很乐于接受的，只要是给社区提供有用的东西。 在 Quora 上还碰到另外一个瑞典的伙计，也帮我提出了一些建议。然后第二天还帮我一句一句做了一个修改版本，发到了我的邮箱。英语不是母语的人写的文章，如果不是让英语为第一语言的朋友阅读，这些表达方面的问题是不容易看出来的。 一些技巧词汇很多人对于自己的词汇量没有信心，觉得词汇量不够不足以表达自己的想法。这是不对的，其实你看看大部分技术类英文文章，对于接受过大学教育的技术人人员来说，应该是 95% 以上的单词都是认识的。对于不认识的单词来说也可以根据上下文来推测的，所以至少词汇不会构成阅读障碍。对于英文写作来说，基于简明表达自己的要求，我们那点四六级词汇也很够玩的。词汇在于平时积累，我现在也在着重注意积累一些词汇。日常使用过程中，多注意一些应文的惯用词汇。有一个 Chrome 插件叫做“单词小卡片”，可以把日常浏览网页的过程中发现的不太熟悉的单词加入列表，可以日后以便回顾。 阅读 阅读和写作是分不开的，只有多读才会发现更多套路。上面提到的那些社区都有很多不错的英文内容可以读，另外要特别提到一个的是 medium.com，类比为国内的简书。不过个人感觉质量比简书的内容好很多，可能是我阅读了付费内容的缘故。这个付费也挺便宜的，一个月 5 美金。 作为程序员，另外要多阅读就是技术类的书籍。这些年我买了不少英文类的技术书籍，大多是翻过的，而且有少部分是精读完了。其实只要你能坚持阅读完一本 300 页左右的技术书籍，第二本就很简单了。如果是非技术类的英文文章，要数量阅读就需要提高词汇。 撰写其实写作无非是表达自己，中文和英文写作有很多都是相通的。 撰写过程中需要时刻明白，写的东西是给其他人看的。所以排版也很很重要，如果文章比较长，需要让人看得不至于疲累。适当地配一些贴近情景的图片也非常有助于提高可读性。段落要分明，不要某些段落太长。 最后，即使是英语是母语的人也很容一些常见的语法错误。所以我们需要工具来减少这类问题，grammarly.com 就是非常有用的工具，即使是免费版本对于日常使用来说也是足够了的。 建议不断练习，收集反馈，持续改进。唯此而已。 有两本书可以看看。 《七十二堂写作课》 《风格的要素》","tags":[]},{"title":"C 语言的 typecheck","date":"2019-08-06T01:31:18.000Z","path":"p/type_check_in_c/","text":"类型保证强类型的编程语言通常编译器自带一些类型检查，保证代码编译后不会出现类型方面的错误，比如 Rust 之类的甚至做了变量的生命周期检查，以防止内存出错或者未定义行为。常见的变成语言类型如下： typecheck 但是 C 为弱类型语言，弱类型语言，类型检查更不严格，如偏向于容忍隐式类型转换。譬如说 C 语言的 int 可以变成 double。 这样的结果是：容易产生 forbidden behaviours。为了解决类似问题，Linux 内核中的这个宏比较有技巧。 #define typecheck(type,x) \\ (&#123; type __dummy; \\ typeof(x) __dummy2; \\ (void)(&amp;__dummy == &amp;__dummy2); \\ 1; \\ &#125;) 使用的时候可以保证某些变量为特定的类型： int a;typecheck(char, a); 这样就会报出一个编译错误：","tags":[]},{"title":"My org-mode stuff","date":"2019-08-01T19:31:24.000Z","path":"p/org_mode_stuff/","text":"I switched to org-mode from EverNote recently, and the experience imrpoved much for note and journal writing, especially for technical notes. After the whole tool is set appropriately, I am even addicted to writing. During my setting up for org-mode and related tools, I found these code snippets are really handy, so let’s have a share. Insert Pic from paste You need to install pngpaste first, then with this elisp function, we can copy the picture from paste very quickly, the picture will store on current directory’s img sub-directory, it will create it if img directory is not exists. (defun org-insert-image () (interactive) (let* ((path (concat default-directory &quot;img/&quot;)) (image-file (concat path (buffer-name) (format-time-string &quot;_%Y%m%d_%H%M%S.png&quot;)))) (if (not (file-exists-p path)) (mkdir path)) (shell-command (concat &quot;pngpaste &quot; image-file)) (org-insert-link nil (concat &quot;file:&quot; image-file) &quot;&quot;)) ;; (org-display-inline-images) ;; show inline picture ) Using org-ruby for Hexo publishing I using Hexo for blogging, the default format is markdown in Hexo, so I need to convert org format to markdown format very conveniently, and finally org-ruby solve it. I did some dirty hacks on the codebase, please have a look at this PR, this PR solve three issues. Add title and path attributes in org file, and the ruby script will extract it for dumping markdown file. Fix the fill paragraph problem, I don’t need the blanks which will broken the paragraph layout. Copy the images to proper directory for Hexo, support image size attributes. Then I added an elisp function for auto publish it after saving file whenever “#MD_TITLE:” is founded in buffer: (defun org-publish-to-hexo () (interactive) (shell-command (concat &quot;org-ruby &quot; &quot;--translate &quot; &quot;markdown &quot; &quot;-a &quot; (buffer-name))))(defalias &#x27;op &#x27;org-publish-to-hexo)(defun buffer-contains-substring (string) (save-excursion (save-match-data (goto-char (point-min)) (search-forward string nil t))))(defun org-auto-publish-save-hook () (when (and (eq major-mode &#x27;org-mode) (buffer-contains-substring &quot;#+MD_TITLE:&quot;) (buffer-contains-substring &quot;#+MD_PATH:&quot;)) (message &quot;publishing to Hexo markdown&quot;) (org-publish-to-hexo)))(add-hook &#x27;after-save-hook #&#x27;org-auto-publish-save-hook)(defun org-before-save-hook () (when (eq major-mode &#x27;org-mode) (message &quot;saving org-file&quot;) (pangu-spacing-space-current-buffer) ;;(fill-region (point-min) (point-max)) ))(add-hook &#x27;before-save-hook #&#x27;org-before-save-hook) pangu-spacing This package will add spacing between Chinese word and English word, so I hooked it before save org file: (require &#x27;pangu-spacing)(global-pangu-spacing-mode 1);;(setq pangu-spacing-real-insert-separtor t)(defun org-before-save-hook () (when (eq major-mode &#x27;org-mode) (message &quot;saving org-file&quot;) (pangu-spacing-space-current-buffer) ))(add-hook &#x27;before-save-hook #&#x27;org-before-save-hook) org-capture And the best thing is org-capture, with this we can write all kinds of tempaltes, for journal writing, I need to generate file according to date and time: (defun create-code-file () (interactive) (let ((name (concat (format-time-string &quot;%Y_%m_%d_&quot;) (read-string &quot;file-name: &quot;)))) (expand-file-name (format &quot;%s.org&quot; name) &quot;~/Dropbox/org/snippets/&quot;)))(defun gen-date-file () &quot;Create an org file in ~/notes/snippets.&quot; (format-time-string &quot;~/Dropbox/org/journals/%Y_%m_%d.org&quot;))(setq org-capture-templates &#x27;((&quot;t&quot; &quot;Todo&quot; entry (file+datetree &quot;~/Dropbox/org/work.org&quot;) &quot;** TODO %?\\n %i\\n &quot; :empty-lines 1) (&quot;x&quot; &quot;Task&quot; entry (file+datetree &quot;~/Dropbox/org/work.org&quot;) &quot;** TODO %^&#123;priority|[#A]|[#B]|[#C]&#125; %?\\n&quot;) (&quot;e&quot; &quot;Task&quot; entry (file+datetree &quot;~/Dropbox/org/life.org&quot;) &quot;** TODO %^&#123;priority|[#A]|[#B]|[#C]&#125; %?\\n&quot; :empty-lines 1) (&quot;l&quot; &quot;Todo&quot; entry (file+datetree &quot;~/Dropbox/org/learn.org&quot;) &quot;** TODO %?\\nEntered on %U\\n %i\\n\\n &quot; :kill-buffer t :empty-lines 1) (&quot;k&quot; &quot;Todo&quot; entry (file+datetree &quot;~/Dropbox/org/learn.org&quot;) &quot;* TODO %?\\n %i\\n %f\\n %a&quot; :empty-lines 1) (&quot;j&quot; &quot;Journal&quot; entry (file+datetree &quot;~/Dropbox/org/_journal.org&quot; ) &quot;** %?\\nEntered on %U\\n %i\\n&quot; :empty-lines 1) (&quot;J&quot; &quot;Journal&quot; entry (file gen-date-file) &quot;** %?\\nEntered on %U\\n %i\\n&quot; :empty-lines 1) (&quot;c&quot; &quot;Code snippet&quot; entry (file+headline &quot;~/Dropbox/org/_code.org&quot; &quot;Code&quot;) &quot;** %^&#123;desc&#125;\\n#+BEGIN_SRC %^&#123;language|ruby|shell|c|rust|emacs-lisp&#125;\\n%?\\n#+END_SRC&quot; :empty-lines 1) (&quot;C&quot; &quot;Notes&quot; entry (file create-code-file) &quot;** %^&#123;desc&#125;\\n#+BEGIN_SRC %^&#123;language|ruby|shell|c|rust|emacs-lisp&#125;\\n%?\\n#+END_SRC&quot; :empty-lines 1) ))","tags":[]},{"title":"满足感源自细节","date":"2019-07-31T23:40:03.000Z","path":"p/details_matter/","text":"最近自我感觉生活质量提高了不少，并不是突然撞大运发大财了，总结下来居然都是一些小细节，奇怪正是这些小细节每次都会让我会心一笑。 org-mode作为一个近十二年的 Emacs 用户，最近开始使用 org-mode 了。之前一直偶尔看到说什么单独为了 org-mode 而花时间熟悉 Emacs 也是值得的，不过我一直没认真看，因为我认为在 Emacs 下不太适合大量编辑中文，快捷键太多在中文输入的过程中会有一些影响。 最近因为杂事比较多，我特别想要一个结合了日程管理和文档管理的软件。之前用过 Bear，这款软件的好处在于其编辑支持得特别好，但是 Bear 没有日程管理。后来又重新用回 EverNote，这东西的文字编辑支持有点弱，日程管理就是个最基本的清单。还有一些代码嵌入方面的问题，拷贝进去支持再拷贝出来居然其中嵌了部分中文符号。 最后我终于花了点时间来看看这个传说中的 org-mode 到底神奇在何处。结果真的符合了好香定律，我怎么不一开始用 Emacs 就着手用这呢，后悔万千！ 其实不管日程管理也好，日志、技术笔记等也好，本质上都是文字。org-mode 的日程和笔记都是存储的最原始的文本格式，而 org-mode 的编辑模式类似 Bear，写起来非常容易上手。和 Markdown 类似属于「易读易写」的轻量级标签格式。 日程管理也有一些记录时间、统计时间，培养习惯的打卡类日程计划。配合 org-agenda 的各种视图，org-capture 的可定制的模板，用起来真是简洁而又迅速。自己再定制一些函数和脚本，实现从剪切板拷贝图片，使用修改过的 org-ruby 自动从 org 转换为 Markdown，反正只要是文本其可塑性就非常强。 这才是对程序员最友好、最强大的文档和日程管理工具，其满足点在于『可定制』。 全屏中小红点当我开始大量使用 org-mode 记录之后，就不可避免地需要在全屏的 Emacs 下输入中文。而这经常会被打乱，总结一下发现其实是因为全屏状态下我经常会不知道目前是否启用了中文输入法。全屏模式下看不到输入法的任何图标，Baidu 的 Mac 输入法这个浮动状态栏不会在 Emacs 全屏的模式下显示，而且那个辐条本身看起来也太占空间了。在没有图标的情况下只有靠 Shift 或者 Ctrl blank 瞎切换了，非常让人厌烦。 这个困扰很久的问题最近也终于解决了， 这个 ShowEdge 工具可以根据不同的输入法，配置不同的颜色，而且在任何全屏状态都根据输入法显示颜色。我的屏幕顶部就配置了这么一个小红点： 从此输入中文的体验大幅提高！虽然这是非常细节的一个地方，但是当你想到折磨自己的问题，其他人也关注到了，并且用了极其符合自己使用习惯的开源软件解决了，顿时觉得世界真美好！ 这里的满足点在于『可控性』。 黑暗中的黄色光这东西犹如黑暗中的萤火虫，让人温暖，哈哈，其实就是小米的一款感应夜灯。我对小米的这种小的智能家电比较感兴趣，比如小爱同学也不错。这款夜灯的好处在于自动感应，进洗手间自己就亮，我每次都是比较晚才去洗漱刷牙，这灯不太亮也不太暗，而且可以根据声音、移动、和自然光亮度自动开关。其实功能很简单，符合软件设计中的哲学：专注唯一功能，但是功能做到极致。 这应该是简单地满足了『确定性』的心理需求，为什么像语音助手这类东西虽然看起来比较炫酷，但用的人并不多，因为语音识别在日常使用过程中还是会存在各种干扰，最终造成使用过程中存在一些不确定性，从而影响了根本的使用体验。 Entered on [2019-07-26 五 23:31]","tags":[]},{"title":"保存 kmacro ","date":"2019-06-23T23:48:42.000Z","path":"p/2019-06-23-random-notes/","text":"宏是很强大的编辑方法，如果要长久保存一些宏可以使用下面的办法： M-x start-kbd-macro 开始记录宏，通常快捷键为”C-x (“, 结束的快捷键为 “C-x )”。 然后使用命令： M-x kmacro-name-last-macro 可以把这条宏给命名，如果要保存这个宏以便日后使用，需要打开 init.el 继续使用命令： M-x insert-kbd-macro 选中命名的宏，这样就在 init.el 里面插入了刚才的宏，这个名字也就可以当作日常命令使用了。 例如我新建一个宏，作用是查找测试文件中的 “#[ignore]”，并删除掉那行： (fset &#x27;rust-ignore (lambda (&amp;optional arg) &quot;Keyboard macro.&quot; (interactive &quot;p&quot;) (kmacro-exec-ring-item (quote ([12 115 101 97 114 99 104 return 35 91 105 103 110 111 114 101 return 1 11 11 14] 0 &quot;%d&quot;)) arg))) 如果要重复执行，则需要运行： C-x z 当然后面可以连续按 z z z …. ， 执行多遍。 参考：https://emacs.stackexchange.com/questions/70/how-to-save-a-keyboard-macro-as-a-lisp-function","tags":[{"name":"Notes","slug":"Notes","permalink":"http://catcoding.me/tags/Notes/"},{"name":"Emacs","slug":"Emacs","permalink":"http://catcoding.me/tags/Emacs/"}]},{"title":"2019，愿你也健康","date":"2019-01-23T23:48:42.000Z","path":"p/2019-wishes/","text":"坚持最近在坚持养成每天尽量花一小时锻炼的习惯，因为我想在 2019 年有个更健康、有活力的身体。 随着年纪的增长，身体的一些反馈还是如实地告诉自己在变老。衰老就是能力不断地退化、消失。之前打球能蹦蹦跳跳的，现在多跑跑就会喘气；之前精力更好、更喜欢到处走动，现在更倾向于静静休息。去年有的时候身体感觉不太好，有段时间特别疲劳，甚至也体验过一段低迷的至暗时刻。大概是因为生活不规律，而且基本没有怎么锻炼，体重也不断上升。因为在 2017 年初打篮球的时候把膝盖伤了，后来也不能激烈打球了。现在比较适合自己的运动方式就是跑步、游泳、散步之类的。 人总是会忘掉这件事当然锻炼养生也不能抵抗衰老，这是个自然过程，锻炼至少能有助于健康。健康是所有幸福的最大基础，比什么都重要，俗话说『宁做健康的乞丐，也比做病恹恹的国王快活得多』。人更无法逃避的是死亡，这是所有生物的最终归宿和命运。只是人总会渐渐忘记自己会死，梁文道说的一个故事： 很多年前，一位德国摄影师跟一个记者合作的拍摄计划，很有意思。那个摄影师去很多的临终病房，拍摄一些快要死去的人，趁他们还在世的时候，拍下他们的遗照。然后他们刚刚离开，合上眼睛的时候，又为他们再拍一张照片，两张照片放在同一版上，前面则是文字记者做的采访。 在这一系列的采访跟摄影当中，其中一个已死的老太太，在她的采访里面说的一句话，他一辈子都不会忘记。她说什么呢？她跟文字记者说，“你看，你看”，就指着病房玻璃外面楼下对面马路的一个超级市场，她指着那个超级市场跟摄影师和记者说：“你看那里头的人们，天天进进出出买东西，买面包、买肉、买卫生纸，你看他们的样子，他们好像从来不觉得自己会死。” 读《最后的告别》这本书很多人都推荐过，我最近刚好也看了一遍。这里面谈了一些人在最终衰老、告别时必须面对的问题和思考，其中也有一些作者所经历的老人故事，还有自己的父亲最后的抗争。其中有一个故事印象深刻，看完后我又查了查还真有这么个人和事。 1980 年 3 月，当附近火山已经开始冒水汽、隆隆作响时，这位 83 岁的老人却仍然拒绝撤离他在华盛顿奥林匹亚市附近圣海伦山脚的家。他是第一次世界大战时期的飞行员、禁酒时期的私酒制造者，已经在灵湖的这所房子里住了半个多世纪了。5 年前，他成了鳏夫。所以，当时，在山脚这处 300 多亩的地盘上，只住着他和他的 16 只猫。三年前，他在屋顶铲雪的时候掉下来，摔断了腿。医生说他是个“该死的傻瓜”，在这样的年龄还爬到房顶去做事。 “该死！”他给医生骂回去，“我都 80 岁了！我有权做决定，有权做我想做的事。” 由于受到火山喷发的威胁，官方要求附近居民全部撤离，但是杜鲁门哪儿都不去。火山闷烧了两个多月，官方把撤离区域扩大到火山周围 16 千米。杜鲁门固执地不肯离开。 “如果这个地方要毁灭，那我想跟它同归于尽，”他说，“反正如果失去它，我也会在一周之内结果我自己。”他直率、不和悦的讲话方式吸引了记者。他说起话来滔滔不绝，头戴一顶绿色的约翰·迪尔棒球帽，手拿一大高脚杯波旁威士忌和可乐。当地警察考虑为了他好而逮捕他，但是，由于他的年龄以及他们必须得承受的负面新闻，只好作罢。他们提出但凡有机会就带他离开，但他坚决予以拒绝。他告诉一位朋友：“如果我明天死去，我也已经度过了愉快的一生。我能做的事都做了，想做的事都做了。” 1980 年 5 月 18 日早上 8 点 40 分，火山终于爆发了，其威力相当于一颗原子弹。巨量的岩浆流吞没了整个湖，埋葬了杜鲁门、他的猫和他的家。事后，他成了偶像——一个老头留在自己家里碰运气，在这种可能性似乎已经消失的年代，他按照自己的方式生活。 相对书中的很多老人来说，这位老人的选择充满了勇气，他以决绝的选择来面对衰老和死亡，并没有经受医院的无尽折磨。年轻人看起来这算是是自杀吧，加缪认为自杀是唯一严肃的哲学问题，看来老人对此已经有了答案。能有多少人老了能还以自己喜欢的生活方式活着，并在最终告别的时候心里都是满足：我已经愉快地度过了一生。 孔子说『未知生，焉知死』，反过来如果没有认真思考过死这件事，人又能真的知道怎么活。 最后最近大环境不太好，很多人都在纠结于今年能拿到多少年终，好多事情并不是个人所能决定，自己能最能把握的是自己的身体，珍惜生命、保护好自己，以免年纪轻轻落得一身病，年纪大了用钱换命。 最后推荐一个纪录片：《人世间》。每天都有无数的人在和疾病、死亡抗争，活着对很多人来说其实真不是件容易的事。 日子中很多艰辛和苦难，和生死比起来那就不是事。","tags":[{"name":"Notes","slug":"Notes","permalink":"http://catcoding.me/tags/Notes/"}]},{"title":"Rust 的 dbg！宏","date":"2019-01-18T00:23:24.000Z","path":"p/rust-dbg/","text":"前几天在群里看到有人讨论 dbg！宏已经在 Nightly 可以使用了，最近发布的 stable 版本 1.32.0 也可以使用了。 翻看了一下并玩了玩，这个简单的宏确实是调试好帮手，特别是适合我这样的喜欢打印调试的开发者。这个提议从 2017 年 10 月开始，从 https://github.com/rust-lang/rfcs/pull/2173 可以看到，为了增加这个宏很多贡献者经过了无数次的讨论和回复。真是太佩服 Rust Team 的开发者，付出了这么多时间来增加这个看似很小又实用的功能。 使用先看看这个调试宏是怎么使用的，目前使用这个宏需要切换到 Nightly 版本或者最新的稳定版，已经安装了 rustup 的话就很简单了： rustup default nightlyrustup update 然后很简单就是把一个表达式当作参数传入： fn factorial(n: u32) -&gt; u32 &#123; if dbg!(n &lt;= 1) &#123; dbg!(1) &#125; else &#123; dbg!(n * factorial(n - 1)) &#125;&#125;fn main() &#123; dbg!(factorial(5));&#125; 运行结果如下： [src/main.rs:4] n &lt;= 1 = false[src/main.rs:4] n &lt;= 1 = false[src/main.rs:4] n &lt;= 1 = false[src/main.rs:4] n &lt;= 1 = false[src/main.rs:4] n &lt;= 1 = true[src/main.rs:5] 1 = 1[src/main.rs:7] n * factorial(n - 1) = 2[src/main.rs:7] n * factorial(n - 1) = 6[src/main.rs:7] n * factorial(n - 1) = 24[src/main.rs:7] n * factorial(n - 1) = 120[src/main.rs:12] factorial(5) = 120 实现原理当然也就是把表达式和位置打印出来，但是这里有个技巧，在宏里面使用 match，这是为了避免参数被调用多次，因为宏在编译之前会被展开。Rust 的宏比较复杂，也不可避免会有些 hacky，对于喜欢爱折腾的程序员还是有吸引力。再看看这个宏是怎么实现的，代码很少。： macro_rules! dbg &#123; ($val:expr) =&gt; &#123; match $val &#123; tmp =&gt; &#123; eprintln!(&quot;[&#123;&#125;:&#123;&#125;] &#123;&#125; = &#123;:#?&#125;&quot;, file!(), line!(), stringify!($val), &amp;tmp); tmp &#125; &#125; &#125;&#125; 可以看到目前这个实现是只支持一个参数的，如果传入的参数类型没有实现 Copy Trait，可以传入引用。另外如果想同时打印多个参数，可以使用类似这样的做法： dbg!((exp1, exp2))","tags":[{"name":"Rust","slug":"Rust","permalink":"http://catcoding.me/tags/Rust/"}]},{"title":"《见识》阅读笔记","date":"2019-01-10T23:22:40.000Z","path":"p/book-review-wujun/","text":"到年底小组内还有多余的预算，于是大家都在网上选书。看到吴军出了两本新书，出于对作者的信任就直接下单了。上个周末就花了些时间很快地看完了两本。内容稍微有些重合，主要是有的例子会拿来阐述多个道理。所以两本连着看会有些作者凑书的感受。当然两本都还是不错的，读完《态度》对于我这个新手爸爸来说也是收获不少。个人更推荐《见识》这本书。 《见识》更多关注个人成长、看待问题的视角、工作职场中的一些经验。其中几个主题： 人生是一条河每个人都希望自己这条河能够更宽一点、更深一点、更长一点。只有给予才能带来幸福感。 认识到生命是有限的，应该挑重要的事做，向死而生。 人生需要做减法不做选择的幸福，从另外一个角度去解释为什么印度人在硅谷更容易成功。我觉得是有一定道理的，印度人因为名族的阶级观念，在生活工作中少了一些选择，却能一直在某个领域坚持数十年。第一份工作的过程中，接触了不少印度人。其中一位从印度到硅谷，一直都是在一个公司工作了 14 年左右，我问他为什么不跳槽，他倒觉得无所谓，安家乐业地每天过得很稳。少了选择就不容易思前想后，一门子扎进去了。在工作上，很多人都不能坚持一直耕耘于某个特定的领域，坚持下来的就成了。 做人与作诗：这章讲的道理类似于『出世』与『入世』，让我想起《月亮和六便士》里的画家。 要会做减法，为“做重要的事”服务，同时认清什么是重要的事。 西瓜与芝麻想起骚年的时候总是花时间去找些破解软件，舍不得一点钱买些软件或者工具，渐渐地意识到了这就是为了芝麻丢西瓜的事。类似的还有很多，现在则改变了认知，能付费节约时间则付费，能花钱买到更好的则花钱。 生也有涯 知也无涯正因为如此，生活、学习、工作中需要聚焦，别分散精力。人能在某一段时间内做好一件事，并且做得比其他人好，好到自己觉得不能更好为止。也正是因为『知也无涯』，不要为了自己的未知而焦虑，因为这是再正常不过的了，自己学起来就好，别丢掉好奇心。 我们一定比 18 世纪的人过得幸福么？显然，当代人并不幸福，特别是我们这些年轻的一代。物质上倒谈不上匮乏，而是没有自己的时间，然后则是人到中年必不可免的生活压力和焦虑。EB 的说唱里有段歌词『所有人都忙着想要更多的东西 所以得到之后就没有精力去珍惜 情歌越来越多 真情却越来越少 巧克力的保质期越来越长 爱情的保质期却越来越短 生活变得越来越丰富多彩 于是越来越多的人变得分不清黑白』。 我们与天才差多远我们绝大部分人成长过程中，迟早会意识到自己不过是芸芸众生中的普通人。硅谷中，我认为有一种气氛特别好，就是对聪明人的崇敬。之前的老板应该已经算是又聪明又勤奋的那种，谈话中总是会说起自己碰见过的聪明人，聪明到如何程度，以及一些小故事。有的生理上的差异是解释不清的，比如有的人就是善于计算，有的人精于细节。不过天才的见识、勇气、或者方法上有的是值得学习的。","tags":[{"name":"Books","slug":"Books","permalink":"http://catcoding.me/tags/Books/"}]},{"title":"使用 Markown 编辑公众号方法","date":"2019-01-06T23:48:39.000Z","path":"p/wechat-tools/","text":"技术人员很多都喜欢使用 Markdown 格式来编辑文档，但是公众号后台默认不支持。 所以关于工具和流程，最近我摸索出来目前最适合自己的一套是： 还是维护之前 Hexo 那套，像代码那样使用 Git 管理，内容会上传到 Github 上。 继续使用 Typora 编辑 Markdown 文件。注意使用图片工具 IPic 来方便地把图片上传到图床上，其实免费的微博图床就足够。然后使用在线的转换工具md.codingpy.com即可很方便地把 Markdown 转成适合公众号的内容，复制粘贴到后台编辑器里。 这样在个人网站和公众号里都会有相同的内容，而且格式之类的都比较统一。 这里再次推荐 Typora: https://typora.io/ 这个工具，会让人特别有写东西的冲动。","tags":[]},{"title":"开始写公众号","date":"2019-01-04T22:57:24.000Z","path":"p/try-wechat-blog/","text":"2018 过得很快，对于自己来说有点颓废、也很辛苦。说是颓废因为花了一些时间在游戏上，还有不少焦虑。最近看书，翻到胡适 1932 年一篇《寄语即将毕业的大学生》中写到，人到社会容易丢掉求知的欲望、抛弃学生时代的理想追求，为了防止堕落文中给出三点建议。读来觉得颇有道理，这三点建议放在现在也合适： 总得时时寻一两个值得研究的问题 总得多发展一点非职业的兴趣 你总得有一点信心 新的一年想着尝试做些改变，逼着自己再做一些其他尝试，不然生活除了工作和日常，真是过得有些索然无趣了。业余写些东西是很好的积累，从 2006 年左右开始一直都有写博文的习惯，从搜狐、Yo2、WordPress， 一直到后来的 Hexo 托管到 Github 上。个人域名 http://cyukang.com 用了多年，其中的文章大概也有 140 来篇。在这么多年写博客的过程中收获不少，认识了一些朋友，也锻炼了自己的文字能力。 平台和工具一直在变化，文字只是一种表达的方式，能写出来还是得靠自己平时所想、所做。之前写的技术类的文章偏多，因此一直觉得公众号这种生态圈有些封闭，不利于检索。不过终究是大众的选择，公众号里好的内容也很多。如果要逼着自己写，有些人看、有些互动自然是更好的。不求有多少关注，但愿自己能坚持多写写而已。 关于写什么，我也还不太清楚。在技术方面可能涉猎较多，精通的不算多。总之算得上技术爱好者，还未丢掉这块兴趣。所以这里多是关于工作、技术的一些学习总结、实践等。把技术相关的东西写得通俗易懂绝非易事，希望在这方面能有更多进步。另外我更想拓展自己在其他方面的知识和积累，所以公众号上会写更多读书笔记和思考。『构成我们学习的最大阻碍是已知的东西，而非未知』，局限于技术角度并非好事。 关于公众号名字『递归说』，这是乱想的，刚好在取名的时候想到了而已。听起来比较好念，而且递归真是计算机里一个很简洁、优美的概念，也是解决问题的一种方法，还可以延伸理解为『自我进化』吧。人这一辈子不也像一个递归么，过一年就像过了一个迭代，而且都是有终点的。 先写起来再继续摸索找方向吧，总得对自己有些信心。","tags":[{"name":"WeChat","slug":"WeChat","permalink":"http://catcoding.me/tags/WeChat/"}]},{"title":"使用 peco 飞起 zsh","date":"2019-01-04T22:55:22.000Z","path":"p/peco-for-zsh/","text":"pecopeco 是一个能做交互式 filte 的工具，是 percol 的 Go 实现。特别适合在 shell 里做一些过滤操作，当然适合做日志方面的过滤。典型的使用方法是： zsh 配置下面这个配置主要增强了 zsh 的 history 补全，以及pwdf可以用来迅速找一个文件，并拷贝其全路径： function exists &#123; which $1 &amp;&gt; /dev/null &#125;if exists peco; then function peco_select_history() &#123; local tac exists gtac &amp;&amp; tac=&quot;gtac&quot; || &#123; exists tac &amp;&amp; tac=&quot;tac&quot; || &#123; tac=&quot;tail -r&quot; &#125; &#125; BUFFER=$(fc -l -n 1 | eval $tac | peco --query &quot;$LBUFFER&quot; --layout=bottom-up) CURSOR=$#BUFFER # move cursor zle -R -c # refresh &#125; zle -N peco_select_history bindkey &#x27;^R&#x27; peco_select_historyfiOS_NAME=`uname`function pclip() &#123; if [ $OS_NAME = &quot;CYGWIN&quot; ]; then putclip &quot;$@&quot;; elif [ $OS_NAME = &quot;Darwin&quot; ]; then pbcopy &quot;$@&quot;; else if [ -x /usr/bin/xsel ]; then xsel -ib &quot;$@&quot;; else if [ -x /usr/bin/xclip ]; then xclip -selection c &quot;$@&quot;; else echo &quot;Neither xsel or xclip is installed!&quot; fi fi fi&#125;function pwdf() &#123; local current_dir=`pwd` local copied_file=`find $current_dir -type f -print | peco --layout=bottom-up` echo -n $copied_file |pclip;&#125;","tags":[{"name":"Linux","slug":"Linux","permalink":"http://catcoding.me/tags/Linux/"}]},{"title":"编译脚本到二进制","date":"2019-01-01T22:55:22.000Z","path":"p/compile-script-to-binary-for-obfuscation/","text":"缘由因为自己习惯使用 expect 脚本登录各种服务器，有一段时间因为要登录的服务器太多了，所以之前写过一个程序来管理各种 expect 脚本。实现思路是根据配置文件，用一个程序来动态生成脚本，执行完之后再删除。这样临时生成的文件里也是包含密码等信息的。最近突然想是不是可以直接写一个程序，把所有脚本类的程序转换为二进制可执行文件 ^image。我不想把密码之类的直接写在固定的脚本里面，所以密码也是被编译在可执行的二进制文件里的，这样能达到一些代码混淆的目的。 rshc 的开发这个程序看起来有些好玩，所以先我先搜了一下是否之前有其他人这样做过。于是找到了 shc 这个开源程序，这个最初版本是 96 年用 C 写的，最终执行的时候还是用 execvp 调用解释器执行各种脚本。我使用了一下发现居然不支持 expect 之类的。然后想着自己写个玩玩，顺便再动手用用最近看得又心痒的 Rust，最后用搞出来一个初版：rhsc。 目前我这个程序只是能把脚本程序，转换为 Rust 代码，然后使用 rustc 来编译为二进制，为了做一些代码混淆，其中也类似 shc 使用了 RC4 算法来做了一个简单的转换，加密用的 key 是随机生成的。然后也做了另外一个增加密码的模式，这样可以为任何脚本增加密码校验功能，最终使用 Process 来执行解释器。当然也谈不上多安全，如果要破解可以使用一些类似 ptrace 或者其他方式来试试。以后我会继续完善这方面的防御。另外，为了在生成代码之后尽量减少依赖，所以目前密码输入时还未做到隐藏输入。 安装使用使用方式非常简单，先安装： cargo install rshc 然后使用命令： rshc -f demo.sh -o demo.rs// add a passowrd when compile it, // then binary will prompt for correct password before executionrshc -f demo.sh -o demo.rs -p 其他时隔两年再用 Rust 写一些小项目，发现整个语言还是成熟很多： 工具链很好用，特别是 cargo 之类的，从开发到发布都非常方便 相关的库和文档也多了起来，相对来说更加容易上手写一些东西了 编译器的错误提示特别好，可以通过错误索引号找到示例","tags":[{"name":"Rust","slug":"Rust","permalink":"http://catcoding.me/tags/Rust/"}]},{"title":"SQL Injection attack","date":"2018-03-10T20:51:40.000Z","path":"p/sql-injection-attack/","text":"注入原理SQL 注入一直是 Web 应用的一大安全隐患，注入的基本原理是通过修改输入的参数来操作后台执行的 SQL，注入可能会导致数据库被恶意修改、数据被恶意读取等严重行为。所以如果一个参数有漏洞，通过小心的构造注入点即可利用，这里的渗透攻防 Web 篇-SQL 注入攻击初级有一些编写注入点的教程。 最初的时候我在一个用 C 写后台的项目里待过，现在回想起来我们当时根本没注意 SQL 注入，C 拼接处 SQL 的字符串很常见。不过现在大多数 Web 框架都已经有 ORM 了，ORM 可以在很大程度上避免注入的产生，因为程序员通常来说不用写纯的 SQL 了， 在最佳实践的前提下 ORM 会生成安全的 SQL。当然什么工具最终还是依赖程序员，比如下面的 Ruby 代码即会有问题： User.where(&quot;email = #&#123;params[:email]&#125;&quot;).first 更多作死的办法可以参考： https://rails-sqli.org/ WAF通常我们会使用一些 WAF 来阻挡 一些 SQL 注入，但是 WAF 也有其局限性。WAF 一般是通用的，不会局限于某个特定的框架。我们可以实现在 Nginx 上，或者使用一些商用的 WAF，通常来说对于应用也不用修改其代码。不过 WAF 的问题在于其实基于规则的，而 SQL 本省是比较复杂的，可以看看2003 SQL BNF 的描述有多么的长。所以 WAF 的规则大多数是一大堆较难维护的正则表达式，比如： Nginx Waf 示例，注意这个项目用不太成熟，初步看会有比较严重的性能问题。正因为规则是固定的，会导致存在很多误拦截的情况，所以我在 Kong 上实现的 WAF 就还不敢用起来。例如现实情况中出现过包含 select 的 uri被拦的情况，一脸忧伤。 静态代码扫描静态代码扫描会发现一些 SQL 注入，比如 Brakeman 之类的。不过通常静态代码扫描的问题也是分析得不够精准，会漏报、也会出现误报比较多，扫描的结果需要进行人工审计。当然这些工具也在逐步改进。 RASP 工具RASP 的意思是Runtime Application Self Protection，这个概念近些年才提出，目前已经有一些安全公司做出了对应的产品，比如Sqreen, 百度最近也新开一个开源项目叫做OpenRASP，目前来说只支持 Java，开发者可以自己使用 Javascript 编写自己的插件。RASP 除了自己的规则还会依据请求时候的上下文来进行分析，这篇文章里有一些描述，这样误报的问题会大大减少。","tags":[{"name":"security","slug":"security","permalink":"http://catcoding.me/tags/security/"}]},{"title":"Kong 集群 Left Cluster Node 问题","date":"2018-03-04T11:02:32.000Z","path":"p/kong-cluster-left-node/","text":"问题Kong 在实践中会有一些疑惑的地方，这里记录一下。注意这里记录的 Kong 集群部署的问题是 0.10.3 版本的，最新 Kong 版本已经不是通过 serf 来管理不同节点之间的配置同步问题。 在 Kong 多节点部署的时候，有时候某个节点停掉后，我们在后台可以看到 left 的信息，而且这个 left 信息会保留一段不短的时间。类似于如下： 分析管理后台 Konga 是通过 api 获取的节点信息，在kong/kong/api/routes/cluster.lua文件里可以看到如下路由处理逻辑： GET = function(self, dao_factory, helpers) local members, err = singletons.serf:members() if err then return responses.send_HTTP_INTERNAL_SERVER_ERROR(err) end local result = &#123;data = &#123;&#125;&#125; for _, v in pairs(members) do if not self.params.status or (self.params.status and v.status == self.params.status) then table_insert(result.data, &#123; name = v.name, address = v.addr, status = v.status &#125;) end end result.total = #result.data return responses.send_HTTP_OK(result)end, 具体serf:members()的实现在 serf.lua 里面可以看到，就是执行了serf cluster members命令获取结果然后返回 JSON。所以我们在服务器上执行这个命令其实也可以看到类似的结果： 那么问题的根源当然是在 Serf 本身里面，通过看文档发现原来确实是有一定延迟的。 Serf keeps the state of dead nodes around for a set amount of time, so that when full syncs are requested, the requester also receives information about dead nodes. Because SWIM doesn’t do full syncs, SWIM deletes dead node state immediately upon learning that the node is dead. This change again helps the cluster converge more quickly. 参考 serf 文档» serf 的具体实现接着稍微看了一下 Serf 的代码，果然 Go 的项目代码直观好读。在 Serf 这个结构体里面保存了一个 leftMembers 的状态列表，每次收到 left 事件的时候处理逻辑是： // handleNodeLeaveIntent is called when an intent to leave is received.func (s *Serf) handleNodeLeaveIntent(leaveMsg *messageLeave) bool &#123; .................. // State transition depends on current state switch member.Status &#123; case StatusAlive: member.Status = StatusLeaving member.statusLTime = leaveMsg.LTime return true case StatusFailed: member.Status = StatusLeft member.statusLTime = leaveMsg.LTime // Remove from the failed list and add to the left list. We add // to the left list so that when we do a sync, other nodes will // remove it from their failed list. s.failedMembers = removeOldMember(s.failedMembers, member.Name) s.leftMembers = append(s.leftMembers, member) ................ return true default: return false &#125;&#125; 通过索引变量发现这个列表会定时通过handleReap函数更新，逻辑如下： // handleReap periodically reaps the list of failed and left members, as well// as old buffered intents.func (s *Serf) handleReap() &#123; for &#123; select &#123; case &lt;-time.After(s.config.ReapInterval): s.memberLock.Lock() now := time.Now() s.failedMembers = s.reap(s.failedMembers, now, s.config.ReconnectTimeout) s.leftMembers = s.reap(s.leftMembers, now, s.config.TombstoneTimeout) reapIntents(s.recentIntents, now, s.config.RecentIntentTimeout) s.memberLock.Unlock() case &lt;-s.shutdownCh: return &#125; &#125;&#125; 所以看起来这里相关的 Timeout 是s.config.TombstoneTimeout, 接着需要看看reap到底做了什么，这里果然是把到了一定时间间隔的节点删掉了： // reap is called with a list of old members and a timeout, and removes// members that have exceeded the timeout. The members are removed from// both the old list and the members itself. Locking is left to the caller.func (s *Serf) reap(old []*memberState, now time.Time, timeout time.Duration) []*memberState &#123; n := len(old) for i := 0; i &lt; n; i++ &#123; m := old[i] // Skip if the timeout is not yet reached if now.Sub(m.leaveTime) &lt;= timeout &#123; continue &#125; // Delete from the list old[i], old[n-1] = old[n-1], nil old = old[:n-1] n-- i-- .......... &#125; return old&#125; 那么这个时间间隔是多久呢，在serf/config.go有一个默认配置： TombstoneTimeout: 24 * time.Hour, 其他serf 这个软件值得好好分析一下，节点的状态同步和事件处理都是分布式软件的基础，后续继续看看这个gossip protocol based on SWIM的具体实现。另外hashicorp这个公司的开源代码和文档都非常好，值得学习一番。","tags":[{"name":"Tools","slug":"Tools","permalink":"http://catcoding.me/tags/Tools/"},{"name":"Kong","slug":"Kong","permalink":"http://catcoding.me/tags/Kong/"},{"name":"Golang","slug":"Golang","permalink":"http://catcoding.me/tags/Golang/"}]},{"title":"Docker compose 初始化失败问题","date":"2018-03-02T23:17:35.000Z","path":"p/docker-postgres-password/","text":"问题今天在 Docker Postgresql 用户名和密码授权的问题上花了一些时间，问题是： psql: FATAL: password authentication failed for user &quot;postgres&quot; admin 的用户名和密码是可以在 docker-compose.yml 里设置的，通常我们可以配置为： postgresql: image: postgres:latest ports: - &quot;5434:5432&quot; volumes: - ./data/pgsql:/var/lib/postgresql/data - ./initialize/pgsql:/docker-entrypoint-initdb.d environment: POSTGRES_USER: postgres POSTGRES_DB: postgres secrets: - pg_superuser_password 某个用户的密码可以在./initialize/pgsql目录的脚本里设置： #!/bin/bashset -epsql -v ON_ERROR_STOP=1 --username &quot;postgres&quot; &lt;&lt;-EOSQL CREATE USER user WITH PASSWORD &#x27;the-password&#x27;; ALTER USER user CREATEDB;EOSQL 只是今天碰巧想修改一下这个密码，所以就把这个脚本里的密码修改了，然后执行命令： docker-compose up --build -d --force-recreate 而后就一直出现上面的用户授权失败。 原因刚开始一直认为是可能 dockerfile 配置得不对，结果花费了些时间。后来突然想到了，PG 里数据初始化应该只是第一次做了，后续如果发现/var/lib/postgresql/data里已经有数据了就再也不会重新设置密码，这里是配置 volume 的，如果还未有重要数据把./data/pgsql删除了即可，或者应该是可以通过 attach 进入容器通过 pg 命令修改。 总结最近在自己工作的项目都完全 Docker 化，感觉是配置来折腾用起来飞。最近也在做一个重度依赖 Docker 的项目，所以 Docker 的文档需要看完，特别是网络和数据存储那块，否则会花费不少时间折腾。","tags":[{"name":"Tools","slug":"Tools","permalink":"http://catcoding.me/tags/Tools/"},{"name":"Docker","slug":"Docker","permalink":"http://catcoding.me/tags/Docker/"}]},{"title":"使用 overcommit 生成 git hooks","date":"2018-02-26T19:02:14.000Z","path":"p/overcommit/","text":"git hooks很方便地可以在 git 操作流程的各个阶段加入 hooks，比如执行一些脚本来检查代码风格、跑单元测试、做代码静态检查等。git hooks 的试用方法是在.git/hooks 目录下写各种脚本，但是.git 目录的这些脚本是不会 checkin 到 repo 里的，所以如果一个代码如果被多个开发人员共享就会显得不太方便同步 hooks。 当然也有一些其他方法来解决这个问题，比如配置 links 或者对于git 2.9以后也可以使用来定制 hooks 的目录： git config core.hooksPath hooks 对于熟悉 Ruby 的同学可以使用overcommit这个 gem 来解决。使用方法就是通过配置.overcommit.yml，比如： PreCommit: RuboCop: enabled: true command: [&#x27;bundle&#x27;, &#x27;exec&#x27;, &#x27;rubocop&#x27;] # The shell command should run AuthorName: enabled: false 然后执行命令： overcommit install 来自动生成各种 hooks，通常后面的修改都是修改这个 yaml 文件即可，不过记得修改后需要overcommit --signed来重新生成 hooks。","tags":[]},{"title":"Nginx https too many redirect","date":"2018-02-23T17:38:44.000Z","path":"p/nginx-https-too-many-redirect/","text":"Http 请求在经过多层 Nginx 的时候，通常强制 http 跳转到 https 的时候会这样配置： return 302 https://$host$request_uri; ## 需要注意这里是 request_uri 而不是 uri，否则会引起安全问题 但是如果是多层 Nginx，前面的 Nginx 需要把用户原始请求的 scheme 传递到后端，可以加上头部设置： proxy_set_header X-Forwarded-Proto $scheme; 后面的 Nginx 再判断一次： if ( $http_x_forwarded_proto != &#x27;https&#x27; ) &#123; return 301 https://$host$request_uri;&#125; 否则强制 https 经常会出现类似ERR_TOO_MANY_REDIRECTS 将您重定向的次数过多这样的问题。 可是在实践过程中偶尔也碰到过一些 ELB 会丢掉 scheme 的问题，比如在这样的请求链路情况下elb =&gt; nginx =&gt; nginx =&gt; application第二层 Nginx 获取的 scheme 就有问题了，这也可能会导致too many redirects问题。 可以尝试在第二层 Nginx 上这样解决： proxy_set_header X-Forwarded-Proto $http_x_forwarded_proto; 当然强制 https 这样的跳转逻辑尽量放在请求链路的最外层，这样问题会少一些。","tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://catcoding.me/tags/Nginx/"}]},{"title":"Linux 当前 shell 执行命令","date":"2018-02-22T21:46:33.000Z","path":"p/linux-source/","text":"Linux shell 执行脚本的时候一般是会 fork 出一个子 shell，这样在有的时候就不方便了，比如要 unset 当前 shell 的环境变量等， #!/usr/bin/env zshif [ -z $http_proxy ]; then echo &quot;not using proxy, set it now ... &quot;; export http_proxy=&quot;http://127.0.0.1:1087&quot;; export https_proxy=&quot;https://127.0.0.1:1087&quot;; echo $http_proxy;else echo &quot;using proxy now, unset it now ...&quot;; unset http_proxy; unset https_proxy; echo $http_proxy;fi 这时候需要执行 . ./proxy_toggle.sh 或者 source ./proxy_toggle.sh。 . (a period) is a bash shell built-in command that executes the commands from a file passed as argument, in the current shell. source is a synonym for . From Bash man page: . filename [arguments]source filename [arguments] Read and execute commands from filename in the current shell environment and return the exit status of the last command exe‐ cuted from filename. If filename does not contain a slash, file names in PATH are used to find the directory containing file‐ name. The file searched for in PATH need not be executable. When bash is not in posix mode, the current directory is searched if no file is found in PATH. If the sourcepath option to the shopt builtin command is turned off, the PATH is not searched. If any arguments are supplied, they become the posi‐ tional parameters when filename is executed. Otherwise the positional parameters are unchanged. The return status is the status of the last command exited within the script (0 if no commands are executed), and false if filename is not found or cannot be read.","tags":[]},{"title":"Ruby 的 open 函数导致命令执行","date":"2018-02-12T20:39:46.000Z","path":"p/ruby-open-vul/","text":"说明首先看看 open 函数的文档说明：https://apidock.com/ruby/v1_9_3_392/Kernel/open/class： If path starts with a pipe character, a subprocess is created, connected to the caller by a pair of pipes. The returned IO object may be used to write to the standard input and read from the standard output of this subprocess. If the command following the “|” is a single minus sign, Ruby forks, and this subprocess is connected to the parent. In the subprocess, the open call returns nil. If the command is not “-”, the subprocess runs the command. If a block is associated with an open(“|-”) call, that block will be run twice—once in the parent and once in the child. The block parameter will be an IO object in the parent and nil in the child. The parent’s IO object will be connected to the child’s stdin and stdout. The subprocess will be terminated at the end of the block. 其中说明了如果以 | 开头则会 fork 出一个进程，| 后面的内容则会当成一条命令执行，比如： cmd = open(&quot;|date&quot;)print cmd.getscmd.close=&gt; 2018 年 2 月 12 日 星期一 21 时 37 分 45 秒 CST 漏洞正因为这样，这个 open 函数真的是很容易出错，最近的这个 PR： https://github.com/ruby/ruby/pull/1777 之前我们的项目里也出现过类似的情况，直接相当于一个 webshell，任意执行命令。这样的 command injection 当然也很好检测，brakeman 之类的就可以。所以 Rails 项目还是时不时地扫描一下比较好。 Ruby 里面有几个 Open，这里有比较明晰的解释，Kernel.open 这个函数就是一个 wrapper，根据不同的情况做对应的处理。趟多了坑之后，才会觉得这样的特性其实是增加了程序员的负担，比如这个|特性可能有的人就没注意到，即使是看过文档也可能看到了老版本的文档，从而不知道这个边边角角。 当然同样的 system 这样的命令执行函数也是类似的情况，比如railsgoat 里的这个 command injection。原则是对于任何用户输入的参数，都需要做不安全的假设，做好检查。 https://github.com/OWASP/railsgoat这个项目里有各种 Rails 漏洞，值得看看。","tags":[]},{"title":"BuckleScript and Reason","date":"2017-09-17T22:47:27.000Z","path":"p/bucklescript-and-reason/","text":"BuckleScript虽然我不是前端工程师，不过因为喜欢 OCaml，所以偶尔关注 BuckleScript 有一段时间了，今天又花时间看了看文档和代码。BuckleScript 是张宏波主导开发的开源项目，『有希望成为第一个完全由国人设计主导实现并被世界各地广泛使用的编译器』，不过是否能广泛被使用还得看后续推广。 简单来说 BuckleScript 是一个代码转换器，把你写的 OCaml 代码生成为纯 JS 代码。这样做的好处和必要性在于： JS 太牛了，这个跨平台语言正在吞噬着所有软件领域 JS 太难维护了，大规模的 JS 代码更是噩梦。不管是从开发者角度和是从代码安全的角度，JS 需要类型！微软的 Typescript 和 FB 的 Flow ，甚至是Elm都是为了给 JS 带来类型。 OCaml 类型系统稳定可靠，关键是编译器速度快，并且可以编译在多个平台上。 就我个人而言非常喜欢 OCaml，之前也有一些自己的小项目用过 OCaml。BuckleScript 从技术角度来说是非常好的，我看了一些生成的代码可读性比很多代码生成器要好。并且除了直接翻译代码，这个编译器也做了很多代码优化的工作，生成 size 更小，performance 更好的 JS 代码。遗憾的是目前还不支持 Core 这个库，我之前用 Core 比较多，ಥ_ಥ。 关于代码生成，想起我们原来做过的 Gorazor，从技术角度来说还是有些挑战的，不过从使用角度我个人持保留态度。代码生成毕竟会引入新的语法，我发现很多前端程序员其实并不怎么熟悉函数式编程那套，OCaml 的语法是否能在前端程序员中推广开来是个问题。BuckleScript 的文档有待改进，可以给更多大一点的完整的例子。 关于 BuckleScript 和 js_of_ocaml 的区别，从文档上来看 js_of_ocaml 可以把 bytecode 转换为 JS 代码，而 BuckleScript 是在从编译器里面的 rawlambda 生成代码，所以理论上来说 js_of_ocaml 对 OCaml 的兼容性更好，而 BuckleScript 能生成更可读的 JS 代码，目标在于兼容 npm 平台。 ReasonMLReasonML的来由是之前我说的 OCaml 独特的语法，在很多人看来并不是很友好，所以 FB 的这群人做了一个更符合大众品位的方言。然后可以通过 BuckleScript 再翻译为 JS 代码。好绕啊！不过据说 FB 已经在生成环境使用这些了。ReasonML 的开发者移植了一个之前用 js_of_ocaml 写的mario 的例子，看了一遍觉得 reason 的语法其实改动并不大，可能对 JS 的程序员来说更友好吧。reason 和 OCaml 的关系类似于 Elixir 和 Erlang 之前的关系，为了讨好一类程序员，又为了利用一个已经非常成熟可靠的现有平台。 在 HN 上有一个比较老的讨论帖，有时间也可以再看看。 Why bucklescript matters for Javascript platform","tags":[{"name":"OCaml","slug":"OCaml","permalink":"http://catcoding.me/tags/OCaml/"},{"name":"Javascript","slug":"Javascript","permalink":"http://catcoding.me/tags/Javascript/"}]},{"title":"《深度工作 - 如何有效使用每一点脑力》读后","date":"2017-09-14T22:20:14.000Z","path":"p/deep-work/","text":"深度工作这本书主要讲解了一些时间和精力管理方面的东西，人到了一定年龄就会觉得时间不够用，日子过得太快，每天觉得都没干什么就过去了。工作几年后这种感觉时不时袭来。反而是如果某段时间一直有一个阶段性的目标，就会觉得很踏实，进度和效率也可以。那种完全沉浸在思考中的状态真的也并不是累，相反所得到的结果往往是真实的收获和进步。用这本书里的术语可以称之为『深度工作』的阶段吧。 说起来也有道理，如果自认为我们是知识工作者，那么大多数时间处于浮潜的工作状态就得不到什么深刻的结果。作为程序员，我也有时候感觉自己并不是在做什么高深的工作，那么这样长久下去会怎么样呢，随之而来的是不可避免的压力。 这里讲的四个准则，任何一个都值得好好修炼，对于大多数人而言，大脑都已经被互联网和手机训练得愚钝和不可专注了： 工作要深入拥抱无聊远离社交媒体摒弃浮浅 深入工作的价值在当今社会格外突出，因为机器的迅猛发展，特殊的技能所展现的价值越发明显。『连续听一系列中等水平的歌手唱歌并不能累加成一场无与伦比的演出— 换言之，才能并非一种商品，你不可以通过大批购买，然后累积起来达到一定水准，只有成为最优秀的才会得到额外奖励』。我们所面临的时代需要掌握一些更为复杂的工作和技能，而这些技能并不是随便看看就能轻易得到的。深入的东西只有静下心来，持续花大量时间和精力才能逐渐掌握。 想要进入深度工作，会有两个方面需要注意： 时间分配，如何避免被频繁打断，如何尽量延长一大段可以持续的时间 学习和锻炼持续专注的能力 关于时间分配，我之前尝试过番茄工作法，但是感觉并不好。因为仪式感太强和太频繁，在我正在进入工作状态的时候可能就到了节点。对于大多数程序员来说晚上可能是最能安静的写程序和思考的时间，不过随着更多的家庭责任，晚上的时间也短了。所以现在我打算早上尽早起来，这样还有一两个小时加以利用。 关于专注能力这块： 不断地切换注意力会对大脑产生长久的负面影响 这个结论应该大家都有体会，持续专注的能力往往决定人的能力，有的人可以一直脑袋里想着问题，即使是在走路或者吃饭的时候。之前在学校我也有过一段时间，脑袋里一直在想着要找的答案，那种体验已经好久没有了。 总之，这本书还不错，推荐有时间的话看看。","tags":[{"name":"Books","slug":"Books","permalink":"http://catcoding.me/tags/Books/"}]},{"title":"Kong 的 0.11.0 版本","date":"2017-09-12T14:43:00.000Z","path":"p/kong-new-release/","text":"Kong 发布了新的版本0.11.0，从这里开始区分了社区版本和商业版。这次改动比较大的是丢弃了 serf，这样整个 Kong 节点之间的缓存同步方式变化了。开发者给出的理由如下： 依赖 serf，serf 并不属于 Nginx/OpenResty 这种依赖相互间通信来同步的机制对于 deployment 和容器化都有些不便 在运行的 Kong 节点触发 serf 需要一些租塞的 I/O 新的实现的思路是以数据库作为中心，增加一个 cluster events 的表。任何 Kong node 都可以向数据库发送变更消息，其他节点 polling 数据库改动，然后来更新缓存内容。这个改动非常大，不过最终 Kong 终于实现了节点无状态，之前那个数据库里的 nodes 可以丢弃掉了，任何时候节点重启只要连上数据库即可工作。我们需要担心的是这么多节点去 polling 数据库 (当然这些动作都是在后台)，是否是一个比较耗时的工作。 Kong 增加了新的配置选项 db_update_frequency，默认为 5s，表示多长时间 polling 一次，这需要用户自己权衡效率和及时性了。对于我们的业务来说及时性还是很重要的，比如我们新品发布时间精确到秒，那么我们就需要尽量调低这个参数。 所有的改动在 https://github.com/Mashape/kong/pull/2561/files， 我大概看了一下代码，一些值得注意的地方如下： cluster 相关的 API 和 cmd 都被移掉了，启动部分和 serf 信号处理部分都删掉了不少代码。 polling 需要避免一个问题，比如上一次 polling 还未执行完成，下一次 polling 就不应该启动，所以这里需要锁来处理。kong/cluster_events.lua实现了 polling 的主要过程。 kong/cluster_events/strategies/postgres.lua目前 polling 还不支持分页，cluster_events 是一个新建的表用来存储缓存更新事件，Kong 节点就是来查询这些事件。 缓存部分换成了lua-resty-mlcache，原来还是和之前分析的类似 L1 级别缓存为一个 LURcache，在 LuaVM 里可见， L2 级别的缓存为 lua_shared_dict，同一个 Nginx 下的所有 worker 可见， L3 就是缓存未命中的情况，需要调用其他 hookup 的函数去获取数据然后缓存在 L2。只是这里个 ipc 并不是用的 lua-resty-mlcache 里的，而是使用的 resty.worker.events。 事件处理部分分两部分，worker 之间的事件和 node 之间的处理，分别由 worker_events 和 cluster_event.lua 来处理。","tags":[{"name":"Kong","slug":"Kong","permalink":"http://catcoding.me/tags/Kong/"},{"name":"Lua","slug":"Lua","permalink":"http://catcoding.me/tags/Lua/"}]},{"title":"Lua 时间处理","date":"2017-09-12T09:51:00.000Z","path":"p/lua-time-related/","text":"我需要用 Lua 处理一个与时间相关的问题，比如我们在配置文件里面配置一个日期 (北京时间)，然后在 Openresty 里面判断当前时间是否在这个日期之前或者之后来做对应的逻辑。 Lua 的时间处理还有点麻烦，主要是自带的相关库函数比较少。 os.time() &lt;== 返回当前系统的日历时间， 1505181586os.date() &lt;== 返回本地化的时间字符串，Tue Sep 12 09:59:56 2017os.clock() &lt;== 返回执行该程序 CPU 花去的时钟秒数，这里是 1156.726 我首先需要一个日期字符串转换为时间戳的函数，找来找去有了这么一个函数，使用正则表达式然后组成表： function convert_time(time_str) -- Assuming a date pattern like: yyyy-mm-dd hh:mm:ss -- Assuming timezone is Beijing local pattern = &quot;(%d+)-(%d+)-(%d+) (%d+):(%d+):(%d+)&quot; local year, month, day, hour, minute, seconds = time_str:match(pattern) if not (year and month and day and hour and minute and seconds) then return nil end local converted_timestamp = os.time(&#123;tz = &quot;CST&quot;, year = year, month = month, day = day, hour = hour, min = minute, sec = seconds&#125;) return converted_timestamp end 然后我们可以使用 os.time() 获取当前时间戳来对比。但是必须注意时区问题，Lua 里面要获取当前时区和 UTC 里面的 offset 可以使用一个比较笨拙的办法： function get_timezone_offset_with_utc() local now = os.time() return os.difftime(now, os.time(os.date(&quot;!*t&quot;, now)))end 使用这个函数获取时区的 offset 之后，对 convert_time 返回的结果做一下偏移即可和 os.time() 做对比。有个问题是上面的函数居然调用了三次系统调用，开销是比较大的。 在 OpenResty 的世界里，不推荐使用这里的标准时间函数，因为这些函数通常会引发不止一个昂贵的系统调用，同时无法为 LuaJIT JIT 编译，对性能造成较大影响。推荐使用 ngx_lua 模块提供的带缓存的时间接口，如 ngx.today, ngx.time, ngx.utctime, ngx.localtime, ngx.now, ngx.http_time，以及 ngx.cookie_time 等。 Penlight库也有很多日期相关的函数封装，不过大多也都使用了 os 相关函数。为了避免多次调用 get_timezone_offset_with_utc\u001b我使用了 Kong 里面自带的 cache 相关函数做一下缓存： -- 缓存上面的时区差，减少系统调用local offset_with_cst, err = cache.get_or_set(&quot;timezone_offset&quot;, nil, get_timezone_offset_with_utc, nil)","tags":[{"name":"Lua","slug":"Lua","permalink":"http://catcoding.me/tags/Lua/"}]},{"title":"使用 exercism 来练手学语言","date":"2017-08-22T12:12:02.000Z","path":"p/pl-practice-with-exercism/","text":"有时候我们想学一门编程语言，但是光看看书和代码用例总是找不到感觉，这时候我们应该尝试写点不短不长的程序片段，可能是一个函数，或者是实现一个简单的算法。最近我发现这个叫做exercism.io的网站不错，自己也在闲余时间在上面看看。 这里支持 30 多种编程语言，每种语言大概有 80 个左右的小问题，每个题目已经写好了对应的测试用例。这些题目不是专门的算法题目，但会涉及到编程语言相关的基本方面，单元测试、字符串，数字处理，代码风格等。我们可以随机的找一些来练练手，提交自己的代码后也可以看看别人的代码。然后再对自己的代码进行一些改进。其他人也可能会对我提交的代码 review 并提交改进评论。多写和多看确实就是学习编程的最好途径。 http://exercism.io/当然是开源的，大家都可以提供题目和测试。具体使用起来可以参考文档，其中有已经实现好的 cli 工具，每做一个 fetch 一下即可看到下一题。如果你对数学或者算法方面的问题更感兴趣，也可以试试https://projecteuler.net/，这个则不限语言，只需要最终结果即可。","tags":[{"name":"PL","slug":"PL","permalink":"http://catcoding.me/tags/PL/"}]},{"title":"从 Jekyll 换成 Hexo","date":"2017-08-12T08:38:00.000Z","path":"p/migrate-to-hexo/","text":"昨天看到自己的 Blog 在移动端显示丑死了，所以想着优化一下，找一个 mobile first 的风格试试。顺便把 blog 从 jekyll 换成了 Hexo。最后找到这个 hexo 的主题非常顺眼，便拿来用了，感谢yanm1ng为大家提供如此优秀的主题。回想起自己之前用过搜狐博客，然后是 yo2，然后是 wordpress 自己搭，后来又出现了 jekyll，最终才找到最适合的写日志的方式。这次我把之前残留的 html 完全转换为了 markdown，并保留了创建日期，没想到这么多年来断断续续已经写了 100 来篇文章了。 hexohexo 其实和 jekyll 非常类似，只是迁徙过程中还是需要做一些处理。hexo 的文章排序选择了 date 倒序排，但是依赖于_post 里的文件创建时间，为了解决这个问题，然而 git 是不管理文件的时间戳的。结果会出现一些诡异的问题，文章的顺序会变乱。后来才发现 hexo 为了解决这个问题引入了一个叫做 db.json 的文件，存的内容大概是文件的时间戳之类的。为了保持之前的文章链接有效，写了一些小脚本处理文章。 gitment关于评论还发现一个很好的解决方案，那就是使用gitment，这个方案是专门针对 github 上 host 的博客系统的，唯一不爽的地方在于需要自己为新增文章初始化创建一个 issue，每一条评论会增加对应文章 issue 的 comments。当然结果也导致了只有 github 帐号才能评论。不过我觉得这还是挺不错，毕竟 github 作为程序员的社交系统已经如此流行。 typora另外经大家推荐尝试使用 markdown 编辑软件 Typora。之前因为自己使用的 markdown 格式稍微有点差别， 而且也习惯了用 Emacs，所以并没用深度使用 Typora。这次好好尝试了一下，发现其可见即可得还是非常方便的。另外就是插入图片的时候可以直接拖入，并且配置一下图片的根目录，自动拷贝到图片目录 (或者上传到图床)。这个功能真的很暖心，typora 的作者肯定也是用 git 来管理自己的日志。","tags":[{"name":"Blog","slug":"Blog","permalink":"http://catcoding.me/tags/Blog/"}]},{"title":"Kong 源码分析：事件","date":"2017-07-23T08:38:00.000Z","path":"p/kong-intro-5/","text":"Kong 的缓存更新很多依赖于事件，而事件看起来是相对来说比较复杂、也是最有趣的一部分。 worker 模型假设我们对 Kong 做了一个更改的请求，这个请求通常是通过 admin_api 这个路由处理的。也就是说最终执行数据库操作的动作是在一个 Nginx worker 进程里。因为操作了数据库所以我们需要刷新这个 Kong 节点的所有 worker 的缓存，而且要把事件分发给其他 Kong 节点，让其他 Kong 节点刷新所有 worker 的缓存。 这就涉及到两部分： Kong 节点之间的消息通信，这是使用serf来实现的 Kong 每个节点内部，也就是 Nginx worker 之间的通信，这是使用lua-resty-worker-events来进行。 发布订阅模式发布订阅是实现事件的一种经典设计模式，主要需要有两类操作： 发布消息 订阅消息，收到消息后触发指定的函数。 Kong 使用的是一个叫作 mediator_lua，mediator 中文意思为”中间人”，很符合项目的意思。可以看到 kong/core/events.lua 里面实现如下： function Events:subscribe(event_name, fn) if fn then self._mediator:subscribe(&#123;event_name&#125;, function(message_t) fn(message_t) return nil, true -- Required to tell mediator to continue processing other events end) endendfunction Events:publish(event_name, message_t) if event_name then self._mediator:publish(&#123;string.upper(event_name)&#125;, message_t) endend Kong.init 初始化的时候会调用一个叫做 attach_hooks 的函数： attach_hooks(events, require &quot;kong.core.hooks&quot;) 在 load 插件的时候也会把插件对应 hooks 绑定上： -- Attaching hookslocal ok, hooks = utils.load_module_if_exists(&quot;kong.plugins.&quot; .. plugin .. &quot;.hooks&quot;)if ok then attach_hooks(events, hooks)end 事件的来源上面说过，Kong 节点之间通信是通过serf发送的。我们来看看事件是如何触发发出通知的。事件来于源数据库的修改，那就应该在数据库代码部分有触发事件的代码，查看 dao/dao.lua 这个文件里的代码，我们可以看到在 insert、update、insert 执行的时候都调用了一行代码 event(self, event_types.ENTITY_DELETED, k, v.schema, entity) 这个函数的实现如下，这里做了数据的序列化，然后发布了一种叫做 CLUSTER_PROGATE 类型的消息： local function event(self, type, table, schema, data_t) if self.events_handler then ..... 执行数据序列化 self.events_handler:publish(self.events_handler.TYPES.CLUSTER_PROPAGATE, payload) endend 在 core/hooks.lua 接受消息部分，events.TYPES.CLUSTER_PROPAGATE 对应的处理部分是 singletons.serf:event(message_t)，所以我们看 serf.lua 这个源文件，最终 event 调用了 invoke_signal，这个函数会运行一个 serf 命令，类似于这样： serf event -coalesce=false -rpc-addr=127.0.0.1:7373 kong &#x27;&#123;&quot;type&quot;:&quot;ENTITY_UPDATED&quot;,&quot;primary_key&quot;:[&quot;id&quot;],&quot;collection&quot;:&quot;apis&quot;,&quot;entity&quot;:&#123;&quot;id&quot;:&quot;94acca76-d61a-429e-86a9-5abf2c61ee31&quot;&#125;&#125;&#x27; 这就出发了一个 serf event，其他 Kong 节点会收到此消息。 serf: Kong 节点之间通信那么 Kong 节点收到消息之后是如何处理的呢？Kong 在启动的时候会在后台执行一个 serf 进程，类似这样： serf agent -profile wan -bind 0.0.0.0:7946 -log-level err -rpc-addr 127.0.0.1:7373 -event-handler member-join,member-leave,member-failed,member-update,member-reap,user:kong=/usr/local/kong/serf/serf_event.sh -node Kang.local_0.0.0.0:7946_be3b9352808e4839a272f30ca6025650 可以看看 serf_event.sh 这个脚本，内容如下： PAYLOAD=`cat` # Read from stdinif [ &quot;$SERF_EVENT&quot; != &quot;user&quot; ]; then PAYLOAD=&quot;&#123;\\&quot;type\\&quot;:\\&quot;$&#123;SERF_EVENT&#125;\\&quot;,\\&quot;entity\\&quot;: \\&quot;$&#123;PAYLOAD&#125;\\&quot;&#125;&quot;fiCMD=&quot;\\local http = require &#x27;resty.http&#x27; \\local client = http.new() \\client:set_timeout(5000) \\client:connect(&#x27;127.0.0.1&#x27;, 8001) \\client:request &#123; \\ method = &#x27;POST&#x27;, \\ path = &#x27;/cluster/events/&#x27;, \\ body = [=[$&#123;PAYLOAD&#125;]=], \\ headers = &#123; \\ [&#x27;content-type&#x27;] = &#x27;application/json&#x27; \\ &#125; \\&#125;&quot;/usr/local/openresty/bin/resty -e &quot;$CMD&quot; 可以看到 serf 收到消息后会触发这个脚本，然后把消息发送到本节点的/cluster/events 这个路由。api/routes/cluster.lua 这个文件里有收到消息后的处理代码，其中最关键的是： -- Trigger event in the nodeev.post(constants.CACHE.CLUSTER, message_t.type, message_t) 就是通过 resty.worker.events publish 出收到的消息，本节点的 worker 会处理这些消息。 worker 刷新缓存假设当前 Kong 节点收到一个消息，这个消息是如何分发给各个 worker 的？从代码看出，在 Kong 初始化的时候有调用一个叫做 kong.lua 里面的 Kong.init_worker() 函数，其中有一段代码注册了 event handler:local worker_events = require &quot;resty.worker.events&quot;local handler = function(data, event, source, pid) if data and data.collection == &quot;apis&quot; then assert(core.build_router()) elseif source and source == constants.CACHE.CLUSTER then singletons.events:publish(event, data) endendworker_events.register(handler) 可以从上面的 handler 代码看到，一个 worker 接收到消息之后执行的是： singletons.events:publish(event, data) 也就是通过 mediator_lua 再把消息 publish。之前初始化的时候已经 attach_hooks 了各种 handler，这时候那些注册的函数才会被最终执行，比如核心的刷新缓存部分代码在 core/hooks.lua 的 invalidate 函数里面。 回顾总的来说 Kong 事件部分的代码相当精妙，也很统一。比如当前 worker 做了修改，这个事件会发送给各个节点，包括当前自己所在的节点。通过发布订阅模式，写代码的时候只需关心消息发送、接受消息索要处理的逻辑。","tags":[{"name":"Lua","slug":"Lua","permalink":"http://catcoding.me/tags/Lua/"}]},{"title":"Kong 源码分析：缓存","date":"2017-07-22T08:38:00.000Z","path":"p/kong-intro-4/","text":"Nginx 里的缓存使用在 Kong 里面我们缓存的内容大部分是配置，不管是 API 本身的配置还是插件相关的配置，缓存之后就存储在内存中。 Kong 里的缓存基础代码在 tools/database_cache.lua 文件里面。这里又分两种类型的缓存，一种是shared dict, 一种是使用lua-resty-lrucache。这两者之间是有区别的: shared dict 如同其名字一样是 Nginx worker 之间共享的，而 lrucache 是 worker 级别的，内存空间在 Lua VM 里由 GC 管理，不能在进程之间共享，自然也不会在 Nginx worker 之间共享。 具体我们开发中使用哪一种由具体场景分析，比如在 Kong 的插件 rate-limiting 里就使用了共享缓存，因为我们需要针对一个 Nginx 所有的 worker 做请求数统计。 share dict 最常规的使用方法是： http &#123; lua_shared_dict dogs 10m; server &#123; location /set &#123; content_by_lua_block &#123; local dogs = ngx.shared.dogs dogs:set(&quot;Jim&quot;, 8) ngx.say(&quot;STORED&quot;) &#125; &#125; location /get &#123; content_by_lua_block &#123; local dogs = ngx.shared.dogs ngx.say(dogs:get(&quot;Jim&quot;)) &#125; &#125; &#125;&#125; lrucache 的使用方法如文档所示。 Kong 里的多级缓存实现有了上面的了解，看 database_cache.lua 这个文件就比较直观了，这里 Kong 会分多类缓存: apis, consumers, plugins 等。具体这样分是因为如果我们对配置做了修改，需要发出 serf 消息来指名这次改动涉及到哪些，其他 Kong 节点收到消息后自然只更新对应的缓存部分。所以 Kong 里申明了一个列表 CACHE_KEYS 来存要缓存的数据类别，同时写了不少生成缓存 key 的方法，比如: api_key，plugin_key 等。 仔细查看 database_cache.lua，我们发现其实这里是做了两级缓存。Kong 要从缓存里取出一个 key/value，首先从 lrucache 里取，如果有则返回。如果没有则从 share dict 里去取，如果取到则 deserialize 然后存储在 lrucache 里，然后返回。如果 shared dict 里也没有，则返回 nil。标准的两级缓存流程，这样做的好处在于减少 deserialize 的次数，而且 shared dict 可能被多个 worker 同时修改，要修改的时候需要加互斥锁。 这里最常用的方法是 get_or_set，尝试获取一个 key 的值，如果没有就执行对应的 callback，返回结果当做 value 设置到缓存里，并把 value 作为最后的返回结果。这里的 callback 函数通常做的当然是从数据库里读取内容。 如何避免缓存失效风暴我们在实现缓存的时候缓存失效风暴问题需要谨慎考虑。agentzh 在这里详细描述了加锁解决的策略，ngx.shcache这里也使用了相同的方法，具体可以好好研究一下那个图。 主要注意的是在加锁后，再尝试去读取一次 key，因为可能在加锁之前其他 worker 刚好把数据更新到了缓存里。","tags":[{"name":"Lua","slug":"Lua","permalink":"http://catcoding.me/tags/Lua/"}]},{"title":"Kong 源码分析：插件","date":"2017-07-16T11:43:00.000Z","path":"p/kong-intro-3/","text":"插件的强大之处在我自己使用 Kong 的过程中，最方便的还是在于 Kong 的强大的插件机制。 Nginx 本身提供了提供模块开发机制，但是相对来说更底层一些，并且需要使用 C/C++ 来开发，对于很多开发人员来说 Nginx 仍为一个黑盒。OpenResty 集成了很多好用插件，并提供了通过 Lua 扩展 Nginx 的机制，所以 OpenResty 相对来说更灵活。而 Kong 在 OpenResty 基础上提供的插件机制更灵活，在于： ​ 复用：OpenResty 的复用在于函数级别，我们可以把一些通用的 Lua 函数引入各个项目。而 Kong 的插件复用可以通过 API 修改一下配置即可。是否启用某个插件，这只是数据配置问题，启用与否不会涉及到代码的改动。 抽象、统一: Kong 实现了基础的插件配置的存储和更新机制，所以我们只需按照要求定义插件配置的数据类型，插件实现的时候不用再去关心这些细节。 灵活、组合: OpenResty 的一些处理部分有限制，比如 access_by_lua 在同一个 location 能调用一次， 当然我们可以把多个处理逻辑都放在这里，这又涉及到代码改动。 而 Kong 可以依次调用各个插件对应的 phase，并且通过引入优先级来解决前后顺序问题。 插件开发的原则是提供机制，而非实现，在做插件开发的时候一定需要考虑这个插件能否满足一类相似的需求，这样我们只需要做一下参数的配置就能把插件启动在另外一个站点上。 对于插件这块我的疑问在于这套机制如何运行的？如何找到站点对应的插件？如此多的插件是否会有性能问题？​ Kong 插件的运行机制在上一文 Kong 初始化分析中，我们看到 nginx_kong.lua 模板文件里面有这么一段代码： location / &#123; rewrite_by_lua_block &#123; kong.rewrite() &#125; access_by_lua_block &#123; kong.access() &#125; header_filter_by_lua_block &#123; kong.header_filter() &#125; body_filter_by_lua_block &#123; kong.body_filter() &#125; log_by_lua_block &#123; kong.log() &#125;&#125; 在 kong.lua 文件里面， kong.access 的实现是这样的： function Kong.access() core.access.before() for plugin, plugin_conf in plugins_iterator(singletons.loaded_plugins, true) do plugin.handler:access(plugin_conf) end core.access.after()end 从这里可以看出 Kong 的插件运行机制就是从 loaded_plugins 里面依次执行。 学习 Kong 插件开发的方法是参考现有的一些插件实现，学着写几个就会了。用户自己定义的插件是在 base_plugin 基类上继承而来。Kong 里面使用的了 这套 class 机制，可以看到使用 Lua 实现面向对象还是很简单的。 singletons.loaded_pluginssingletons.loaded_plugins在这里初始化的，在具体实现过程中就是从数据库里面把插件配置读出， local ok, handler = utils.load_module_if_exists(&quot;kong.plugins.&quot; .. plugin .. &quot;.handler&quot;) 在每一个插件在 handler.lua 的最后都是 return XXXXHandler，所以在调用 handler()后我们在内存中导入了插件的对象。另外在初始化后需要按照优先级来排序，以此来保证各个插件之间的执行顺序。 从上面的分析上看出，插件导入后都会在内存中的全局对象中存储，后面的开销在于依次迭代插件。 plugins_iterator我们再来看看某个站点是否启用某个插件是如何处理的，最主要的实现在于 plugins_iterator 这个函数。首先我们得理解如何确定当前 request 对应的唯一标识符， 在 core.handler.access 的过程中保存了经过路由后的 api 在 ngx.ctx 里，这个 ngx.ctx 会在整个 request 处理过程中反复被使用。再回到 plugins_interator 函数，这个函数的参数有两个，后一个叫 access_or_cert_ctx， 因为对于一个 request 处理中 plugins_iterator 会调用多次，这个参数的作用在于判断是否是第一个调用这个函数。第一次调用可能发生在ssl_certificate或者access 阶段， 因为在 ctx 里面 Kong 还是初始化了一个叫做ctx.plugins_for_request的变量来存储当前 request 启用的插件，这样后续 iterator 阶段就完全不会去重复 load 插件配置，这样做当然是为了性能上的考虑。 读取插件配置的函数调用是： if api then plugin_configuration = load_plugin_configuration(api.id, consumer_id, plugin.name)end load_plugin_configuration也会首先尝试从内存缓存中取，如果取不到再从数据库中取出，然后存储在缓存中。 从上面的分析看出，插件相关的读取和执行在大部分时间里是完全不会去读数据库的，所以性能损失并不会大。 错误处理Kong 的插件部分并没有错误处理部分，从现有代码上看错误处理分两个部分： 一种方式是responses.lua， 如果是在 Kong 的 Lua 代码部分检查出来的错误一般使用类似responses.send(500)这样的方式来向客户端返回错误码。 第二种是通过 kong_error_handler。 这种错误可能是执行了 ngx.exit(500) 之类的代码或者是 Nginx 内部触发的。 这在某些情况下对用户不友好，我们不能只简单地返回一个错误信息，有的时候我们需要展示一个漂亮些的错误页面或者是把请求转到别的降级站点，对于这个需求我做了一个分支来扩展错误处理。 目前实现还未完整，不过已经可以定制化错误页面了。 这里增加了一个 ngx.var.api_id，这个变量的初始化也在 core.access 阶段。因为存储在 ngx.ctx 里的这些信息在执行了 ngx.exit 之后已经释放了，所以我需要一个 ngx.var 级别的变量存储 api_id，然后使用这个变量来判断 error-handler 插件是否启用。","tags":[{"name":"Lua","slug":"Lua","permalink":"http://catcoding.me/tags/Lua/"}]},{"title":"Kong 源码分析：启动","date":"2017-07-07T11:43:00.000Z","path":"p/kong-intro-2/","text":"Kong 的初始化过程安装好 Kong 之后我们是用命令sudo ./bin/kong start -c kong.conf -vv来启动。其中 kong.conf 为配置文件，-vv选项打印出一些重要信息展示出来，方便发现问题。 可以看到./bin/kong是一个脚本，是用的#!/usr/local/openresty/bin/resty程序来执行，而 resty 是 OpenResty 的一个 Perl 可执行脚本。kong 的内容很简单，就是一个入口函数调用：require(&quot;kong.cmd.init&quot;)(arg) 所以我们可以从 cmd/init.lua 这个文件开始入手看启动过程。一翻开 init.lua 这个文件，发现其实不过是个 wrapper，解析了 args 之后就是调用 start，stop，quit 等命令。然后我们顺藤摸瓜找 cmd/start.lua 文件，整个启动过程就在这里了： local conf = assert(conf_loader(args.conf, &#123; prefix = args.prefix&#125;))local errlocal dao = assert(DAOFactory.new(conf))xpcall(function() assert(prefix_handler.prepare_prefix(conf, args.nginx_conf)) assert(dao:run_migrations()) assert(serf_signals.start(conf, dao)) assert(nginx_signals.start(conf)) log(&quot;Kong started&quot;)end, function(e) err = e -- cannot throw from this functionend) 从代码上来看很直观，首先 conf_loader 载入配置文件，DAOFactory 构建数据库连接层，prefix_handler.prepare_prefix 是准备一些由程序生成的配置文件。dao:run_migrations 是迁移表结构到数据库，类似其他 Web 框架。serf_signals 是启动 serf 程序，nginx_signals 是启动 nginx 进程。 读取配置文件 conf_loaderconf_loader 读取的当然是命令行里面传入的 kong.conf 文件，打开 conf_loader.lua 看了看，是是用一个 lua 第三方库来做文件解析的。local pl_config = require &quot;pl.config&quot;，最开始不太知道这个 pl 是什么，经过搜索后才知道是这里定义的，在 kong.rockspec 里面有定义了该库的依赖&quot;penlight == 1.4.1&quot;。读取配置的整个过程比较琐碎，最后回构建一个解析好的 conf 表。这里学到了 Lua 里面的 setmetatable 设置元表的方法，table 作为 Lua 里面的最基本数据结构，setmetatable 可以方便的绑定一个 key 和其对应的方法。看起来也像是面向对象的风格，在 conf_loader 的最后部分是： return setmetatable(&#123; load = load, add_default_path = function(path) DEFAULT_PATHS[#DEFAULT_PATHS+1] = path end, ......&#125;, &#123; __call = function(_, ...) return load(...) end&#125;) 这样其他地方调用的时候local conf, err, errors = conf_loader(args.conf)自然就把 args.conf 传入 load，返回解析后的结果。 prepare_prefix 动态生成 Nginx 和 serf 的配置prefix_handler.lua 这个文件主要在准备一些 Nginx 的配置文件和 serf 的配置文件。prepare_prefix 函数前半部分在创建各个子目录，logs、serf、pids、以及各个日志文件。关于 Kong 的 config 部分需要参考一下这里。这个函数比较长，重要的部分是生成 Nginx 的配置文件。可以看到 compile_kong_conf 函数其实是是用 kong/templates 目录下的 nginx_kong.lua 和 nginx.lua 分别生成两个文件，其中 nginx_kong.lua 里面包含了嵌入 Kong 的 Lua 代码的逻辑。 init_by_lua_block &#123; require &#x27;luarocks.loader&#x27; require &#x27;resty.core&#x27; kong = require &#x27;kong&#x27; kong.init()&#125;location / &#123; rewrite_by_lua_block &#123; kong.rewrite() &#125; access_by_lua_block &#123; kong.access() &#125; header_filter_by_lua_block &#123; kong.header_filter() &#125; body_filter_by_lua_block &#123; kong.body_filter() &#125; log_by_lua_block &#123; kong.log() &#125;&#125; 因此我们可以知道 Kong 每次 reload 或者启动的时候会生成新的 Nginx 配置文件，所以我们如果要加入自己的配置可以直接修改 nginx_kong.lua 文件。另外我在使用的时候发现一个小问题，Kong 把 serf 的 node_id 存在一个文件里，如果我们把之前跑过 Kong 的机器做了镜像，然后再启动一个新的实例时，这个 node_id 文件既然存在则没有重新生成，最终导致两台 kong 实例并没有相互通信形成一个集群。我认为这里其实可以再检查一下 node_id 的文件和本机的 ip 是否一致，如果不一致则重新生成。 dao:run_migrations()初始化过程的下一步则是执行数据库操作，Kong 目前只支持 cassandra 和 Postgres，个人认为应该增加 Redis 的支持。 serf_signals.start之前提到过 serf 是用来保证 kong instance 之间的通信的，启动的时候的一个很重要参数是--event-handler，参数的内容是一个可执行脚本 (通常叫做 serf_event.sh)，文件的内容是前面生成配置文件的时候写入的。默认情况下 serf 会监听在 7946 端口，如果多台 server 需要形成一个集群，这个端口之间需要能相互通信。这里就有一个问题，在一个新的 server 刚启动的时候，该 server 是如何发现其他节点的呢？我们可以看到 serf_signals.lua 里的 start 函数调用了 serf:autojoin() 函数，跟踪到 autojoin 里面看代码，其实是从数据库里读取出其他 nodes 的信息，然后依次告诉对方新同志加入了，然后把自己的节点信息写入到数据库里。自然如果要退出也需要把自己的信息从数据库里删掉。 nginx_signals.start启动的最后一步即是 Nginx 的启动，其实最终执行的命令就是： /usr/local/openresty/nginx/sbin/nginx -p /usr/local/kong -c nginx.conf 总结通过上面的分析，可以总结 Kong 的启动过程即是：解析输入参数，验证参数合法性并生成必要的目录和配置文件，执行数据库操作，启动 serf，启动 Nginx。最终其实就是一个 OpenResty 启动过程，嵌入 Kong 里面的 core 部分的 Lua 代码。后面继续分析其可扩展的插件机制。","tags":[{"name":"Lua","slug":"Lua","permalink":"http://catcoding.me/tags/Lua/"}]},{"title":"Kong 源码分析","date":"2017-07-02T11:43:00.000Z","path":"p/kong-intro/","text":"缘由最近在工作上接触了Kong这个开源项目，因为我们内部做微服务化重构，所以导致系统相互间通信比较复杂，如果想做一些涉及各个系统的功能就很困难。比如我们前段时间实现的灰度系统就把人折腾得很惨。因为我们的设计中有一些 http header 需要在各个系统之间传递。每个项目的 Nginx 里面都用了 Lua 写一些授权逻辑，最终这些逻辑分散在各个项目的 Nginx 层，维护困难。除了灰度，其他的一些比较基础的 Nginx 层功能也是各自为政。所以我们的教训是：在做微服务化之前，需要统一的、可扩张的 API 网关。我们希望网关性能好，并且扩张性足够好。使用 OpenResty 是很自然的选择，我们希望有一层 Nginx 是所有请求都会经过的，这层 Nginx 会负责做一些基础操作，当然最重要的是做流量转发。 调研了一阵子之后，我们所面临的是两条路，一是自己写一个类似于京东 JEN的系统，在调研一圈之后我们发现 Kong 是比较适合自身业务需求的。二是在 Kong 的基础上做一些插件开发，然后集群部署 Kong 即可。 我之前稍微看了一下介绍，认为 Kong 可能对我们来说太重了些。后来又仔细看了一阵源码，自己认为代码质量挺好，而且模块化和可扩张性做得很好，因此决定采用。 Kong 简介Kong 项目的目的是这样一幅图kong-intro： 可以看到这正是我们要做的事情。使用 Kong 的优势在于： 可扩展性，Kong 依赖一个数据库来实现配置存储，依赖 serf 来实现 instance 之间的通信。任何一个节点修改了其他节点会收到通知并重新 reload 配置。 模块化，Kong 可以方便地增加新的插件，并且插件可以通过 Restful API 进行管理 主要代码模块Kong 的使用方法这里不做介绍，这里有非常详细的文档和示例。我主要分析一下其源码和原理。 core 目录里面是一些基础框架代码，包括 hooks，事件，插件基础 plugins 目录包括所有 kong 自带的插件，kong 的插件扩展有一套自己的规范，按照规范来非常容易地就能扩展 kong dao 是数据库抽象层，目前 kong 自带支持数据库 postgresql 和 cassandra。 tools 为一些工具函数，需要注意的是 cache。因为所有配置（包括插件的配置）都会是用 cache 来缓存，为了减少读取数据库次数。 api Kong 会提供一个系列接口来更新配置 我觉得 Kong 的代码质量很好，另外依照带着问题来学习新东西感觉非常有收获，这几个部分我都是从一个主题问题逐个分析，这几个问题解决了之后自然对代码就熟悉了很多，并且有信心在生产环境使用。后续我会陆续继续写一些 Kong 相关原理分析，顺便更深入熟悉一下 Lua。主要涉及到 Kong 的初始化部分、缓存如何更新、插件机制如何实现等。","tags":[{"name":"Lua","slug":"Lua","permalink":"http://catcoding.me/tags/Lua/"}]},{"title":"小说推荐","date":"2017-06-27T11:43:00.000Z","path":"p/recent-reading-list/","text":"之前我用过一段时间 Kindle，因为没有使用保护套导致在书包里面被压坏。而后一两年用 IPad 看了一些电子书，始终觉得稍微有些笨重，而且看久了眼睛不舒服。前段时间在 z.cn 上瞎逛又有了买个 Kindle 的欲望，拿到手后又好好找了一些电子书比较多的网站。目前使用最舒服的还是 http://readfree.me。 我已经在上面免费同步了好多本书。 最近用 Kindle 看了不少书，重新燃起了自己看小说的兴趣，当然也不全是小说。印象比较深书的有下面这些： ###《历史转折中的邓小平》 小说口吻讲述近代历史人物略显奇怪，不过还是可以看看。其中恢复高考那段印象深刻。值此香港回归 20 周年时，感谢邓小平的远见和智慧。 ###《褚时健传》强烈推荐的一部传记。特别敬佩褚时健解决问题的精神和执行力。褚时健一生的坎坷经历令人感叹。没几个人能做到，不管在哪个年龄段，都全心全意的做事解决问题，80 多岁的年龄还能种出一大片果林。人生经历当得上『传奇』二字。 ###《牛鬼蛇神录》 王小凯在牢房里的各种见闻，以前还是禁书来着？看看还是有所收获。 ###《围城》 之前看过一次，而这次再重新读的时候才有所感触。有时候既然能在方鸿渐身上看到自己的影子，哈哈。总得来说挺幽默，女人吵架套路很固定。婚姻的不幸很多是来自两个家庭的矛盾，大多如此。 ###《檀香刑》 莫言的小说，最初是在知乎的一个回答上看到的行刑的那段描写，让人窒息，所以一定要找来看完这本。值得一看，看来莫言的其他基本小说也不能放过了。 ###《白鹿原》 这本书只看了一半，个人觉得一般。可能是因为我之前看了电影，大致的情节都知道了，所以觉得书稍显太慢，好长篇幅。 ###《约翰·克利斯朵夫》一个大部头小说，我应该是花了好两周的业余时间看完。最初想看这本书据说傅雷翻译得特别好，然而我下单的时候却买的是韩沪麟版本，在我看来也翻译得挺好。这本大部头叙述了一个音乐家一生的故事，前半部分情节更好。特别是描述小孩的友谊和爱情部分很吸引人。不少部分写的是对音乐的理解，只能怪自己音乐素养不够，浅尝辄止罢了。 大部分人在二三十岁上就死去了，因为过了这个年龄，他们只是自己的影子，此后的余生则是在模仿自己中度过，日复一日，更机械，更装腔作势地重复他们在有生之年的所作所为，所思所想，所爱所恨。 所谓英雄，就是干了自己力所能及的事情的人，而常人还做不到这一点。 毛姆系列 据说毛姆文笔优美，我便开始找他的小说看。最开始是看了比较流行的《月亮和六便士》，看完后真是大呼过瘾，震撼。据说月亮是头顶上的理想，六便士是脚下的现实。小说里主人公斯特里克兰德为什么突然放下家庭，完全投入到画画中文中并没有交代清楚，像是命中注定了的，他必须画画，冷酷地完全舍弃其他。一个人完全沉浸在自己的追求中，现实看起来就微不足道了，道德也不会是约束。天才有时候是一种伟大的不幸，比如主人公，而绝大部分人过的是平庸的幸福，比如施特略夫。施特略夫这个觉得有些可爱，而遭遇有些悲惨。 然后看了《在中国的屏风上》，是毛姆游历中国的随笔，记录的比较杂。这本粗略看了看。 而后继续看《刀锋》，感觉和六便士有点点类似，都是讲一个完全追求精神生活的『圣人』，最后在印度看似有所悟。比较喜欢这女主个角色，诚实地知道自己所要并决心取舍，虽然她的小心机使得儿时的女伴完全堕落。 最后粗略看了《毛姆读书心得》，讲了一些读小说的事情，推荐品论了不少小说。 ###《霍乱时期的爱情》 这部小说被拍成了电影 (我还没看)，大家都说写尽了人间的爱情。这本书我非常喜欢，从拿起就不能停了。故事吸引人，并且文笔有些幽默。比如抓鹦鹉的那段，前面花了大篇幅来描述鹦鹉的来历，而后突然鹦鹉就把医生给弄死。还有男主和女主的各种书信，在那样嘈杂热闹的环境下女主一回头突然崩溃。男主作为纯情男孩，突然被夺了童贞，后面又心安理得地穿梭于各个寡妇之间，并倔强、默默地继续爱女主五十年。妙的是，小说里详细的叙述，让我觉得这也并不矛盾，人性以及爱情就是这么复杂，不乏欺骗和隐瞒。婚姻里到处是妥协和不满。 结尾也非常好，让他们在『霍乱的船』上一直飘荡下去。 ###《树上的男爵》 经同事推荐看的。故事和海上钢琴师类似，讲一个公爵小男孩因为一次偶然的被罚，爬上了树！又因为对一个女孩的承诺，他打算一辈子不下树了。一个很好的故事，结尾也来得有想象力。","tags":[]},{"title":"OpenResty 使用总结","date":"2017-05-22T11:43:00.000Z","path":"p/try-on-openresty/","text":"OpenResty最近用 OpenResty 比较多，除了一些业务逻辑的实现也做了 AB 组灰度相关的实现。OpenResty 是在 Nginx 基础上做的扩展，应该算是国人开源项目中很成功的一个。在做的过程中写了不少 Lua 代码，写 Lua 代码的体验就是库好少，语言好简单。 OpenResty lua 编程相关参考 OpenResty 最佳实践 OpenResty Readme 其中 Readme 要看完，大概会有一个全局的了解。最佳实践辅助看看。理解 Nginx 处理的几个阶段： http://www.nginxguts.com/2011/01/phases/ 处理 Response Body在我们的实现中有一步需要给后端返回的结果里面加一段水印 (也就是一段 JS 代码)，这步可以在 body_filter 这个里面做。不过需要注意 body_filter 是按流式方式处理的，需要把各个 buffer 存下来然后拼接起来。而且后端返回的结果可能是 zip 压缩过的，所以需要解压，然后才能做替换或者拼接的操作。 local chunk, eof = ngx.arg[1], ngx.arg[2] local buffered = ngx.ctx.buffered if not buffered then buffered = &#123;&#125; -- XXX we can use table.new here ngx.ctx.buffered = buffered endif chunk ~= &quot;&quot; then buffered[#buffered + 1] = chunk ngx.arg[1] = nil endif eof then local whole = table.concat(buffered) ngx.ctx.buffered = nil -- try to unzip local status, debody = pcall(com.decode, whole) if status then whole = debody end -- try to add or replace response body local js_code = .... whole = whole .. js_code ngx.arg[1] = whole end 最后因为修改了 response body，所以需要修改 header filter 里面的部分：ngx.header.content_length = nilngx.header.content_encoding = nil 容易出现的 bug 尽量使用 local 变量： 具体的解释，我在实践的过程中出现过变量乱窜的情况，结果发现是没有是用 local。 ngx.ctx 比 ngx.var 性能要好很多，但是在执行了 ngx.exec 后在子请求里 ctx 不一样，在我们的项目里大部分是用的是 ngx.var。使用 ngx.var 需要注意的是需要在 Nginx 配置文件里面提前声明。另外ngx.ctx 在使用的时候也有需要注意的地方 不同阶段共享变量 不要使用错误码来做内部跳转，使用 ngx.exec 很方便。 是用推荐的方法来实现 module","tags":[]},{"title":"rubytt 续","date":"2017-04-09T11:43:00.000Z","path":"p/rubytt-cont/","text":"前段时间继续做了 rubytt 这个小项目，遇到一些问题。 我想做一个自动检测未定义变量的功能，发现如果只是做静态分析，是很难做出来的。还有涉及到各种 gem 包的分析，这些工作量较大。可以看出在这个PR里我甚至用上了一些硬编码。 然后我想做一个自动分析代码复杂度的功能，比如某些函数太长，或者逻辑太多之类的。这个我实现起来很快，也是比较简单的遍历语法树，递归统计逻辑操作和幅值操作的总数之类的。不过这些在 rubocop 里面都实现了，其中Cyclomatic complexity可用来衡量代码的复杂度。我仔细看了看 rubocop 的内容，这个项目里面做的检查还挺全的，不过很多都是风格类的检查。在我下一个项目一开始我就引入了 rubocop ，对于保证代码质量还是挺有帮助的。对于之前老的项目，如果不是一开始就保持代码风格和静态分析的检查，后面要追加就非常耗时了，往往大家也没有时间来做各种重构。 rubytt 暂时告一段落，作为一个业余项目还是花费了些时间，造轮子的过程中收获不少。","tags":[]},{"title":"程序员病","date":"2017-01-24T11:43:00.000Z","path":"p/disease-of-programmer/","text":"最近看费曼的书《发现的乐趣》，里面有一段描述非常好玩： 好，弗兰克先生开始实施他的计划了，与此同时，他也得了一种病——『计算机病』。现在每个使用计算机的人都知道这个毛病，那种病非常厉害，会干扰整个工作。这是我们面临的一个严重问题。所谓『计算机病』就是你一『玩』上计算机，就会上瘾。计算机真的非常奇妙，你手上操作着那些 x 转换开关，这样弄得到某个偶数，那样弄得到某个奇数。如果你够聪明，很快你就能在一台机器上做越来越复杂的计算。只不过，没多久，整个系统就瘫痪了。 他对工作不再上心了，也不再管理手下，整个系统运转得很慢很慢。但是，真正麻烦的是，他一直坐在一间办公室里，琢磨怎么让制表机自动打印出反正切值，然后机器就开始打印，成排成排地打印，扑哧，扑哧，扑哧，一边打印一边还自动用积分计算反正切值，整张表都是方正切值计算结果。 其实，这毫无意义，因为我们人手一份反正切表。不过，如果你用过计算机，你就会理解他为什么得这种病。计算机能让你知道自己究竟能做多少事情，这也是一种乐趣。他第一次接触这机器，就染上了这种病，这个可怜的家伙——整个项目都是他发起的，可他却得了这种病。 其实很多程序员都有这种病，可以概括为一句话『沉迷于工具』，计算机也是工具，这位弗兰克先生还未解决眼前的问题时就丢掉了方向。好奇心是程序员必不可少的东西，而如果管不住自己的好奇心就会耽误事。对于非程序员来说，这件事情看起来就是『某个杀猪佬，拿到了一把新刀，他觉得这么刀真他妈锋利，然后磨磨刀，再磨磨刀，反正猪是不会杀的』。 程序员经常会『磨刀』，学习算法，是磨练自己的头脑和思维。学习语言，是为了多拥有一个工具或者也可说是锻炼自己的思维 (不改变自己思维习惯的语言不足以学之？)。学习操作系统的原理和细节，也可以理解为加深对工具的认识和理解。在学校的学习方法大多数从基本原理和经典书籍学起，顺便找一些小项目练练手。在步职业阶段后，从实用的角度，我们是否应该直面问题，带着问题找工具，学用工具，理解工具，这个过程中更可以锻炼自己的能力。从个人体验来说，这种方式优于『先锻炼自己的能力，先学会某个工具，然后再找个问题来解决』。举例来说，其实做一些 ACM 之类的题也挺有乐趣的，但我理解为刷题也是在『磨刀』。更让自己有成就感的是，在工作中碰到一个解决不了的算法问题，通过学习和思考相关的东西解决了，这样的方式理解更深。其实如果是步入职场，很多程序员也没多少时间来广泛学习，带着问题来『磨刀』也是必然且更有效的选择。 再多扯一点，不少程序员有一些类似于强迫症的症状 (在很多情况下这是一个好的特点)。而在计算机这个领域里有太多东西容易沉溺，比如编辑器，编程语言，操作系统，框架， 范式等。这类工具都有可能让程序员走向某个极端，形成『偏见』。我也有类似的体验，只是现在回想起来觉得挺傻缺、傻气的。大多数程序员都不够拥有开阔的心态来面对这些工具，我们会觉得自己的选择是更好的，能解决一切问题的银弹。这副图能说明这个道理。 我现在会注意避免自己陷入这些『疾病』中。比如一个工具，不管是框架也好，语言也好，不要在还没摸清楚门路的时候，花大片时间去学习。而是最好带着一个需要解决的问题，边做边摸索。 发现自己的傻缺，就是成长，对吧！","tags":[{"name":"Books","slug":"Books","permalink":"http://catcoding.me/tags/Books/"}]},{"title":"Ruby 程序的静态分析: rubytt","date":"2016-12-27T11:43:00.000Z","path":"p/rubytt/","text":"rubytt是一个 Ruby 程序的静态分析器，这个项目从 16 年年初一直到年底，断断续续持续了近一年。这里稍微总结一下自己的开发过程。 0. 缘由14 年开始，从我进入 DJI 之后开始接触 Rails 开发。Ruby 之前也接触过，不过都是写一些小脚本之类的东西。我们几乎用 Rails 写各种系统，开发的效率很快。对于经常变动的 Web 开发 rails 还是挺好的。在我经历过的一个对正确性要求很高的项目里，有一次系统出现一个致命的问题。我们 6 个开发人员在小黑屋里面足足找了一个下午。最后却发现不过是一个 type 错误引入的，导致后台任务一直执行错误。后来稍微多想了想，这样的类型错误应该是在开发阶段就及时发现的。 Rails 项目没有测试是不行的，所以我们后续补充了更多单元测试。另外我所使用过的静态语言几乎都能及早避免这样的错误，特别是在使用过 OCaml 这样的强类型语言后，我对类型有了更强的偏好。于是想我能不能做一个自动检测出类似 bug 的工具。据我所知王垠的 rubysonar 可以做类型分析，于是我 checkout 出来看了看代码。Java 代码不是特别复杂，也发现了两个问题并提交了 PR。然后觉得这个东西还是比较好玩，干脆就自己另起一个项目来玩玩。 1. rubytt 的开发首先得给这个坑起一个名字，想了想就 rubytt 吧，其实就是”ruby to type” 的意思吧。然后语言还是用了最近业余使用得比较多的 OCaml。这可能对后期其他开发参与进来不利，不过也无所谓了，业余的项目先依自己的偏好吧。 parser首先面临的问题是 parser。rubysonar 的 parser 也是依靠 Ruby 自己的ripper。主要是 parser 太过繁琐，如果从头开始写整个坑估计是填不完了。所以我也就直接拿来了 rubysonar 的dump_ruby.rb。 dump_ruby 把 ruby 源文件作为输入，输出一个 json 文件作为后端分析器的输入。这里我做了一些改动，rubysonar 里面是起来一个进程，把 dump_ruby 启动起来，用管道的方式一个个 parse 源程序。这样做的目的是避免 ruby 解释器频繁启动，避免整个速度会被拖慢。 我觉得还不如让 dump_ruby 一次接收多个源程序，甚至可以是用 parallel 这个库来做并行。这样的结果是 parsing 的速度确实快了很多，一般大点的项目在 10s 以内可以完成。这样项目的大概流程如下： type annoation我想做自动的类型错误检查，所以需要类型分析。dump_ruby 出来的结果里面是带一些基本类型的，类型分析过程 rubysonar 里面有一个基本过程了。然后对于 Rails 项目来说，我们很多类型都可以在 db/schema.rb 里面可以分析出来，所以如果我把 schema.rb 文件也扫描分析一边，就可以为这些 model 加上不少类型。结果做出来还可以，至少目前可以分析出来很多 rubysonar 没有的类型。运行rubytt -s source_dir -t type -o res把结果输出到 res 目录。这里还有不少东西未做，比如函数的分析还是很复杂，目前做了一个初步。类型错误报出可以做一些了，但是还未来得及实现。因为我突然想到另外一个有趣的东西。 visualize rails project我既在 traverse 整个 AST，可以做很多好玩的事啊。比如把类之间的继承关系找出来，做一个类的继承关系图。于是就有了类似这样的结果 (看大图)： 既然我能解析 schema.rb，也可以把数据模型给展示出来，然后再通过 model 文件里面分析模型之间的关系 (has_one, has_many 等)， 于是就有了这样的结果： 不过做了一些之后我发现这两个 feature 有点鸡肋。特别是第一个，要找出 ruby 程序内部对象之间的继承关系其实很简单，比如我之前写过的一篇文章。第二个模型的关系图还好，不过项目稍微大一些的时候这些图看起来很复杂。 variable bug finder在做完上面两个蛋疼的 feature 之后，碰巧碰到了项目里面另外一个 bug。是因为重构的时候不小心引入了一个 copy &amp; paste bug。类似代码如下： event = (order.status == &#x27;success&#x27;) ? &#x27;success&#x27; : &#x27;fail&#x27;Job.send([&#x27;Worker&#x27;], &#123;&#x27;order_id&#x27; =&gt; order.id, &#x27;event&#x27; =&gt; &#x27;success&#x27;&#125;) 可以看到这个 event 本来应该使用的，结果却因为重构的时候 copy 了代码忘记把&#39;event&#39; =&gt; &#39;success&#39;改成&#39;event&#39; =&gt; event。event 这个变量是未使用的变量，对于编译型语言来说这样的问题是可以在编译的时候发出报警的。因为一个变量未使用必然意味这要么是冗余代码，要么是 bug。那我可否通过 rubytt 给出类似报警？然后我就继续写了这么一个 checker，去检查 ruby 程序中各种没使用的变量。最后还真能找出项目中一些其他的类似问题，比如： result = &#123;&#125;trans = self.transactions.where(..blah...)trans.each do |tran| result[:amount] = trans.amount_cent &lt;------- bug: `trans` is typo of &#x27;tran&#x27; ...blah...end 当然还是能找到函数中未使用的参数等问题。修复的办法是如果确定这些变量是不被使用的，就在前面加_，这样 rubytt 这样的 lint 类检查工具就跳过。后续我也正在做未定义变量的检查。 2. OCaml 的程序发布在做完上面的几个 feature 之后，我觉得可以尝试着把这个项目推广一下给同事们玩玩。如果让从来没接触过 OCaml 的朋友从头开始编译安装会显得很麻烦。所以我就尝试着把 rubytt 合并到 OCaml 的包管理仓库。于是在经过几次和 travis CI 的斗争后，终于发布了rubytt.0.1 。 安装方法如下： gem install parallel ruby-progressbarsudo apt-get install --force-yes ocaml ocaml-native-compilers camlp4-extra opam// brew install opam (MacOS)eval `opam config env`opam install rubytt OCaml 的圈子比较小众，不过其实很多工具还是挺好用的，比如这个 OPAM 包管理器。 3. 其他心得做这个程序这么久，除了好玩还是收获不少。 OOP 和 FP 哪个好？通过这个项目的实践，我好好体会了一把 FP 写稍微大些的程序的感觉。说不上哪个好，我倒认为 type 确实很重要，rubytt 的过程中自动类型推导帮我发现了好多代码错误。编程语言应该让程序员能够精确无误地表达自己，尽量地避免人为引入的错误。 构建测试脚手架，这也是第一份工作带给我的习惯。把每一个 feature 或者 bug 都写测试来覆盖。每次提交的时候都 review 一下测试用例的改动，这样才能不断保持质量。 希望来年能继续保持对这个程序的热情。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Ruby","slug":"Ruby","permalink":"http://catcoding.me/tags/Ruby/"},{"name":"OCaml","slug":"OCaml","permalink":"http://catcoding.me/tags/OCaml/"}]},{"title":"读《饥饿的盛世》","date":"2016-12-11T11:43:00.000Z","path":"p/qianlong-history/","text":"最近又读了本张宏杰的书《饥饿的盛势》。张宏杰的书今年看了好几本，讲述历史都挺生动，特别是对人物内心的剖析很到位。很多时候作者是站在历史人物的角度去分析，书里所展现的历史人物特别鲜活。很多历史人物都被脸谱化或者自带几个标签，这人不是好的则是坏的。可是人都是复杂的、多面的，真实的历史事件又会有各种偶然因素。这本书看完后，对乾隆印象具体了很多。乾隆盛世的背后，隐藏着这位皇帝仁慈和残暴、宽容和计较。乾隆作为为数不多的自律而有头脑的皇帝，几乎是创记录地维持帝国专制统治近 60 年。 雍正仓促去世，乾隆在 25 岁的盛年继位，继位过程光明正大，水到渠成。上任之后就改变了帝国的航向。乾隆把被雍正折腾得要死的各种皇室宗族放出，给予产业和爵位，一下子扫除皇室王宫对雍正乾隆一族的怨恨。为了争取官僚集团对自己的效忠，他仿效祖父，宽大待下，从实际角度考虑问题，解决困难。对农民也采取了仁政，停捐纳，重视农业，赢取农民的爱戴。乾隆精通驭臣之术，虽然初征的时候执行仁政，他对于权利的集中却丝毫没有松懈过，时刻警惕名称、后宫、宦官等一切可能干扰权利的因素。 张廷玉是雍正时的老臣，对大清可谓鞠躬尽瘁，雍正点名其可配太庙。而乾隆因为各种鸡毛蒜皮的小事和张廷玉斗，最后把人弄得晚节不保。这章读起来真的是好生动啊，这个宇宙第一的皇帝心眼小得夸张！ 原配皇后富察氏的两个皇子的相继去世、富察氏后来也病死，这对乾隆影响很大。皇帝权利再大也抵不过生老病死。终于，乾隆 13 年时，借皇后富察氏去世，乾隆刮起政坛风暴，重回雍正时期刚猛、狠戾、阴险的政治风格。无数人被无辜定罪，包括自己的儿子们。原配妻子的死是乾隆一生的怨念。 在 200 多年前，乾隆为了留给后人一个『安全』的帝国，在内蒙古做了人类历史上一次惨绝人寰的灭族！纯朴的牧民们、归降的地人们一律被杀。 从驯身到驯心，集权统治的最后一步是驯心，就是所谓的『大清精神文明建设』。从书的描述看来，乾隆缔造了中国历史上最严酷的文字狱。无数书籍被烧，文人不敢写字发声。中国的帝王所要的向来是服服帖帖、老老实实的子民，这些子民除了基本的生存权，就不应该有其他诉求了。朱元璋洪武年间甚至规定了子民怎么穿鞋、怎么着衣。乾隆对于越级上访一律惩罚，民间的异说也是不能放任的，疯子在朱元璋手下还能逃脱，乾隆可是能杀则杀。 “千古第一全人”，乾隆年老后一直喜欢把自己和历史上的君王们比较，对自己所缔造的盛世甚为满意。甚至做到了历史上少有的权利的平稳交接，把自己的皇冠带在了嘉庆皇帝头上。不过晚年还是不得安稳，花了三年直到自己死时白莲教都没被压下。乾隆的 60 年统治中，中国的人口和版图都达到了峰值，而这又有什么用呢。自己培养出来的嘉庆守旧胆小，西方列强经过工业革命的洗礼已经远远超越大清。二十世纪初开始大清已经摇摇欲坠。甚至乾隆的坟墓都被炸开，真的是『千古第一全人』的巨大讽刺。","tags":[{"name":"Books","slug":"Books","permalink":"http://catcoding.me/tags/Books/"}]},{"title":"Nginx 限流","date":"2016-11-30T11:43:00.000Z","path":"p/nginx-traffic-limit/","text":"Nginx 限流可以通过几种方式实现： 1. Nginx 自带的流量控制模块ngx_http_limit_req 根据特定的 key(通常为 IP) 控制访问频率 ngx_http_limit_req_module 控制连接数 通过修改 Nginx 的配置文件，然后 reload。这种方式配置比较简单，然而 reload 对于当前访问量比较大的服务器开销也有一些。 根据新浪的经验，每一次的 reload 对 Nginx 的 QPS 与耗时的影响通常会持续 8~10s，考虑到一次扩容会有频繁的变更，这对在线业务来说是不堪承受之重。因此，要避免对 Nginx 进行 reload。 2. 使用 lua-resty-limit-traffic 流量控制代码和文档。这个库分为 limit_conn 和 limit_req 模块，limit_req 限制某个 ip 或者 server 的访问频率，limit_conn 限制连接数。lua-resty-limit-traffic 的原理是使用 Nginx 的 shared_dict，建立一个 hashtable，根据目前连接数或者访问请求记录相关信息。对于每一个 Nginx 请求都有 一系列执行阶段，每个阶段可以增加 hook，access_by_lua 是处理前调用的 hook, log_by_lua 是处理完成后调用的 hook。进入的时候通过 ip 作为 key 找到 share_dict 里面的连接数，增加 1。处理完之后找到连接数， 减去 1。 通俗的理解就是顾客进入试衣间前持一个牌子，出来后归还牌子。当前的正在使用的牌子数目可以配置，以达到限流目的。 依据系统状态动态改变限流的配置，可以考虑两种方案： limit_conn 和 limit_delay 存放在 Redis 内，在 access_by_lua_block 的部分去取出当前限制，这个方案的弊端在于对每个 request 多了一次 redis 请求。 limit_conn 存放在 Nginx 的 shared_dict 内，通过 Nginx 的配置增加一个 location，专门用来请求来修改其值，任何一个 Nginx worker 修改成功后，其他 worker 都可见。 3. 使用 nginx-upsync-modulenginx-upsync-module是新浪的开源库，也是依赖 openresty 的。 这套工具可以修改 backend 的各种属性，weight, max_fails 等。为了避免 reload，可以使用 Consul 或者 Etcd 进行动态配置。 其他为了做一些自动限流，可以考虑分析 nginx 日志，或者系统负载信息。系统负载分析工具，ruby gem 包 usagewatch 可以获取系统目前的 CPU 使用率，Memory 使用率，系统 load 等相关信息，日志分析工具 https://github.com/allinurl/goaccess，使用 goaccess，可以实时分析 rails app 日志。","tags":[]},{"title":"菊与刀","date":"2016-08-09T11:43:00.000Z","path":"p/dao-yu-ju/","text":"前些天在家偶然翻到一部日本电影《黄昏的清兵卫》，看完后觉得非常符合个人口味。顺着同类型的电影又看了《隐剑鬼爪》。两部电影都是由山田洋次导演，主要故事都是围绕德川幕府末期的武士展开。剧情其实有些类似，一个武士，一个柔弱女主，甚至是同一个仆从，在“义务”和“义理”的冲突下来一场厮杀。武士爱着女主，却因为种种“理”而不能靠近。突出武士阶层的隐忍和不可避免的没落。 看完电影后，又顺着看了多人推荐的《菊与刀》。二战后美国急需了解日本，特别是日本人民的习俗和心理特征，因为日本在西方人看来太过特别，他们在战争中所体现的凶残程度也是前所未有的。《菊与刀》正是在这样的历史背景下由本尼迪克所写。据说作者本人并没有去过日本，而是通过书籍和调研来完成。这本书也许有的方面写得有所夸张。 看完这本书后，对上面两部电影有了更深些的理解。日本崇尚秩序，上级对下级的命令是无法抗拒的。这也解释了为什么二战时日本士兵凶暴残忍得像禽兽一般，而当天皇下诏投降书后，日本人绝大部分立马放弃抵抗，站在街头服服贴贴迎接盟军。在《隐剑鬼爪》中，藩府上级要求片桐出卖朋友交出叛党名单，片桐出于“义”而拒绝。但藩府换成“命令”的时候，他还是会去执行。“义务”和“义理”发生冲突的题材是很多日本故事和电影的基础。剧中人为履行义务忍受了一切，无论不幸、遗弃、疾病还是死亡，都未能使他们偏离。他们认为。所谓强者恰恰在于敢于抛弃个人幸福而去履行义务。他们认为，“性格的坚强不是表现为反抗，而是表现为顺从”，“真正的尊严在于各安其分，不卑不亢，自王子以至农夫，皆可以此自许”。 总的来说，日本呈现出了复杂的矛盾： 日本人好斗而又温和；黩武而又爱美；自尊自傲而又彬彬有礼； 顽固而又善变；驯服而又不愿 受人摆布；忠心而又易于叛变； 勇敢而又怯懦；保守而又欢迎革新。 他们十分介意别人对自己行为的看法，但当别人对其劣迹毫无所知时，又怡然自得。 关于个人欲望：日本人并不谴责满足私欲。他们不是清教徒。他们认为享乐是件好事，是值得培养的。他们追求享乐，尊重享乐，但享乐必须恰如其分，不能妨碍人生重大事务。 日本是比较讲究专注精神修炼，在他们看来，培养“一心”和“无我”对任何事业都是有好处的。 这本书算是我看过的翻译书籍里面很流畅的一本，甚至基本看不出来是翻译的。这和《自私的基因》比起来好多了，后者的这个版本基本没法看。 两部电影中，相对来说我更喜欢《隐剑鬼爪》。 －－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－ 最后，两部电影的女主角都挺好，宫泽理惠和松隆子。","tags":[]},{"title":"Add syntax check for Capistrano","date":"2016-07-22T11:43:00.000Z","path":"p/capistrano-syntax-check-for-rails/","text":"In an normal release, Rails app’s unit testing will avoid most errors. But for the urgent code publishing, we have got several time of typo error. Code syntax error may cause server crash for a little while(Passenger web server and we using ./tmp/restart.txt to restart). We use Capistrano to publish code, so I plan to add a syntax checking before publishing code.The method is writing a task to bundle exec rails runner, this will report most ruby syntax error(except the undef variables in some functions, runner will load .rb files). namespace :app do desc &quot;check all the ruby code&quot; task :check =&gt; :environment do res = `RAILS_ENV=#&#123;Rails.env&#125; bundle exec rails runner &quot;&quot; 2&gt;&amp;1` raise res if res.size &gt; 0 endend then add this in the deploy.rb (Capistrano 3.1): namespace :deploy do task :run_code_check do on roles(:all) do within release_path do with rails_env: fetch(:rails_env) do execute :rake, &#x27;app:check&#x27; end end end end before &quot;deploy:updated&quot;, &quot;deploy:run_code_check&quot;end This is not a tricky part, but please pay attention to the line: res = `RAILS_ENV=#&#123;Rails.env&#125; bundle exec rails runner &quot;&quot; 2&gt;&amp;1` This line of code cost me some time, I forget the 2&gt;&amp;1. so res will just got the stdout, not the stderr output, which causes the exception is not raised, and Capistrano flow is not stopped.","tags":[{"name":"Rails","slug":"Rails","permalink":"http://catcoding.me/tags/Rails/"}]},{"title":"刷刷算法和 OJ","date":"2016-07-08T11:43:00.000Z","path":"p/fun-on-hackerrank/","text":"最近我们部门内部组成了一个算法读书小组，每周大家轮流分享自己的学习心得。为了方便学习我还写了一个小的 内部 OJ，看起来还挺还好玩的。界面风格学习了青岛大学的 OJ，后台使用 Docker 来做沙盒跑测试输出结果。顺便学习了实际使用 Docker。唯一麻烦点的是选了一个阿里的主机，最开始更新起来比较慢。还是用亚马逊的比较好。讨论形式还在摸索，我们现在每周选择一两个主题，会有两个分享人主讲，另外在 OJ 上弄几道题目大家做。总的来说还是可以提高一些东西，算法方面的知识，比如分享、表达的技巧。 等 OJ 完善得差不多了再分享出来。 另外业务时间也在 HackerRank 上做了一些题目，刚开始是为了熟悉 OCaml，专门用 OCaml 写FP 方面的题目。 最近两周也顺便参加了一些比赛。这些比赛有的是和一些公司合办的，有的是各个主题的。比如有周赛，从周一到周五每天一个问题。个人觉得这个比较适合已经工作了的程序员，因为可以在空闲时间慢慢思考。等比赛结束之后也可以看其他人的解法和代码。我最近写得比较多，又找到了在学校时写程序的乐趣了。而且熟悉了之后用 OCaml 实现算法还是挺快的。我的一些代码放在了这里，感兴趣的可以参考。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"}]},{"title":"Tiny Interpreters","date":"2015-09-29T11:43:00.000Z","path":"p/programming-language-and-interpreters/","text":"After reading the first simple Scheme interpreter of bootstrap-scheme, I have some interests on studying various programming languages and interpreters. It’s really fun to implement tiny programming languages. For learning a new programming language, a simple Scheme interpreter is a good starting project. Because in this small project we need to know some core aspects of a new programming language, including the basic I/O operations, abstraction methods for expression representation, recursive for eval, and unit testing. Also mini Scheme is so easy for parsing, we can focus on data representation and eval. Two programming language are best suited to implementing interpreter, The first one is Scheme, which used in many famous PL books, such as EOPL, SICP, etc. Another good language in OCaml,which is a sweet spot in language design space: strict, type system and type-inferer, functional. It’s very convenient to implement a parser, and also because of the pattern matching and algebraic data types, it is nature for building AST and traverse on it. For your references, I have these small projects during my studying of languages(to be continued): eopl, hundreds of interpreters written in Scheme, trying to solve most of the EOPL exercises. rust-scm, which is a Scheme interpreter written in Rust GoScheme, yet another Scheme interpreter written in Go ocaml-scheme, yet another Scheme interpreter written in OCaml toy-compilers, still they are interpreters, but not compilers, with js_of_ocaml we can compile OCaml code to Javascript, then run it on web browsers!","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"}]},{"title":"最近读的一些杂书","date":"2015-08-09T11:43:00.000Z","path":"p/reading-notes/","text":"最近看了几本书，大多都是觉得有些意思就从亚马逊上买了。自从我的 Kindle 坏了之后，我就基本只买纸质书了。虽然纸质书携带不够方便，看起来更够味。 别逗了，费曼先生！(5*)这是我最推荐的一本，断断续续看了两遍。这本书虽然是翻译的，但是质量很够水准，费曼聪明的坏教授形象跃然纸上。费曼作为物理学家也挺逗的，从小喜欢发明各种东西、恶作剧，折腾电子器件，好玩。青年时期开始折腾物理，在暑假期间顺便当了一段时间『化学家』。后面又对破解密码锁、画画、打鼓、学习外语产生浓厚兴趣，并极其投入。贯穿其中最让人敬佩的是费曼的好奇心好韧性。整本书都是在用一种诙谐平叙事写法，不过突然怀念自己的妻子那段特别感人，他的妻子去世那段时间正是在研发原子弹期间： 当我返回的时候他们都来问我发生了什么事儿， “她死了，工作进行的怎么样？” 他们立刻明白了，我不想为此终日哀伤。我显然要做些安慰心理的事：现实是重要的。我一定要理解，从生理学上说，阿琳究竟是怎么了； 我没哭，直到几个月之后。当时我在橡树岭，我正走过一家百货商店的橱窗，里头挂着女士服装，我想阿琳或许喜欢其中一件。此时此刻，我不盛悲戚。 他谢绝芝加哥大学高薪聘请的那段挺逗： “我将有能力做我一直想做的事 ——- 找个迷人的情妇，为她买一座漂亮的房子，给她买好东西……用你们给的这份薪水，我必定真的会这么做，我知道那会是什么结果，我会为她操心，挂念她在干什么，我们会吵架。我回家的时候，又会如何如何。这些闹心的事儿，会让我寝食不安，会让我心情不快。我搞物理也搞不好了，一切都将是一团糟！……因此，我已经决定，我不能接受你们的好意。” 费曼的理念是一个东西都可以用更通俗的说法来解释，但必须是建立的自己理解的基础上。 在巴西的教学过程中，费曼对填鸭式教学进行了思考和批判，里面所描述的场景和国内的教学何其相似！学生只是背诵，根本不理解那些科学概念背后的生动的东西。 最后，我认为判断人是否老了的一个标准就是其是否还对新鲜东西保持好奇心，有好奇心的人竟然这么好玩！ 鱼羊野史 (4*)一直比较喜欢高晓松，他的一些老歌都挺好听的。在深圳的时候听过一次他的演唱会，观众大多都是一些 30 岁以上的中年人。高晓松家庭显赫，一直都随性游荡，涉猎广泛，吹起牛来根本停不下来。有一段时间我也会在上班路上听他的小松奇谈，东南西北特别能侃。小松奇谈里面我最喜欢的故事是其二叔的爱情故事《文革时期的何以笙箫默》，是真是假无从考证，不过这还真是个能拍成电影的好故事。偶然在网上看到高晓松的这三本书，空闲时间把这些都看完了。总得来说不如听小松奇谈来劲，而且很多篇都是比较八卦，比如李宇春、齐秦生日之类的。这些还活着的明星们八卦怎么说也不能算作历史吧，即使是野史。另外就是三本的内容竟然有不少是重合的！ 李光耀观天下 (4*)中国的改革开放从新加坡借鉴了，中国相关的篇章还挺直接的。对邓小平和老毛的描述比较多，其他人就呵呵了。 成大事者不纠结 (3*）逻辑思维的公众号更新很勤快，内容也不错。不过这本书倒是没什么太多内容，李鸿章和曾国藩的章节都是在逻辑思维里面讲过的。更让我不爽的是书的封装，居然带了一打微信推广号。 从 0 到 1 (3*)这本书挺有名的，不过看完后并没产生多少共鸣。可能是因为我现在对创业这个词有些抵触，创业现在动不动就是改变人类、情怀。这个词被玩坏了。在互联网这个行业，创业看起来有点类似大跃进。大家都吹牛，比如前段时间被扒皮的云视链就属于吹牛吹破了的。真正从 0 到 1 创造出新事物的公司太少。","tags":[{"name":"Life|Notes","slug":"Life-Notes","permalink":"http://catcoding.me/tags/Life-Notes/"}]},{"title":"惰性求值和流","date":"2015-04-26T11:43:00.000Z","path":"p/lazy-eval-and-stream/","text":"什么是惰性求值惰性在函数式编程语言中很常见，他的通俗解释就是一个变量或者表达式，不到必要的时候不会被 eval。比如函数在传递参数的时候，参数的值可以不确定。 这种方式叫做 call-by-name，首先很明显这可能会造成一部分 performance 差异，如果一个表达式没有用到，那么计算出其结果是毫无意义的。而惰性求值是 memoized 的 call-by-name，叫做 call-by-need。从技术实现上来说，一个表达式在计算其结果之前其状态是 Deferred 或者 Delayed 的，在计算之后将其结果存储下来并修改状态为 Value，之后再取就没有必要重新去计算。用一些 OCaml 代码来说明： # let v = lazy (print_string &quot;performing lazy computation\\n&quot;; sqrt 16.);;val v : float lazy_t = &lt;lazy&gt;# Lazy.force v;;performing lazy computation- : float = 4.# Lazy.force v;; - : float = 4. 关键字 lazy 表示延迟计算这个表达式， Lazy.force 表示求值。可以看到第一次 force 的时候会打印出 performing…信息，后面的 force 就直接返回了 value。 为了更好的理解这个概念，我们可以实现一把 Lazy。首先定义一个 lazy_state: # type &#x27;a lazy_state =| Delayed of (unit -&gt; &#x27;a)| Value of &#x27;a| Exn of exn;;# let create_lazy f = ref (Delayed f);; 这个 lazy_state 有三种状态，第一种就是 dealyed，’a 表示任何类型的 value。Value 表示被 eval 过了，并且保存下来他的值。Exn 表示错误或者异常的状态。那么 create_lazy 就表示创建一个 lazy_expression，这里的参数 f 可以是任何类型的函数 (函数的参数类型和返回类型都可以不确定)，ref 是 OCaml 里面的类似指针的概念。 上面例子就可以这样来写了： # let v = create_lazy (print_string &quot;performing lazy computation\\n&quot;; sqrt 16.);; 然后实现核心的 force:# let force v = match !v with | Value x -&gt; x (* 如果已经求值就直接返回 value *) | Exn e -&gt; raise e (* 如果发生错误，raise 错误*) | Delayed f -&gt; try let x = f () in (* 如果还未求值，eval 保存下来的 f *) v := Value x; (* 并把结果保存下来 *) x with exn -&gt; v := Exn exn; (* 如果发生错误，保存下来 *) raise exn ;; 这里的！v 就是取这个引用里面的值 (类比 C 语言里面的*pointer)。然后 pattern match 这个 lazy_state，注释里面写了每一行的操作。这里的代码很简短，最核心的意思是我们能把一个函数或者代码块保存下来，在真正需要的时候去运行这个代码块。在函数式编程里面这很常见，函数和变量一样可以自由传递。虽然看起来好不起眼，不过这会给编程带来一些深刻的影响。 Memoization通过上面对 laziness 的解释，我们可以发现这个概念的核心思想类似算法设计里面的 memoization，这样在计算过程中把重复计算的过程省略掉。比如这段代码有些好玩： let memoize f = let table = Hashtbl.Poly.create () in (fun x -&gt; match Hashtbl.find table x with | Some y -&gt; y | None -&gt; let y = f x in Hashtbl.add_exn table ~key:x ~data:y; y );; 这个函数接收任何类型的函数 f，他会像一个 wrapper 一样给你包装一下：给你一个 table 用来存储这个函数的结果，键值是你的参数 x，如果发现参数是 x 的结果还没计算的时候，把结果算出来并存储在 table 里面。这里我们又能看到函数式编程带来的好处，f 是任何类型的函数 (这里暂且还没处理递归)，这类问题在算法设计里面挺多的比如 fibnacci，edit-distance。 在递归情况下如何处理可以看看这，这是我看过的排版最好的技术类博客Type OCaml:Recursive Memoize &amp; Untying the Recursive Knot Stream有了 lazy 的概念之后，我们可以在编程里面表示一些看起来很数学的概念，比如一个表示所有整数的流： type &#x27;a stream_t = Nil | Cons of &#x27;a * (unit -&gt; &#x27;a stream_t)let rec from i = Cons (i, fun() -&gt; from (i+1))let hd = function | Nil -&gt; failwith &quot;hd&quot; | Cons (v, _) -&gt; vlet tl = function | Nil -&gt; failwith &quot;tl&quot; | Cons (_, g) -&gt; g()let rec take n = function | Nil -&gt; [] | Cons (_, _) when n = 0 -&gt; [] | Cons (hd, g) -&gt; hd::take (n-1) (g()) Cons 是把两个元素组成链表，递归函数 from 做的事情就是把 i 和一个匿名函数 fun() -&gt; from(i+1) 链起来，当然匿名函数又在做类似的事情。那么 (from 1) 就可以表示从 1 开始的所有整数了，hd 是取一个流的头部，tl 是取流的尾部 (除头部剩下的)，take 是从一个流里面取前 n 个元素。这可是非常的方便，还有更方便的： let rec filter f = function | Nil -&gt; Nil | Cons (hd, g) -&gt; if f hd then Cons (hd, fun() -&gt; filter f (g())) else filter f (g()) 我们虽然只知道有这么一个流，但还是可以加一个筛选条件给他，filter 函数接收筛选函数 f 和一个流，返回的结果就是被筛选后的流！ (* delete multiples of p from a stream *)let sift p = filter (fun n -&gt; n mod p &lt;&gt; 0)(* sieve of Eratosthenes *)let rec sieve = function | Nil -&gt; Nil | Cons (p, g) -&gt; let next = sift p (g()) in Cons (p, fun () -&gt; sieve next)(* primes *)let primes = sieve (from 2) 所有素数就可以这么来写了，有了这个流之后要取多少就取多少。 其他Haskell 是纯函数式纯 Lazy 的实现，OCaml 有 imperative 的部分，而且运行时不是 Lazy 的。相对来说我更喜欢 OCaml 的语法以及设计原则，FP 有其好处，但 imperative programming 也有其益处。Lazy 有其好处，但还是在用户明确需要的时候能提供就好。 部分代码引用Real World OCaml","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"OCaml","slug":"OCaml","permalink":"http://catcoding.me/tags/OCaml/"},{"name":"PL","slug":"PL","permalink":"http://catcoding.me/tags/PL/"}]},{"title":"Types and Programming Languages (2)","date":"2015-03-07T11:43:00.000Z","path":"p/types-and-programming-languages-2/","text":"ReferencesSide effectIn particular, besides just yielding results, evaluation of terms in these languages may assign to mutable variables (reference cells, arrays, mutable record fields, etc.), perform input and output to files, displays, or network connections, make non-local transfers of control via exceptions, jumps, or continuations, engage in inter-process synchronization and communication, and so on. In the literature on programming languages, such “side effects” of computation are more generally referred to as computational effects. 引用指向的对象可以是基本类型、组合类型，甚至是函数，把指向函数的 ref 放进对应的 record，就变成一个简单的 object，OOP 的原型就出来了。 update = λa:NatArray. λm:Nat. λv:Nat. a := (λn:Nat. if equal m n then v else (!a) n); 通过这个习题的例子可以看出 ref 引进的副作用。 Garbage CollectionGC or notThis is not just a question of taste in language design: it is extremely difficult to achieve type safety in the presence of an explicit deallocation operation. The reason for this is the familiar dangling reference problem: we allocate a cell holding a number, save a reference to it in some data structure, use it for a while, then deallocate it and allocate a new cell holding a boolean, possibly reusing the same storage. Now we can have two names for the same storage cell—one with type Ref Nat and the other with type Ref Bool. PointerPointer arithmetic is occasionally very useful (especially for implementing low-level components of run-time systems, such as garbage collectors), it cannot be tracked by most type systems: knowing that location n in the store contains a Float doesn’t tell us anything useful about the type of location n + 4. In C, pointer arithmetic is a notorious source of type safety violations. Store typings: 引入引用后类型系统需要处理 Cyclic reference structures，比如 double linked list。Store typings 就是一个 locations 到 typings 的映射。 实现 fullref： 引用部分的实现非常简单， | TmRef(fi,t1) -&gt; TyRef(typeof ctx t1)| TmLoc(fi,l) -&gt; error fi &quot;locations are not supposed to occur in source programs!&quot;| TmDeref(fi,t1) -&gt; (match simplifyty ctx (typeof ctx t1) with TyRef(tyT1) -&gt; tyT1 | TyBot -&gt; TyBot | TySource(tyT1) -&gt; tyT1 | _ -&gt; error fi &quot;argument of ! is not a Ref or Source&quot;)","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"OCaml","slug":"OCaml","permalink":"http://catcoding.me/tags/OCaml/"},{"name":"PL","slug":"PL","permalink":"http://catcoding.me/tags/PL/"}]},{"title":"Types and Programming Languages (3)","date":"2015-03-07T11:43:00.000Z","path":"p/types-and-programming-languages-3/","text":"Subtypingsubtyping 解决的问题是多态，OO 的一个基本要素。 we say that S is a subtype of T, written S &lt;: T, to mean that any term of type S can safely be used in a context where a term of type T is expected. This view of subtyping is often called the principle of safe substitution. 这章只是以 record 来作为例子说明，直白的所一个类型 S 是另外一个类型的 T 的子类型，意思是任何使用 T 的 context，我们可以安全的使用 S。对于 record 类型来说，field 数量多的是 field 数量少的子类型，因为这样任何从 T 要取得的 field 都可以从子类型里面取到。 对于函数类型来说，如果S1-&gt;S2, T1-&gt;T2, S1 是 T1 的子类型，S2 是 T2 的子类行，那么S1-&gt;S2是T1-&gt;T2的子类型。 引入 Top 类型，是所有类型的父类，对应很多编程语言里面的 Object(OOP 里面常见的伎俩)，Go 里面我就这样定义： type Object interface&#123;&#125; 引入 Bottom 类型似乎就没什么大用处了，还增加了 typecheker 的复杂度。 Ascription and Casting类型的强制转换，分为 up-cast 和 down-cast。up-cast 对于类型检查来说要简单一些，比如类型Animal -&gt; Dog, Animal -&gt; Cat，由Cat到Animal的类型转换为 up-cast。在很多语言里面是当做一种抽象方法。 down-cast 要复杂一些，而且也可能会导致类型系统的不安全，比如： f = λ(x:Top) (x as &#123;a:Nat&#125;).a; 这个函数接收任何类型的参数，但是隐含一个假设，必须是一个有成员变量为数字类型的 a，如果传递一个错误的参数 typechecker 也不报错，但运行的时候就会有错误了。所以含有 down-cast 的类型系统应该遵循： trust, but verify，编译的时候不报错，但是留着运行的时候检查。为了避免 down-cast 引起的复杂问题，ML 等语言选择的是down-cast with type tags。 channels: The key observation is that, from the point of view of typing, a communication channel behaves exactly like a reference cell: it can be used for both reading and writing, and, since it is difficult to determine statically which reads correspond to which writes, the only simple way to ensure type safety is to require that all the values passed along the channel must belong to the same type. subtyping 的引入导致分支多的情况下类型检查麻烦，因此引入了 Join 和 Meet 的概念，实现可参考代码里面的： let rec join ctx tyS tyT = if subtype ctx tyS tyT then tyT else if subtype ctx tyT tyS then tyS else let tyS = simplifyty ctx tyS in let tyT = simplifyty ctx tyT in match (tyS,tyT) with (TyArr(tyS1,tyS2),TyArr(tyT1,tyT2)) -&gt; TyArr(meet ctx tyS1 tyT1, join ctx tyS2 tyT2) | _ -&gt; TyTopand meet ctx tyS tyT = ....... Case Study: Imperative Objects不考虑实现效率和语法简洁的条件下，目前为止学到的语言特性已经足够来模拟实现 OOP。最简单的例子就是一个 counter: c = let x = ref 1 in &#123;get = λ_:Unit. !x, inc = λ_:Unit. x:=succ(!x)&#125;; OOP 作为一种抽象手段，可以让通过接口来隐藏实现，客户端的代码只通过同一个接口才操作各种子类的对象。这里的例子一个子类只是比父类多接口而已。 newResetCounter = λ_:Unit. let x = ref 1 in &#123;get = λ_:Unit. !x, inc = λ_:Unit. x:=succ(!x), reset = λ_:Unit. x:=1&#125;; self 的简单是现实需要动态找到对应的 method，更高效的实现当然是对象创建好后 method table 建好。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"OCaml","slug":"OCaml","permalink":"http://catcoding.me/tags/OCaml/"},{"name":"PL","slug":"PL","permalink":"http://catcoding.me/tags/PL/"}]},{"title":"Types and Programming Languages (1)","date":"2015-03-01T11:43:00.000Z","path":"p/types-and-programming-languages/","text":"最近掉进另外一个 PL 的坑里面，就是想读一下这本书，顺便继续熟悉一下 Ocaml。下面的记录是阅读过程中的一些摘录和理解。 1-2 章是数学预备部分，理论部分有些地方比较难懂，主要是一些数学符号看久了眼花。解释器的实现大多只用看 syntax.ml 和 core.ml，就是语法和具体 eval，typeof 函数。 Untyped Systemsarith 是一个无类型的解释器，是后面所有章节的基础。printtm_Term 用了 Format 模块来格式化打印。 The Untyped Lambda-Calculus浅显易懂的 Lambda-Calculus 解释，同时列举了一些 lambda calculus 扩展其他语言部分的例子。 An ML Implementation of the Lambda-Calculusshifting 和 substitution 的实现挺难看懂的，本质上是把 context 里面的变量用 index 来替换，处理变量查找的一种实现而已。eval 部分是非常地简洁，我觉得 ML 系的语法看起来比 Scheme 都舒服紧凑。 Just because you’ve implemented something doesn’t mean you understand it.​ —Brian Cantwell Smith 说起来全是泪，用这种函数式的编程语言来解释自己确实比较简单，但现实往往不是这样。语言能比较容易地实现自己至少可以表明语言的内核挺小，一个语言能实现 bootstrap 是成熟的一个表现。Rust 的实现最初是用 Ocaml 写的，然后编译出一个 Rust 的编译器，然后用上一版本的 Rust 再重新实现 Rust 编译器。 Typed Arithmetic Expressionstyarith 是最简单的带类型的解释器，有 bool 和 Nat 类型。 Progress: A well-typed term is not stuck (either it is a value or it can take a step according to the evaluation rules).Preservation: If a well-typed term takes a step of evaluation, then the resulting term is also well typed These properties together tell us that a well-typed term can never reach a stuck state during evaluation. Safety = Progress + Preservation Simply Typed Lambda-Calculus In general, languages in which type annotations in terms are used to help guide the typechecker are called explicitly typed. Languages in which we ask the typechecker to infer or reconstruct this information are called implicitly typed. Well-typed programs cannot “go wrong.” —Robin Milner (1978) An ML Implementation of Simple Typessimplebool 是一个只有 bool 类型的解释器，但是加上了函数。typeof 挺简单，主要是函数这里注意处理形参和实参： | TmAbs(fi,x,tyT1,t2) -&gt; let ctx&#x27; = addbinding ctx x (VarBind(tyT1)) in let tyT2 = typeof ctx&#x27; t2 in TyArr(tyT1, tyT2)| TmApp(fi,t1,t2) -&gt; let tyT1 = typeof ctx t1 in let tyT2 = typeof ctx t2 in (match tyT1 with TyArr(tyT11, tyT12) -&gt; if (=) tyT2 tyT11 then tyT12 else error fi &quot;parameter type mismatch&quot; | _ -&gt; error fi &quot;arrow type expected&quot;) if 的判断部分必须为 bool，而且两个分支必须为同一类型： | TmIf(fi,t1,t2,t3) -&gt; if (=) (typeof ctx t1) TyBool then let tyT2 = typeof ctx t2 in if (=) tyT2 (typeof ctx t3) then tyT2 else error fi &quot;arms of conditional have different types&quot; else error fi &quot;guard of conditional not a boolean&quot; Simple Extensions在上一章的基础上，加上各种 Drived Form。 Sequencing: 是多个表达式串，这在有副作用的语言里面很常见。另外也可以把 t1;t2 理解为 (λx:Unit.t2) t1。 Wildcards: 如何翻译好，意思就是无用形参可以不指定名字。 Ascription 是指类型缩写 (或者昵名)，C++ 里面的 typedef，和 Rust 里面的 usize as U 都是。这个的好处在于文档和接口更清晰，如果函数的参数可以是函数，类型加进以后语法看起来就比较繁琐了，用类型缩写更清晰。typechecker 的时候当然需要展开来进行。ascription 和 casting 也有一定关系。 增加各种简单的基础类型，比如 String，还有 Pairs，Tuple，Record， Sum，Enum，List。支持一种类型除了一个新类型名字外，其 evaluation rules 和 type rules 也要明确。这里的 datatypes 是按照 Ocaml 的语法来说明的。 因为加上了好多种类型，fullsimple 这个解释器复杂多了。 Type Dynamic Even in statically typed languages, there is often the need to deal with data whose type cannot be determined at compile time. This occurs in particular when the lifetime of the data spans multiple machines or many runs of the compiler—when, for example, the data is stored in an external file system or database, or communicated across a network. To handle such situations safely, many languages offer facilities for inspecting the types of values at run time. General Recursiontyped lambda-calculus 加上 fix combinator 就是一门极小的但是是 full abstraction 的语言。Ocaml 里面的 letrec 可以用来定义递归函数。fix point 的概念需要继续理解。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"OCaml","slug":"OCaml","permalink":"http://catcoding.me/tags/OCaml/"},{"name":"PL","slug":"PL","permalink":"http://catcoding.me/tags/PL/"}]},{"title":"Understanding Computation","date":"2015-02-10T11:43:00.000Z","path":"p/understanding-computation/","text":"前些天花了一些时间读这本书《计算的本质：深入剖析程序和计算机》。总的来说这本书非常不错。虽然讲述的是一些看似理论的东西，里面有不少短小的 Ruby 程序，读起来还是非常有趣的。回想当年大学的时候有一门课程叫做形式语言与自动机，当时觉得这门课真是太没劲了。理论的东西终究需要一些实践才能掌握，早早读到这样的书就好了。 首先第一部分介绍了一些基本 Ruby 语法，十来页的介绍就够了。Ruby 的语法真的是非常直观，人性化的。两年前我被 Ruby 吸引，现在我每天大部分时间都敲着 Ruby 代码，用 Ruby 很省事！对 Ruby 来说数据也是程序是很常见的，这本书使用 Ruby 来做示例是很好的选择。 什么是程序？这是一个可以从各个角度深入的问题，程序是程序员表达自己脑海中的思想的形式。我们需要从编程语言开始，语言的语法和语义完整地定义了一门编程语言。这本书开始以小步语义来解释一个简单的语言，这样就得到一个的解释器程序。小步语义提供了一种轻松的方式来模拟计算的中间过程。随后介绍了大步语义，我觉得这两者之间的关联有些像自顶向下和自底向上。然后介绍了 treetop 这个工具，自定义 grammar 来实现一个简单的语法解释器。 第三章开始介绍自动机，从最简单的确定性有限自动机开始 (DFA)，然后是非确定性自动机 (NFA) 和正则表达式。我原来上学的时候大多在手动画这些状态图，远没这些简单的代码好玩。有输入，有状态，有输出，这些状态机就是最简单的机器了。而 NFA 虽然看起来比 DFA 有更多的特性，但本质上它可以转化为 DFA。为了增加计算能力，为自动机加上一些外部存储。用自带栈的确定性有限状态机 (DPDA) 能识别出平衡字符串。 第五章介绍图灵机，图灵机本质上是有外部存储的状态机。我之前看过图灵传记，图灵对密码学非常感兴趣，而且在二战中破译了大量德军密电。图灵机的概念很简单，而计算的本质就是如此简单直接的描述。模拟图灵机的过程倒并没什么大的乐趣。 第六章开始 lambda 演算，lambda 演算是从另外一个角度去理解计算。这一章非常好玩，这里只是用了 Ruby 的三个特性： 对变量的引用，创建 proc，调用 proc 来实现一个极小的编程语言。lambda 演算的基本元素就是这三个： &lt;exp&gt; ::= &lt;var&gt; :变量引用 | (lambda (&lt;var&gt;) &lt;exp&gt;) :创建 proc | (&lt;exp&gt; &lt;exp&gt;) :调用 proc 从这些简单的元素构建出语言的各种特性非常好玩，最终一个简单的 gcd 被解释成充满了 proc 的 Ruby 程序，然后就能运行了。 后面几章继续简述了可计算行问题。停机问题表明我们无法拥有能力不受限制的编程语言，淡淡的忧伤。 这位作者Tom Stuart的博客非常有料，他在自己的网站上用幽默了一把I Have No Idea What I’m Doing，这本书是这么写出来的。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Books","slug":"Books","permalink":"http://catcoding.me/tags/Books/"}]},{"title":"广告","date":"2015-01-19T11:43:00.000Z","path":"p/refer/","text":"我到了一个做无人机的公司工作，叫做大疆创新 (DJI)。最近内部有一些推广活动，有感兴趣的朋友了解一下。 大疆精灵 这页面我隔壁小伙子做的，看起来还不错 :) Phantom 系列是公司卖得最好的一款产品，市场主要在欧美。 这个东西挺好，比如能拍出这样的照片：stacy-s-breathless-moment。 https://www.skypixel.com/#/photos这里是大量用户上传的航拍照片。从不同的视角来欣赏地球，自有另一番风景。 当然如果以后还能做得更好，或许可以这样自拍了：DJI 云拍 Inspire 是下半年出的产品，这个还是挺惊艳的。设计很前卫，4k 镜头，操作灵敏且稳定性极佳。不过价格也不便宜，接近 2w 了。 “悟” INSPIRE PHILIP BLOOM DJI Inspire 1 – “Soar” This is the most amazing drone we’ve seen yet 顺便，再分享一个好东西给大家。大家都知道我们外面有个墙，红杏出墙就是个梯子。 我用了一段时间了，挺方便的。 所以在这里推荐一下，可以用这个链接注册。","tags":[]},{"title":"Rust coming to 1.0","date":"2015-01-10T11:43:00.000Z","path":"p/rust-10-alpha/","text":"Again, one article just for writing practice. :) Rust-lang release alpha 1.0 today. Rust aims to be a systems level programming language to replace C and C++. I hit Rust-lang about two month ago, and found it’s a funny language. Then I read some Rust code and also wrote a hobby project with it. There are several feature attract me: Write low-level code with safety guaranteesRust have the concept of onwership. For the resource in computation(this is usually refer to memory, file handler etc), the should be an owner. Rust try to solve the common errors caused by pointers in C/C++, such like dangling pointer, unfree pointer, double free issues. The borrow checker in compiler will keep the resource onwership move correctly with some rules. for more details please refer to offical guide. So as a newbie, writing code in Rust code seems always fighting with compiler. We can not just write code and then fix the memory later, the compiler refuses to accept anything which maybe unsafe, but this also make me think more about the code and design.By the way, the error hints from compiler is very helpful, this is not like C++(specially templates got in). There are some comparisons between Go and Rust, Gc is optional in Rust, compare Rust with Go is not sensible. Recent changes of removing runtime make Rust lower level. There are even some hobby projects writting OS with Rust, refer to this and this. High level abstraction for system programmingAs a modern system programming, Rust is surprisingly expressive. I like the Ruby syntax, Rust has the same similarly mind-blowing effect. Rust carry some functional programming concepts, these make code looks just simple and elegant. Let’s have some trivial code snippet: // construct array with 0 3 6 ...let v = (0..10us).map(|x| x * 3).collect::&lt;Vec&lt;_&gt;&gt;();for i in v.into_iter() &#123; println!(&quot;&#123;&#125;&quot;, i); &#125; // construct array with random valuesuse std::rand;let v = Vec::from_fn(10, |_| rand::random::&lt;uint&gt;()); Pattern match is so elegant:match number &#123; 1 =&gt; println!(&quot;One!&quot;), 2 | 3 | 5 | 7 | 11 =&gt; println!(&quot;This is a prime&quot;), 13...19 =&gt; println!(&quot;A teen&quot;), _ =&gt; println!(&quot;Ain&#x27;t special&quot;), &#125; Colsures, reminds me with Ruby’s block:fn main() &#123; let captured_value = 7u; let closure = |&amp;:argument| &#123; println!(&quot;I captured this: &#123;&#125;&quot;, captured_value); println!(&quot;Argument passed was: &#123;&#125;&quot;, argument); true &#125;; println!(&quot;Closure returned: &#123;&#125;&quot;, closure(&quot;a string&quot;));&#125; Almost every statement is an expression, this means that the statement returns a value. Blocks are also expression. This is good thing, we may write less “return”! Mixing with pattern match ends with a better sugar. Of course, nice syntax doesn’t really mean real expresiveness, There are more abstraction tools in Rust, like traits, macro definiation, generic types etc. I have tried some macros for testing in rust-scm. High SpeedI have found my favorite interpeter language, it’s Ruby. But in real world, we need to write some code need critical time performance. For this kind of task, Rust maybe a good choice. Benchmarks show Rust is almost as fast as C++. CommunityThe Rust have a small, but exciting, openly community. The language have been evolving several years, most design discussion are open source. The core team seems nice. Have a try for Rust.","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Rust","slug":"Rust","permalink":"http://catcoding.me/tags/Rust/"}]},{"title":"lcc 阅读记录","date":"2014-09-14T11:43:00.000Z","path":"p/a-retargetable-c-compiler-design-and-implementation/","text":"之前看 EOPL 感觉收获挺大，最近又花业余时间看了看编译相关的东西，这是我看 lcc 的时候顺手记下的一些自己的理解。这本书《A Retargetable C Compiler》还挺大头的。lcc 代码量不是特别大，更复杂的是 tinyCC，tinyCC 甚至可以直接运行 C 代码。 alloc.c为了尽量的少调用系统调用，在 alloc 基础上封装了一下。 sym.c用来存储 symbol，注意 scope 的表示方法。 input.c为了减少读取文件的开销，用一个 buffer 来缓存源文件内容。cp 表示当前读取出来的字符位置，limit 表示缓存的结尾字符位置，如果 fillbuf 一次以后仍然cp == limit则表示读取文件到 EOF 了。 注意这里的 fread 读取的时候是通过 stdin 的，但是在 main.c/main_init 函数的时候通过 freopen 将源文件重定向到了 stdin。 fillbuf 其实读取的时候是永远先把内容读取到 buffer[MAXLINE+1] 的位置，如果发现cp &lt; limit就把前面剩下的内容往前移动，这样永远保证 buffer 足够下一次预读取，这里有点巧妙。 比较复杂的部分是处理 resynch，input 处理的内容是经过 C 语言预处理器的，这部分没有包含在这个编译器内。 lex.c一个完全是手写的 C 语言 Parser，虽然只是兼容 C99，但手写还是比较复杂的。码农约架比写 Parser 是个体现实力的比赛。 getchr 逐个字符读取，cp 就是 input.c 里面的当前字符。跳过 BLANK，如果碰到 NEWLINE 则调用 input.c 读取下一行。 token.h 看起来有很多列，这个文件被多个地方用到。是用宏来生成一些 Enum 里面的代码。比如 token type 和 expr type。 gettok 顾名思义在 lex 运行的时候不断提供一个一个的 token，这主要是通过 cp 匹配 map 来判断，条件分支很多 (依据当前的第一个字符)。register unsigned char* rpc存储当前字符。register 作为一个对编译器的提示，尽量用 register 来存储变量。事实上现在的编译器很多都能做 auto register allocation，有的时候编译器的选择可能比人的选择更好。register 在老的 C 代码里面可能更为常见。 这个函数里面很多地方都用到了 goto，主要是在匹配关键字的时候区分 identifier。主要几大类是: number, keyword, identifier, string。 icon 处理数字的前缀，fcon 处理浮点数。 Lexical analyzer 基本理论是自动状态机，没一个 token 可以根据相应的正则表达式来表示。有一些工具可以用来自动生成这些繁琐的代码，比如 LEX，更新一些的有 Flex 和 re2c。 error.c终于来到 Parser 部分了，lcc 使用的是 recursive-descent，很多商业的编译器都是用的这种直观的算法，事实上对于大部分语言都足够了。recursive-descent 是自上而下的递归的，依据当前的 token 匹配语法结构。一个重要的问题是如何在处理的过程中给出适当的错误信息。error.c 里面的函数 test 和 expect 用来测试下一个 token 是否是预期的，expect 可以打印出错误信息。 tree.c最重要的数据结构 struct tree，AST 中的基本节点，包含子节点，和 operator 类型 (比如 AND，OR，NOT 等）。在构建 AST 的时候 root 函数经常被用到。 expr.c enode.cparser 的一部分，用来识别表达式。代码好复杂，和 paresr 有些类似，整个过程是构建 AST。编译器的前端最重要的事情就是这了，后面的操作都是在这个基础上做的。为什么 Scheme/Lisp 的 front 部分比较简单，因为这货代码就和 AST 有些类似了，括号把一个一个的节点组合了起来。初看起来很难看，其实习惯了还好。 上面说的是语法的识别，在构建 AST 的过程中另外一个事情就是语意的分析。包括类型检查，类型的转换，操作符优先级等，这些也在构建 AST 的时候顺便做了。比如在遇到 expr1 ? expr2 : expr3 的时候，expr1 的值最后被 cast 成一个 bool。指针之间的隐式转换也比较复杂。function call 比较复杂，这里还做了函数参数的写法是否是老的风格，类型说明放在函数头的最后。assignments 和 binary operator 的分析相对来说简单一些，需要做各种 cast。 前些天稍微看了一些 Erlang，发现里面的类型推导比较好玩，甚至可以发现一些代码里面的逻辑错误： 比如： fact(0) -&gt; 1;fact(N) -&gt; N * fact(N-1).test() -&gt; fact(-5). 不用运行 Erlang 的 dialyzer 就可以发现这里面的死循环，因为可以通过上面的定义推断出 fact 的参数是 non_neg_integer，而-5 是不符合的，所以报出来一个错误： fact(-5) will never return。 stmt.ccodelist 为双向列表，遇到新的执行块就加到这个列表上。在处理 control-flow 的过程中有的死代码块是可以被编译器发现的，只是我们平时都被忽略了。 比如 C 代码：int loop() &#123; Loop: goto Loop; return -1;&#125;int main() &#123; printf(&quot;loop: %d\\n&quot;, loop()); return 0;&#125;loop 永远不会返回，Gcc 选项-Wsuggest-attribute=noreturn可以报出一个 warning。 decl.c声明是 C 语言中最难解析的部分，原因是声明涉及到变量和类型，而从 C 声明中弄出类型信息还是挺复杂的。另外声明还分局部，全局，其中还涉及到函数参数，结构体等。decl.c 可能是最复杂的文件了，1100 多行代码，里面的函数之间又相互调用。finalize() 函数最后检查是否有重复定义的变量。 dag.clcc 的 intermediate code 是用 listnodes 把前面 parser 的 tree 转换为 DAG，最终整个程序会经过转换变成由多个 DAG 组合成的森林。listnodes 还负责把一些公共的 sub-expression 简化。 接口为 gencode,emitcode。后面每一个代码生成的后端都是一个 Interface 结构，在 function 函数里面调用这两个函数生成汇编代码，其中还包含一个 Xinterface 成员，这是平台相关的接口。 小结到现在我只是大概看了了前端和中间层，后面 lcc 跨平台的指令生成还没来得及研究，这本书的电子版不是很清晰，还是买个中文版来再稍微看看。总的来说，lcc 是的 Parsing 和语义分析是同时进行的，就是所谓的 one-pass 方法。现在很多编译器所用的方法是先建立 AST，后面可能要多次遍历整个 AST 进行分析，LLVM 好像就是采用的这种方案。另外代码的优化是一个 trade-off，作为教学用途的 lcc 没有过多做代码优化，这样 lcc 代码还是可以花不多的时间来一个大概的学习。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Compiler","slug":"Compiler","permalink":"http://catcoding.me/tags/Compiler/"}]},{"title":"折腾服务器","date":"2014-08-01T11:43:00.000Z","path":"p/install-server/","text":"最近花了一些时间研究机器的部署，主要是实践了网络安装服务器和 OpenStack 部署。 网络安装 Ubuntu如果有多台服务器，网络安装似乎是唯一的选择。基本原理就是在局域网里面配置一个 host，里面配置好一个 HDCP 服务和 TFTP 服务，用 Apache 弄一个系统镜像供服务器下载。当然这里面有许多许多的坑，一个一个爬出来感觉还是挺好的。我把一些记录在了这个Gist里面。Kickstart 用来自动化安装过程，这样安装过程中就不会弹出等待用户输入的对话款。总的来说就是： dhcp + tftp + web 服务器 + ubuntu 镜像 + kickstart : 局域网自动部署 弄这些似乎有点回到从前的感觉，我在 05 年左右大二的时候开始折腾系统。那时候 Ubuntu 正在作推广，在校学生可以免费申请光盘。因此，从 4.04 开始所有的 Ubuntu 盘我都有一份，经常乐此不疲地安装。当然也安装过各种 Linux 其他发行版。有时候出现问题还会找一些学长来帮忙弄。现在想来挺浪费时间的，应该花时间来多学些基础的东西。 弄完这网络安装以后我就想，如果当年整个男生宿舍弄这么一个安装系统的服务器，那可是能节省很多同学的时间啊！ OpenStack 安装部署OpenStack 号称下一个 Linux，分为很多独立的部件组成，看起来是一套很复杂的系统。我们主要是想利用 OpenStack 来构建私有云。OpenStack 的安装涉及到非常多的包，过程和配置都稍微有些复杂。所幸这里有一个比较成熟的安装脚本OpenStackGeek。是一些比较简单的 shell 脚本，我们在这个基础上自己做了一些默认配置，这样基本能够做到一键安装 OpenStack。 其他运维做的事情虽然很杂，不过中间还是能学到不少东西，比如我在这些折腾过程中学到了一些网络知识。虚拟化技术真是很好玩，『云』这个东西其实并不只是一个大家炒作的概念，即使公司现在只是用 OpenStack 来弄个私有云，这其中的便利真是让人感叹。有了这一套机器资源真是挥之即来，用完即丢。每个服务独立跑一个虚拟机上，相互独立。","tags":[]},{"title":"Automatically cleanup the buffer for Eshell","date":"2014-07-29T11:43:00.000Z","path":"p/buffer-size-limit-for-eshell/","text":"Keep writing some simple thing in English, for I will have less chance for writing English words in daily working. I will always run eshell for shell tasks, because this is really like the normal buffer in Emacs, so all the command for Emacs will keep working for this buffer. This is convenient for some actions. The problem annoying me is that if the size of buffer for eshell is too big, Emacs will gets more and more slow. Emacs essentially is a sole process program. So I have some digg and written a trivial elisp code like this solved the problem. (defun clear-and-send-input() (interactive) (if (&gt; (count-lines 1 (point)) 800) (let ((inhibit-read-only t)) (message &quot;Clear the eshell now !&quot;) (erase-buffer))) (eshell-send-input))(add-hook &#x27;eshell-mode-hook (lambda () (local-set-key (kbd &quot;&lt;return&gt;&quot;) &#x27;clear-and-send-input))) clear-and-send-input is a wrapper for eshell-send-input, I set the maximal number of eshell buffer to 800, and I bind this function to , so every time if the buffer size is too big, this wrapper will automatically clean up the buffer. And yesterday I found this article Mastering Emacs in one year guideis really thought-provoking, Hope this may help you.","tags":[{"name":"Emacs","slug":"Emacs","permalink":"http://catcoding.me/tags/Emacs/"},{"name":"shell","slug":"shell","permalink":"http://catcoding.me/tags/shell/"}]},{"title":"A mini Scheme interpreter written in Go","date":"2014-06-28T11:43:00.000Z","path":"p/scheme-go/","text":"Scheme-Brained Hare 在我学 Go 的时候开始了一个自己的业余小项目，就是这个GoScheme，打算用 Go 来写一个 Scheme 解释器，因为重写轮子是学习新东西的好手段。现在基本完成了，当然只是一些基本的语法支持，没有宏。 我只是用这个项目来熟悉 Go 的语法，Go 来做这种项目没有特别大的优势，这个项目用 C 来实现代码量会更少一些。比如这里个里面的基本数据对象包括各种类型，boolean, symbol, fixnum, proc 等等，又都是一个 Object 类型。如果是 C 可以用 union 类型来表示，然后通过 Object*实现接口上的统一操作各种数据，类似的代码像这样子： typedef struct object &#123; object_type type; union &#123; struct &#123; char value; &#125; boolean; struct &#123; char *value; &#125; symbol; struct &#123; struct object *car; struct object *cdr; &#125; pair; // .......... &#125; data;&#125; object; Go 里面没有 Union 这种类型，所以我用了reflect来实现这些东西，看起来还不是那么简洁。Go 的自带的一些 toolset 还可以，比如 testing，format，coverage 等，可以减少一些琐碎的事。 另外，以后项目里配一下 travis-CI 可以做集成测试。 Go 更适合做一些需要并发的任务，比如服务端的事情。","tags":[{"name":"Scheme","slug":"Scheme","permalink":"http://catcoding.me/tags/Scheme/"},{"name":"Go","slug":"Go","permalink":"http://catcoding.me/tags/Go/"}]},{"title":"最近在用 Go","date":"2014-06-22T11:43:00.000Z","path":"p/go-dev/","text":"最近一直在用 Go 做开发，我们打算整一套和 Rails 对应的 Go 开发框架。一些代码在我们的Github 小组里有。这里的几个项目都用到了代码生成的方法，生成 Go 文件，最后的整个 web 程序被编译成一个可执行文件。我们正在用一个项目来验证这个想法。其中： 1. xuanwu(玄武)根据 thrift 文件产生对应 MVC 里面的 Model。生成的 go 文件里面，一个 thrift 类型对应一个 go 里面的 type struct，生成的代码中包含一些基本的方法，比如 FindByID 等等，这都是根据 thrift 文件定义的对象属性自动生成的。这里用到了ptsd来解析 thrift 文件，自己定义模板来生成 Go 代码。我后来加了crud.py和crud.tmpl来生成 Controller 的代码，这样 MVC 里面 Model 和 Controller 就都有了。不过对于 Go 这样的静态语言，生成代码这套方案有个难解决的问题就是如何在生成的代码基础上实现用户自定义。我们现在的解决办法是另外写一个对应的 fix 文件，在里面写入自己要重写的函数，另外写一个程序根据 gen 文件和 fix 文件来做一个基于函数定义的 diff，如果用户定义了就忽略自动生成的函数。好绕的方法，不过因为 Go 库里面自带的的 parser 和 AST，做这么一个 diff 程序还挺简单的。 2. gorazor(白虎)功能是 MVC 里面的 view engine，从 C#里面的 razor 模仿而来，具体为什么要这么做 这个详细的中文文档 里面说了。有了这个东西我们可以混着 html 写 Go 代码了。我是从这个项目开始正式学习 Go 的，整个开发过程还是比较顺利的。刚开始 lexer 大量使用了正则表达式，后来发现速度有些受影响就手动写了一部分。parser 部分现在还有些难看，后面继续重构一下。Debug 一直都是 Println，很多时候已经够用了。 3. web在 web.go 的基础上做了一些自己的修改。 再说一下使用 Go 的一些感受，大部分时候是很爽的。对于喜欢 C 和 Python 的人来说上手 Go 是很容易的事情。Go 更像是一个更现代化的 C(而不是 C++)，因为简洁是其一个重要特性。和 Python 相似的地方是提倡一种事有一种解决方法，而不像 Ruby 那样有各种魔法写法，所以看别人的代码容易一些。Go 对代码的格式化有一些强制约定，但是缩进并不是语法的一部分，而是通过 gofmt 工具来自动纠正格式，这太方便了。再加上 goimport 这样的工具来自动加上或者移除不必要的 import，我现在写 Go 代码的时候基本不需要关心格式和 import 这些琐事，绑定 Emacs 快捷键保存文件以后基本都解决了。 Go 的编译速度很快，我的机器上这里 20w 行左右的 Go 代码基本编译在 13s 左右，这和 C++ 比起来要快很多很多。 其他我是这么配置 Emacs 的 Go 相关的东西的 其中 go-autocomplete 是来自动补全的，对于内置的库函数补全还是很好的。有的自定义的补全不出来。 goimports 修正 import 的。 gocover 是我自己写的一个程序，看到同事写在 Vim 里写 Go 代码的时候一个快捷键就跑相关的 pkg 的 testing，并把结果打印出来。对于 Go 的这么快的编译速度，真的可以边写代码迅速按下快捷键测试的结果就出来了 (还包括 coverage 噢)。于是我也写了个程序分析出当前编辑文件对应的 package 名字，设定好 GOPATH，然后去 tmp 目录跑测试。这个程序就是gocover，我绑定到C-x g，太方便了。 Vim 和 Emacs 的可扩展，是我们这群装逼党依然坚持用这些老古董的原因。因为可扩展意味着将来要面对新的编程语言和环境时候，我们可以做出自己改变来适应。 好的 Go 上手教程： Go by Example","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Go","slug":"Go","permalink":"http://catcoding.me/tags/Go/"}]},{"title":"Visualize Git Projects with Ubigraph","date":"2014-04-18T11:43:00.000Z","path":"p/visualize-git-proj/","text":"一个比较大的项目一般都由一群人协作开发，开发人员可能活动于各个模块之间。前两天突然想起如果把一个工程的所有 commit 数据提取出来，然后按时间顺序动态演示出来可能会比较好玩。从这个过程中我们可以看到一个项目是如何进化的，各个开发者到底在折腾哪些模块。比如这是一个多个开发者参与的一个项目展示图，其实是 3D 动态的。 我写了两个脚本来做这件事情，代码放在这里了。第一个脚本是 Ruby 写的 gitstat.rb，用来提取 git 的 commit 数据，这些信息包括：提交者名字，日期，增加的行数，删减的行数，相关的模块。所有这些数据都按照提交的时间排序，然后输出到一个文本文件里。使用方法是： $./gitstat.rb -l eventmachine,tinyrb -o log.txt -l 后面是模块名字列表，如果不加-l 脚本会自己检测出当前文件夹下所有的.git，每一个目录当做一个模块。log.txt 的格式看起来像这个样子： Francis 2008-07-28T16:57:15+00:00 1 1 eventmachineFrancis 2008-07-28T17:03:46+00:00 2 0 eventmachineFrancis 2008-07-29T23:34:53+00:00 3 1 eventmachineMacournoyer 2008-07-31T23:34:52+00:00 13 47 tinyrbMacournoyer 2008-08-01T00:36:27+00:00 32 0 tinyrb 另外一个脚本就是 gitshow.py 用来从文件中读取数据，然后发送给 Ubigraph 渲染。 Ubigraph 可以从官方网站上下载，解压后会看到一个 example 目录，里面有几种语言的示例。使用方式是： $./bin/ubigraph_server [在 Ubigraph 目录启动服务端]$./gitshow.py log.txt 这里开发者用圆球表示，模块用多边形球表示，并且颜色加以区分。另外加入了一点效果就是当开发者有提交的时候，其颜色闪红一下，同时开发者和模块之间加上一条虚线。并且开发者和模块的体积会随着代码改变量而增大，这样也能看出哪些模块工作量比较大 (当然用行数来衡量工作量本身并没有多大参考价值，只是为了效果)。 对于一个多人参与的项目也可以看出一些好玩的信息来，如果一个开发者贡献大其体积越大，而且离项目的节点越近，比如 eventmachine 的演示图如下： 有一个类似的开源的 C++ 项目叫做：Gource，效果做得很漂亮。","tags":[{"name":"Tools","slug":"Tools","permalink":"http://catcoding.me/tags/Tools/"}]},{"title":"Heartbleed 简单分析","date":"2014-04-11T11:43:00.000Z","path":"p/heartbleed/","text":"这几天不断听到一个词“心血漏洞”，近年来影响最严重的互联网漏洞。今天小小地研究了一把，顺便把引起一些思考记录下来。 到底是什么样的代码有一些 C 语言和开发经验的朋友看看这个Fix就能了解些具体细节了。在网络传输中有一个叫做心跳的概念，简单来讲就是客户端发送一个简单的心跳包给服务端，服务端又返回给客户端，然后客户端检查传回来的内容是否是预期，这样就知道了当前的 TLS 通信是否正常。这个 Bug 不是协议的问题，而是具体实现的时候的遗漏了相关的逻辑。 这个函数 dtls1_process_heartbeat 就是处理这块代码的，先读出长度和包类型，然后申请一段内存空间做一个 memcpy，其中长度为 write_length，而这里遗漏的就是这个长度的合法性检查。 /* Read type and payload length first */ hbtype = *p++; n2s(p, payload); pl = p; unsigned char *buffer, *bp;unsigned int write_length = 1 + 2 + payload + padding;buffer = OPENSSL_malloc(write_length);bp = buffer;/* Enter response type, length and copy payload */*bp++ = TLS1_HB_RESPONSE;s2n(payload, bp);memcpy(bp, pl, payload);bp += payload;/* Random padding */RAND_pseudo_bytes(bp, padding);r = dtls1_write_bytes(s, TLS1_RT_HEARTBEAT, buffer, write_length); 可以想象如果客户端发送一个长度为很大的数，而实际给的内容还是在符合范围内的长度，而 memcpy 仍旧拷贝了一个比较大范围的内存空间 (因为申明的包长度类型这里最大为 64K)。而这个临近的内存空间存的是些什么东西就不确定了，偶尔可能包含一些敏感信息，比如用户密码等等，这些数据有一定特征，是可以通过一定手段检测出来的。这个 Bug 的名字很形象，就像是血从服务器这个身体里慢慢渗出来一样。 这个简单的长度检查遗漏照理来说应该会被发现，因为内存如果越界了可能会引起 SegmentFault。但是 OpenSSL 有一个自己的内存分配器。可以想象 OpenSSL 先开辟一大块内存，后面的内存使用再自行分配。这样 memcpy 即使超出了预订的范围也没有造成问题。 影响有多大OpenSSL 作为一个基础设施，世界上大量现存的网络相关的软件都在使用，特别是一些服务器。光 Apache 和 nginx 就占了 Web server 的 66%，甚至还包括 Email 服务器 (SMTP,POP, IMAP 协议等)，VPN，和一大堆的客户端软件。这些都使得大量用户的密码有可能泄露。各个互联网公司都在为自己的产品打 patch 来解决这个潜在的风险。用户也有可能要再修改自己的密码来规避风险。 如何避免这样的 Bug这个 Bug 引起了一些争议，是否开源软件存在更大的风险。因为这个 Bug 如果是在私有软件里，可能不会一下引起这么多人的关注，整个互联网也不必整个为此 patch 一遍。 对于程序员来说，如何避免这样的 Bug? Redis 的开发者 Antirez 的这篇文章 Using Heartbleed as a starting point 写得挺不错，公司应该投入更多的资金在这种关键的涉及到安全的代码上，OpenSSL 每年接收到的资助为 2000 美金。系统程序员和测试人员应该使用一些静态代码分析器，另外动态检测器 (比如 Valgrind) 也很有帮助。因为 C 是一个贴近硬件的语言，可以在 C 上再增加一个抽象层来保护关键信息。Random 测试有可能发现很多软件中潜在的问题，单元测试有可能测不到这种情况。我现在工作的公司对于测试这块还是做得挺不错 (这也与我的产品特性有关，测试相对容易一些)，我们每天晚上除了跑单元测试，还需要跑 Valgrind 来检测内存问题，还有大量极端的 random case 可以发现很多 Bug。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Bug","slug":"Bug","permalink":"http://catcoding.me/tags/Bug/"}]},{"title":"另一本魔法书: EOPL","date":"2014-03-29T11:43:00.000Z","path":"p/eopl/","text":"概述很多学习计算机的同学都知道有一本号称魔法书的经典教材叫作《SICP》，《计算机程序的构造和解释》，MIT 的计算机入门课程用的教程。这本书内容广泛而深邃，从出版几十年来影响了很多程序员。今天介绍另外一本我认为也是魔法书的教材，叫做《Essential of Programming Language》，简称 EOPL，当然能获得简称的书都是不简单的。这本书虽然也年代久远，但是知名度不如 SICP 高。其作者是 Dan Friedman，就是那位王垠同学的导师。这位程序语言领域的大牛写过很多 Scheme 相关的书籍，比如《The Little Scheme》系列，这个系列广受好评，可能很多人都读过。 我读的是 EOPL3，据说这个版本稍微有点冗长，不过我还没读过前面的版本，所以对此不好评价。EOPL 主要关注程序语言的方方面面，一共分为 9 章。这本书的讲解方式是先稍微概述主题，然后会有相关语法的定义，然后是关键代码的实现。这里同样采用了 Scheme 来讲解。用 Scheme 的好处的我们可以站在一个更抽象的角度来编写程序 (Scheme 如此强大，可以定义自己的语法，比如这里面的 define-datatype 和 sllgen)。你可以看到这本书在反复折腾各种解释器，里面都是在往一个简单的解释器添加各种特性。 预备基础阅读这本需要一些简单的 Scheme 基础，不过对于有一些编程经验的人来说不难。我推荐这本Teach Yourself Scheme in Fixnum Days。Scheme 的基本元素很少、内核简单（用 Scheme 写一个能自身的元解释器非常容易），这和象棋有些像：规则简单，组合变化多。至少需要了解以下 Scheme 的基本内容 递归思想递归不只是理解程序的一种方式，同样也是写程序的一种方式。在 EOPL 中到处都是递归，解释器执行的过程是递归，里面的 Checker 也是递归。递归无处不在。 高阶函数在函数式编程语言中，函数和变量一样也是一等公民。在 Scheme 里函数可以接收函数作为参数，可以把函数作为返回值。在 EOPL 中的 envrioment 可以用函数来表示。 代码即数据 数据即代码抛开效率不说，用 List 可以表示很多数据结构。用 Scheme 的一个好处，就是代码和数据几乎没有界限，比如 Parser 部分，因为书里自带的 sllgen 如此强大，要修改语法的定义是如此的简单。而 Parser 出来的结果就是语法树，这语法树同样是个层层嵌套的表，解释器把这个作为输入就行了。 各章内容Abstraction前两章都是基础准备，介绍了如何用递归来做抽象，包括定义和相关数据结构的实现。比如 Enviroment，这不过是在一个小的 envrioment 上添加一个新的绑定。仔细思考那种用高阶函数的表示方法，这在以前的语言中不常见。 Expression基本的解释器，但这个解释器是后面章节的基础。到这里这个简单的语言已经可以支持递归了。 State实现了一个简单的 store，用来映射 variable 到 value。接着讲述 call-by-value, call-by-reference。到这里你可以看到程序语言中指针到底是个什么东西，以及这到底是如何实现的。 CPSCPS 内容比较难理解，但是 CPS 也是一个很有用的概念。可以看到使用 CPS 使得程序的空间固定，如何使用 CPS 来实现多线程。后面一章也是关于 CPS 的，实现了一个通用算法来进行 CPS 转换。 Type System为语言添加类型的好处，类型推倒如何实现，用替换法来做的一个简单的 Type Checker。 Module如何从语言层面支持 Module，以及面向接口编程。 OO面向对象和接口是如何实现的，在这里 OO 的实现看起来是有点繁杂，通过实现 OO 来看清楚本质。 习题这本书有很多习题，每一个题目都有相应的星号标示难度，三颗星的习题大部分还是需要很多思考。这里大部分习题都是需要 coding，在解释器里添加一些新的特性，往往需要一些简单的代码修改即可。 我做了大部分习题，https://github.com/chenyukang/eopl，不敢保证全是正确的代码，可供参考。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"}]},{"title":"关于随机数","date":"2014-03-06T11:43:00.000Z","path":"p/random-number/","text":"随机数代表着不确定性，其在计算机中广泛使用，比如用作加密的 key、密码的生成、模拟，扑克游戏中，还有一些经典的算法 (比如Monte Carlo) 依赖随机数的产生。以下是一些随机数相关的问题简单总结。 随机数产生，真随机数和伪随机数生成器随机数的产生是一个很有趣的问题。我们希望只通过计算机来产生随机数的时候会有一些困难，计算机擅长做确定的事情，按照制定的指令去依次执行。有两种产生随机数的方法，真随机数和伪随机数，这两种有各自的优点和缺点。 伪随机数生成器 (PRNG)，顾名思义产生的不是严格意义上的随机数，一般是通过一些数学公式 (或者计算好的表) 来产生。比如简单的Linear congruential generator，可以用来产生伪随机数。伪随机数的行为是可被预测的，但是在统计意义上来说是随机的。因为这个特点其所以使用范围有限，比如一些模拟程序。而且伪随机数有可能出现固定的周期，比如下面这两幅图分别是通过真正的随机数产生器和 Windows 下面的 PHP 的伪随机数生成器产生的 Bitmap，可以清楚地看到右边的那副图有规律可循。 另外如 Borland 随机数生成器 Random 的实现：long long RandSeed = #### ;unsigned long Random(long max)&#123; long long x ; double i ; unsigned long final ; x = 0xffffffff; x += 1 ; RandSeed *= ((long long)134775813); RandSeed += 1 ; RandSeed = RandSeed % x ; i = ((double)RandSeed) / (double)0xffffffff ; final = (long) (max * i) ; return (unsigned long)final;&#125;可以看到 Random 的最初一个随机数依赖于 seed，后一个随机数依赖前一个随机数。 真随机数生成器 (RNG)，通过向计算机中引入一些不可预测的物理信息，比如键盘敲击和鼠标移动等。所以真随机数才是很难预测的或者根本来说不可预测。每个操作系统的实现有各自的区别，比如 Linux 中产生随机数引入了物理噪音作为输入，比如 mac 地址可以用来初始化 entropy pool，随机源可以加入中断时间，硬盘的寻址时间等等。接口是/dev/random、/dev/urandom、get_random_bytes()，其中 get_random_bytes 在内核中使用。/dev/random 和/dev/urandom 的区别是/dev/random 强度更大并且是阻塞的，因为要收集更多熵。 随机数的使用涉及到随机数的程序要特别小心。比如一个很简单的程序，我们知道 C 语言中的 rand() 产生的随机数是有范围的，0～32767，如果我要生成范围在 0～10 的随机数如何做？可能你会简单认为 rand()%10 可以得到 (惭愧我以前也这样用的)，但是这真的是随机的吗？如果你把 0～32767 的所有数字依次%10，统计一下可以发现有的数出现的次数要大一些，因此最后出现某些数的概率相应的要大一些。 另外一个思考题，给一个 rand() 可以产生 [1, 5] 之间的随机整数，利用这个 rand 产生 [1, 7] 之间的随机整数？ 另写一个抽奖程序，从 30w 个用户中随机抽取 10w 个中奖用户？ 写个好的洗牌程序不容易 写一个对的洗牌程序看起来很容易，其实不然。Robert Sedgewick 说过： &quot;That&apos;s a pretty tough thing to have happen if you&apos;re implementing online poker. You might want to make sure that if you&apos;re advertising that you&apos;re doing a random shuffle that you go ahead and do so.&quot; —Robert Sedgewick, Professor of Computer Science, Princeton 比如 ASF Software 在多年前写的一个流行的网上扑克游戏，其中的洗牌程序是这段 Pascal 代码： procedure TDeck.Shuffle;var ctr: Byte; tmp: Byte; random_number: Byte;begin &#123; Fill the deck with unique cards &#125; for ctr := 1 to 52 do Card[ctr] := ctr; &#123; Generate a new seed based on the system clock &#125; randomize; &#123; Randomly rearrange each card &#125; for ctr := 1 to 52 do begin random_number := random(51)+1; tmp := card[random_number]; card[random_number] := card[ctr]; card[ctr] := tmp; end; CurrentCard := 1; JustShuffled := True;end; 可以分析一下这里的好几处问题，这里的洗牌算法也有问题，52！个排列出现的概率不一样。拿三张牌来作为例子就明白了。 for (i is 1 to N) Swap i with random position between 1 and N 可以看出 231, 213, 132 出现的次数要多一些，因此相对应的概率也大。 正确的洗牌程序算法是： for (i is 1 to N) Swap i with random position between i+1 and N 一个 32 位的数作为 seed，对于伪随机长生器是有问题的，因为如果给定 seed 伪随机产生器的行为是可以预测的。32 的 seed 的所有可能值的个数为 2^32 个，这相比 52!(8.0658 * 10 ^ 67) 小得很多。所以对于 32 位的 seed，甚至可以用蛮力法来攻破。 其他摘自&lt;&lt;思考的乐趣&gt;&gt;10 个人坐在一起谈天，突然他们想知道他们的平均年薪是多少，但每个人都不愿意透露自己的工资数额，有没有什么办法让他们能够得到答案，并不用担心自己的年薪被曝光？一个简单的协议模型，当然与随机数有点关系。 参考： Wiki: Random number generation。 How We Learned to Cheat at Online Poker: A Study in Software Security。 顾森，思考的乐趣。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Algorithms","slug":"Algorithms","permalink":"http://catcoding.me/tags/Algorithms/"}]},{"title":"LeetCode: anagrams","date":"2014-01-14T11:43:00.000Z","path":"p/leetcode-anagrams/","text":"LeetCode 这个题目想出来一个好办法，题目的意思是输入一组字符串，把他们按照 Anagrams 归组出来，Anagrams 的意思是字母相同，排列不同的两个字符串。 比如：aabcbaaccbaa 这些都是 anagrams 的。如果两个字符串是满足这种关系的，那么把字符串排序后的结果一定相同。因此想到用一个 map 去存来。 class Solution &#123;public: vector&lt;string&gt; anagrams(vector&lt;string&gt; &amp;strs) &#123; typedef map&lt;string, vector&lt;string&gt; &gt; Dict; vector&lt;string&gt; res; Dict S; for(int i=0; i&lt;strs.size(); i++) &#123; string tmp = strs[i]; sort(tmp.begin(), tmp.end()); if(S.find(tmp) == S.end()) &#123; S[tmp] = vector&lt;string&gt;(1, strs[i]); &#125; else &#123; S[tmp].push_back(strs[i]); &#125; &#125; for(Dict::iterator it = S.begin(); it != S.end(); ++it) &#123; vector&lt;string&gt;&amp; vec = it-&gt;second; if(vec.size() &lt;= 1) continue; res.insert(res.begin(), vec.begin(), vec.end()); &#125; return res; &#125;&#125;;","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Algorithms","slug":"Algorithms","permalink":"http://catcoding.me/tags/Algorithms/"}]},{"title":"正则表达式匹配和 NFA/DFA","date":"2014-01-04T11:43:00.000Z","path":"p/regular-expression-matching-dfa/","text":"正则表达式匹配是一个经典问题，这里有一个问题。实现 isMatch，其中。表示任意一个字符，*表示 0 个或者任一个前面的字符： isMatch(&quot;aa&quot;,&quot;a&quot;) → falseisMatch(&quot;aa&quot;,&quot;aa&quot;) → trueisMatch(&quot;aaa&quot;,&quot;aa&quot;) → falseisMatch(&quot;aa&quot;, &quot;a*&quot;) → trueisMatch(&quot;aa&quot;, &quot;.*&quot;) → trueisMatch(&quot;ab&quot;, &quot;.*&quot;) → trueisMatch(&quot;aab&quot;, &quot;c*a*b&quot;) → true 这是一个正则表达式问题的简化版本只有.和*，可以用递归来解决。正则表达式涉及到自动机理论，顺便再复习一下当年没好好学的东西。查找一番后发现了这篇 Russ Cox 写的文章非常好 (这家伙写了不少文章，xv6 里也有他的代码，现在在为 Go 项目工作)。于是我也尝试着用 DFA 来解决这个问题。 DFA 和 NFA 的概念首先对于没一个正则表达式都有一个对应的 DFA 可以来表示，DFA 是 Deterministic Finite Automaton 的简称，还有 NFA(Non-deterministic Finite Automata)。NFA 对于一个字符的输入有可能存在多个以上的状态转移，而 DFA 对于没一个输入只存在一个选择。所以每一个 NFA 都可以转化为一个 DFA，但是一个 DFA 可以转化为多个 NFA。我们来看一个例子： 对于正则表达(a|b)*abb的 NFA 和 DFA 分别表示为： DFA 的状态数目和 NFA 一样，但是一般实践过程中 DFA 的状态转移要多，所以 DFA 相对来说要难构造一些，同时 DFA 比 NFA 需要的内存空间更大。正因为在 NFA 中一个状态可能向多个状态转移，在极端的情况下其效率比不过 DFA。更多关于正则分类可以参考正则表达式引擎及其分类。 对于 NFA 不同的实现效率会不一样，这也是 Russ 的文章里所说的。Russ 的文章里面介绍了 Thompson NFA 算法实现 (没错就是发明 C 的那神)，一些老的 Unix 工具是用的这个算法，比如 Awk，Tcl，GNU grep 等，而一些更通用的编程语言用的是基于回溯的一种 NFA 实现，比如 Perl/Python。通过数据比较，在最坏的情况下用 Thompson NFA 实现的 awk 表现比匹配回溯的 NFA 要好很多倍。最坏情况下的复杂度不一样，回溯 NFA 是 O(2^N)，而 Thompson 的复杂度是 O(N^2)。文中的代码可以号好看看，非常简洁的 C 实现。 一个尝试实现对上面那个问题我尝试着实现了一个程序构建 DFA 来解决，提交上去完成 439 个测试用例只用了 28ms，相对于递归版本的需要 104ms。也可能 LeetCode 上面的测试数据太少，比较的意义不大。代码长度当然要比递归的长不少。定义 State： enum OpType &#123; ZERO_PLUS_ONE, ANY_ONE, MUST_ONE&#125;;struct State &#123; OpType type; int id; char value; bool end; State* prev; vector&lt;State*&gt; next; State(OpType t, int i, char v, State *p) : type(t), id(i), value(v), end(false), prev(p) &#123; if(type == ZERO_PLUS_ONE) next.push_back(this); //匹配任意个 next 加上自己 if(p == NULL) prev = this; &#125; void add(State* n) &#123; next.push_back(n); if(type == ZERO_PLUS_ONE &amp;&amp; prev != NULL) //匹配任意，前驱加上当前需要添加的状态 prev-&gt;add(n); &#125;&#125;; 构建 DFA 的过程如下，注释的部分需要注意： State* construct_dfa(const char* pattern) &#123; if(pattern == NULL) return NULL; const char* p = pattern; State* start = new State(ANY_ONE, Num, &#x27;.&#x27;, NULL); State* cur = start; State* next = NULL; char prev = &#x27;.&#x27;; Num = 1; while(*p &amp;&amp; *p != &#x27;\\0&#x27;) &#123; if(*(p+1) != &#x27;*&#x27;) &#123; OpType type; char value; if(*p == &#x27;*&#x27;) &#123; type = ZERO_PLUS_ONE; //匹配 0 个或者多个 value = prev; &#125; else &#123; value = *p; type = *p == &#x27;.&#x27;? ANY_ONE : MUST_ONE; //匹配任意一个。或者指定的字符 &#125; next = new State(type, Num, value, cur); prev = *p, p++; &#125; else &#123; next = new State(ZERO_PLUS_ONE, Num, *p, cur); prev = &#x27;*&#x27;, p+=2; &#125; cur-&gt;add(next); cur = next; Num++; &#125; cur-&gt;end = true; // 例如 ab*a*c* 对于 &quot;a&quot;， 即使后面几个*, &quot;a&quot;也算是一个 end， while(cur-&gt;type == ZERO_PLUS_ONE) &#123; cur = cur-&gt;prev; cur-&gt;end = true; &#125; return start;&#125; 匹配的过程就是一个搜索的过程，需要注意避免重复访问，另外如果下一层要访问的为空就可以退出整个搜索过程了，整个代码看这个Gist。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Algorithms","slug":"Algorithms","permalink":"http://catcoding.me/tags/Algorithms/"}]},{"title":"Kernel analysis: Defunct Process","date":"2013-11-23T11:43:00.000Z","path":"p/kernel-analysis-process-defunct/","text":"我发现带着问题去看内核代码比较容易理解。如果一个父进程显示的设置 SIGCHLD 为 Ignore，子进程将自己清理自己。 #include &lt;signal.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;int main() &#123; struct sigaction sa; memset(&amp;sa, 0, sizeof(sa)); sa.sa_handler = SIG_IGN; sigaction(SIGCHLD, &amp;sa, NULL); int pid = fork(); if(pid &gt; 0) &#123; printf(&quot;parent:%d\\n&quot;, getpid()); sleep(30); &#125; else &#123; printf(&quot;child:%d\\n&quot;, getpid()); sleep(4); &#125; printf(&quot;finished\\n&quot;); return 0;&#125; 我们可以顺便看看内核里面是怎么写的， linux/kernel/exit.c 里面这部分是负责进程退出的，我截取了相关的代码： /* * Send signals to all our closest relatives so that they know * to properly mourn us.. */static void exit_notify(struct task_struct *tsk, int group_dead)&#123; bool autoreap; forget_original_parent(tsk); write_lock_irq(&amp;tasklist_lock); /* .... */ &#125; else if (thread_group_leader(tsk)) &#123; autoreap = thread_group_empty(tsk) &amp;&amp; do_notify_parent(tsk, tsk-&gt;exit_signal); &#125; else &#123; autoreap = true; &#125; tsk-&gt;exit_state = autoreap ? EXIT_DEAD : EXIT_ZOMBIE; /*..... */ /* If the process is dead, release it - nobody will wait for it */ if (autoreap) release_task(tsk);&#125; 其中有一段是判断是否 autoreap，我们继续可以看看linux/kernel/signal.c 里面的 do_notify_parent 函数： bool do_notify_parent(struct task_struct *tsk, int sig)&#123; struct siginfo info; unsigned long flags; struct sighand_struct *psig; bool autoreap = false; /* .... */ if (!tsk-&gt;ptrace &amp;&amp; sig == SIGCHLD &amp;&amp; (psig-&gt;action[SIGCHLD-1].sa.sa_handler == SIG_IGN || (psig-&gt;action[SIGCHLD-1].sa.sa_flags &amp; SA_NOCLDWAIT))) &#123; /* * We are exiting and our parent doesn&#x27;t care. POSIX.1 * defines special semantics for setting SIGCHLD to SIG_IGN * or setting the SA_NOCLDWAIT flag: we should be reaped * automatically and not left for our parent&#x27;s wait4 call. * Rather than having the parent do it as a magic kind of * signal handler, we just set this to tell do_exit that we * can be cleaned up without becoming a zombie. Note that * we still call __wake_up_parent in this case, because a * blocked sys_wait4 might now return -ECHILD. * * Whether we send SIGCHLD or not for SA_NOCLDWAIT * is implementation-defined: we do (if you don&#x27;t want * it, just use SIG_IGN instead). */ autoreap = true; if (psig-&gt;action[SIGCHLD-1].sa.sa_handler == SIG_IGN) sig = 0; &#125; if (valid_signal(sig) &amp;&amp; sig) __group_send_sig_info(sig, &amp;info, tsk-&gt;parent); __wake_up_parent(tsk, tsk-&gt;parent); return autoreap;&#125; 可以看到如果父进程对子进程的生死不关心，那么设置 autoreap 为 TRUE，甚至这个信号也可以不发送了。","tags":[{"name":"Linux","slug":"Linux","permalink":"http://catcoding.me/tags/Linux/"},{"name":"Kernel","slug":"Kernel","permalink":"http://catcoding.me/tags/Kernel/"}]},{"title":"拓扑排序","date":"2013-11-20T11:43:00.000Z","path":"p/topological-sort/","text":"最近在看一些图算法，发现拓扑排序频繁出现，这里写一下自己的一些总结。 拓扑排序是对于有向无环图而言的 (DAG)，就是对于这个图所有的点 (V1, V2, … Vn) 找到一个点序列使得任意边 (u, v)， u 出现在 v 的前面。很容易证明，如果一个有向图中有环那么不存在拓扑排序。 现实中的问题首先来看现实中哪些问题需要拓扑排序的，课程排序，编译依赖问题，类似的凡是涉及到相关顺序的时间安排，比如 Rails 里面的初始化调用了库Tsort来进行排序。Unix 中有个命令也叫tsort)，在有的 makefile 里面还直接使用了这个命令来解决依赖问题。 O(V+E) 的算法 拓扑排序的基本算法是用 DFS，我们希望把有出度的点尽量排在前面，所以这里需要注意和 DFS 的区别。比如上面图中的一个 DFS 访问顺序是: 5 2 3 1 0 4，但是这不是一个拓扑排序，4 需要排在 0 的前面，5, 4, 0, 2, 3, 1。拓扑排序中需要等迭代完节点的连接邻点后再把当前点压入栈。 #include &lt;iostream&gt;#include &lt;stdio.h&gt;#include &lt;list&gt;#include &lt;stack&gt;using namespace std;class Graph &#123; int V; list&lt;int&gt;* adj; void _topological_sort(int v, bool visited[], stack&lt;int&gt;&amp; stack);public: Graph(int v); ~Graph(); void addEdge(int v, int w); void Topological_sort();&#125;;Graph::Graph(int v):V(v) &#123; adj = new list&lt;int&gt;[V];&#125;Graph::~Graph() &#123; delete [] adj;&#125;void Graph::addEdge(int v, int w) &#123; adj[v].push_back(w);&#125;void Graph::_topological_sort(int v, bool visited[], stack&lt;int&gt;&amp; stack) &#123; visited[v] = true; for(list&lt;int&gt;::iterator it = adj[v].begin(); it != adj[v].end(); ++it) &#123; int u = *it; if(visited[u] == false) _topological_sort(u, visited, stack); &#125; stack.push(v);&#125;void Graph::Topological_sort() &#123; bool visited[V]; stack&lt;int&gt; stack; for(int i=0; i&lt;V; i++) visited[i] = false; for(int i=V-1; i&gt;=0; i--) &#123; if(visited[i] == false) &#123; _topological_sort(i, visited, stack); &#125; &#125; while(!stack.empty()) &#123; int v = stack.top(); stack.pop(); std::cout &lt;&lt; &quot; &quot; &lt;&lt; v &lt;&lt; &quot; &quot;; &#125; std::cout &lt;&lt; std::endl;&#125;int main() &#123; Graph g(6); g.addEdge(5, 2); g.addEdge(5, 0); g.addEdge(4, 0); g.addEdge(4, 1); g.addEdge(2, 3); g.addEdge(3, 1); cout &lt;&lt; &quot;Following is topological sort result: \\n&quot;; g.Topological_sort(); return 0;&#125; 唯一性如果一个 DAG 的拓扑排序中任意连续的两点都是可连通的，那么这个序列也就是 DAG 的 Hamiltonian 路径，而且如果 DAG 图的 Hamiltonian 路径存在，那么拓扑排序就是唯一的。否则如果一个拓扑排序结果不是 Hamiltonian 路径，那么就存在多个拓扑排序结果。 其他图算法的预处理 DAG 的强连通分支问题先得到拓扑排序，形成逆向图 (所有边与原来方向相反)，然后根据拓扑排序依次再进行 DFS。 DAG 的最短路径问题，这可以在 O(V+E) 复杂度解决最短路径问题。同样类似的算法适用与 DAG 的最长路径问题，给定一个点求 DAG 中的各个点与给定点之间的最长路径。最长路径问题要比最短路径问题难，因为最长路径问题没有最优子结构，对于通用的图的最长路径算法还是 NP 难的问题。","tags":[{"name":"Algorithms","slug":"Algorithms","permalink":"http://catcoding.me/tags/Algorithms/"}]},{"title":"Do Presentation like a Geek","date":"2013-10-05T11:43:00.000Z","path":"p/do-presentation-like-a-geek/","text":"很多程序员不喜欢做 PPT 之类的东西，我也不喜欢。这有另外的原因是一直没找到一个合适的工具，Linux 下 PPT 是个悲剧，Latex 学习成本又大了点。上次在公司分享的时候偶然找到了这个叫做showoff的工具，熟悉了大概半个小时就上手了，迅速把自己的 PPT 完成。 showoff 是 Ruby 写的一个适合程序员写 PPT 的工具，你可以用类似 Markdown 的语法编辑文本文件，同时在 terminal 下开一个服务，浏览器访问localhost:9090可以预览的成果。这个过程非常类似用 Jekyll 来写博客。当然最后可以导出成 PDF 格式的，或者直接在浏览器上展示。 安装Showoff 安装非常简单： $ gem install showoff$ git clone (ppt-repo)$ cd (ppt-repo)$ showoff serve 使用我觉得 showoff 一些特别好的特点是： 纯文本编辑 (对程序员有吸引力) 嵌入代码方便，高亮代码 嵌入图片方便 可执行内嵌 Javascript，Coffeescript 或者 Ruby 代码，并显示结果。(对程序员来说很不错) 一些显示特效 赶快看看 example 目录吧，你就能上手了。","tags":[{"name":"Tools","slug":"Tools","permalink":"http://catcoding.me/tags/Tools/"},{"name":"Ruby","slug":"Ruby","permalink":"http://catcoding.me/tags/Ruby/"}]},{"title":"初到美国","date":"2013-09-26T11:43:00.000Z","path":"p/gotous/","text":"很久没有更新了，这段时间挺忙的。公司让在美国待一段时间，所以 7 月份开始办理相关签证，由于自己粗心大意导致跑签证馆好几次。第一次是因为没有填写完教育信息，签证馆挂着个牌子写着 The main difference between a cat and a lie is that a cat only has nine lives. - Mark Twain 我这还不算撒谎吧，他们还算通情达理给我个纸条让回来重新填写表。 终于费劲周折前两天到了湾区，我穿着沙滩裤下了飞机，一时特别的困。这边温度 19 度左右，风又特别的大，感觉有点冷。 当地时间上午 11 点到的，为了倒时差那天就不能睡觉，所以吃了午饭我和同事骑车到处逛了逛。 这边风景不错，最让人羡慕的是各种树比较多，而且高大茂盛。树上有果子，天上有老鹰。 作为土鳖虽然以前在电视和 Google 街景上看过美国的房子，不过亲眼来看看还是忍不住羡慕嫉妒，可恶的美帝，这让我们这些省吃俭用买个小笼子的共产主义奋斗者情何以堪。 这边亚洲人多，华人占的比例应该也很大。跑去大华超市附近买东西，那一片和上海没什么区别。 在这边待到 11 月中旬回去，打算周末再出去溜达一下，主要是自己还不会开车，在这边没车就基本残废。 我前一两个月开始看本书《Essentials of Programming Languages》，顺便做做里面的练习，写了不少 Scheme 代码，这些习题基本都是往一个解释器里面添加一些东西。总得来说挺好玩的，做到第五章了。代码在 Github 上：https://github.com/chenyukang/eopl。","tags":[]},{"title":"Metaprogramming Ruby","date":"2013-08-24T11:43:00.000Z","path":"p/meta-programming-ruby/","text":"『Metaprogramming Ruby』这本书看了两遍，从这本书里获取了一些乐趣。技术书籍就应该这样简明扼要，寓理于事。通过一个显示中的例子引入问题，展示元编程的解决办法， 顺带介绍一下用到相关技术的 gems。 下面这些不是书评，只是我在看第二遍的时候的一些简单的择要，用于自己的记忆和检索。 Introduction Meteprogramming is writing code that writes code 鬼城和集市，很多语言的运行环境在执行的时候已经固定，一片死寂。而支持 Metaprogramming 的语言的执行环境是充满活力的集市。很好的比喻。 动态元编程和静态元编程，C++ 的 template 属于静态元编程。 The Ruby Object Model Class 定义永远是开放的，你能重新定义任何类或者给类加上一些新的东西。注意 MonkeyPatch 可能导致的 Bug。 分清楚 instance_method 和 class_method， Class 也是对象。与 C#/Java 的 Class 不一样的地方，Ruby 允许在代码运行期间操作类相关的信息，比如增加 method 或者重新定义 method。 Methods static type checking, for example, if you call simple_talk() on Layer object that has no such method, the compiler protests loudly. call method dynamic using send(). define_method generates instance method dynamically, to_s vs to_sym. Ghost method, method_missing. 过多是用会不会拖慢执行效率，要顺着继承链一直查找 method。 注意 method_missing 可能导致的死循环调用。 和继承过来的 method 之间的冲突， undef_method 解决。 Blocks class, module, and def change scope. Flat Scope. instacen_eval/instance_exec create block : lambda/proc/Proc.new lambda vs Proc return in Proc also return from the scope. lambda’s argument checking is more strict. A event DSL, a elegent example for blocks. Class Definitions A Ruby class definition is actually regular code that runs. class_eval vs instance_eval class_eval both changes self and current class Eigenclass, the metaclass of a object three way to define class method Around alias Code writes code The powerful weapon: eval A good example: add_attribute Three ways to express this idea Active record Validations alias_method_chain Dynamic attributes, define read/write/question Dynamic Methods for all the columns in databases, for performance. Lesson learned, performance/complexity/readable trade-offs. Metaprogramming safely Defusing Monkeypatches, make it explicit with module, check it before patche, add warning messages.","tags":[]},{"title":"Learning Ruby with Ruby Warrior","date":"2013-07-14T11:43:00.000Z","path":"p/ruby-warrior/","text":"Ruby 上总有好玩的东西，偶然看到这个RubyWarrior，玩了一把感觉还有些意思。这个有些像我原来介绍的RubyRobot,不过更像之前的Wumpus，看来我对这种游戏有些兴趣。 Ruby 新手边玩边熟悉了语言。需要代码的可以 clone 下来看看，如果只是玩可以 gem 装上，然后运行 rubywarrior 就开始练级了。 gem install rubywarrior 我现在只是完成了初学者模式，这里的 AI 还比较简单，主要实现一个函数就行了。分为两种模式，第一种只用对付当前的场景，第二种为 epic(史诗？) 模式，要从 1~9 连续闯关。 我的平均成绩是 C，所有级的代码放在Github 上了。 Level Score: 27Time Bonus: 18Level Grade: FTotal Score: 374 + 45 = 419Your average grade for this tower is: CLevel 1: SLevel 2: CLevel 3: BLevel 4: BLevel 5: DLevel 6: FLevel 7: BLevel 8: FLevel 9: F 中级模式是二维的地图，所以更有挑战。 这里有一个前端，不过我还没用过。 这还有人用神经网络的方法来做的，可以学习一下，:)。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"}]},{"title":"初学 Rails","date":"2013-07-06T11:43:00.000Z","path":"p/studying-rails/","text":"我在 2012 年左右开始关注 Ruby，平时有的时候会用 Ruby 写一些脚本。这是一个很活跃的社区，Ruby 火起来也不是最近的事。可贵的这里总是有一些新的东西出来，比如我现在的这个博客是基于 jekyll 和 Github 的。Ruby 的迅速崛起更多的还是因为 Rails，所以学习 Rails 也是了解 Ruby 的一个好方法。 最近为公司内部所配置的 GitLab 是 Rails 开发的。另外我自己也在公司做一些 Web 程序，其实是很简单的东西，就是把每天晚上跑的程序各种测试结果展示出来 (nightly/weekly/coverage 等等)。我选用 Rails 来开发，果然一个最初的版本很快就做出来了。在初学 Rails 的过程中让我体会到了一些 web 开发的乐趣。 Rails 适合小团队的快速开发，其中的一些理念是： Encourage Agility –鼓励敏捷开发 Convention Over Configuration –约定高于配置 DRY –不要重复自己 Less Code –更短小的代码 正是这些开发原则使得 Rails 开发如此简单明了 (当然前提是你按照 Rails 约定的方式来)。我原来做过一些 web 开发服务器方面的工作，在那种模式下开发需要每个人各司其责。但是 Rails 不同，在 ActiveRecord 这样的抽象层基础上你需要关注的数据库方面的东西少了，明确的 MVC 模式把你需要关注的撤离开来，这种复杂程度一个人完全能掌控下来。当然这种高度的抽象是以牺牲一部分效率为前提的，但其实在很多时候开发效率的优先级是高于实现效率的，这也是 Ruby 所选择的一个理念。 学习 Rails 的过程中这些资料是非常好的，这几本书都面向初学者，写得非常详细： Ruby On Rails 教程 Begining Rails 3 Agile Web Development with Rails 当我熟悉了一些基本概念的时候，我就可以看 Github 上各种 Rails 的代码了，约定高于配置的另外一个优点就是所有 Rails 开发的东西结构看起来是一样的，便于不同开发者之间的交流。 Rails 的一个比较突出的问题是版本之间的兼容性比较差。 比如 Begining Rails 里面 Plugin 那章的那个例子，在 Rails3.1 系列开始已经不支持那种方式的 plugin 了，其中用到的class_inheritable_accessor也变成了 class_attribute。这种问题非常多，另外据说最新的 Rails4.0 改动也很大。 这是一个老问题，在早起的版本就有人在这上面都发生过争吵。一些人说变化太频繁，不容易学习。其中这篇“WTH is happening to Rails?” I’ll tell you 解释了一下 Rails 如此的原因，并称这种改变位『成长』。 学习 Rails 的路还比较长，后面继续。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Rails","slug":"Rails","permalink":"http://catcoding.me/tags/Rails/"}]},{"title":"高效的 Crit-bit Tree","date":"2013-05-18T11:43:00.000Z","path":"p/critbit/","text":"最近了解到有这么一种数据结构，想拿来在工作中做一些事情，结果效果不好。原来我的理解有一些不对。在这里记录一下。 Crit-bit tree是一种特别的树结构，一般用于存放字符串。Critbit tree 是一种BitWise tries，其树的深度为 O(longest-length)，有点像二叉树，不过对于字符串做分支检测的时候代价很小。 Crit-bit 快速高效的支持下面的一些操作： 插入一个字符串 测试一个字符串是否在树里 删除一个字符串 查找出树中所有以某个字符串开始的所有字符串 和 hash 有点像，不过 hash 对于第四点没这么方便。我做了一些性能对比，测试数据是/usr/share/dict/words里面的所有单词，同时做插入和查询的操作。具体测试代码看这里，结果是： critbit 11.6MB 23.34 set 21.6 MB 45.85s trie 332.3 MB 17.84s 从中可以看到 trie 树的内存消耗是比较大的，但是查找速度最好。critbit 的内存消耗真的非常小，如果只是把这里所有的单词存下来都要 4MB 的内存，其查找的速度虽然和 trie 树比起来差一些，但还是相当不错。 好好的研读了 crit-bit 的实现和这篇文章，里面技巧挺多的。critbit 的结构很简单： typedef struct&#123; void* child[2]; uint32 byte; uint8 otherbits;&#125;critbit0_node;typedef struct&#123; void* root;&#125;critbit0_tree; 其中 child 是 void*指针，对于树的内部节点其指向的是子节点，对于叶子节点其指向的是字符串。byte 用来表示当前节点匹配的长度，otherbits 是一个 mask，可以用来快速的取得不同最高位，在查询的过程中用这个来做 branch。 具体的代码分析这里比较少，最复杂的函数是 critbit0_insert。在插入过程中需要记录下来 byte 和 otherbits,并且更新前面的父节点。​ 然后再继续插入后的结构变化是： 下面记录一下其中的几个技巧。 align 指针最后一位用来做标志树的结构需要一个标志变量来表示是否是内部节点或者是叶子节点。这个变量如何能省掉？看上面的 void root 和 void child，都是即可以用来指向字符串又可以指向节点，一般申请过来的指针变量都是 align 好的，所以最低位为 0，这是可以拿来用的。因此对于内部节点我们可以在这个位上设置为 1，只是要注意在通过这个指针取值的时候需要减回去。 a = (posix_memalign((void**)&amp;x, sizeof(void*), ulen+1)) posix_memalign 在这里用的是 sizeof(void*)，其实就和 malloc 一样了，因为一般 Linux 上编译器和 C 库已经处理了对齐问题。 因此在查找的这段代码里是这样的： int critbit0_contains(critbit0_tree*t, const char* u) &#123; const uint8* ubytes= (void*)u; const size_t ulen= strlen(u); uint8* p= t-&gt;root; if(!p) return 0; while( 1 &amp; (intptr_t)p )&#123; //内部节点？ critbit0_node* q = (void*)(p-1); //取得真正的指针 uint8 c = 0; if(q-&gt;byte &lt; ulen) c = ubytes[q-&gt;byte]; const int direction= (1+(q-&gt;otherbits|c))&gt;&gt;8; p = q-&gt;child[direction]; &#125; //叶子节点 return 0 == strcmp(u, (const char*)p);&#125; 取最高位的非 0bit在插入过程中计算最高位的不同位。 newotherbits = p[newbyte]^ubytes[newbyte]; 其实也可以用一个 for 循环来计算，不过这里是这样实现的： newotherbits |= newotherbits&gt;&gt;1;newotherbits |= newotherbits&gt;&gt;2;newotherbits |= newotherbits&gt;&gt;4; 这相当于是计算不小于它的 2 的整数次幂，对于 32bit 的代码可以看看这里的next_pow_of_2。 文章和代码，其中那篇文章有详细分析。 我的测试代码，trie/set 等。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Critbit","slug":"Critbit","permalink":"http://catcoding.me/tags/Critbit/"}]},{"title":"迁移到 Git","date":"2013-05-09T11:43:00.000Z","path":"p/git-command/","text":"公司这群人终于打算从 CVS 迁徙到 Git 上了，CVS 这套公司用了六年。CVS 这是 90 年代的东西，我们不能因为年代久远而嫌弃这，只是 CVS 这东西对于一个比较大的项目来说创建分支是相当漫长，大多数程序员都没有耐心的。迁徙计划虽然纸上谈兵了很长时间，直到现在才终于打算行动。 上午把 Git 在服务器上搭建好，主要卡在一个 Git 的命令上，因为一些权限问题。 git init --bare --shared=group ; --shared=group forget this Git 的 web 接口是用的是ViewGit，自己做了一些修改，加上GeShi来高亮代码，并使用了GitStats来做代码统计。GitStats 统计的项目非常多，看起来很直观。 稍微记录一下常用的一些 git 命令： 检出仓库git clone repo更新git pull提交到远程git push提交到本地git commit -am”log message”创建 branchgit branch branch_name切换 branchgit checkout branch_name合并 branchgit merge branch_name图形界面gitk解决冲突git mergetool撤销上一次 commitgit revert HEAD撤销上上次 commitgit revert HEAD^撤销上一次的 mergegit reset –hard HEAD^ 这里有一个最直观的 Git 学习的地方leanGitBranch。","tags":[{"name":"Tools","slug":"Tools","permalink":"http://catcoding.me/tags/Tools/"}]},{"title":"一些包管理命令","date":"2013-04-17T11:43:00.000Z","path":"p/apt-usage/","text":"包管理器是 Linux 上一个经常用的东西，我觉得下面这几个命令是非常有用的，便于查询包的状态，或者搜索我该安装哪些包。 apt-cache用来根据名字查询软件包，比如 apt-cache search vim 查询 vim 相关的。 apt-file用来根据某个文件查询软件包，这在编译程序的时候非常有用，可以通过所需要的头文件去查询要安装的东西，可以避免去 Google 了。注意使用之前需要安装并 update。 sudo apt-get install apt-file sudo apt-file update 比如我在编译某个软件的时候找不到&lt;readline/readline.h&gt;，使用下面的命令来查询一下： sudo apt-file readline.h 结果中有这么一行，那么我就知道继续安装 libreadline5-dev 库就行了。 dpkgapt 是基于 dpkg 开发的，dpkg 是更古老更底层的一套工具，Debian 系统管理器的基础。 dpkg -l 列出所有已经安装的包 dpkg -s vim 列出包 vim 的状态 dpkg -L vim 列出本地所有 vim 相关联系的文件 dpkg -S vim 搜索所属包的内容 brewMac 下推荐 Brew 来替代 apt，大部分的开源包都有对应的地址源了。我没使用过 MacPorts，无法比较这两套的差别。不过我个人很喜欢的一点是 brew 所有安装的东西都在brew -prefix/Cellar 这个统一目录下， brew 相关的命令： brew list — 列出已安装的软件 brew update — 更新 Homebrew brew home — 用浏览器打开 brew info — 显示软件内容信息 brew deps - 显示包依赖","tags":[{"name":"工具","slug":"工具","permalink":"http://catcoding.me/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"巧妙的 XOR Link List","date":"2013-04-11T11:43:00.000Z","path":"p/xor_link_list/","text":"XOR Link List，只用一个附加的变量来实现双向链表。首先 xor 本身是个稍微有点难理解的操作。xor 有下面的一些特性： A ^ 0 = A A ^ A = 0 A ^ B = B ^ A (A ^ B) ^ A = B (B ^ A) ^ B = A 注意最后两条，这是 XOR Link List 的关键，这也是通过 xor 操作来实现 swap 的关键。 void xorSwap (int *x, int *y) &#123; if (x != y) &#123; *x ^= *y; *y ^= *x; *x ^= *y; &#125; &#125; 这里注意需要判断 x!=y，否则如果传入的是相同的指针，最后所指向的变量被设置为 0 了。 通过最后两条联想到双向链表中的两个指针的实现，一般如下图所示： ... A B C D E ... –&gt; next –&gt; next –&gt; next –&gt; &lt;– prev &lt;– prev &lt;– prev &lt;– 如果把 next 和 prev 用一个变量替换还能实现前向和后向遍历，那就节省了一个变量的空间。 ... A B C D E ... &lt;–&gt; A⊕C &lt;-&gt; B⊕D &lt;-&gt; C⊕E &lt;-&gt; 比如当前在 B 节点，其 pointer 变量为 A⊕C，如果前面的 A 地址保存下来然后做运算 (A⊕C)⊕A -&gt; C，这样就得到下一个节点指针，反向遍历同样如此。当然其缺点是逻辑复杂了，删除其中的某一个节点也不方便 (删除头和尾要好点)，遍历的时候需要保存上一个节点。这样看来为了省一点点空间这样实现似乎有点不值，在大部分情况下这样的一个 pointer 的节省并没什么用，不过这其中的细节有趣、巧妙。 同样上面的 xorSwap对于现代的 CPU 来说也没什么优化，这样的代码只是更加不便于编译器来实现指令级别的优化。这种类型 trick 的东西还是要避免使用才好。 自己稍微写了一下，代码在这个 Gist。","tags":[{"name":"C/C++","slug":"C-C","permalink":"http://catcoding.me/tags/C-C/"},{"name":"XorLinkList","slug":"XorLinkList","permalink":"http://catcoding.me/tags/XorLinkList/"}]},{"title":"Jekyll 使用 MathJax 来显示数学式","date":"2013-03-03T11:43:00.000Z","path":"p/try-mathjax/","text":"使用 Jekyll 写作文章的时候有可能需要内嵌一些数学公式，MathJax就是用来干这个的，试用了一下感觉非常方便。步骤如下： 修改 html 头部。 在每个页面开头加上这么一句，在 Jekyll 下可以通过修改 default.html 加上。 &lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&gt;&lt;/script&gt; 本地安装 kramdown。 因为 rdiscount 和默认的 markdown 在解析带公式文件的时候都会出现一些问题，所以最简单办法还是安装 kramdown。$ gem install kramdown 修改_config.yml，把 markdown 选项修改为： markdown: kramdown 然后在发布的时候就可以使用$$来把需要显示的数学式子扩起来。像这样： $$a^2 + b^2 = c^2$$ 发布出来就是漂亮的公式了。 $$a^2 + b^2 = c^2$$ $$x^my + a^2 + b^2 = c^2$$ $$x_\\mu$$ 一些更酷的例子： $$ J_\\alpha(x) = \\sum\\limits_{m=0}^\\infty \\frac{(-1)^m}{m! \\, \\Gamma(m + \\alpha + 1)}{\\left({\\frac{x}{2}}\\right)}^{2 m + \\alpha} $$ $$ \\frac{1}{\\Bigl(\\sqrt{\\phi \\sqrt{5}}-\\phi\\Bigr) e^{\\frac25 \\pi}} =1+\\frac{e^{-2\\pi}} {1+\\frac{e^{-4\\pi}} {1+\\frac{e^{-6\\pi}}{1+\\frac{e^{-8\\pi}} {1+\\ldots} } } } $$ $$ \\left( \\sum_{k=1}^n a_k b_k \\right)^2 \\leq \\left( \\sum_{k=1}^n a_k^2 \\right) \\left( \\sum_{k=1}^n b_k^2 \\right)$$ $$\\begin{aligned}\\nabla \\times \\vec{\\mathbf{B}} -\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{E}}}{\\partial t} = \\frac{4\\pi}{c}\\vec{\\mathbf{j}} \\ \\nabla \\cdot \\vec{\\mathbf{E}} = 4 \\pi \\rho \\\\nabla \\times \\vec{\\mathbf{E}}\\, +\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{B}}}{\\partial t} = \\vec{\\mathbf{0}} \\\\nabla \\cdot \\vec{\\mathbf{B}} = 0 \\end{aligned}$$ 不过我可能永远用不到这么复杂的表达式 :). 另外今天找了一个markdown-mode.el，在 Emacs 下编辑 Markdown 文件又方便了不少。 Mac 下的 Markdown 编辑器Mou也是非常不错的。","tags":[{"name":"Jekyll","slug":"Jekyll","permalink":"http://catcoding.me/tags/Jekyll/"}]},{"title":"读 bootstrap scheme","date":"2013-02-15T11:43:00.000Z","path":"p/reading-bootstrap-scheme/","text":"For a List in Lisp, Car is the First, Cdr is the Rest, and Lisp means List-Proccessing. 前段时间偶然在网上看到这个bootstrap scheme 这个开源程序，读来简洁明了，十分有趣。我对 scheme 有一点了解，毕竟以前看过一段时间 SICP，自己做练习的代码也是 scheme 写的。scheme 本身属于 Lisp 方言，语法也极其简单，学习起来非常快的。 看看这个简单的 scheme 实现，不禁再次感叹递归的优美。Lisp 这样的语言直接使用语法树结构来表示程序，不仅使得表示出来的程序异常简洁，就是用 C 语言来实现这种语言的解释器代码也看起来非常优美。在这里区区 2000 行的 C 语言代码，当然没有完整地实现 scheme 所有的内容，甚至只支持了整数。但是包含 scheme 的基本语法层面的东西，还有 lambda。抛开实现的效率不说，递归是易于编写和理解代码的一种方式，这里语法是递归的，parser 是递归的，eval 也是递归的。在这里所有的东西都是 object，没有显示的列表结构，但是嵌套的 pair 里蕴含着列表和树的关系。在 parse 阶段建立好一个以 object 为基本元素的树结构，做 eval 的时候顺着往下走就是了。 推荐对语言实现感兴趣的同学阅读一下这个代码，如果对 scheme 不了解也没关系，用一个小时看几个 scheme 程序基本就了解了。再看这个解释器，你就懂了代码是如何被运行的。 参考scheme-from-scratch-introduction 图片来自Draperg’s cartoons","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Lisp","slug":"Lisp","permalink":"http://catcoding.me/tags/Lisp/"}]},{"title":"Emacs 会说话","date":"2013-01-27T11:43:00.000Z","path":"p/emacs-speaking-now/","text":"出来工作之前我从来没认真考虑过我的英语口语问题，大学时候的四级口语考试 C 级也没让我意识到自己的发音比较烂。学了好多年哑巴英语，又因为本人生性有点害羞经常不好意思开口说英语，悲剧早就注定。其实我的英语阅读能力还是可以的，不过工作之后同事们都嘲笑我口语听起来像印度人，据说发音极其古怪。 在 Mac 下有一个叫做 say 的命令行程序，我有时候会用来听单词单词发音。这个程序加上-f 参数也可以用来朗读整个文件。 say hello wrold say -f demo.txt 前几天突然觉得如果写个 Emacs Minor Mode，能在边写单词的时候 Emacs 就把你写的朗读一遍就好了，Emacs 号称能煮咖啡，这点小事当然不在话下。其实除了在公司我也很少写英文，不过这个想法看起来比较好玩，于是动手做了一下。预想的基本功能是实现了，我把它叫做 EmacSay-mode，意为在 Emacs+Mac+Say 下实现的，所以这东西可能不能在 Linux 下运行。 这也是我第一次学着写一个 minor mode，实现起来也很简单。整个不到 100 行 elisp 代码。 基本思路就是如果当前输入的字符是空白 (或者其他非字母字符)，寻找前面一个字符串，格式化成一个命令行，用 start-process 或者 shell-command 来调用。注意 start-process 会 fork 出来一个子进程来执行命令，在书写过程中最好还是使用 start-process 来调用命令，因为 say 可能要待个一两秒才返回，如果使用 shell-command 来调用会造成输入有迟钝的感觉。 绑定的快捷键有这些，其中 eamcsay-say-buffer 是用来朗读当前的整个 buffer，如果你想在其中中断朗读使用 emacsay-say-stop。 (defvar emacsay-mode-map nil &quot;Keymap for emacsay minor mode&quot;)(unless emacsay-mode-map (let ((map (make-sparse-keymap))) (define-key map &quot;\\C-cs&quot; &#x27;emacsay-say-current-string) (define-key map &quot;\\C-cp&quot; &#x27;emacsay-say-buffer) (define-key map &quot;\\C-ct&quot; &#x27;emacsay-say-stop) (setq emacsay-mode-map map))) 还可以有一些小的改进，比如阅读时候闪烁单词，或者 say 声音的选择等等。 所有代码在 GitHub: emacSay-mode。","tags":[{"name":"Emacs","slug":"Emacs","permalink":"http://catcoding.me/tags/Emacs/"}]},{"title":"迟到的 POJ 500","date":"2013-01-22T11:43:00.000Z","path":"p/poj-500/","text":"我发现自己有了很重的拖延症，一个表现就是在 2011 年 3 月定下的目标POJ 500最近才完成。 这一页 500 道题耗费了我很多时间和精力，同样也带给了我很多知识和乐趣。 当然工作后毕竟还是没有学校的时间充足了，现在还花时间来做题似乎显得很悠闲，这 500 题最后十个是在元旦的几天假期里完成的。我是从 2010 年的 4 月份开始在 Poj 上做题，那天偶然发现自己原来 2006 年还注册过账号，于是做了两题试试，没想到后面就竟然沉迷其中，一直到自己从学校毕业出来。这两年强度还不算大，平时还是要在实验室做做项目的。我没参加过专业队的训练，不过参加过一次学校的比赛，和王骆驼两个人一个下午做出来五道，比较悲剧的是差一道没进决赛。不过当时还是挺欣慰的，毕竟自己还是不算专业选手啊。这一年多静下心来写程序收获很多，因为体会到了写程序的乐趣，有时候在睡觉的时候脑袋也在不知不觉地想问题。有时候我选择按不同的数据结构或者算法思想来选题做，有时候就在线上泡着看排我前面的人在做什么，然后自己也跟着做，这真写的是寂寞啊。不过现在回想起来这一两年算是最自由、最充实的写程序的日子了。 像 ACM 题这些东西最好还是大学开始接触，在开始学习基本算法和数据结构的时候就开始进行训练是最好的。当然如果大学能进专业队训练就更不错了，如果只是业余拿来练练手也是大有裨益的。也许我们做不到专业队哪些人写代码就像秀肌肉一样，体会到其中的乐趣就够了。在我开始做 POJ 之前我还是对算法充满了恐惧，感觉太高深。经过这些渐进的学习和训练，现在至少说有点入门的感受，面对一个问题多多少少会有一些思路和想法。也许平时项目和工作并没用到多少纯粹的算法部分，只是这有了这基本功还是能让你迅速上手其他东西。 《黑客和画家》里写到学习写程序和学习绘画的诸多相同点，这都是一门技能，除了多写、多看、多思考之外没有其他捷径可走。折腾多了自然就会有一点感觉。学习绘画的另外一个途径就是观摩经典的杰作，同样对应地看开源项目是另外一个很好的学习编程的途径。 幸好 GitHub 又被解封了。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"POJ","slug":"POJ","permalink":"http://catcoding.me/tags/POJ/"}]},{"title":"获取挂掉程序的栈信息","date":"2013-01-04T11:43:00.000Z","path":"p/print-stack-before-exiting/","text":"在程序挂掉的时候最好还是留点有用的遗言，特别是对于一些比较难重现的 Bug，也许这些信息会成为解决问题的关键。 下面这个技巧可以让程挂掉的时候打印出来栈信息。这个办法来自这里, 我觉得把 SIGABRT、SIGBUS 信号加进去也挺好的，在此做了点修改。曾经尝也试过 glibc 的 backtrace 函数，，但是给的信息不全 (没有行号)，对此做得最好的还是 gdb。 在终端可以用 gdb 获取某个进程的当前栈： $ gdb -p 5595 -batch -ex bt 0xb7fb4410 in __kernel_vsyscall () #0 0xb7fb4410 in __kernel_vsyscall () #1 0xb7dc2d50 in nanosleep () from /lib/tls/i686/cmov/libc.so.6 #2 0xb7dc2b87 in sleep () from /lib/tls/i686/cmov/libc.so.6 #3 0x0804874f in main () at print_stack.cc:64 那么一个好的办法就是在程序开始的时候设置好信号，绑定 SIGSEGV 和 SIGABRT 到 DumpBackTrace() 函数，DumpBackTrace 函数 fork 出来一个新进程，运行上面的命令来获取调用栈。 #include &lt;stdlib.h&gt;#include &lt;signal.h&gt;#include &lt;stdio.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;#include &lt;unistd.h&gt;#include &lt;assert.h&gt;void DumpBacktrace(int) &#123; pid_t dying_pid = getpid(); pid_t child_pid = fork(); if (child_pid &lt; 0) &#123; perror(&quot;fork() while collecting backtrace:&quot;); &#125; else if (child_pid == 0) &#123; char buf[1024]; sprintf(buf, &quot;gdb -p %d -batch -ex bt 2&gt;/dev/null | &quot; &quot;sed &#x27;0,/&lt;signal handler/d&#x27;&quot;, dying_pid); const char* argv[] = &#123;&quot;sh&quot;, &quot;-c&quot;, buf, NULL&#125;; execve(&quot;/bin/sh&quot;, (char**)argv, NULL); _exit(1); &#125; else &#123; waitpid(child_pid, NULL, 0); &#125; _exit(1);&#125;void BacktraceOnSegv() &#123; struct sigaction action = &#123;&#125;; action.sa_handler = DumpBacktrace; if (sigaction(SIGSEGV, &amp;action, NULL) &lt; 0) &#123; perror(&quot;sigaction(SEGV)&quot;); &#125; if (sigaction(SIGABRT, &amp;action, NULL) &lt; 0) &#123; perror(&quot;sigaction(SEGV)&quot;); &#125;&#125;void test() &#123; //assert(0); int* p = 0; *p = 0;&#125;int main() &#123; BacktraceOnSegv(); test();&#125; 另外前段时间看到这篇文章Solving vs. Fixing写得不错，在面对一个 bug 的时候，先不要急于立马上 gdb 调试，根据现有的信息好好思考为什么会出现这个情况。Reddit 上的一个得分最高的回复： The ability to reason about code is probably the most important skill. But it is sadly rare, and doesn&apos;t seem to be taught much, if at all. Some things are simple, others take some more thought: * Under what conditions will this branch get taken? * What could cause this API to fail? * Are all these parameters even valid? * What sequence of events could lead to this situation? * What assumptions does this code make? * What side-effects does this code have? * What contract is this code making (or breaking)? The most talented engineer I know, when presented with a bug, does nothing but read the code and think about the code and how it could fail. Most of the time, he just figures it out in his head and fixes it. Sometimes he will insert some strategic printfs and narrow it down like that. I don&apos;t think I have ever seen him use a debugger, even on the most complex of problems.","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"C/C++","slug":"C-C","permalink":"http://catcoding.me/tags/C-C/"}]},{"title":"Browser objs and class hierarchy  in Ruby","date":"2012-12-26T11:43:00.000Z","path":"p/browser-objs-in-ruby/","text":"Ruby 里一切都是对象，如何能看到 Ruby 内建的对象模型呢。这里有个小程序来查看 Ruby 内部构建好的的对象和类。ObjectSpace 可以迭代所有对象。 set = Set.new() ObjectSpace.each_object do |x| set.add(x.class) endset.each do |x| puts xend 下面这段就能根据对象，取得 class 对象，建立起类的继承图。 # Creates or updates a klass_tree.# When updating no classes or objects are removeddef object_browser(classtree = ClassTreeNode.new(Kernel)) ObjectSpace.each_object do | x | classnode = classtree x.class.ancestors.reverse[1..-1] \\ .inject(classtree)&#123; | classnode, klass | classnode.add_class(klass) &#125;.add_object(x) end classtreeend use this command to get image: $ruby prog.rb &gt; class.dot; dot -Tpng class.dot -o class.png 结果看起来像这样，所有对象都画出来比较多，看大图还稍微能看到一些。完整的代码在这里。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Ruby","slug":"Ruby","permalink":"http://catcoding.me/tags/Ruby/"}]},{"title":"Clang is Making Emacs Smarter","date":"2012-12-16T11:43:00.000Z","path":"p/use-clang-autocomplete-mode/","text":"在 Emacs 下自动补全总是个问题，对于同一个 buffer 内的基于 symbol 补全 auto-complete-mode 做得非常好了，但是因为没有进行代码的分析，所以像结构体的成员变量或者类的成员函数的补全是不可能的。当然你可能试过这个号称最智能的GCCSence,但是我觉得这个东西够复杂的，在使用之前还需要用户手动运行一个命令来用 Gcc 处理一遍，它还会把一些东西放在 sqlite 数据库里面。这大概是因为 Gcc 不编译做静态分析工具造成的，在这里、这里、这里有讨论，Google 的一个静态分析的项目从 Gcc 迁移到 LLVM，重点是这： The gcc version has been difficult to support and maintain, due mainly to the fact that the GIMPLE intermediate language was never designed for static analysis. The abstract syntax tree provided by Clang is an easier data structure to work with for front-end analyses of this kind. 这个 thread 挺好玩的，后面变成了一大群人争论 functional programming 和 Imperative Programming。这篇The Downfall of Imperative Programming再好好看看。 回到正题，我最近切换到 Mac 下。因为在 Mac OS X 下编译器变成了 Clang， Clang 是基于 LLVM 的。LLVM 对于分析代码是有比较方便的支持，所以基于 LLVM 有各种分析源程序的工具了，Xcode 下的一些辅助开发的工具还是很舒服的。前些天突然想到那么会不会有个东西来作为 Emacs 的自动补全的后端，一搜果然有了这个auto-complete-clang，使用了一下非常的方便。其实看看其代码是在后面调用 Clang 的，比如在 main.cc 源文件里面写一些代码： #include &lt;string&gt;#include &lt;vector&gt;using namespace std;class Demo&#123;public: void print(); void test();private: int value;&#125;;int main() &#123; std::string s; Demo demo; demo.&#125; 结果还是非常精准的，不想截图了。后端运行的命令其实是：cmd: clang -cc1 main.cc -fsyntax-only -code-completion-at main.cc:18:10 所得到的结果是：COMPLETION: Demo : Demo::COMPLETION: operator= : [#Demo &amp;#]operator=(&lt;#const Demo &amp;#&gt;)COMPLETION: print : [#void#]print()COMPLETION: test : [#void#]test()COMPLETION: value : [#int#]valueCOMPLETION: ~Demo : [#void#]~Demo() auto-complete-clang 做的事情就是把这个结果再展示出来，其实这条命令也做了语法检查的，所以加上一个语法检查的功能应该也是可以的。一搜果然还是有了，看这个Realtime syntax checking with emacs，需要翻墙，不过代码在Github 上。其实其后端运行的命令是： cmd: clang -fsyntax-only -fno-exceptions main.cc 最近用这个插件，基本代码都会是一遍编译通过啊，哈哈。Clang 错误提示也人性化一点，比如在 Xcode 下会提示你想的是不是”XXX”之类的。","tags":[{"name":"Emacs","slug":"Emacs","permalink":"http://catcoding.me/tags/Emacs/"},{"name":"LLVM","slug":"LLVM","permalink":"http://catcoding.me/tags/LLVM/"},{"name":"Gcc","slug":"Gcc","permalink":"http://catcoding.me/tags/Gcc/"}]},{"title":"Have a try on Ninja","date":"2012-12-13T11:43:00.000Z","path":"p/have-a-try-for-ninja/","text":"什么是 Ninja 在 Unix/Linux 下通常使用 Makefile 来控制代码的编译，但是 Makefile 对于比较大的项目有时候会比较慢，看看上面那副漫画，代码在编译都变成了程序员放松的借口了。所以这个 Google 的程序员在开发 Chrome 的时候因为忍受不了 Makefile 的速度，自己重新开发出来一套新的控制编译的工具叫作Ninja，Ninja 相对于 Makefile 这套工具更注重于编译速度。除了 Chrome 现在还有一些其他的比较大的项目也在开始使用 Ninja，比如 LLVM。我试用了一下感觉还是不错，比如编译 Cmake 时间大概是原来的 1/4。Ninja 试用 C++ 实现，其支持的语法非常简单，作者在这里说明了为了控制复杂度。 代码如何编译其实对于 C/C++ 和很多其他程序的编译都是一个道理，就是把一些源代码文件编译成目标文件，或者有的目标文件再编译到一个库里，然后再链接起来。所以 Ninja 的配置文件分为两个部分，rule 和文件依赖关系。看个简单的例子： cc=gcccflags= -g -crule cc command = $cc $cflags $in -o $outrule link command = $cc $in -o $outrule cleanup command = rm -rf *.exe *.obuild func.o : cc func.cbuild main.o : cc main.cbuild app.exe : link main.o func.obuild all: phony || app.exebuild clean: cleanup 非常易懂，编译的可执行未见叫做 app.exe，其中有三条 rule: cc, link, cleanup。看看这个官方的试用手册，还有一些附加参数可以加在 rule 的下面，比如 description 用来在编译的时候显示出来。Ninja 还有个比较好玩的功能就是 Ninja -t graph all 命令，这可以用来生成编译时候的依赖关系，可以用 dot 来生成图片等。Ninja 的实现也可以大概推测到，根据用户给的依赖关系图，_并行_ 地编译各个文件。 使用 Ninja 的一个问题就是需要生成这个 build.ninja 文件，对于大型项目来说这样一条一条地写配置文件是不可能的。幸好我们可以使用 Cmake 来生成这个配置文件，Cmake 对应的是 automake 这样的东西。在Cmake 的最新版本中已经支持参数 Camke -G Ninja，Cmake 会根据用户给定的 CMakeLists.txt 来生成 build.ninja 文件。而 CmakeLists 文件相对来说要简单一些，只要写清楚编译的可执行文件的名字，和其依赖的包含 main 函数的源文件。把我的迷宫小项目来举个例子，在项目文件夹下写配置文件 CMakeLists.txt: cmake_minimum_required(VERSION 2.8)project (Maze)add_library(maze A_star.cpp Algorithm.cpp DFS_L.cpp DFS_R.cpp DisjSets.cpp Maze.cpp)add_executable(Maze.exe main.cpp)target_link_libraries(Maze.exe maze) add_library 写明了生成一个叫做 maze.a 的库文件，然后和 main.cpp 编译出来的 main.o 生成可执行文件，写好 CmakeList.txt 后运行 Cmake -G Ninja，然后运行 ninja all 就能编译这个工程。具体的 Cmake 语法参考 这里，对于不少项目来说 Cmake 已经足够使用，只是我觉得 Cmake 还是稍微复杂了一点。 我这样来使用 整个 Ninja 是使用 C++ 写的开源项目，如果我们想增加一些自己的 feature 可以 hack 一下，不过作者估计不会接受增加语法支持的 patch。我准备做一个小的 hack 来自动分析我当前的源码，自动生成 build.ninja 文件，不要求处理所有的复杂情况，只是分析.cc 和.c，自动检测 main 函数文件。最后用户只用配置链接参数就可以了。我觉得这样用起来就非常方便了，待完成中，顺便看看 Ninja 的内部实现。","tags":[{"name":"Ninja","slug":"Ninja","permalink":"http://catcoding.me/tags/Ninja/"},{"name":"makefile","slug":"makefile","permalink":"http://catcoding.me/tags/makefile/"}]},{"title":"Ruby Robot AI","date":"2012-11-22T11:43:00.000Z","path":"p/ruby-robot-ai/","text":"最近看到一个RRobot，这是一个用 Ruby 来实现的坦克对战平台。感觉挺好玩的，周三在公司也顺带和同事分享了一下。有时间的同学可以尝试尝试，用 Ruby 来写坦克的 AI。另外这个不到 1000 行的程序也比较好读，这种 Robot AI 平台以前也有 C++/Java 版本的，不过都要比这个实现得复杂一点吧。 每个你控制的 robot 的 api 是这些，注意雷达扫描到的目标只包含距离信息，没有 x 和 y，如果雷达扫描得越快所得到的目标位置准确率越低。自己摸索着写，找一些别人写好的策略来对战一把吧。 battlefield_height #the height of the battlefield battlefield_width #the width of the battlefield energy #your remaining energy (if this drops below 0 you are dead) gun_heading #the heading of your gun, 0 pointing east, 90 pointing #north, 180 pointing west, 270 pointing south gun_heat #your gun heat, if this is above 0 you can&apos;t shoot heading #your robots heading, 0 pointing east, 90 pointing north, #180 pointing west, 270 pointing south size #your robots radius, if x &lt;= size you hit the left wall radar_heading #the heading of your radar, 0 pointing east, #90 pointing north, 180 pointing west, 270 pointing south time #ticks since match start speed #your speed (-8/8) x #your x coordinate, 0...battlefield_width y #your y coordinate, 0...battlefield_height accelerate(param) #accelerate (max speed is 8, max accelerate is 1/-1, #negativ speed means moving backwards) stop #accelerates negativ if moving forward (and vice versa), #may take 8 ticks to stop (and you have to call it every tick) fire(power) #fires a bullet in the direction of your gun, #power is 0.1 - 3, this power will heat your gun turn(degrees) #turns the robot (and the gun and the radar), #max 10 degrees per tick turn_gun(degrees) #turns the gun (and the radar), max 30 degrees per tick turn_radar(degrees) #turns the radar, max 60 degrees per tick dead #true if you are dead say(msg) #shows msg above the robot on screen broadcast(msg) #broadcasts msg to all bots (they recieve &apos;broadcasts&apos; #events with the msg and rough direction) 最近关注 Ruby 比较多，平时工作中也会用 Ruby 来写一些脚本 (渐渐代替了 Python)。有两个原因，Ruby 的语法更符合口味 (不喜欢用 Python 的 indent 约束),Ruby 也更 Lisp 化，Ruby 的开源气氛非常好。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Ruby","slug":"Ruby","permalink":"http://catcoding.me/tags/Ruby/"}]},{"title":"Ruby's Block and Proc","date":"2012-11-14T11:43:00.000Z","path":"p/ruby_block_proc/","text":"Callable objects在 Ruby 当中一切都是对象，但是有一个例外，那就是 block。Block 和 Proc 类似，但是还是有稍有差别的，Block 更常用一些。最近在看《Metaprogramming Ruby》，在这节中有个例子是这样的。 require 'highline' hl = HighLine.new friends = hl.ask(\"Friends?\" , lambda {|s| s.split(',' ) }) puts \"You're friends with: #{friends.inspect}\" ⇒ Friends? Bill,Mirella,Luca You're friends with: [\"Bill\", \"Mirella\", \"Luca\"] 这里看起来 hl.ask 把 Proc 当作参数来传递，而不是接受了一个 block，接受 Block 是另外一种使用模式： require 'highline' hl = HighLine.new new_pass = hl.ask(\"password: \") { |prompt| prompt.echo = false } 在 highline 代码可以看到相应的处理方式，第一种方式 lambda 构造成的 Proc 其实传递给了 answer_type，而 yield 来处理 block。 def initialize( question, answer_type ) # initialize instance data @question = question @answer_type = answer_type # allow block to override settings yield self if block_given? Proc, Lambda, Block有三种方式转化 Block 为 Proc, Proc.new、Lambda、&amp;Operator。但是在使用过程中 Block 还是比 Proc 要常见，在给一个函数传递这种 callable objcts 的时候，可以隐式或者显示传递，像这样： def foo(*args) yield(args.join(' ')) end foo('Yukang', 'Chen'){|name| puts \"Hello #{name}\"} # => \"Hello Yukang Chen\" def foo(*args, &blk) blk.call(args.join(' ')) end foo('Yukang', 'Chen'){|name| puts \"Hello #{name}\"} # => \"Hello Yukang Chen\" 隐式传递要比显式传递 performance 要好一些。这很早就有讨论，具体原因是根据 Ruby 的实现一个 Block 在 yield 的时候并没有转换为 Proc 或者其他对象，所以少了一些开销。Ruby 中的函数块是高阶函数的一种特殊形式的语法，Matz 在设计块的时候考虑到： (1) 在高阶函数中，这种只有一个函数参数非常常见，在实际使用中几乎没有必要在一个地方使用多个函数参数，(2) 外观和形式上更直观，Enumerable 利用块写的代码简洁易懂。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Ruby","slug":"Ruby","permalink":"http://catcoding.me/tags/Ruby/"}]},{"title":"丽江印象","date":"2012-11-08T11:43:00.000Z","path":"p/lijiang/","text":"上周我们公司一行九个人去丽江开会、游玩了四天。我去之前心里还没什么期望的，不过在那边待了一段时间后对丽江的印象还是挺好的。其实像这种古镇以前也逛过不少，成都的和江浙一带的都去过，大多商业化比较严重。不过丽江的古镇确实是我见过的最大的，虽然说也是商业化，还是存在不少原生态的东西。我们去的时间也刚好还算是合适，避开了人流的高峰期，也还有暖暖的阳光。 关于住宿因为前面两天要讨论一些技术问题，所以刚到丽江住的是宾馆。在丽江古城的边缘地带，价格比较贵。如果是个人去旅游，坚决不要住宾馆，找个靠谱的客栈吧，比如我们后来一天所住的泡沫之夏就非常实惠，老板人也挺好。丽江古城的客栈非常多，而且据我观察不少看起来非常干净，有的还可以跟着客栈主人一起吃饭，价钱也便宜。当地人给人印象还算是朴实，也很容易和游客乐成一片。 关于吃饭第一天我们因为旅途劳累所以随便选择了一个古城边缘的饭店吃饭，气氛不错，就是有点小贵。其实丽江吃饭便宜又好吃的地方挺多的，找那些当地的特色馆子，我们去过的唠叨妈私房菜是个很好的馆子，里面有个唠叨妹特别好玩，唠叨妈开馆子不是为了多赚钱，价钱实惠份量又足。在人多的时候他们准备收拾收拾为自家做饭了，要不是我们人多都不会被接待。 关于艳遇在丽江到处都写着艳遇，艳遇乃丽江的另一个代名词。丽江的酒吧非常多，各种风格的都有，这歌声和酒精为所谓艳遇创造了条件。在丽江玩的人大多都比较放松，在那种环境下人的隔阂也会少一些，问问几个哲学基本问题搭讪基本没问题的。但我觉得大部分人都是普通旅客，所谓”艳遇”也不过是交个陌生朋友，谈谈旅行见闻而已。当然也有不少是单独在那边待着“疗伤”的，如果恰好能碰上聊得来的也算是缘分了。去酒吧泡着是丽江夜生活的常态，我们去了几个比较有名气的酒吧，其中江湖酒吧感觉是最好的，乐队的现场表演非常吸引人。我在丽江等你音乐要要轻一些。Bamboo 很有名因为小倩那首《一瞬间》是丽江今年的街歌，不过现场表演的效果不如江湖酒吧。后街 2 号就没有时间去了。 一点照片丽江的狗挺多，大多都还看起来很干净，无聊地天天在那里晒太阳。 江湖酒吧，小松的嗓音极好。 茶马古道上面那座山，因为时间紧张，所以我们没爬到山顶，遗憾。 拉市海附近非常漂亮，蓝天碧水。 拉市海旁边老太太的玉米，我所吃过的最好吃的玉米。 云南玩的地方还真是非常多，丽江附近可去的还有泸沽湖、玉龙雪山、香格里拉等等。有机会再去一次把这些地方看一看，最好能稍微多住一段时间。","tags":[{"name":"旅行","slug":"旅行","permalink":"http://catcoding.me/tags/%E6%97%85%E8%A1%8C/"}]},{"title":"Emacs iedit/occur 插件","date":"2012-11-05T11:43:00.000Z","path":"p/emacs-symbol-util/","text":"今天看到Mastering Emacs上介绍 iedit 插件的一篇文章。对于程序员来说，经常要重命名一个变量，之前我在 Emacs 下面使用替换命令来完成的，而 Iedit 可以编辑当前 buffer 里面多处相同的一个单词，编辑一处其他地方相同的 symbol 会自动被修改，这对于这样的操作是非常地直观有效，看下面这样的效果，图片来自Mastering Emacs。 最开始看到这个功能是在比较新的编辑器Sublime上，算是编辑器里一个很好的小创新吧。 另外在 buffer 中查找一个 symbol 也是经常需要的一个操作，我基本会用 (global-set-key [f3] 'highlight-symbol-next) (global-set-key [(shift f3)] 'highlight-symbol-prev) 来快速地在相同的 symbol 之间切换，这是来自 highlight-symbol.el 里面的。 同样的操作也可以用 occur-mode 来实现，occur 的好处在于可以在另外一个窗口列出所找到结果大纲，这样更方便快速跳到相应的位置，这对于任何类型的文件都可以使用，而不止是可能需要静态分析后生成 tags 的程序。在Mastering Emacs后面有一段代码使得 occur-mode 可以在当前所有打开的 buffer 里找关键字。","tags":[{"name":"Emacs","slug":"Emacs","permalink":"http://catcoding.me/tags/Emacs/"}]},{"title":"调优的小工具 RunLim","date":"2012-10-29T11:43:00.000Z","path":"p/runlim/","text":"在公司有同事用这个小程序RunLim来调试程序的内存问题。刚开始以为是我们上海的一个同事写的，就弄来看了看。后来发现是公司一个早期同事Armin Biere写的，还开源了，debian 的源里有这个东西。我在公司维护的一部分代码是这个人写的，据说厉害的程序员，他现在在学术圈里。 用这个小程序来测试程序跑的时间和内存，用法很简单： ./runlim prog.exe 比如： kang@ubuntu:~/download/runlim-1.7$ ./runlim sleep 1 [runlim] version: 1.7 [runlim] time limit: 311040000 seconds [runlim] real time limit: 311040000 seconds [runlim] space limit: 4294966090 MB [runlim] argv[0]: sleep [runlim] argv[1]: 1 [runlim] start: Tue Oct 30 00:02:52 2012 [runlim] main pid: 22546 [runlim] end: Tue Oct 30 00:02:53 2012 [runlim] status: ok [runlim] result: 0 [runlim] children: 0 [runlim] real: 1.63 seconds [runlim] time: 0.00 seconds [runlim] space: 0.5 MB [runlim] samples: 10 查看 help，这个工具还可以指定 time limit 和 space limit，在指定的时间和内存限制内强制退出程序，其功能很像那些Online Judge，只是没有检测结果输出是否正确。 发现代码里有一个小小的 Bug，根据源代码如果没有指定 space limit， space limit 那栏应该是当前的空闲内存大小，但是看我上面运行的命令，显示的 4294966090 MB 明显偏大，是其中的一个获取系统内存大小的函数溢出了。这里应该是这样： static unsigned get_physical_mb () { unsigned long long mem; mem = (unsigned long long)sysconf(_SC_PAGE_SIZE)* (unsigned long long)sysconf(_SC_PHYS_PAGES); return mem >>= 20; } sysconf 获取页大小和页数目，具体看这里How to get information about the memory subsystem?。 这个小工具还是查询/proc 下的进程统计信息的，根据 fork 出来的子进程 pid，递归地查询统计信息。 时间的统计可能会稍显粗略，如果需要更精确的时间统计该如何实现。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"RunLim","slug":"RunLim","permalink":"http://catcoding.me/tags/RunLim/"}]},{"title":"Ruby vs C++ for delegation","date":"2012-10-16T11:43:00.000Z","path":"p/delegate_ruby_cpp/","text":"下班之前同事 BigBird 给我 show 他的一段 C++ 代码，对于我等拿 C++ 当作 C 来用的未入门者实看起来实在是炫丽。虽然比较冗长晦涩，不过还是能看懂个大概，然后觉得这对于动态语言是非常容易实现的。 于是晚上回来用 Ruby 来搞搞，弄出下面这么段代码。 C++ 版本在这里https://gist.github.com/3900077。可见动态语言和编译型语言实现起来效率还是好太多了，同时代码也好理解。再次我讨厌 C++ 类型推导，^_^。 Ruby 实现这个方式很多，另外 Ruby 的库包含 SimpleDelegator 的，将调用的方法直接传递到其他对象。 #!/usr/bin/rubyclass Delegate attr_reader :proc_list def initialize() @proc_list = [] end def add(*proc) proc_list.push(proc) end def eval(obj) for e in proc_list: if obj.respond_to?(e[0]) if e.size == 1 obj.__send__(e[0]) else obj.__send__(e[0], e[1]) end else printf &quot;ERROR:%s is not defined\\n&quot;, e[0] end end endendclass Demo attr_writer :valuepublic def print() printf &quot;value:%d\\n&quot;, @value end def hello() printf &quot;Hello world!\\n&quot; end def set(val) @value = val endenddelegate = Delegate.new()delegate.add(&quot;print&quot;)delegate.add(&quot;set&quot;, 1)delegate.add(&quot;print&quot;)delegate.add(&quot;hello&quot;)delegate.add(&quot;nodefine&quot;)d = Demo.new()delegate.eval(d)","tags":[{"name":"Ruby","slug":"Ruby","permalink":"http://catcoding.me/tags/Ruby/"},{"name":"C++","slug":"C","permalink":"http://catcoding.me/tags/C/"},{"name":"delegator","slug":"delegator","permalink":"http://catcoding.me/tags/delegator/"}]},{"title":"UbiGraph 动态显示 Python 函数调用","date":"2012-09-27T11:43:00.000Z","path":"p/3d-python-call-path/","text":"UbiGraph 显示环境 UbiGraph是一个显示平台，可以非常方便地使用 Python/C/Ruby 来控制渲染，只需要制定节点和边还有其他相关属性，其余的都不用管了。其使用 XML-RPC 服务于客户端，所以甚至可以在一台机器上开 server，在另外一台机器上用渲染代码控制，这个环境对于算法和数据的可视化很有用。 比如： import ubigraphU = ubigraph.Ubigraph()U.clear()x = U.newVertex(shape=&quot;sphere&quot;, color=&quot;#ffff00&quot;)smallRed = U.newVertexStyle(shape=&quot;sphere&quot;, color=&quot;#ff0000&quot;, size=&quot;0.2&quot;)previous_r = Nonefor i in range(0,10): r = U.newVertex(style=smallRed, label=str(i)) U.newEdge(x,r,arrow=True) if previous_r != None: U.newEdge(r,previous_r,spline=True,stroke=&quot;dashed&quot;) previous_r = r 显示效果如下： 只是这个软件是免费的但不是开源的，另外还没有支持 Windows 平台。 使用 Ubigraph 显示 Python 函数调用这是在这里看到的，貌似需要翻墙。代码比较简单，在点击查看prof3d.py。 使用方法是先启动 Ubigraph 的 server，然后运行下面的代码： import prof3ddef run_main(): # your codeif __name__ == &quot;__main__&quot;: prof3d.profile_me() run_main() 这段 Python 的代码函数调用关系就显示出来了，而且还是动态的。 效果如下：","tags":[{"name":"Python","slug":"Python","permalink":"http://catcoding.me/tags/Python/"},{"name":"Tools","slug":"Tools","permalink":"http://catcoding.me/tags/Tools/"}]},{"title":"A*算法解决 kth-shortest 路径问题 (2)","date":"2012-09-18T11:43:00.000Z","path":"p/a-start-k-shortest/","text":"我之前写过一篇图文并茂的文章来介绍这个算法，有好几次有朋友反馈说对自己有帮助，深感荣幸。这次再次写这个也是因为帮忙于一个朋友解决这类问题，这里再成一篇，稍显罗嗦。 问题描述无向图 G，需要求出 S-&gt;T 点的前 k 短路径，要求路径中没有环。(所有的边的权值不为负) A*算法求解 kth-shortest 问题A*算法已经被广泛运用于路径规划问题中，同时A*算法作为一种启发式算法的框架，可用于多种搜索问题，还是先回顾一下A*的基本符号： f(s)=g(s)+h(s)，其中h(s)&lt;=h*(s)，h*(s)是某点到终点的真实代价，h(s)是估计代价，并且对 s 的任意后继 t 有：h(t)+w(s,t)&gt;=h(s)，其中w(s,t)是从 s 转移到 t 的代价，符合这条件的评估函数f(s)可以得到正确的最短路径。 而这里评估函数f(s)是A*算法的关键，其效率都取决于此，退化的A*算法就是宽度搜索 (即启发函数 h(s) 为常数)。另外A*算法的最优性证明在这篇论文里有阐述。 所以如果能确切的计算出来h*(s)，那么评估函数 f(s) 将是 s 点的最短路径，这可算是一个最优的启发函数。可以利用 Dijkstra 算法来求解出各个点到 T 点的最短路径，假设第 i 个节点到 T 的最短路径计为Dist_T(i)，Dist_T(i)作为A*函数中的启发函数h(s)，从 S 开始搜索，因此算法描述如下： int Astar()&#123; if(dist[S]==INF) return -1; priority_queue&lt;Node&gt; Q; //极小堆，定点为 f(s)=g(s)+h(s) 最小的节点 Q.push(Node(S,0)); //源点 S 加入堆，估计代价为 0 while(!Q.empty())&#123; int len=Q.top().len; int u=Q.top().v; Q.pop(); cnt[u]++; //节点 u 访问一次 if(cnt[T]==K) return len; //第 K 次从队列弹出的值为 kth-shortest 的值 if(cnt[u]&gt;K) continue; for(int i=0;i&lt;Adj[u].size();i++) &#123;//取 v 节点的临接节点计算评估函数并加入优先队列 int v = Adj[u][i].v; int eval = len + Dist(u,v) + Dist_T(v); Q.push(Node(v, eval)); &#125; &#125; return -1;&#125; 因为没有标识哪些节点访问过哪些节点没有访问过，所以这种方法计算出来的结果路径可能含有环，即可能出现 1-&gt;2-&gt;3-&gt;2-&gt;5，为了避免这样的情况可以在每个扩张 Node 里面增加当前路径已经访问过的点，在进行下一次扩张的时候可以避免访问这些已经在路径中的节点。但是这样所需要的空间复杂度是巨大的，所以需要再次用一些剪枝办法来避免过多的扩展。 一个优化A*算法在扩展节点的时候，如果我们能筛除掉更多无用的节点，那么都可以利于减少搜索的空间复杂度和时间复杂度。当 k 取值较小的时候，即当我们并不需要知道所有路径长度和其排序，而只需要知道前 k(假设 k&lt;=10) 段的路径，这里加上一个剪枝会有很大的优化。 假设我们事前知道 kth-shortest 的最大值，就能在扩张的时候加入这个限制，避免大部分的无用的节点扩张。 for(int i=0;i&lt;Adj[u].size();i++) &#123;//取 v 节点的临接节点计算评估函数并加入优先队列 int v = Adj[u][i].v; int eval = len + Dist(u,v) + Dist_T(v); if(eval &gt; max_dist) continue; else Q.push(Node(v, eval));&#125; 如何知道 kth-shortest 的最大值这个临界点呢？ 假设我们知道某条经过点 v 的 S-&gt;T 路径的最短长度，即对于所有的点 v1,v2,v3,….vn，有 dist(v1) 为 S-&gt;…-&gt;v1-&gt; …-&gt;路径的长度，一共 n 个 dist，把这 n 个 dist 排序以后，取第 k 小的 dist(v_kth_smallest) 即为 kth-shortest。如何计算出 dist(v)，通过 Dijkstra(T) 可以计算出 v 到 T 的最短路径，同样可以通过 Dijkstra(S) 可以计算出 S 到 v 的最短路径 Dist_S(v)，这里有如下定理： 对于任意最短路径 S-&gt;K 中，假设经过点 v，则必有: min(S-&gt;v) 和 min(v-&gt;T)。因此要计算经过 v 的从 S-&gt;K 的最短路径可以用: min_dist(v) = Dist_S(v) + Dist_T(v) 因此如果我们用这种方法计算出 Dist(v)，那么最后第 k 小的 dist(v_kth_smallest) &gt;= kth-shortest。这对于A*算法的最后结果没有影响，但是同样可以作为一个条件来删除掉大部分不符合条件的节点，因此得到一个很好的优化方案。这个优化可以用于k&lt;N时的 kth 最短路径问题，可以预见 k 越小剪枝效果越好。 据我实现在 18600 个节点的图上，这个算法比Yen’s 算法快了很多倍，甚至在我的 PC(3G 内存) 机上，后者在算到 k=3 的时候内存就支持不住了。 算法复杂度分析假设图 G 有 m 条边和 n 个节点，Dijkstra 算法的复杂度为((m+n)log n)(二叉树实现的优先队列)。A*算法的时间复杂度取决于启发函数，事实我还不清楚如何分析这样的算法的时间复杂度和空间复杂度，根据这篇文章来说是O(delta*V^2*(lgV+lg(delta)))的。 如果哪位知道如何分析 A*算法的复杂度，劳烦请教。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Algorithms","slug":"Algorithms","permalink":"http://catcoding.me/tags/Algorithms/"}]},{"title":"换域名了 cyukang.com","date":"2012-09-13T11:43:00.000Z","path":"p/change-domain-name/","text":"昨天晚上突然发现自己的域名moorekang.com不能用了，上午问了一下域名提供商 Bloghost，原来因为双方沟通上的问题导致我的域名没及时续费，甚至进入了赎回期，在这个时候只有这么几种选择： 换一个域名 赎回自己原来的域名，价格不太便宜，国际域名和国内域名也有差别，我的需要 150 美金 等域名过了赎回期再重新购买，期间需要等待 40 来天左右 所以，血的教训啊，及早续费自己的域名，免得面临这么一个窘境。无奈，我选择了换域名，虽然原来那个稍显长的域名已经用了近两年多。稍微找了一下，觉得这个域名cyukang.com还比较短，于是就申请了下来。国际域名不用各种备案，所以几分钟就下来了。另外对于 Jekyll 和 GitPage 这样的组合，换域名是多么的简单，几分钟就搞定了，所以这次折腾也没花多少时间。 另外我觉得 twitter 这个主题已经够简洁了，今天稍微做了一下改动，用我仅有的一点 css 知识让顶部的导航栏固定下来。 有我链接的麻烦换一下，呃，其实也没几个人用我做友链:)，不过还是得喊一声的。 –","tags":[]},{"title":"OS dev 的 Bochs 调试","date":"2012-08-19T11:43:00.000Z","path":"p/os-dev-debug/","text":"最近在弄一个自己的 hobby OS，作为菜鸟在调试时候积累一些经验，记录一下。 Bochs 调试Bochs 自带调试功能，但是如果你是 apt 装上的是不行的，下源码来自己编译，编译选项为： ./configure --enable-debugger --enable-disasm 这个我只是尝试过，在 OS 的 loader 阶段可能会用到，当如果进入 C 语言实现部分的代码如何调试？我希望看到 C 的源码级别调试，而不是汇编的。 Bochs + gdb 调试同样需要在编译的时候加上选项，这个选项必须注意，否则在 gdb 调试的时候会出现”Cannot find bounds of current function”之类的问题。 ./configure --enable-debugger --enable-disasm --enable-gdb-stub 诡异的是这个–enable-gdb-stub 选项和上面的 –enable-debugger 选项只能二选一。也行，编译出来后重命名吧。编译完成后在 Bochs 的配置文件.bashrc 中加上这么一行： gdbstub: enabled=1, port=1234, text_base=0, data_base=0, bss_base=0 另外注意 kernel 的代码也需要加入-g 编译选项。最后在编译完成后的文件是带调试信息的，但是我们在用 Bochs 启动的 img 文件不需要这些，现在比如 kernel.elf 是带编译信息的 kernel文件，用下面的这个步骤去掉调试信息，据说也可以用 strip 来。 cmd=&quot;objcopy -R .pdr -R .comment -R .note -S -O binary kernel.elf kernel.bin&quot; cat boot.bin setup.bin kernel.bin &gt; ../a.img; Bochs 使用的是这个 a.img 文件， gdb 载入的是 kernel.elf 文件。 启动 Bochs 后会等待 gdb 连进来 (其实 Qemu 也可以这样进行调试的)，查资料过程中发现还可在调试的目录加上.gdbinit，这样每次启动 gdb 就不那么麻烦了： file ./objs/kernel.elf target remote localhost:1234 set disassembly-flavor intel b kmain 一些有用 tipsOS 的代码中经常会有内联汇编，有的时候一条内联过去就崩溃了，所以在 gdb 里需要查看反汇编语句和 registers。下面这些 gdb 指令比较有用： (gdb) info line main.c:26 (查看 main.c:26 行在目标文件中的位置，为 0x1cbc) Line 26 of &quot;./kernel/main.c&quot; starts at address 0x1cbc &lt;kmain&gt; and ends at 0x1cc2 &lt;kmain+6&gt;. (gdb) info line *0x1cbc (上面的反操作) Line 26 of &quot;./kernel/main.c&quot; starts at address 0x1cbc &lt;kmain&gt; and ends at 0x1cc2 &lt;kmain+6&gt;. (反汇编 kmain 函数，箭头指向的是当前运行的汇编代码) (gdb) disas kmain Dump of assembler code for function kmain: =&gt; 0x00001cbc &lt;+0&gt;: push ebp 0x00001cbd &lt;+1&gt;: mov ebp,esp 0x00001cbf &lt;+3&gt;: sub esp,0x28 0x00001cc2 &lt;+6&gt;: mov eax,DWORD PTR [ebp+0x8] 0x00001cc5 &lt;+9&gt;: mov ds:0x5ccc,eax 0x00001cca &lt;+14&gt;: call 0x2a29 &lt;init_video&gt; 0x00001ccf &lt;+19&gt;: mov DWORD PTR [esp+0x4],0xb 0x00001cd7 &lt;+27&gt;: mov DWORD PTR [esp],0x4777 0x00001cde &lt;+34&gt;: call 0x2a40 &lt;puts_color_str&gt; 0x00001ce3 &lt;+39&gt;: mov DWORD PTR [esp+0x4],0xa 0x00001ceb &lt;+47&gt;: mov DWORD PTR [esp],0x478d 0x00001cf2 &lt;+54&gt;: call 0x2a40 &lt;puts_color_str&gt; 0x00001cf7 &lt;+59&gt;: cli 0x00001cf8 &lt;+60&gt;: call 0x3876 &lt;time_init&gt; 0x00001cfd &lt;+65&gt;: call 0xc13 &lt;gdt_init&gt; 要正确的看到反汇编最好设置好 gdb 里面的汇编指令集，对于 Nasm 设置”set disassembly-flavor intel”,在.gdbinit 里面弄好就行。 最后 info registers 查看 cpu 寄存器内容，info registers %eax 只查看 eax 内容，而info all-registers 会把 cpu 的所有寄存器内容显示出来，不过 cr0,cr3 这些貌似没有 :(。看看这里 GDB 参考。","tags":[{"name":"debug","slug":"debug","permalink":"http://catcoding.me/tags/debug/"},{"name":"bochs","slug":"bochs","permalink":"http://catcoding.me/tags/bochs/"},{"name":"OS","slug":"OS","permalink":"http://catcoding.me/tags/OS/"}]},{"title":"Linux 下快捷切换屏幕","date":"2012-08-09T11:43:00.000Z","path":"p/switch-screen/","text":"在办公室工作的时候一般面对两个显示器，大部分时候左边用来看代码，右边用来写程序。双显示屏还是有助于提高工作效率的。有一点困扰我的是如果要切换屏幕一般得用鼠标，这对于Emacs 党是有些不能忍受的，右手离开键盘总是得停顿一下的感觉。今天找到一个解决办法。 最终找到的是这个号称 Linux 下键盘精灵的一个程序：xdotool，下载下来编译安装。这个东西可以模拟鼠标和键盘的行为： 比如： xdotool search &quot;Mozilla Firefox&quot; windowactivate --sync key --clearmodifiers ctrl+l (快速切换倒 firefox，并 focus 在地址输入栏)xdotool getmouselocation --shell (获取当前鼠标位置等信息)X=880Y=443SCREEN=0WINDOW=16777250xdotool getactivewindow windowmove 100 100 # Moves to 100,100xdotool getactivewindow windowmove x 100 # Moves to x,100xdotool getactivewindow windowmove 100 y # Moves to 100,yxdotool getactivewindow windowmove 100 y # Moves to 100,yxdotool mousemove --screen 0 100 100 # Moves to screen 0 pos at 100,100 有了上面 windowmove 命令，屏幕的切换就好实现了。写个丑陋的 python 脚本来保存当前的位置，切换到另外一个屏幕，再次调用的时候返回到原来的位置，保存为 mouse.py。 #!/usr/bin/pythonimport osimport sysimport commandsdata_f = &quot;/tmp/window_data&quot;now_info = commands.getoutput(&quot;xdotool getmouselocation --shell&quot;).split(&#x27;\\n&#x27;)x = (now_info[1])[2:]y = (now_info[2])[2:]screen = (now_info[3])[7:]window = (now_info[4])[7:]def do_store(): data = open(data_f, &quot;w+&quot;) content = screen+&quot;\\n&quot;+x+&quot;\\n&quot;+y+&quot;\\n&quot;+window data.write(content) data.close() def do_update(): if screen == &quot;1&quot;: new_sc = &quot;0&quot; else: new_sc = &quot;1&quot; cmd = &quot;xdotool mousemove --screen &quot; + new_sc + &quot; 0 0&quot; commands.getoutput(cmd)if os.path.exists(data_f): data = open(data_f, &quot;r+&quot;) content = data.readlines() data.close() screen = content[0][0:-1] old_x = content[1][0:-1] old_y = content[2][0:-1] old_window = content[3] if old_window != window: cmd = &quot;xdotool mousemove -w &quot; + old_window + &quot; &quot; + old_x + &quot; &quot; + old_y commands.getoutput(cmd) do_store() else: do_store() do_update()else: do_store() do_update() 最后，通过 Emacs 下绑定快捷键来调用这个脚本即可实现两个屏幕之间的切换，又可以远离鼠标了。哈哈。 (defun switch-screen() (interactive) (start-process \"mouse.py\" nil \"bash\" \"-c\" \"/home/yukang/apps/bin/mouse.py\")) (global-set-key (kbd \"C-x q\") 'switch-screen) Jekyll 下写点东西快多了。","tags":[{"name":"Tools","slug":"Tools","permalink":"http://catcoding.me/tags/Tools/"},{"name":"Linux","slug":"Linux","permalink":"http://catcoding.me/tags/Linux/"}]},{"title":"分支预测优化","date":"2012-07-11T11:43:00.000Z","path":"p/branch_prediction/","text":"问题Stack_overflow 上有这么一个帖子：为什么排序后会快很多，说是下面这段代码比较诡异，引发了比较多的回复，一起来看看。 #include &lt;algorithm&gt;#include &lt;ctime&gt;#include &lt;iostream&gt;int main()&#123; // generate data const unsigned arraySize = 32768; int data[arraySize]; for (unsigned c = 0; c &lt; arraySize; ++c) data[c] = std::rand() % 256; std::sort(data, data + arraySize); //排序这行不注释掉下面的 for 循环会快得多 // test clock_t start = clock(); long long sum = 0; for (unsigned i = 0; i &lt; 100000; ++i) &#123; // primary loop for (unsigned c = 0; c &lt; arraySize; ++c) &#123; if (data[c] &gt;= 128) sum += data[c]; &#125; &#125; double elapsedTime = static_cast&lt;double&gt;(clock() - start) / CLOCKS_PER_SEC; std::cout &lt;&lt; elapsedTime &lt;&lt; std::endl; std::cout &lt;&lt; &quot;sum = &quot; &lt;&lt; sum &lt;&lt; std::endl;&#125; 如果把 std::sort(data, data + arraySize);注释掉，下面那段 for 循环所花费的时间是 11.54 秒。 如果不注释掉，即排序后下面那段所用的时间是 1.93 秒。 相差比较大。那个 for 循环总是要执行完的，为什么排序后会快不少？ 分支预测 下面的获得票数最多的回复质量非常高，很生动细致地说明了 cpu 的分支预测技术。 看上面这情形，如果在没有通讯设备的年代，如果你是这个火车枢纽的操作人员，是不是要让火车驾驶员把车停下来，然后告诉你他需要往哪个方向行驶，等你完成转向操作的时候再继续行驶火车呢。也许有一些更好的办法，你可以猜测火车要往哪边行驶。 如果你猜对了，那么节省了不少时间。 如果猜错了，火车停下来，等你撤销刚才的操作，再往前走，这会比较耗费时间。 同样在执行指令的时候，cpu 也能做这样类似的工作。现代 cpu 都采用 指令流水线技术 ，即处理器会预取下面要执行的一些指令，如果下面的指令正是需要被执行的那就节省了时间，如果在概率上大部分能猜对下面要运行的指令，那就提高了 cpu 的运行效率。更详细的图文介绍可以参考wiki。简单的说明就是 cpu 会根据前面所执行的指令的历史，归纳出相应的模式，把预测的指令预取进来，然后继续沿着预测的指令执行。如果发现预测错误，则倒过来重新初始化预测表、刷新指令管道然后继续执行。所以看上面的例子： T = branch takenN = branch not takendata[] = 0, 1, 2, 3, 4, ... 126, 127, 128, 129, 130, ... 250, 251, 252, ...branch = N N N N N ... N N T T T ... T T T ... = NNNNNNNNNNNN ... NNNNNNNTTTTTTTTT ... TTTTTTTTTT (easy to predict) 后面作者又加了一条 hack，把这段代码重新改写一下： if (data[c] &gt;= 128) ====&gt; int t = (data[c] - 128) &gt;&gt; 31; sum += data[c]; ====&gt; sum += ~t &amp; data[c]; 那么前面是否排序就对这段代码效率没有影响了，同样是 2 秒多。 这和编译器的优化非常相关，不同的编译器的结果不一样，4.6.1 GCC 加上-O3 或者-ftree-vectorize 编译选项可以对这种情况进行优化，所以排序与否没有关系，而 VC++2010 却不能进行类似优化 (GCC 果然强大)。 一个优化例子 在 Linux kernel 里面会看到类似 likely 和 unlikely 这样的代码，从其名字就很直观的解释了其意义。看其定义为两个宏。 include/linux/compiler.h#define likely(x) __builtin_expect (!!(x), 1)#define unlikely(x) __builtin_expect (!!(x), 0) Linux 内核开发者使用这两个宏来通过编译器提示 cpu：某一段代码很可能会执行，应该被预测，而有的情况出现的概率比较小，不必预测。类似这样的代码： if(likely(some_cond)) &#123; //this is often happen! /* Do something */&#125;if (unlikely(some_cond)) &#123; //this is rare! /* Do something */&#125; 关于这个方面，在这篇论文What every Programmer should know about Memory里面有更详细的讲述。分支预测在现代 cpu 上如此通用，竟然还有人利用这个来尝试破解 RSA 的，看这个On the Power of Simple Branch Prediction Analysis。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"优化","slug":"优化","permalink":"http://catcoding.me/tags/%E4%BC%98%E5%8C%96/"},{"name":"分支预测","slug":"分支预测","permalink":"http://catcoding.me/tags/%E5%88%86%E6%94%AF%E9%A2%84%E6%B5%8B/"}]},{"title":"GDB 调试动态链接库","date":"2012-06-25T11:43:00.000Z","path":"p/gdb-with-libso/","text":"今天解决了一个长期会碰到的问题，就是用 GDB 如何来调试动态链接库。我这个问题的难点是我的需要调试代码是在动态链接库里面，但是启动的不是普通的可以调试的二进制文件，换句话说这不是我所能控制的代码所编译出来的，甚至可能是由脚本程序来控制启动的。这个问题时不时地困扰着我，总结一下尝试过几种调试方式： 1 使用 print 来打印 log，有时候有用，不好的地方是有时候定位出问题的代码位置还是稍显麻烦。很常用的会定义一对宏，进入函数和退出某个函数的时候都相应调用。 #define APP_LOG(X) \\ fprintf(stderr, &quot;log: %s %d %s %s\\n&quot;, \\ __FILE__, __LINE__, __FUNCTION__, X); \\#define LOG_ENTER \\ APP_LOG(&quot;enter&quot;) #define LOG_LEAVE \\ APP_LOG(&quot;leave&quot;) 2 对于 crash 掉的 bug，打印出来调用栈是非常有用的。使用libc 提供的 Backtraces 函数来获取调用栈。这是在不能提供 GDB 环境下拿到调用栈的不错方法。不过经过我的实验这对于动态链接库有一定的问题。 3 最后就是今天试用的比较通用办法。 我们不管是如何调用到动态链接库文件的，但是肯定会调用进来。所以需要想办法让代码在库代码处停下来，然后把找机会把 GDB 弄进去。于是乎有这么一个变态的办法，在动态链接库入口处来这么一段，就是执行到这里停住，等待 GDB attach 这个进程，然后在 GDB 里设置一个断点，touch 创建当前文件夹 debug 文件就跳出死循环，接下来就是一切在 GDB 控制下了。 void wait_attach() &#123; fprintf(stderr, &quot;Waiting attach pid: %d\\n&quot;, getpid()); while(1) &#123; if((access(&quot;./debug&quot;, F_OK)) != -1) &#123; break; &#125; else ; &#125;&#125; 这是一个 stupid and work 的方法，不过我总觉得还有更好的办法来在这种情况下调试。 在查找资料的过程中有点意外收获，顺便推荐 GDB 一个选项，gdb -tui，以 texture gui 方式启动 GDB，这是非常方便的文字界面。如果不用这个选项也可以在运行 GDB 以后按下快捷键盘 C-x C-a(怎么这么像 Emacs 快捷键) 来进行 gui 和非 gui 的切换。CLI 爱好者可以试用一下，DDD 什么的可以放下了，嘿嘿。 另外一些有用的 GDB 命令： rbreak: break on function matching regular expressionwhere: Line number currently being executedtbreak: Break once, and then remove the breakpointwatch: Suspend the process when a certain condition is metfinish: Continue till end of functioninfo locals: View all local variablesbacktrace full: Complete backtrace with local variablesup, down, frame: Move through framesset print pretty on: Prints out prettily formatted C source codeset print array on: Pretty array printingenable and disable: Enable/disable breakpointsset logging on: Log debugging session to show to others for support","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"gdb","slug":"gdb","permalink":"http://catcoding.me/tags/gdb/"},{"name":"debug","slug":"debug","permalink":"http://catcoding.me/tags/debug/"}]},{"title":"bsfl 指令和 Bitmap 的一个优化","date":"2012-06-20T11:43:00.000Z","path":"p/bsfl-bitmap/","text":"如何找出 int 中第一个 1对于这个问题我们可以从最原始的做法开始，如果没找到 1 返回 0，如果第一位为 1 返回 1。所以代码很简单如下： static int first_onebit(int x)&#123; if(!x) return 0; else&#123; int idx = 0; if(x%2 != 0) return 1; while( x%2 == 0 ) &#123; x&gt;&gt;=1; idx++; &#125; return idx+1; &#125;&#125; 如何能做到更好呢？这里有一个 trick 使用一条指令来完成这个工作，具体可以参考Linux Kernel 里面这个 ffs的代码。我来简化一下就是这么一个函数： /* ffs: if ret == 0 : no one bit found return index is begin with 1 */static int first_onebit(int x)&#123; if (!x) &#123; return -1; &#125; else &#123; int ret; __asm__(&quot;bsfl %1, %0; incl %0&quot; : &quot;=r&quot; (ret) : &quot;r&quot; (x)); return ret; &#125;&#125; 这里的 bsfl 是一条 intel 汇编指令，它的用法是 bsfl op1,op2:顺向位扫描从右向左（从位 0–&gt;位 15 或位 31）扫描单节字或双字节操作数 op2 中第一个含”1”的位，并把扫描到的第一个含’1’的位的位号送操作数 op1 中，所以就是一条指令完成了这个计算过程。 这里真的会有多大的差别么，我们可以用程序来计算一下，测试如下： int main()&#123; int x; for(x=0; x&lt;=1000000000; x++)&#123; first_onebit(x); &#125; return 0;&#125; 第一个版本花费时间 15.685s，第二个版本花费时间 5.960s，而其实如果只是循环 1000000000 次什么也不做也好花费 3.091s，所以第二个版本快到如此程度。 bitmap 的优化bitmap 是一种常用的数据结构，在编程珠玑有详细介绍，应用也比较广泛比如可以用来做操作系统当中的地址索引查询。对于 bitmap 中我们常常需要一个操作来找一个空位的 bit 来做 set 操作。既然我们知道了第一个 1 是如何快速查找的，第一 0 也就好办了，先取反，然后再找第一个 1 就行了。 #define first_zerobit(x) (first_onebit(~(x))) 继续 bitmap 的 first_empty 就优化成这样了： u32 first_empty()&#123; u32 idx; for(idx=0; idx&lt;max_idx; idx++)&#123; if(arr[idx] == 0xFFFFFFFF) //full continue; u32 v = arr[index]; return 32*idx + first_zerobit(v) - 1; &#125; return -1;&#125; 注意这样的用汇编指令来优化可能会有平台差异，所以你最好清楚自己的平台是否适用。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"bitmap","slug":"bitmap","permalink":"http://catcoding.me/tags/bitmap/"}]},{"title":"使用 Jekyll 和 Github 搭建博客","date":"2012-06-13T11:43:00.000Z","path":"p/try-jekyll-git/","text":"为什么要折腾折腾了几次终于把博客从 wordpress 搬到 Github 了，迁徙这事本来是够麻烦的，而且也比较无聊。不过最终还是抑制不住诱惑，这有下面几点点好处。 编辑方便，专注写作 在线下编辑，可以随便选择自己喜欢的编辑器。当然 wordpress 也有离线编辑工具，不过 Linux 下我还没找到合适的，我平常是用Muse生成 html，然后再粘贴到站上。其实还好，就是插入图片不方便。使用 Github 和 Jekyll 是完全的离线，你甚至都不需要离开终端就可以发布文章，一切都只是简单的 git push 而已。写的过程中还可以用 jekyll –server 预览最终排版。 可以使用 Github 进行版本管理 像写程序一样写日志，这对程序员吸引很大。我用这个小脚本来完成发布： #!/bin/shdo_commit() &#123; cmd=&quot;git commit -a -m\\&quot;$log\\&quot;&quot; echo $cmd git add .; git commit -a -m&quot;$log&quot; git push;&#125;while [ $# -gt 0 ]do case $1 in -commit |-u) shift; log=$1; do_commit; exit 0;; esac shiftdone 简洁 我喜欢这套是因为感觉一切都很简单，在_post 目录下写 markdown 格式的文章，生成网页、push 上去就发布了。页面也非常整洁，这对于一个以文字和代码为主要内容的站点来说最合适不过了。而且因为生成的全是静态网页，所以打开的速度也非常快。 折腾过程 这套工具适合程序员，因为一切都可以在本机上操作，你可以自己写程序来批量处理文档。我是自己写了一点 Python 小程序转移图片。 迁徙的过程中也会碰上一些问题，不过如果你懂一点 Ruby，这些都还是比较好解决的。基本步骤为： 申请 GitHub，这个不少程序员有，直接跳过。 安装 Jekyll 在本地，可能会遇上 ruby 版本的问题，我的机子上是 1.8.7，需要 1.9.2，使用rvm来解决，具体参考这里。具体使用下面一些命令： sudo apt-get install gems curlgem install rvmrvm get latest rvm reloadrvm install 1.9.2rvm use 1.9.2ruby -v #(use 1.9.2)gem install directory_watcher liquid open4 maruku classifier jekyll 再建立 yourname.github.com 项目，git clone jekyll bootstrap到自己的代码库。 从 wordpress 迁徙，我使用 wordpress.xml 这个方法，最后修改域名解析就大功告成了。修改域名的时候在 Git 上建立 CNAME 为 demo.com，在 DNS 处设置 demo.com 的 A 记录到 Github 的地址 (207.97.227.245)，同时为了使得 www.demo.com 也指向 GitHub，设定www 的 A 记录到这个地址。这是我设置的时候出错了的地方。 整个流程非常简单，你甚至可以在三分钟内完成 Github 的博客搭建，更相详细可以参考这里这里。","tags":[{"name":"jekyll","slug":"jekyll","permalink":"http://catcoding.me/tags/jekyll/"},{"name":"git","slug":"git","permalink":"http://catcoding.me/tags/git/"}]},{"title":"Find duplicated Number and Cycle detection","date":"2012-04-11T11:43:00.000Z","path":"p/find-duplicated-cycle-detection/","text":"一个有趣的问题，据说这个题目耗费了 Don Knuth 24 小时解决。一起来看看。 You are given an array of integers of length n, where each element ranges from 0 to n - 2, inclusive. Prove that at least one duplicate element must exist, and give an O(n)-time, O(1)-space algorithm for finding some duplicated element. You must not modify the array elements during this process. 这有几个重要的约束，O(n)，O(1) 的复杂度，不能修改这个数组。可能有多个数重复了，但至少有一个数重复了。首先第一个证明问题，等价于 n 个鸽子，n-1 个笼子，那么至少有一个笼子里面有 2 个鸽子，就是鸽笼原理 (抽屉原理), 反证法可以证明。难的是第二个问题，假设 a[0, n], 值都在 0,1, …, n-2 范围内。如果扫描这个数组，重复的会出现第二次 (废话，囧)，关键是只能用 O(1) 的空间，否则用空间记录出现过的就行了。如果把数组看成一个映射，i -&gt; f(i) = a[i]， 那么这个问题可以转换成更抽象的模型。 举个例子： n = 6index: 0 1 2 3 4 5value: 1 4 0 0 3 2 其 index 对应 value 映射为为 0-&gt;1, 1-&gt;4, 2-&gt;0 等等，那么把这个图画出来就是这样： &nbsp; 这个问题转换为求图中环开始的点，因为出现环说明某个点重复出现了。从 5 开始遍历这个图会在 0 处发现环，为什么选取 5，因为 5 肯定为一个起点，并且不在 0~N-2 内。其实只要选取不孤立的那个点当作起点就可以检测环，极端情况比如： n = 6index: 0 1 2 3 4 5value: 0 1 2 4 5 3 选择 index=5 还是可以发现环，如果选取 0 就发现不了 3 和 4,5 之间的那个环。 [Cycle detection] 是一个经典的计算机问题。经典的算法是 Floyd’s cycle-finding algorithm，这个算法简单而优美。严格的数学证明当然可以，也能更明显的从现实经验得出结论。如果一个赛道中间出现某个环 (分两种情况，赛道本身是环、赛道前面有一段没环而中间出现一个环 9 字形)，求这个环的周长 C。让两位运动员同时出发，并且 P1 的速度是 P2 的两倍，当他们第一重新相遇的时候，一定是在环的某个点上，并且其路程之差为这个环的周长的 K 倍 (K&gt;=1)，这解决了一部分问题，我们知道了 KC 的值，如果 K==1，则得出结果，说明两人刚好是在环开始点相遇。否则就是在环内其余点相遇，可以得知现在 P2 的路程为 KC(P1 的路程为 2KC), 如果让 P3 以和 P2 同样的速度从起点开始，P2 继续从相遇点开始跑，那么 P2 和 P3 肯定还会相遇，并且相遇的点一定为环开始点！回到这个问题，这个 index 的值就是重复的值。代码描述如下： int detectCycle(int* seq， int Num)&#123; int slow = Num -1; int fast = Num -1; while(1) &#123; slow = seq[slow]; fast = seq[seq[fast]]; if(slow == fast) break; &#125; int finder = Num - 1; while(1) &#123; slow = seq[slow]; finder = seq[finder]; if(slow == finder) break; &#125; return finder;&#125; 算法描述很简单，但其中思维的却很有乐趣。以前同样有一个问题，检测一个链表是否有环，这是由此出来的一个特例，因为对于一个链表的每个节点除了头节点都有一个前节点和后节点 (无环则末节点指向空)，而图是一个更通用的模型。 bool hasCycle(ListNode *head) &#123; ListNode* slow = head; ListNode* fast = head; while(fast &amp;&amp; fast-&gt;next) &#123; slow = slow-&gt;next; fast = fast-&gt;next-&gt;next; if(slow == fast) return true; &#125; return false;&#125;","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Algorithms","slug":"Algorithms","permalink":"http://catcoding.me/tags/Algorithms/"}]},{"title":"eproject","date":"2012-03-08T11:43:00.000Z","path":"p/eproject/","text":"我之前一直用的是 project-mode.el 来管理项目，在碰上代码很多的工程时还是有点不方便，源文件太多速度有点慢。快速检索文件还是可以，需要指定代码目录，可以增加目录。工程的概念还是不太直观，主要用来快速查找文件。 以前看有同学推荐过 eproject，当时没仔细看。这会儿想自己写一个，而今天偶尔试用了一下这个eproject.el这才是真正需要的好东西啊。 一个工程包含的是经常需要访问的文件，另一个重要的地方是可以自己绑定 Make, clean, run, configure 等命令。 一组常用命令加文件检索，非常方便。看下面的配置文件很清楚，make 绑定到了一组命令。 (setq prj-tools &apos;((&quot;Make&quot; &quot;cd ~/source/Panda/; ./run.sh -c;&quot; &quot;f9&quot;) (&quot;Clean&quot; &quot;cd ~/source/Panda/; ./run.sh -x;&quot; &quot;C-f9&quot;) (&quot;Run&quot; &quot;cd ~/source/Panda/; bochs;&quot; &quot;f8&quot;) (&quot;Stop&quot; &quot;-e eproject-killtool&quot; &quot;C-f8&quot;) (&quot;Configure&quot; &quot;./configure&quot; nil） (&quot;Explore Project&quot; &quot;nautilus --browser `pwd` &amp;&quot; nil) (&quot;XTerm In Project&quot; &quot;xterm &amp;&quot; nil)) 另外再推荐一个扩展viewer.el, 这个可以模拟 vi 里面的快捷键，其实我不是觉得 vi 的快捷键好，而是 vi 分为几个模式，编辑模式、浏览模式。这对 emacs 有些用，因为往往我打开一个文件只是看看，编辑的时候少，有时候按错了键使得文件内容不经意就改变了。所以通过这个扩展，默认打开一个文件都是浏览模式，还可以设置和 vi 一样的移动光标的快捷键，当需要进行编辑操作的时候按下 i 键进入编辑模式。状态栏可以显示当前所处的模式。 (add-hook ‘find-file-hook ‘view-exist-file) (global-set-key (kbd “C-o”) ‘view-mode)","tags":[]},{"title":"A Emacs func","date":"2011-12-21T11:43:00.000Z","path":"p/a-emacs-func/","text":"这个操作好像经常要用到，拷贝当前光标连续的一段字符串 (除了空白和换行), 写了个小函数来实现。 (defun get-continue-string () (interactive) (skip-chars-backward &quot;^ \\n&quot;) (setq low (point)) (skip-chars-forward &quot;^ \\n&quot;) (setq high (point)) (copy-region-as-kill low high) (message (buffer-substring low high)))(global-set-key (kbd &quot;C-x y&quot;) &#x27;get-continue-string)","tags":[{"name":"Emacs","slug":"Emacs","permalink":"http://catcoding.me/tags/Emacs/"},{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"}]},{"title":"A Basket-Ball Demo","date":"2011-10-20T11:43:00.000Z","path":"p/basketball/","text":"最近闲暇时间用 C++ 写了个小 Demo，一个小小的篮球模拟。在学校的时候看过《人工智能编程精粹》，里面有个足球模拟，看起来还比较逼真。我这个篮球模拟是比较类似的，主要好玩的地方是在于状态机。图形方面做得很简单，还是用 OpenGL 来实现的，另外用了一个库 glui，这个东西很好，把 GUI 方面琐碎的事情就简化了。整个效果图如下，这可是湖人对火箭噢。 调试状态机是个很有趣的过程，每一个球队有自己的状态机，分为进攻状态、防守状态、准备发球状态，每个球员也有自己的状态机，如下图所示。这里使用的是状态模式，把复杂的转移逻辑分散到各个状态节点，这正是状态模式的精华啊。现在这个还只是个粗糙的版本，虽然看得出来有那么点意思，规则都出来了，但是每个球员的跑位不逼真，没有多少智能的感觉。当篮球碰到边界的时候自动反弹，这点有点假，不过这也简化了不少比较繁琐的捡球和发球动作。当然现在的规则都比较简单，连三分和两分都没有分出来，罚球也没有，哈哈。现在的状态机看起来大部分时间还可以，很少的时候会出现一些比较反常规的现象。把每个状态转移过程在画面中显示出来能比较直观的去调试。下面这个是球员的状态转移图，也就是 FieldPlayerStates.cpp 实现的。球队的状态机要简单一些，只有三个。 程序在这里GitHub:BasketBall，感兴趣的可以看一下，也有 7000 行的代码了，也有点乱:). 后面有时间再调试一下，慢慢细化，球员的站位和防守动作做到更智能些。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"C","slug":"C","permalink":"http://catcoding.me/tags/C/"},{"name":"Game","slug":"Game","permalink":"http://catcoding.me/tags/Game/"}]},{"title":"姓氏的消失","date":"2011-09-25T11:43:00.000Z","path":"p/xingshi/","text":"前些天看到一篇文章有点意思。假设，人口的数目不变，儿子的姓氏随着父亲，那么随着时间的推移一代一代的演化，最后所有的人都只有一个姓了。具体用个例子描述就是：100 个父亲，按照上面的假设会有 100 个儿子，也就是平均每个父亲在下一代会有一个儿子，假设某个父亲姓”王”，并且王在父亲这一代所占的比例是 7%，那么概率上来说这个儿子姓”王”的概率为 7%。你不能说我姓王，我儿子肯定随我姓呐，概率上的说法都是放在一个大的数目下。上面那句话的意思就是，平均来说占 7% 姓”王”的父亲在下一代能产出 7% 姓”王”的儿子，这是合理的吧。那么最后人们只剩下一个姓氏了么？对于这么简化的模型是很好模拟的，比如下面这段 python 的代码： def run(populationSize): generations = 0 cur = [x for x in range(1, populationSize+1)] count = 0 while max(cur) != min(cur): count = count + 1 next_generation = [] most_occur_name(cur) for x in range(0, populationSize): son = cur[random.randint(0, populationSize-1)] next_generation.append(son) cur = next_generation print &quot;finished through %d generations, last name is %d&quot;%(count,cur[0]) 初始化每种姓氏都有一个，最后只剩下一个姓氏，具体是哪个不确定，要花费多少代的演化也不确定，这一切都是随机的。那可以从上面的模型看出，如果在某个代中某个姓氏所占的比例相对而言比较大，那这个姓成为最后剩下的那个的概率也更大，我觉得这是个合理的结论。就我国目前的姓氏分布来说，这一个结论看起来是被验证了， 据统计我国大小姓的悬殊是十分明显的，这种悬殊还在有逐步增大的趋势，其发展的结果可能是大姓人口越来越多，很多小姓越来越少甚至被淘汰。我国目前使用着 3000 多个姓氏，但经常使用的仅有 500 个左右，占人口总数 87％以上的人只使用 100 个姓氏，”王”姓最多占了 7.25%，”张”占了 6.7%。原来和同学讨论这个问题，对方一副自己将会儿孙满堂的模样”我们姓’王’”的是最多的，这看来是有依据的，而且很有可能会有更多。 继续想想，这也是进化的一个简单模型吧。不论进化论到底是真是假 (进化论本身也只是个假说而已)，事实中会有这么一个现象：基数大的物种在下一代会有增大的趋势。而且姓氏看来比其他东西遗传得更坚固，对于单个人而言，后代随着父亲姓的概率应该远远大于身高随着父亲的概率吧，所以理论上看来姓氏的消失应该是比较快的。那到底是哪个姓氏会坚持到最后呢？这个不确定，而且也许在多少年内这都不会发生。我国目前的姓氏分布有地域关系，比如湖南可能姓陈的比例比较大，北方姓王的比例很大，这种不是完全随机的分布可以延缓姓氏的消失吧。张学友有首歌叫做《你的名字我的姓氏》里面的歌词是“可用你的名字和我姓氏 ，成就这故事，从此以后无忧无求”，可见，男人对于自己的姓氏留下来的愿望是多么强烈！哈哈，一点浪漫感都没了。","tags":[{"name":"Backup","slug":"Backup","permalink":"http://catcoding.me/tags/Backup/"}]},{"title":"在外漂着","date":"2011-08-18T11:43:00.000Z","path":"p/life_in_shangha/","text":"来上海有一段时间了，在这段时间里一切都还好。 刚来这边一切都感觉比较新鲜，现在慢慢习惯了。在这边的生活比较规律，每天早上八点四十起来，洗刷完毕，早饭是面包片和同事磨的豆浆。这近两个月早餐都是这样，我觉得挺好的，一点都还没感觉到腻，带黑芝麻或者葡萄干的面包片真的很好吃！每天的九点钟开始出发上班，坐上两路地铁到张江一般整好 10 点左右。因为比较晚，所以不会赶上地铁的高峰。中午在公司附近的食堂，吃了一个月后觉得有点味觉疲劳了，主要是太清淡，和成都没法比啊。中午还会躺着休息一段，下午的精力才是最好的。公司前辈们都挺好，相处得不错，会耐心教我一些，自己在工作上面还有不少需要自己弄明白的。晚饭在公司吃，我这种刚来从学校出来的饭量是最大的，汗，我以前总觉得自己饭量不行。因此，在上海长胖了一些。在公司比较囧的事是中文式的英文，这个我觉得不太 make sense 啊，这个 actually 我不是很 understand 啊，anyway 我想要撞墙，^_^。 另外最近喜欢打乒乓球，每周二下午公司一起活动，一般是乒乓球和羽毛球，我们几个打得都比较菜，过了几周后我觉得自己还是提高了一些。 来上海之前，不少在上海待过的朋友警告我，在上海的各种压力、排斥外地人，好像我要入火海似的。通过这两个月的生活来看，这些还没遇到。可能我在环境比较小，又相对单纯。只是在一个月左右的时候，某天早上我爬起床来，觉得有些不对劲，总感觉少了些什么。再仔细想想，原来我已经很久没和女生说过话了，自从成都到上海后一个师姐接过，之后这么常时间内我没和女生说过话！因为公司一个女生也没有，而我在上海的也没有的生活圈里的女生。嗯，这是个问题，长此以往会是个问题:)。倒也好，最近认识一些朋友和老乡，周末也可以找人耍耍了。上周去了人民广场，没见过世面的迷路了，还时不时没见过世面地感叹一把上海的楼高。周日去了华师大，因为看了“深度游上海”系列，说夏季最美校园为华师大，据说是“爱在华师大”，于是约上一个豆瓣好友一起去。传说中的美女没看到，一群男生暑假没回家在球场上耗费体力。不过荷花池附近还可以看看的。回来的时候坐的四号线地铁，很大一部分是在外面，看了一下觉得很多地方和成都差不多呃，浦东也就是陆家嘴那块要繁华些。问了好几个同事，说上海附近哪里风景比较好人又比较少的，都是得到鄙夷的答案，你看上海都开发成这样了，哪里还有人少的地方。我是个比较恋旧的人，还是会怀念成都，学生时代的无忧无虑，周末骑车乱逛，一群人三国杀。我的一个室友在北京，说成都的手机号多用两个月，保持一点回忆。我之前总说该出来看看外面的世界，少不入川，在成都待久了不好。所以出来感受一段时间后，我更觉得自己以后应该还是会回成都或者回家乡的小镇，“我见过的异地越多，就越怀念我的故乡”，成都算是第二故乡，第一故乡不好找工作。另外，这里 送一本书，因为是在豆瓣上未曾谋面的人送给我的，叫做 《自由在高处》，看完了觉得还不错。现在这本书还是全新的，放在我这里也浪费了，既然我是白白得来的也该白白送出去。如果有人想要的邮件给我你的地址，我邮寄给你，你付快递费 (顺丰之类的是可以收货人付款的)。今天看到一些很美的画，然后就把这弄上博客头了，原图是这张。这里还有不少：）","tags":[{"name":"Notes","slug":"Notes","permalink":"http://catcoding.me/tags/Notes/"}]},{"title":"C 的面向对象风格代码","date":"2011-08-16T11:43:00.000Z","path":"p/ooc_in_python/","text":"OO 是一种编程范型，而不只是特定语言的特定支持，所以用 C 来实现也是可行的。最近碰到的一部分代码都是用 C 实现的面向对象风格，可能是参考了 Python 里面的实现，Python 内部实现的基本对象这块也全是这样的代码。在这里做一个小小的总结。 C 语言里面没有语言层面的面向对象支持，那 OO 中的三个基本要素封装、继承、多态如何实现？C 里面最强大的东西是指针，指针中最神奇的是 void 指针，这是一切的基本。首先来看封装，如何通过实例来调用方法，而对内部数据进行隐藏。完全可以写一些 struct，然后写对应的函数来针对这个 struct 来操作，我们需要更进一步，把数据和方法绑定起来。这样写初看起来并没什么好处，后面会发现，通过函数指针去找对应的函数是多态的关键。 //object.htypedef struct _obj&#123; char name[MAXLEN]; int ref_cnt; int value; void (destructor) (void thiz); void (print) (const void thiz); int (equal) (const void thiz, const void* other);&#125; Obj;//object.c destruct,print,equal 定义为 staticObj Obj_new(int value)&#123; Obj o = malloc(sizeof(Obj)); strcpy(o-&gt;name,“baseobj”); o-&gt;ref_cnt = 1; o-&gt;value = value; o-&gt;destructor = &amp;destruct; o-&gt;print = &amp;print; o-&gt;equal = &amp;equal; assert(o); return o;&#125;//使用方法 &#123; Obj first = Obj_new(1); Obj other = Obj_new(2); first-&gt;print(); other-&gt;print(); first-&gt;equal(first, other); Obj_drop(first); Obj_drop(other); return 0;&#125; 对于继承 C 当然也没原生的支持，可以在子类的定义中写入父类中的成员变量和成员函数，这里如果父类中定义的时候就是宏，直接拿过来就是。所以把父类的定义重新改写一下，分为 DATA 类型和 TYPE 类型，在 Python 里面就是这样，PyObject 和 PyVarObject 是一切其他对象都包含有的。下面是一个例子 People 继承 Object,Student 继承 People。 #define PEOPLE_DATA \\ OBJ_DATA \\ int age;\\ char fullname[100]; //OBJ_DATA 必须放在子类新的数据成员前面，只有这样才能把子类的指针强制转换成父类指针 或者转化为 Object 指针 #define PEOPLE_TYPE \\ OBJ_TYPE \\ void (sleep)(void thiz); typedef struct _People_Type&#123; PEOPLE_TYPE&#125; People_Type;extern const Object_Type Object_type;extern const People_Type People_type;typedef struct _People&#123; const People_Type* methods; PEOPLE_DATA&#125;People; 这里 sleep 为新增加的子类方法，fullname 为新增加的成员变量。注释部分为特别注意的，只有在保证内存的里面数据的分布前面部分都是一样的 (一个 methods 指针和 obj_data 部分) 才能进行指针之间的强制转换时候不出问题。例子里面的 Student 类也是类似的继承 People 类，这里可以看到 sleep 这个方法不好弄，因为在 People 那里申明为 static 了，这里想复用就麻烦，所以只有再自己写一个 (即使实现是一样的)，这也是 C++ 内部帮用户做好的。可以看到通过 type 里面的函数指针的不同，不同对象相同的方法实现就不同了，因此实现了多态。 最后我们可以写一个基于计数的指针管理，在持有一个指针的时候调用 Obj_pick，用完以后执行 Obj_drop。 void Obj_pick(const void thiz)&#123; assert(thiz); Object o = (Object*)thiz; o-&gt;ref_cnt++;&#125;void Obj_drop(const void thiz)&#123; Object o = (Object)thiz; const Object_Type p; if( –o-&gt;ref_cnt &lt;= 0)&#123; for( p = o-&gt;methods; p; p=p-&gt;father)&#123; if(p-&gt;destructor) p-&gt;destructor(o); &#125; &#125; free(o);&#125; 按照这种 OO 的风格的 C 代码感觉要清晰一些，至少我习惯了。不过还是看个人品位吧，这样的代码风格是我另外一个同事所鄙视的。关于用 C 实现 OO 风格，还有一本比较好的书叫做Object-oriented Programming with ANSI-C，感兴趣可以看看。 上面的代码在这里下载：https://github.com/chenyukang/ooc。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Backup","slug":"Backup","permalink":"http://catcoding.me/tags/Backup/"}]},{"title":"一种更快的字符串匹配算法 - 源自 Python2.5","date":"2011-07-30T11:43:00.000Z","path":"p/fastsearch-in-python2/","text":"Python2.5 的实现中有一个字符串匹配算法，在 s 中查找 p 是否存在，s 的长度为 n，p 的长度为 m。这个算法符合以下要求： 任何情况下都要比 brute-force 算法快 O(1) 的空间，O(m) 的初始化复杂度 O(n/m) 的查找复杂度 最坏情况下不能比 O(nm) 时间复杂度差 实现简单，对于实际中的查找大部分表现良好，最坏情况出现概率小 标准的字符串查找算法不满足这些要求，KMP 的时间复杂度为 O(m+n)(初始化 O(m) 加第二部分 O(n)， Boyer-Moore 和其变形要求额外的空间，Python2.5 里面增加了这个结合了 Boyer-Moore 和 Sunday 的思想的变形实现。来看看这是怎么个神奇的算法，KMP 的思想是在每一次不匹配的情况下尽量的向右边移动，所以计算一个 Next 的移动下标数组。如果不匹配，最理想的情况下是向右边移动多长？应该是 m，这样就能尽量减少对比的次数。所以每次比较的时候先比较 p 的最后一个字符，比如 s=”aaaaaaad”，p=”aae”，如果从 s 的开头查找，只要发现第 3 个和 p 的第三个不一样，移动指标，移动多少？如果发现没有 e，最长能移动 p 的长度，就是 3。如果最后一个不匹配并且 s[i+m] 不是 p 中的字符就移动 m，否则移动 1。这里有两个问题： 如何知道 s 中的某一个字符是否是 p 中的一部分？如何尽量移动 m 而不出现少找的情况？ 第一个问题，可以用某个存储空间存下是否有 p 中的某个字符出现过，方便以后查找。Hash 的思想，但是这里字符串查找里面再弄个 Hash 太无语了吧。一个简单的 Bloom-filter，这里是这样实现的。 /*计算 mask*/ mlast = m-1;for (mask = i = 0; i &lt;= mlast; i++) &#123; mask |= (1 &lt;&lt; (p[i] &amp; 0x1F));&#125;/*判断 s[i] 不是 p 中的一个字符串*/ if(!(mask &amp; (1 &lt;&lt; (s[i] &amp; 0x1F)))) printf(&quot;s[i] is not in pattern&quot;);else printf(&quot;s[i] is in pattern&quot;); 其实我们是要判断一个 s 中的一个字符串没有出现在 p 中，取低 5 位不是可能产生冲突么？产生冲突也没问题，就像一个 Hash 只要一个元素算出来的 Key 指定的 slot 没元素不就能确定这个元素不在里面了么。 第二个问题，有些巧妙。上面那个例子是因为 s 的最后一个字符没被匹配，所以能移动 m 的长度。如果这个例子 s=”aaacaaaacaa”，p=”aacaa”，第 5 个位置都为 a，最后一个匹配，但是 s 里面前几个其实不为 aacaa，所以需要移动，但是移动多少呢？如果移动 p 的长度，那从第 2 个位置开始的 aacaa 就没被检查到。所以需要一个变量记录在每次最后一个字母匹配的情况下向右移动的合理偏移量，在这里为 skip，初始化的时候计算出来，这最偏移量其实是计算的最小偏移量，就是移动 skip 个位置到第一个 s[m-1] 的位置。 整个实现既节省空间又速度快，强大。 具体实现如下： //如果 mode 为 FAST_COUNT，则查找 pattern 出现的次数#define FAST_COUNT 1int fastsearch(const char* s, size_t n, const char* p, size_t m, int mode)&#123; long mask; size_t skip, count = 0; size_t i, j, mlast, w; w = n - m; if (w &lt; 0) return -1; /* 如果 m=1，特例，扫描一遍解决*/ if (m &lt;= 1) &#123; if (m &lt;= 0) return -1; if (mode == FAST_COUNT) &#123; for (i = 0; i &lt; n; i++) if (s[i] == p[0]) count++; return count; &#125; else &#123; for (i = 0; i &lt; n; i++) if (s[i] == p[0]) return i; &#125; return -1; &#125; mlast = m - 1; skip = mlast - 1; /*计算 mask*/ for (mask = i = 0; i &lt; mlast; i++) &#123; mask |= (1 &lt;&lt; (p[i] &amp; 0x1F)); if (p[i] == p[mlast]) skip = mlast - i - 1; &#125; mask |= (1 &lt;&lt; (p[mlast] &amp; 0x1F)); for (i = 0; i &lt;= w; i++) &#123; if (s[i+m-1] == p[m-1]) &#123;//pattern 末尾匹配 /* candidate match */ for (j = 0; j &lt; mlast; j++) if (s[i+j] != p[j]) break; if (j == mlast) &#123;//一个匹配成功 if (mode != FAST_COUNT) return i; count++; i = i + mlast; continue; &#125; /*移动多少？,根据 mask*/ if (!(mask &amp; (1 &lt;&lt; (s[i+m] &amp; 0x1F)))) i = i + m; else i = i + skip; &#125; else &#123; /* skip: check if next character is part of pattern */ if (!(mask &amp; (1 &lt;&lt; (s[i+m] &amp; 0x1F)))) i = i + m; &#125; &#125; if (mode != FAST_COUNT) return -1; return count;&#125;","tags":[{"name":"Python","slug":"Python","permalink":"http://catcoding.me/tags/Python/"},{"name":"Algorithms","slug":"Algorithms","permalink":"http://catcoding.me/tags/Algorithms/"},{"name":"C","slug":"C","permalink":"http://catcoding.me/tags/C/"}]},{"title":"让 Emacs 提醒睡觉","date":"2011-07-24T11:43:00.000Z","path":"p/emacssleep/","text":"最近都睡的比较晚，对身体不好啊。写了几行恶趣味的 elisp，晚上 10 点 40 开始提醒提醒我准备睡觉，如果 10 点 50 还没动，我的上下移动键就不能用了，下面会有一条提示：太晚了，该睡觉了。不过这时可以用方向键盘来移动。但过十分钟后快捷键又恢复正常，因为过了 11 点表示我确实要再待晚点，下个小时 40 分钟继续提醒，50 分锁死快捷键盘。12 点过后 emacs 彻底对我无语了。真是 egg hurt… (defun is-late-now() \"Check if it is now late, emmm, go to sleep\" (let ((hr (nth 2 (decode-time (current-time)))) (minute (nth 1 (decode-time (current-time))))) (and (and (&gt;= hr 22) (&gt;= minute 40) (message \"prepare sleep now....\")) (&gt;= minute 50)))) (defun my-next-line() (interactive) (if (is-late-now) (message \"late now, go to sleep ... baby!\") (next-line))) (defun my-prev-line() (interactive) (if (is-late-now) (message \"late now, go to sleep ... baby!\") (previous-line))) (global-set-key (kbd \"C-n\") 'my-next-line) (global-set-key (kbd \"C-p\") 'my-prev-line) 这样写不好看，更好的办法是用 defadvice，那就不用重新绑定 C-n 和 C-p 了，defadvice 可以直接在运行 next-line 和 previous-line 之前检查一下。 (defadvice previous-line (before check-is-later) (if (is-late-now) (progn (message “late now”) (sleep-for 1)))) ;;just sleep 1 second (ad-activate ‘previous-line)这样后只要执行 previous-line 这个函数之前都会执行我这个 defadvice 定义的代码，但是这样连方向键也不能移动了，因为向上这个按钮是绑定的 previous-line 这个函数。","tags":[{"name":"Life|Notes","slug":"Life-Notes","permalink":"http://catcoding.me/tags/Life-Notes/"}]},{"title":"到上海了","date":"2011-07-23T11:43:00.000Z","path":"p/toshanghia/","text":"很久没写咯，我已经在上海了，房子刚好弄好。 毕业之前去了青海湖，我和一个同事本来打算三天环青海湖骑行一圈的，第一天骑车 148 公里，第二天一早就走错了路（环行的居然走错了路），结果骑过了橡皮山，发现是已经骑了 20 公里左右。幸好在路上等了个回去的卡车，把我们带回黑马河。重新出发，环湖西路的路况非常好，车也很少。继续骑了 120 公里到达刚察，到刚察之前的最后一段感觉是最累的。第三天早上我刚出门过了个大坡，下来的时候不小心摔了一下，于是最后那一段就没骑了，真是遗憾啊。在西海镇继续住了一晚，221 骑吧的店主人很好，看我摔了下巴，晚上给我做粥喝。牦牛肉粥非常好喝，嗯，非常感谢！也非常感谢同行的同事，一路给了我很多鼓励和帮助。青海一行虽然有些意外，但是也还是觉得挺不错的，那边人和风景都可以。 更多照片在豆瓣上面，照得不好，实景更漂亮，如果七月份去会更好。在从青海回成都的火车上，躺在铺上看《瓦尔登湖》，以前总没好好静下心来看完这本书，那天慢慢翻着有些入味了。“你们要尽可能长久地生活得自由，生活得并不执着才好。执迷于一座田园，和关在县政府的监狱之中，简直没有分别。” 如何生活得简单、自由，是我所难于学会的。 从青海回成都后，在学校办了一些手续，然后直接到上海了。国庆看有没有时间再回家一趟吧。在成都，走之前还和不少朋友没有聚，先记下吧，我觉得我会回成都的:) 在上海待了已经有几天了，说不上适应不适应，至少还没融入，只是一个旁观者。至少楼比成都高多了，交通比较方便也稍微有点贵。房子基本没找，有同事的一个二室一厅的，租下来就行了吧，认识的人住在一起也好些。工作上面还在适应，不少东西要好好学习一下噢。新的开始，努力一把。","tags":[{"name":"Life|Notes","slug":"Life-Notes","permalink":"http://catcoding.me/tags/Life-Notes/"}]},{"title":"Wumpus and 《Land of Lisp》","date":"2011-07-22T11:43:00.000Z","path":"p/wumpus-and-2/","text":"最近在看一本书《Land OF Lisp》，看了大部分。离前一次看 Lisp 方面的书刚好三年，用 Emacs 也有四年了，这期间接触的多是简单的 Elisp。总得来说，Lisp 的书看起来是比较有趣的，这本也不错，稍微比《Practical Lisp》简单。竟然有个第 6.5 章，Lambda 这么重要，怎么说也要占一章！第八章实现了一个小游戏。Wumpus(Hunt the wumpus) 是个古老的游戏，那个年代还没有绚丽画面，只有文字界面。这里游戏的规则是： 1. 地图为一个无向图，玩家控制一个人物在图中行走，目的是寻找潜伏在节点中的一个怪兽。其中要边走边推理，得出怪兽在哪个节点。 1. 还有其他角色，有的节点隐藏着超级蝙蝠，它能把你扔到图的任何位置。节点之间的边可能有警察。 2. 如果你推测出怪兽的位置，向那里射箭，如果射中则胜利，否则输掉。如果你不小心从有警察的边通过了，也死掉。 3. 在怪兽的附近两个距离范围内，会有血气。如果一个点的某条边有警察，这个点会有光晕。 说起来复杂，来看副图。有点像挖地雷那种小游戏。有？符号的为没访问过的点，*为当前点，从 14 到 15 遇到警察死掉了。上周末玩了好几个小时，还挺难胜，主要还是图比较大，游戏一开是整个地图是已经生成了的，要偷懒可以看看。来看看如何用 Lisp 代码来实现这个程序，程序比较短。首先是如何生成图，需要生成一个随机的连通图。设定节点数目和边的数目，以编号代表节点。random-node:随机地选一个节点。edge-pair:连接两个点表示边。make-edge-list: 重复 N 次，生成 N 条边的集合。这个随机图可能不是连通的，下面的代码找出孤立的点集，用一些边连接起来这些孤立的点集，随机图产生完成。第二步向某些点之间加警察，随机的。这其中用了各种 mapcar 和 Lambda，这样的效果使得 Lisp 程序看起来全是括号。mapcar 的意思就是我要在这个列表上面所有的元素上都执行这个 Lambda 函数。visited 列表保存已经访问过的节点，know-city-nodes 更新 (不是纯函数式编程的风格)，know-city-edges 根据访问的节点，生成已知的路径，当前已知的用 dot 画出来。graphviz是个好东西，最近也在学习用这个来画一些流程图，效果挺好的。 乱说说 Common Lisp，看了一些这方面的资料，这语言不管有多少牛逼人士簇拥 (最近 Paul Grahamd 的书被翻译了)，使用的人还是太少还是有一定的历史原因，早期的实现效率是一个问题，而当实现和硬件都不错了的时候 C/C++ 已经成大局了。另一个很重要的原因是，文档不是很好，我想找个处理图片方面的库，见到一个 README 文件跟救命稻草似的，打开一看”Do you really need DOCS?”。Lisp 的哲学是语言不能给太多限制，甚至做到代码就是数据、数据就是代码，你可以轻而地为语言添加特性，你还可以用宏来写出生成代码的代码。Lisp 给了程序员最大的自由来挑战语言的限制，所以会出现如此多种的方言。好的一面是面对特定的问题或许能得到优美而高效率的解决方法，而这个代码对于另外一个程序员来说太难读懂 (特别是夹杂了宏的代码)，继而难于流传。这里有篇经典的Lisp:Good news,Bad news，作者为早期用 Lisp 作为开发语言开公司的。以后看看 Haskell 吧，这个比较有前途。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Books","slug":"Books","permalink":"http://catcoding.me/tags/Books/"},{"name":"Lisp","slug":"Lisp","permalink":"http://catcoding.me/tags/Lisp/"},{"name":"wumpus","slug":"wumpus","permalink":"http://catcoding.me/tags/wumpus/"}]},{"title":"《Advanced linux progamming》笔记","date":"2011-06-14T11:43:00.000Z","path":"p/advanced-linux-porg-notes/","text":"Writing and using Libraries 链接分为动态链接和静态链接。 Archives archive(静态链接) 为目标文件的集合，linker 从 archive 文件中找到 obj 文件进行链接。 % ar cr libtest.a test1.o test2.o 创建库文件 libtest.a(类似 windows 下 test.lib)，当 linker 处理 archive 文件的时候，将在库文件中查找当前已经处理但是还没定义的 symbols。所以库文件应该出现在命令的最后。 % gcc -o app app.o -L. -ltest Shared Library Shared lib 和 archive 的两个区别： 1，当进行的是动态链接，最后得到的可执行程序中不包含实际库中的执行代码，只是一个对库的引用。所以动态链接最后得到的可执行程序要小一些。 2 多个程序可以共享动态链接库，动态链接库不只是 obj 文件的集合，其中是单一的一个 obj 文件，包含了库中所有的信息，所以一个程序动态加载 shared lib 的时候是把库中所有的东西都加载了，而不是所引用的那部分。 % gcc -c -fPIC test1.c % gcc -shared - fPIC libtest.so test1.o test2.o -fPIC 选项指编译为位置独立的执行代码，这样可以动态加载，产生 libtest.so 文件。 默认的库文件寻找路径变量：LD_LIBRARY_PATH 库文件之间的依赖关系：如果是动态链接，链接库会自动寻找到自己所依赖的其他库文件，如果是静态链接，必须为 linker 提供所有依赖的库文件名称。 % gcc -static -o tifftest tifftest.c -ltiff -ljpeg -lz -lm 上面例子中 tiff 依赖 jpeg 库，因为是-static 链接，必须指明所有依赖的库文件。 Pros and Cons 动态链接的优势：可以减少可执行文件的 size，如果库文件进行升级，原程序可以不用重新链接。如果是静态链接，库文件改变了程序要重新进行 link。 也有一些特殊情况必须使用 static link。 动态加载和卸载库 void* handle = dlopen (&#8220;libtest.so&#8221;, RTLD_LAZY); void (*test)() = dlsym (handle, &#8220;my_function&#8221;); (*test)(); dlclose (handle); 上面例子中打开 libtest.so 动态链接库，找到 my_function 定义，执行，然后卸载库文件。 进程 创建进程 using system #include &lt;stdlib.h&gt; int main () { int return_value; return_value = system (\"ls -l /\"); return return_value; } system 将执行/bin/sh，然后执行命令，因为不同系统中/bin/sh 所链接的 shell 不同，所以会导致执行差异，同时这种方式存在安全隐患。 using fork and exec fork 创建一个子进程，fork 的返回值用来区别父进程和子进程。子进程将和拷贝父进程一些信息，更详细的东西在这本书内没说明。 exec 函数家族，fork 创建一个子进程，用 exec 在子进程中执行命令。 process scheduling nice 命令可以调节 process 的优先权值。 niceness value 越大，进程的优先权越低，越小进程的优先权越高。一般进程的 niceness value 为 0。只有 root 的进程可以减少一个进程的 niceness value。 signal signal is asynchronous:进程收到信号的时候会立即处理信号，处理信号的一般方式分为几类：忽略，执行默认处理，执行特定的处理程序。 因为信号处理是异步的，所以在信号处理程序中尽量不要执行 IO，或者调用库函数。信号处理函数应该作最少量的工作，尽快返回到主流程中，或者干脆结束掉程序。一般只是设置变量表明某个信号发生了，主程序定时检查变量再处理。SIGTERM 和 SIGKILL 区别，前一个可能被忽略，后一个不能被忽略。 改变 sig_atomic_t 的值的操作是原子性的。 process exit exit(int return_value) 函数退出一个进程，并把 exit_code 告诉父进车。kill(pid_t,KILL_TYPE) 向某个进程发送相应的退出信号。 wait 函数家族，让父进程等待某个子进程的结束。WIFEXITED 宏判断子进程是否正常退出或者是由于其他原因意外退出。 zombie process(僵死进程) 为一个进程已经退出，但是没有进行善后处理。一个父进程有责任处理子进程的善后处理，wait 函数即为此用，父进程调用 wait 一直被阻塞 (当子进程没有退出的时候),子进程退出后 wait 函数返回。如果父进程没有为已经退出的子进程处理善后，子进程将变为 init 的子进程，然后被处理删除。 一种更好的处理方法是当子进程退出的时候发信号通知父进程，有几种方式可以实现 (进程间通信),其中一种比较方便的方式是父进程处理 SIGCHLD 信号。 Threads 线程作为亲量级进程，切换引起的开销更小，一个进程的多个子线程共享进程的资源。 create thread 创建线程：pthread_create (&amp;thread_id, NULL(pointer_to_thread_info), &amp;thread_func, NULL(argument)) 线程的执行顺序是异步的，不能假设其执行顺序。 向 thread 传递数据：可以通过 pthread_create 的地四个参数，传递一个 void* 的指针，指针指向一个数据结构体。注意在多线程中的数据空间的销毁。 More about thread_id: if (!pthread_equal (pthread_self (), other_thread)) pthread_join (other_thread, NULL); Thread Attributes，为了设定线程的某些属性，detach 线程退出后自动回首资源，joinable 则等到另一个线程调用 pthread_jion 获得其返回值。 Thread-specific data:每个线程都有一份自己的拷贝，修改自己的数据不会影响到其他线程。 Cleanup Handlers:使用 pthread_cleanup_push(function,param) 和 pthread_cleanup_pop(int) 在线程退出的时候自动调用清理函数，释放资源。 多线程程序可能出现的问题：竞争，需要使用 atomic 操作。 互斥锁 只有一个线程能够拥有，此时其他线程访问互斥锁将被阻塞。 pthread_mutex_t mutex; pthread_mutex_init(&amp;mutex,NULL); //&#25110;&#32773;pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; //&#32447;&#31243;&#20013;&#20351;&#29992;pthread_mutex_lock&#21644;pthread_mutex_unlock&#26469;&#38145;&#20303;&#21644;&#35299;&#38145;&#20114;&#26021;&#38145;&#65292; Semaphores for Threads sem_t 可以作为一个 share counter 来使用， sem_t job_queue_count; //initialize sem_init(&amp;job_queue_count,0,0); //wait for sem_wait(&amp;job_queue_count); //lock mutext //and do somethting //unlock //new job sem_post(&amp;job_queue_count) Threads VS Process Guidelines: 1，所有线程所执行的指令必须是在一个可执行文件里面，而多进程可以执行多个命令。 2，因为多个线程共享相同的虚拟内存地址，所以一个线程的错误可能会影响到其他线程，而多进程程序中一个进程的错误不会影响到其他进程。 3，为新进程拷贝内存将增加开销，但是只有在新进程写其内存的时候才会进行拷贝 (写拷贝)。 4，多线程适用于多个相似的执行任务，而多进程可以执行不同类型的任务。 5，多个线程中共享数据要容一些，但是也会产生相关问题 (条件竞争，死锁)，多个进程共享数据难一些，使用 IPC 机制，虽然实现要难一些，但是不容易出现并发 bug。 Interprocess Communication Share Memory share Memeory 是最简单的进程间共享数据的方式。 Allocation shmget 函数创建或者访问一个已经存在的 share mem。 int segment_id = shmget (shm_key, getpagesize (), IPC_CREAT | S_IRUSR | S_IWUSER); Attachment and Detachment 函数 shmat(SHMID,pointer to address,flag) 使得一个进程 attach 到一个共享内存。进程通过 fork 创建的子进程也将继承这一共享内存。函数 shmdt(address) 将 detach 共享内存。 int segment_size; const int shared_segment_size=0x6400; //allocate a shared mem segment_id=shmget(IPC_PRIVATE,shared_segment_size, IPC_CREAT|IPC_EXCL|S_IRUSR|S_IWUSR); //atach the share mem share_memory = (char*)shmat(segment_id,0,0); printf(\"share memory attached at addreass %p\\n\",share_memory); Control share mem 函数调用 exit 或者 exec 可以 detach 一个共享内存，但是并没有释放它。必须调用 shmctl 去释放其空间。ipcs -m 命令可以查看系统中当前的 share mem 的信息，如果没有删除遗留的 shared mem，其 nattch 为 0。可以使用 ipcrm shm segment_id 删除。 Process Semaphores semaphore 和 shared memory 的使用方式类似，可以通过 semget,shmctl 创建和删除，提供的参数表明要创建 semaphore。没详细说，查看其他书。 Mapped memory Mapped memory 是不同进程可以通过一个公用的共享文件进行交流。Mapped mem 在进程是进程和文件的一个桥梁，linux 通过把文件映射到虚拟内存，这样进程可以像访问普通内存一样访问该文件。void* mmap(address,LENGTH,prot_option,option,file_rp,pos) //将一个文件映射到 address，如果不提供系统将映射到合适的地址munmap(file_memory,FILE_LENGTH);// 释放 memory设置了 MAP_SHARED，多个进程可以通过同一文件访问该内存区。 管道 pipe int pipe_fds[2]; int read_fd; int write_fd; pipe (pipe_fds); read_fd = pipe_fds[0]; write_fd = pipe_fds[1]; pipe_fds[0] 为 reading file desc,pipe_fds1为 writing file desc。 Pipe 只能用于同一个进程的子进程之间。 dup2 重定向标准输入输出符。 popen,pclose 很方便，FILE* stream=popen(&quot;progam&quot;,&quot;w&quot;) 向 program 发送。pclose(stream) 关闭。 FIFO 为有名字的 pipe，任何不相关的两个进程可以通过 fifo 来进行数据传递。mkfifo 函数创建 FIFO。 Socket 系统调用: socket-- Creates a socket close -- Destroys a socket connect -- Creates a connection between two sockets bind -- Labels a server socket with an address listen -- Configures a socket to accept conditions accept -- Accepts a connection and creates a new socket for the connection Unix-domain sockets 能用于同一机器上的进程通信。Internet-domain sockets 用于不同机子上的通信。struct sockaddr_in addr 类型变量为其地址结构。addr.sin_family=AF_INETaddr.sin_addr 存储一个 32bit 的 IP 地址。 只是给了两个程序例子，详细内容看网络编程相关书籍。 Mastering Linux Device 分为字符设备和块设备，块设备可一随机访问，字符设备提供流。一般应用程序不会直接访问块设备，而是通过系统调用来使用块设备。设备号，主设备号是根据设备类型分的，从设备号根据具体设备分。cat /proc/devices 查看设备类型和主设备号。 Device Entry 只有 root 的进程可以通过 mknod 创建新的 Device Entry。mknod name b/c 主设备号 从设备号 linux 目录/dev 下面是系统所支持的 Device Entry。字符设备可以像一般文件一样访问，甚至可以用重定向去访问。 cat somefile &gt; /dev/audio 可以发出声音了 特殊设备：/dev/null /dev/zero /dev/full /dev/random /dev/urandomLoopback Devices:环回设备，在文件系统上新建一个普通文件，可用于模拟特定设备，比如软盘。也可把实际设备中的内容拷贝到其中，比如把光盘中的内容拷贝到新建的一个 cdrom-image 中。 /proc mount 命令可以看到一行输出：proc on /proc type proc (rw,noexec,nosuid,nodev)/proc 包含系统的一些配置信息，不和任何设备相关联。 $cat /proc/version 查看内核版本 $cat /proc/cpuinfo 查看 cpu 信息 /proc 目录下同时包含系统中当前的进程信息，由于权限设置，有的只能由进程本身访问。可以通过访问文件获取系统中进程的相关信息，比如参数，运行环境，内存使用信息等等。 Linux system call system call 和一般的 C 库函数的区别：系统调用一般通过门陷入实现，是系统内核和用户程序的接口，运行过程中会进入系统内核。C 库函数一般和普通的函数没有区别。 strace:该命令可以追踪一个程序执行过程中的调用的 system call。access:测试进程对于一个文件的权限。 int access(path,bit_flag),注意返回值和 errno。fcntl:锁住文件和控制文件操作。fsync,fdatasync:flush disk buffer。getrlimit,setrlimit:资源限制设置。getusage:获取进程的统计信息。gettimeofday:获取 wall_clock time。mlock:锁住一段物理内存，使得该内存不能因为 swap 换出，一些速度要求很高的和安全性要求很高的代码会使用这个功能。 mlock(address,mem_length)mprotect:设置内存的权限。nanosleep:高分辨率睡眠函数。readlink:read symbolic links。sendfile:Fast file Transfer。setitimer:定时器。sysinfo:获取系统统计信息。uname:获取系统版本信息和硬件信息。 Inline Assembly Code /usr/include/asm/io.h 定义了汇编代码中能够直接访问的端口。/usr/src/linux/include/asm and /usr/src/linux/include/asm-i386 linux 内核中汇编代码头文件/usr/src/linux/arch/i386/ and /usr/src/linux/drivers/ 汇编代码当使用特定平台的汇编代码时使用宏和函数来简化兼容问题。 Security 用户组 文件 进程权限 用户和组的概念超级用户 无穷权力proccess user id 和 proccess group id。进程开始的时候其 id 和启动该程序的用户信息相同。文件权限 chmod stat(filename,&amp;(struct stat))program without Execution Permissions: a security hole。 其他用户能够拷贝该文件，然后修改其权限。Sticky bit:用于文件夹，当一个文件夹的 sticky bit 设置了后，要删除该文件夹下的一个文件必须拥有对该文件的拥有权，即使已经拥有该文件夹访问权。Linux 下的/tmp 设置了 sticky bit。Real and Effective ID::EID 代表进程所具有的系统权限，如果是非 root 用户，EID=RID；只有 root 用户可以改变它的 EID 为任何有效的用户 ID。su 命令：是一个 setuid 程序，当程序执行的时候其 EID 是文件的拥有者，而不是启动程序的用户号。chmod a+s 使得文件有这个属性。 缓冲区漏洞 如果栈中有固定长度的输入区，则会含有缓冲区漏洞。最通常的形式： char username[32];/ Prompt the user for the username. /printf (&#8220;Enter your username: &#8220;); / Read a line of input. /gets (username);/ Do other things here… /攻击者可以故意使得缓冲区读满，然后在超出的区域植入想执行的代码段，获得控制权。 Race Conditions in /tmp 攻击者先创建一个链接，如果应用程序在/tmp 下创建打开一个相同名称的文件，所有写入的数据将传送到链接所指向的文件里。解决方法：在文件名称内使用 Random，open 函数使用 O_EXCL 参数，如果文件存在则失败，打开一个文件后用 lstat 查看是否是链接文件，检查文件的所有者是否和进程所有者一样。/tmp 文件不能挂载在 NFS 下，因为 O_EXCL 不能在 NFS 文件系统下使用。 system ,popen 函数的危险 替代使用 exec 族函数。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Linux","slug":"Linux","permalink":"http://catcoding.me/tags/Linux/"}]},{"title":"从豆瓣 FM 下载喜欢的音乐","date":"2011-06-07T11:43:00.000Z","path":"p/554/","text":"我是豆瓣 FM 的忠实用户，用这个东西已经有一年多了吧，累计收听了不少歌曲 (316 首喜欢的，45 首不再播放的，7352 首播放过)。通过这个东西发现不少符合自己口味的音乐。这 316 首是我喜欢的类型，所以想把这个列表弄下来，然后把这些歌曲下载到电脑上。 看了一下豆瓣是有自己开放的 API 的，不过还是够麻烦的。于是折腾了一个 Python 程序，输入你的豆瓣用户名和密码，模拟登录豆瓣并记录 cookie，自动地到 FM 的页面去取下这个音乐列表。这个程序在处理 HTML 文件的时候有点笨拙，正则表达式不够强嗄。需要另一个库 python-beautifulsoup。 通过歌曲名，自动下载这个应该是已经有人做了的，于是发现这个 getsong.py，是通过 Baidu 音乐自动下载的，使用了一下速度和成功率都不错，于是在这个上面做了一些修改，直接从上面的程序生成的列表中取歌曲名字，下载下来。如果网速可以一般能在 500k 左右的下载速度，挺不错的。这个程序有可能会抛出一些异常，我没做仔细的检查，如果一首歌下载不下来就 pass 掉。 上面的程序都放在 GitHub 上了，Git/GitHub 可个是真好东西。需要的朋友们从这个地址弄下代码:https://github.com/chenyukang/fmmusic 使用方法： 1 修改 fm_get_music.py，在里面填入自己的豆瓣用户名和密码。 2 运行这个程序，会在当前目录生成一个歌曲列表：songlist.txt。 3 运行 getsong.py 程序， python getsong.py -x，就是通过 songlist.txt 逐个通过百度搜索自动下载，存在当前目录。","tags":[{"name":"Python","slug":"Python","permalink":"http://catcoding.me/tags/Python/"},{"name":"mp3","slug":"mp3","permalink":"http://catcoding.me/tags/mp3/"},{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"豆瓣","slug":"豆瓣","permalink":"http://catcoding.me/tags/%E8%B1%86%E7%93%A3/"}]},{"title":"读 memcached","date":"2011-05-22T11:43:00.000Z","path":"p/memcached/","text":"最近在看 memcached 的源代码，边看边随手记录了一下。 assoc.c: 记录一个 item 是否存在于缓存中，这里使用了 power 2 扩展，primary_hashtable，和 old_hashtable 分别存新申请的 hashtable 和旧的 hashtable。这里起了个线程来做拷贝的工作，当需要扩展 hashtable 的时候就触发 assoc_expand 函数，但是这个函数做的工作是备份 primary_hashtable，即 old_hashtable=primary_hashtable；然后申请新的空间，标识 expanding 为 true，如果申请空间失败则交换回来。通过条件信号量，assoc_maintenance_thread 把 old_hashtable 的数据逐步拷贝到新的 hashtable 中，当拷贝完了后释放 old_hashtable 的空间。耗时的操作用另外一个线程逐步来处理，不过查询和插入都要注意是否是在扩展状态，判断是去 old 还是 primary 里面去操作。 cache.c: 在 malloc 和 free 的基础上封装了一层，多线程安全的。维持了一个指针列表，释放的时候并没有一下就把内存还给系统，而是在列表中保存了下来，申请时如果列表中有没用的指针就直接返回给出来。能这么因为这个 cache 模块只是负责申请和释放 size 相同的内存块。 thread.c: 维持连接列表相关的内容。为一个队列，cq_push、cq_pop，维持一个 LRU 机制。cqi_new 函数返回一个新的 CQ_ITEM 指针，同样维持了一个 cqi_freelist，当有空闲指针的时候直接返回，当没有空闲的时候申请一个列表，从第二个开始连结成链表形式，返回第一个元素的指针。create_worker，创建一个处理线程。Item 为 memcached 中处理的主要对象，item_alloc、item_get、item_link、item_unlink、item_remove 方法，处理的时候都要锁住 cache_lock。threadlocal_stats_reset、threadlocal_stats_aggregate：统计信息相关。slab_stats_aggregate：统计一个线程使用的 slab 信息。threadlocal_stats_reset：清空统计信息。 thread_init：主程序中调用的创建多线程函数，包括初始化互斥锁 (cache_lock,stats_lock)，条件锁，空闲连接列表等。nthreads 为初始化的线程数目，继续调用 setup_thread 启动每一个线程，调用 create_worker 创建处理线程。 stats.c:负责统计信息，记录 get、set、delete、hits 的数目。以前缀作为 key。 slabs.c：负责管理内存申请和释放，slabs 主要是为了避免内存碎片问题，同时提高申请内存的速度，其基本原理是大块地申请内存，根据不同的 slabclass 块大小分给 slabclass，申请内存的时候根据地址选择最适合的 slabclass，从中去下内存返回指针，释放的时候只是放在其空闲指针列表中 (不少地方都用到这样的方式)。slab_list 没什么用，因为释放的指针放在了 slots 里面啊！slabs 贪婪地使用内存，整个这东西的作用就是用内存空间来换时间效率的。 memcached.c：主程序，分析设置参数默认值，分析参数根据参数修改配置参数。初始化 stats，assoc，conn，slabs 等。thread_init 启动线程，每一个线程都有自己的 struct event_base，setup_thread 函数初始化这些，最重要的设置 thread_libevent_process 来处理新的连接。一直到： / Create threads after we’ve done all the libevent setup. / for (i = 0; i &lt; nthreads; i++) { create_worker(worker_libevent, &amp;threads[i]); }每个线程进入自己的 event_loop。 当请求来临的时候对于每一个连接，增加一个事件来调用处理函数 event_handler。每个连接的处理过程是一个状态机，drive_machine(conn* c) 来处理，由 even_handler 来调用，状态转移这部分代码比较复杂，conn_listening —&gt; conn_new_cmd —&gt; conn_parse_cmd —&gt; conn_mwrite —&gt; conn_closing。process_command 来处理各种命令。","tags":[{"name":"C","slug":"C","permalink":"http://catcoding.me/tags/C/"},{"name":"Linux","slug":"Linux","permalink":"http://catcoding.me/tags/Linux/"},{"name":"Backup","slug":"Backup","permalink":"http://catcoding.me/tags/Backup/"},{"name":"memcached","slug":"memcached","permalink":"http://catcoding.me/tags/memcached/"}]},{"title":"valgrind","date":"2011-05-06T11:43:00.000Z","path":"p/valgrind/","text":"纪念一下跑测试跑了几天才找出的一个内存泄漏，这个函数源于 UNP，还以为 UNP 有 bug 呢，找到原书当 getaddreinfo 失败或者 res==NULL 的时候直接退出了。但是写这个代码的同学当然不想连接不上直接退出，于是忘记了 freeaddrinfo 调用直接返回，那个 struct addrinfo 就没释放。很多错误都是这种，涉及到库函数的时候更加难查。 int tcp_connect(const char host, const char serv)&#123; int sockfd, n; struct addrinfo hints, res, ressave; bzero(&amp;hints, sizeof(struct addrinfo)); hints.ai_family = AF_UNSPEC; hints.ai_socktype = SOCK_STREAM; if ( (n = getaddrinfo(host, serv, &amp;hints, &amp;res)) != 0) &#123; log_sprintf(“tcp_connect error for %s, %s: %s”, host, serv, gai_strerror(n)); freeaddrinfo(res); //oops: memory leak return -1; &#125; ressave = res; do &#123; sockfd = socket(res-&gt;ai_family, res-&gt;ai_socktype, res-&gt;ai_protocol); if (sockfd &lt; 0) continue; / ignore this one / if (connect(sockfd, res-&gt;ai_addr, res-&gt;ai_addrlen) == 0) break; / success / close(sockfd); / ignore this one / &#125; while ( (res = res-&gt;ai_next) != NULL); if (res == NULL) / errno set from final connect() / &#123; log_sprintf(“tcp_connect error for %s, %s”, host, serv); freeaddrinfo(ressave); //oops: memory leak return -1; &#125; freeaddrinfo(ressave); return(sockfd);&#125; 上一篇博文中说到自己包装的内存检测方法，这还有个问题当时没发现，就是那个包装 malloc 之类的方法对于库函数中的内存申请调用没法记录，所以是不会发现上面这个 bug 的。这个 Memwatch 倒是把原生的 malloc 都重定义了，但是最好的 Linux 下检测内存泄漏的工具还是 valgrind，这真是个神器，在代码上不用做一点修改，这东西甚至能测试程序的 cache 命中率。看了一下 valgrind 的相关论文，对于检测方法都是一种称之为 shadow value 的方法，也就是用信息来记录每一个 byte 内存的使用情况。这种方式的一个缺点都是会拖慢速度，前面提到的那种稍微包装了一下的方式可能还好 (因为使用的是静态数组), Memwatch 里面使用了不少链表也会拖慢速度。再看看 valgrind 的实现，以后工作可能会碰上类似的。 更多 valgrind 更多 Memwatch","tags":[{"name":"Tools","slug":"Tools","permalink":"http://catcoding.me/tags/Tools/"}]},{"title":"内存又泄漏","date":"2011-04-25T11:43:00.000Z","path":"p/memleak2/","text":"内存泄漏 上一次以为内存泄露查完了，发现服务器跑了比较长时间后又占用太多内存。刚好这段时间加了一些新的模块，又该查查了。整个服务器模块分的还行，但是中间经过几个人一起写，所以看起来就麻烦了。要解决问题还是必须找到泄露的代码段。在 C/C++ 中，只要用了指针这东西，很多逻辑上的问题也会产生内存泄露。在线下用上次封装 malloc 和 free 的方法测试，找不到产生内存泄露的样例，grep 了一下没有用原来的 malloc 之类的东西啊，那就应该是测试数量太少的问题。没法，从线上的 log 中导入一些天的访问记录，其中包含了一天的访问 url。试着用 Python 写个小程序把一天中所有的 url 依次往线下的服务器发送，这应该有几万条数据了。Python 中这相关的库够多的，可以用的 httplib，或者 webbrowser 模块中的 webbrowser.open(“url_address”,1),不过这得打开系统的默认的浏览器，并且好像还没关掉一个 tab 的接口。最合适这个简单任务的是 urllib 这个模块，下面这样就行了，往线下的服务器狂发请求吧: for rec in alllogs: urlstr = rec[0] #print urlstr line=line+1 print line,allnum,allnum-line,urlstr try: u = urllib.urlopen(urlstr) except IOError,e: print ‘connect refused’,e except UnicodeError,e: print ‘UnicodeError’,e res = u.read() ##print u.info() print “read %d data”%(len(res)) ##time.sleep(0.01) 调试方式 Linux 下有一些内存调试工具，不过感觉要么过于复杂要么对代码改动太多，对于在后台这种长时间运行的程序不是很适用。上次提到的封装 malloc,calloc,free 这些函数的检测方法本来是挺好的，但是有两个问题： 1.用于存储内存信息的空间是用数组的，其大小运行时候就固定。2.不适合多线程程序。 如果用上面所有的 url 向服务器发送完毕后，再来检查输出文件不可行，因为运行中超过了数组的最大记录数后面的检测就没办法记录下来了。对于第二个问题，这个服务器模型是一种简单的多线程并发，启动时设定其启动线程的数目，多个线程排队，一个线程处理一个请求所以之间并无过多的交互。如果保证一个线程运行过程中不会出现内存泄漏，那应该就没问题了。调试的时候在每一个线程开始跑的时候就启动清空上面的记录内存申请和释放的数组，如果某个一个 url 请求产生了泄漏就停下来查看生成的 meminfo.xls。这样跑完几万个 url 后，发现一些代码问题。这些 bug 要是通过人来审查代码不可能查出来，所以测试还是非常重要。其中一部分代码错误是使用了 C 写了一些基本的数据结构，这些里面有的使用了 malloc 来动态调整空间大小，用起来倒是比较方便，但是用完后必须显式地释放掉。这和指针的问题是一样的：何时何地释放。调试后会在代码中加入了很多语句，打印信息、脚手架位置等等，这可以用下面这些命令来替换成空白或者注释。 grep debug_str -rl ./*.c | xargs sed -i “s/debug_str/substr/g”","tags":[{"name":"Python","slug":"Python","permalink":"http://catcoding.me/tags/Python/"},{"name":"C","slug":"C","permalink":"http://catcoding.me/tags/C/"},{"name":"Backup","slug":"Backup","permalink":"http://catcoding.me/tags/Backup/"}]},{"title":"面对巨人","date":"2011-04-10T11:43:00.000Z","path":"p/mianduijuren/","text":"昨天小组分享换了种形式，大家一起看了一部片子《面对巨人》。看完后一起分享，我觉得这样很有收获。 这是一部带有一些基督信仰色彩的片子。其实我在今年的 1 月 2 日已经受洗成为基督徒，这是个很重要的事，以前也是经过自己的努力探索和思考后做出的决定。但是在受洗后的这段时间里，我并没有活出一个基督的样式，信心大幅度降低。我明白什么是好的，什么是不好的，我相信每个人都明白自己最丑陋的一面，如果长时间不静下心来审视自己就会渐渐麻木，并且认为人就是这样，自私、冷漠、贪婪、好胜、骄傲、虚伪等等。 信仰对于我来说曾经是一个很遥远的话题，或者一想到和宗教什么的联系起来就有点虚幻了，这和大部分人的感觉是一样的。在这片土地上，我们都不需要信仰，信钱、信房子，因为这些看起来能给我们安定。我也从来没有钱过，甚至还没毕业，算是负债累累。但我知道钱和房子远不能给人安宁。而后在自己经历一段痛苦阶段的时候，一些基督徒朋友给了我帮助，并介绍我来认识基督信仰。 信仰的一些基本问题是： 你觉得人是如何来的？不要脱口而出那一套生物进化论，达尔文那一套只是一个假设。其实和创造论是同样的。我们的课本大多只是介绍了进化论，并称之为科学。这里我毕竟学识疏浅，《游子吟》是一本不错的书，可以参考一下。“世界上任何人都没有办法来解释这个问题，毕竟世界的开端没有任何人在场”。进化论的基本依据是人类后来发现的一些化石等等，但是其中有一段时进化论没法解释的。在寒武纪后，地球上突然出现大量的智慧人，这是没有相关化石的。达尔文本人晚年是否坚定这一立场现在也被怀疑。 另一个问题，人在世上的的意义是什么？该如何度过？ 再说这一部片子，讲述的是一个比较简单的故事。高中橄榄球教练泰勒如何从低谷中重持信心和勇气，借助信仰的力量击败恐惧，也就是自己内心中的巨人。其中也包含一些父子、夫妻之间的故事。 其中的一些印象比较深刻的片段： 泰勒教练根据《圣经》的启发，改变团队的哲学。这个团队的存在是为了什么？获得胜利是为了什么？只是为了一场胜利，然后大家都在谈论你，然后获得大学的奖学金么？然后呢，一个人死去的时候，什么都没了，不是么？什么东西都不是永恒的。“日光之下，并无新事”。这是任何问题的根源，你工作是为了什么？赚钱是为了什么？不同的答案对应不同的人生态度，也就是不同的过日子的态度。 教练的妻子在得知自己还未怀孕后，仍然诚心赞美主：”I still love you”. 在低潮中仍然相信上帝还爱你并在你身上自有他的美意，这才是最大的信心。一如云上的太阳，不管我们的生活是处于何种状态，","tags":[{"name":"Notes","slug":"Notes","permalink":"http://catcoding.me/tags/Notes/"}]},{"title":"论文吐槽","date":"2011-03-27T11:43:00.000Z","path":"p/fuckpaper/","text":"前些天在写毕业论文，开题弄了个什么神经网络什么数据融合，至今没搞懂过，真是没话说，但是又不得不硬着头皮写，废话连篇，说来说去就那么几句。做的东西本来挺简单的，没用到那么高深的理论，不过为了装装深度，硬要往上面套，希望最好别出什么问题吧。写论文的时候我就想嗄，写代码好玩多了，异常怀念那段天天在 poj 上写程序的日子。这两天交完初稿，继续做做题，一是玩玩，二是为了原来定下的一个小目标：毕业前水到 500 题，还差 20。两个比较好玩也折腾得比较久的题目。 poj 2050 这题折腾了很久很久，刚开始误以为每个文件的最大行数为 1500，最后因为输出格式问题。代码也比较长 330 行，954ms。使用数组作为 hash，使用位图记录文件中存在的单词，idx 为由单词转化得到的该单词在 hash 表中的 index。 unsigned int docs_flag[MAXDOC][(MAXWORDS+31)/32]; //记录某个文件中是否存在某个单词void set_docflag(int doc[], unsigned int idx)&#123; doc[idx&gt;&gt;5] |= (1&lt;&lt;(idx&amp;0x1f));&#125;int get_docflag(int doc[],unsigned int idx)&#123; return doc[idx&gt;&gt;5] &amp; (1&lt;&lt;(idx&amp;0x1f));&#125; poj 2518 这个好玩，一个 44 的方格，里面分别放四个 A,B,C,D，初始状态从输入获取，先随便选取一个字母，然后能进行很多次操作。每次能交换两个相邻的方格，到任何一个小的 22 的方格中全部都是所选的字母就获胜。对于每一个输入，求最少多少次交换就能达到胜利状态，以及有多少方案可以达到这个目的。例如：AABBABABCDCDCCDD output ==&gt; 1 4 (选择 A 或者 B 交换 BA 选择 C 或者 D 交换 DC)ACABCBBDADADDCBC output ==&gt; 4 96首先想到还是搜索，用 bit 来减少空间。求最少次数，BFS 搜索也许太慢，毕竟每次状态转移会有 16 个选择。对于每一个输入，先枚举 A,B,C,D 进行搜索。对于每一个字母，比如 A，用一个整数表示其在方格的位置 (最大数字到 1&lt;&lt;16)， AABBABABCDCDCCDD state ==&gt; 1100 1010 0000 0000 胜利的状态有 9 个，可以先枚举出来，1100110000000000 等等。胜利状态比较多，照一般的 BFS 写下去代码肯定比较复杂，时间和空间肯定也都要求比较多。考虑可以从胜利状态反着向初始状态搜，先把 9 个胜利状态放入数组，求到初始状态最少的步数，同时可以算出有多少种走法。这样做了还是超时，看有人说线上输入有很多组数据。 看来每次计算调用了四次 BFS 确实比较要时间，看提示打表，对于每一个输入先查查看以前计算过没有，计算过则直接输出结果，否则照上面的枚举字母，调用 BFS。提交还是超时。 再想想，每次输入可能 A 的分布是一样的，其他字母分布不一样，照上面那样做对于 A 还是 BFS 搜索了一次。从 16 个位置选择 4 个位置给 A 的总分布数目是 C(16,4)=1820，不是很大的。很开心，把 A 的状态记录下来，对于每个输入先看看 A 这种布局以前算过了没有，如果算过则不用算了，其他字母都是一样处理。结果还是超时，无语了。 正要崩溃时，发现自己还是没看到本质，对于 A 的每一个布局，B 不是一样么，是 A 还是 B 没关系的啊。所以，打表不用分字母需要 1820*4 这么大的表，只要一个 1820 的表就行了。对于每个输入，分字母获取四个分布状态，看这个状态以前是否算过了，如果算过直接拿那个结果，如果没算过算了存下来。再提交，终于 AC 了，：）这一步步够辛苦的。","tags":[{"name":"Backup","slug":"Backup","permalink":"http://catcoding.me/tags/Backup/"},{"name":"ACM","slug":"ACM","permalink":"http://catcoding.me/tags/ACM/"},{"name":"POJ","slug":"POJ","permalink":"http://catcoding.me/tags/POJ/"}]},{"title":"近期","date":"2011-03-27T11:43:00.000Z","path":"p/guitar/","text":"1 学吉他 我终于开始学吉他了，五音不全双手不灵活不识谱的我居然开始学吉他了。跟某些朋友说我要学吉他，对方往往有几种反应：1.头被墙夹了 2.要改变风格了？装文艺小青年了？ 3.要追哪个女生么？其实弹吉他还是符合本人闷骚这一特质的。说来惭愧，很早就想学点乐器了，小时候爸想让我学二胡来着，幸好没学，一听那声音就觉得悲催啊。在我高中毕业那会，会憧憬着大学应该能拿个吉他在湖边，身边还有个妹子坐着。这个画面在沙河少林寺和清水河少林寺连实现的欲望都没有。所以，这么个小愿望到现在才付诸实践。前些天买了个民谣吉他，目前还只上了一堂课，右手拨弦有点感觉了，左手按着很痛，这要靠长期练习，慢慢来吧。等我学会了对某个女生来这么首歌 - 黑眼睛的姑娘。[audio:http://www.moorekang.com/wp-content/uploads/2011/03/20.mp3|titles=黑眼睛的姑娘] 2 到处逛了一趟 从上学期开始实习并找工作以来就没怎么出门玩过，这段时间刚好论文写完，可以出去耍耍。刚好王聪同学从北京解放后开始到处游荡，打算在成都待一周，所以一起找个地方玩。本来计划去海螺沟的，出发前一天晚上被某失恋男说服去碧峰峡。提前假期一天出发，到了雨城雅安。上里古镇没什么好玩的，就是一条河，半个多小时逛完了。立马往碧峰峡赶，下午三点多才到，已经不卖门票了。在山上的旅馆住了一夜，晚上三个大男人在旅馆看成都电视台的特色节目《今天我相亲》，真实得很喜感。第二天从碧峰峡动物园开始逛，因为学生证没带，我买了全票，看完后真是觉得不值啊！！下午逛植物园，在票上看到一个雅女园。话说雅安三大特色：雅雨、雅鱼、雅女，这雅女园莫非有什么非同寻常的东西:)。沿着碧峰峡逛了一圈，中途发现三个 mm，其中两个算是美女双胞胎，于是我们三个后面一直处于两种状态，等 mm 追上我们，在后面追 mm。到最后最后，除了王同学搭讪了一句并且没下文，我们都只是有胆看没胆搭讪，很失败。逛完大概耗时三个多小时，急忙忙看完熊猫就得赶车回成都了，前面一直满怀期望的雅女园都没来得及逛，不过肯定是没雅女在里面的，哈哈。总得来说，这碧峰峡是不值我那两张全票的价格的，风景算一般吧。 回成都第二天去了石象湖，在我印象中石象湖应该是不错的，有几个人向我推荐过此处。于是叫上那失恋男饭量同学三个人一起前往。快出成都上高速的时候才发现出来的不是时候啊，车暴多太堵塞，经过漫长的堵车后 13 点多才到。在门口感觉已经不好了，人太多。进去后刚开始一块还可以，全是一片一片的郁金香，美女也不少。逛进去也就没什么了，一个小湖加几个小石头象，坑啊，开发商太黑了，弄个几个别墅在这园里，卖房又卖票。三个人很失望，立马找出口。在门口等回成都的车足足等了一个多小时，在路上又堵了一个很久，这一天总共在来回路上耗费七个小时，人挤人看了一个小时！我提议的出游计划，对不住两位了。这几天玩下来还真是有点累！ 接下来该锻炼一下身体，打算去青海骑车，目前有四个人了。","tags":[{"name":"Notes","slug":"Notes","permalink":"http://catcoding.me/tags/Notes/"},{"name":"Backup","slug":"Backup","permalink":"http://catcoding.me/tags/Backup/"}]},{"title":"Cflow 分析","date":"2011-03-09T11:43:00.000Z","path":"p/cflow/","text":"cflowcflow是个比较古老的程序 (好像比我老一岁)，主要是用来打印 C 程序的函数调用关系，通过函数调用关系能大概看一下程序的流程。最近看了一下这个程序的代码，主要分为两个小程序组成。首先是 prcc.c 这个程序，作用是读源文件，提取出函数名称，然后生成一个函数列表。第一列是调用函数，第二列是被调用的函数名称 (如果是函数声明则这两列相同)。第二个程序 prcg.c 是读取函数关系，里面建起一个有向无环图。根据这个图加上缩进打印出函数调用轮廓，这里有一个例子。最后是一个脚本 cflow.sh，其核心代码就是。 prcc demo.c | prcg 这是典型的通过管道把小程序组起来的例子。 life is short , use Python 闲着的时候在这个程序上做了些小工作。既然有了第一个程序，那也可以用 python 来快速写个程序继续做些工作。首先想到的是写个程序把函数名打印出来，在有调用关系的函数之间用直线连起来。python 就是容易实现。这里有一个问题，就是怎么排列函数名的位置，使得连线不怎么相交，因为相交起来就不容易看到函数之间的关系了。不好解决，还是用了以前《集体智慧编程》里面的优化函数，也就是优化问题。通用思路就是试着移动各个函数的位置，朝着相交点最少的部分移动 (这里给一个解，相交点的个数为评估函数)。效果不是很好，当函数比较多的时候哪种算法都比较慢，而且交点看起来不可避免。这是一个结果。运行方法是: prcc demo.c | python drawfuncs.py 或者 find *.c | xargs prcc| python drawfuncs.py 来处理多个程序。 &lt;img src=”/images/out.jpg” alt=”screen” class=”img-center” width=”400”, height=”400” /&gt; 然后又想着可以做一个标签一样的东西，把调用深度比较潜的放大，调用深度深的缩小。不连线，位置随机画。这样一眼能看出来这个程序的主要函数是哪些。结果成这样了。 &lt;img src=”/images/out5.jpg” alt=”screen” class=”img-center” width=”400”, height=”400” /&gt; 位置随便画还是不好，可以分层。然后再相邻层之间的函数有调用关系的再用直线连起来，就变成这样了。清晰一点。既然有函数关系，其实是可以做到更好的，就像上面那个 prcg.c 程序，不过代码要复杂些了。 &lt;img src=”/images/out6.jpg” alt=”screen” class=”img-center” width=”400”, height=”400” /&gt; C 要的是运行速度，Python 实现速度快！","tags":[{"name":"Python","slug":"Python","permalink":"http://catcoding.me/tags/Python/"},{"name":"Tools","slug":"Tools","permalink":"http://catcoding.me/tags/Tools/"},{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"C","slug":"C","permalink":"http://catcoding.me/tags/C/"},{"name":"Linux","slug":"Linux","permalink":"http://catcoding.me/tags/Linux/"}]},{"title":"给老婆介绍 OOD(翻译)","date":"2011-03-03T11:43:00.000Z","path":"p/ood_for_wife/","text":"晚上看到个有趣的文章，翻译了一下，看过 Head First 绕过。 原文在这里。 OOD 介绍 Why OOD? Single Responsibility Principle 单一职责原则 Open-closed Principle 开闭原则 Liskov’s Substitution Principle 里氏可替换原则 The Interface Segregation Principle 接口分离原则 The Dependency Inversion Principle 依赖倒置原则 总结 我的妻子 Farhana 想重新她软件开发师的职业生涯 (她以前也是个软件开发师，但是因为第一个孩子的出生而没有继续下去)。所以，这段时间我在帮助她学习一些 OOD 方面的东西，我是一个比较有开发经验的程序员。 从我早期的职业生涯中，我发现不管是多么复杂的技术问题，如果从普通交谈中以平常生活常见的角度去解释往往变得更容易理解。因为之前我和她有不少富有成果的交谈，我想可以和大家一起分享一下这种学习 OOD 的有趣方式。 下面是我们学习 OOD 的对话： OOD 介绍 Shubho : 好，让我们开始学习 OOD，你已经知道了面向对象三大特性，对吗？ Farhana: 你是指封装、继承、多态吗？是的，这些我知道。 Shubho : 好，希望你已经知道了使用对象和类，让我们今天开始学习 OOD。 Farhana: 等等，知道面向对象特性还不够面向对象程序设计吗？我的意思是，我能定义类，封装成员变量和函数，我也能根据类之间的关系定义继承类。那还有什么需要学的么？ Shubho : 好问题，OOP 和 OOD 是两码事。让我给个例子给你。当你还是小孩的时候你学会了字母表，对吧？ Farhana: 嗯 Shubho : 好，你也学会了如何用字母形成一个个有意义的单词，同时，你也学会了一些语法来造句子。比如，你要维持时态，使用介词、连接词、和其他语法来造出正确的句子。比如说一个句子像下面这样。”I” (pronoun) “want” (Verb) “to” (Preposition) “learn” (Verb) “OOD” (Noun) 你看，你要让这些单词安特定的顺序组成，你也 要选取正确的词来使得这个句子有意义。 Farhana: 呃，这是什么意思？ Shubho : 这和 OOP 是类似的。OOP 是面向对象程序设计的基本原则和核心思想。这里，OOP 对应于英语语法，这些基本语法告诉你如何用单词去构造一句有意义的话，OOP 告诉你使用类，封装成员变量和方法，也告诉你在代码中使用继承关系。 Farhana: 嗯，有点懂了。那么 OOD 对应于什么呢？ Shubho : 你马上就知道。好，现在比如说你想要就一个论题写一些文章。你也想就一些你比较精通的方面写一些书。知道如何遣词造句还不够写一篇好文章或者好书出来，对吧？你还需要学习很多，你需要知道如何用一种好的方式去解释一个东西，这样读者才能了解你到底在说什么。 Farhana: 有点趣，继续。 Shubho : 好，现在比如说你想就 OOD 方面写一个本书，你需要知道如何把这个主题分为小题目。然后在这些小议题上面逐章地写，你还要写前言、简介、解释、例子，还有许多其他段落。你需要知道如何从整体上把握这本书的构造，甚至需要一些写作技巧。这才能让你的书通俗易懂。在软件设计领域，OOD 同样是个更上层的角度。你需要好好的设计，使得你的类和代码可以更好地模块化、复用、灵活。使用这些设计原则可以是你少重复发明轮子。懂了吗？ Farhana: Hmm，我明白了一些，但是请继续。 Shubho : 别急，一会你就知道了。我们只管讨论就是了。Why OOD? Shuboho : 这有个很重要的问题，为什么我们需要 OOD，我们明明就能很快的稀里糊涂的设计一些类，赶快完成开发然后交付？这还不够么？ Shubho : 就是，我以前也不知道 OOD，我仍然能开发完成项目。那这有什么问题么？ Shuboho : 好，让我来给你一个经典的引用: “Walking on water and developing software from a specification are easy if both are frozen.” - Edward V. Berard (如果水是冰冻的在上面行走很方面，如果规格书是不变的，开发软件也很方便) Shubho : 你是说软件的需求说明书一直都在变化？ Shuboho : 正确，最普遍的真理就是”你的软件注定都要变化”,为什么？因为你的软件需要解决的是现实生活中的问题，而这些都是会变化的—永远会变。你的软件按照今天需要做的，做的足够好。但是你不设计得足够好，你的软件足够灵活来应对”变化”吗？ Shubho : 好，这样，快给我介绍什么是”设计得足够灵活的软件”! Shuboho : “一个设计的灵活的软件是容易适应变化的，它能够便于扩展和复用”。而使用一种好的”面向对象设计”方式是得到这种灵活设计的关键。但是，我们有什么标准来说明我们的代码中使用了良好的 OOD？ Shubho : 呃嗯，这也是我的问题。 Shuboho : 你需要做到了下面几点: 面向对象方式 可复用 修改代价最小化 不修改现有代码的基础上扩展前人已经在这方面做了许多工作，他们已经对一些通用的场景列出了一些通用的设计准则。最基本的五点可以简称为 SOLID 原则 (Uncle BoB)。S = Single Responsibility PrincipleO = Opened Closed PrincipleL = Liscov Substitution PrincipleI = Interface Segregation PrincipleD = Dependency Inversion Principle下面我们逐一介绍上面的几个原则。Single Responsibility Principle 单一职责原则 Shubho : 先来看幅图，很形象。你能把所有的功能都集成在一个东西上，但是真的不应该。为什么？因为这为以后增加了很多额外的管理工作。我来用 OO 术语解释一下，”不能有多个理由去改变一个类”,或者说”一个类有且只能有单一职责”。 Farhana: 能解释一下吗？ Shubho : 让我们来看这个继承的例子，这是从 Uncle Bob 书上弄来的。Rectangle 类做了两件事， 计算矩形的面积 在 UI 上画出矩形两个程序要用这个类， 一个几何计算的程序要用来计算面积 一个图形界面程序要用来在 UI 上画一个矩形这就违反了 SRP 原则。 Farhana: 怎么？ Shubho : 你看，一个矩形类包含了两个不同的动作，一个计算面积，一个画矩形，这导致了下面的问题： 在几何计算的程序中我们要包含 GUI，进而又需要包含 GUI 所用的图形库。 任何因为图形界面而在这个类上面所做的修改将导致几何计算程序重新编译测试，相反也是。 Farhana: 变得有趣了，所以我们应该根据其功能把这个类分开，对吧？ Shubho : 正是，那么该如何做？ Farhana: 我来试试，也许该这样，根据职责分为两个类，比如： Rectangle 这个类定义方法 method() RectangleUI 这个类从 Rectangle 继承并定义 Draw() 方法 Shubho : 非常好，现在两个程序分别使用两个不同的类，我们甚至可以将两个类放在不同的 Dll 文件里面，这样任何一个类的改动不会影响到另外一个程序。 Farhana: 谢谢，我想我理解了 SRP。一方面，SRP 是一种把东西分开到一些便于复用和集中管理的小模块中。那么，我们同样也能在成员函数这一级别来使用这个原则吧？我是说，如果我写了很多很多行代码在一个函数中完成几件不同的事，这也违反了 SRP 原则，对吧？ Shubho : 是的，你应该把这个函数分成几个小的分别做一份特定的事。这也让你只需要很小的代价来应付变化。 Open-closed Principle 开闭原则 Shubho : 这幅图是说开闭原则的。 Shubho : 先来解释一下：软件实体 (类、模块、函数等等) 应该对扩展开放，对修改封闭。最基本的层次，你应该能够在不修改一个类的基础上扩展它的行为。比如，我不需要在我的身体上做什么改变，就能穿上一件衣服，哈哈。 Farhana: 有趣，你能穿不同的衣服来改变的外貌，而不需要对你的身体做改变，所以你是对扩展开放的，对吧？ Shubho : 是的，在 OOD 里面，对扩展开放意味着我们能够扩张模块/类，对需求的变化添加一些新的东西。 Farhana: 而你的身体对修改是关闭的，我喜欢这个例子。那么核心的类和模块在扩展的时候是不能被修改的，你能具一些例子吗？ Shubho : 好，我们来看这副图，这是一个违反了开闭原则的例子。 Shubho : 你看，服务端和客户端是直接连接的，这样不管是因为什么原因，当服务端实现改变了的时候，客户端也需要改变。 Farhana: 恩，懂了点。如果一个浏览器只是针对于特定的服务器 (比如 IIS)，如果因为什么原因我们需要换一个服务器 (比如 Apache),浏览器也需要改变，这真是恐怖。 Shubho : 对，下面这个设计应该要好。 那个抽象的服务器类对修改是关闭的，而具体的子类实现对扩展是开放的。 Farhana: 恩，懂了。抽象是关键，对吧？ Shubho : 对，我们应该抽象系统中那些核心的概念，如果你抽象得好，当添加新功能的时候不需要修改。比如上面服务端是个抽象概念，如果 IISServer 是服务器的一种实现，现在需要扩展服务端这个概念，比如说一种新的 ApacheServer 实现，而这些扩展对客户端程序没有任何影响。 Liskov’s Substitution Principle 里氏可替换原则 Shubho : LSP 原则听起来很难理解，其实含义很简单，看下面这副图。这个原则意思就是：子类必须能够替换其继承的基类。或者换一种说法：基类能使用的方法，子类也能使用。 &lt;p&gt;&lt;a href=&quot;/images/7.jpg&quot;&gt;&lt;img class=&quot;aligncenter size-medium wp-image-431&quot; title=&quot;7&quot; src=&quot;/images/7-300x237.jpg&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;237&quot; /&gt;&lt;/a&gt;&lt;/p&gt; &lt;li&gt;Farhana: 对不起，听起来很难懂。我认为这时 OOP 的基本规则，这时多态，对吗？&lt;/li&gt; &lt;li&gt;Shubho : 好问题，答案是：在基本 OOP 里面，&quot;继承&quot;被描述成一种&quot;is-a&quot;的关系，如果&quot;开发者&quot;是一个&quot;软件职业者&quot;,那么&quot;开发者&quot;类应该继承&quot;软件职业者&quot;,这种&quot;is-a&quot;的关系在类的设计中非常重要，但是这样非常容易导致一种错误的继承设计。LSP 原则是一种保证正确使用继承的方法。让我们看个例子。&lt;/li&gt; &lt;p&gt;&lt;a href=&quot;/images/8.png&quot;&gt;&lt;img class=&quot;size-full wp-image-432 aligncenter&quot; title=&quot;8&quot; src=&quot;/images/8.png&quot; alt=&quot;&quot; width=&quot;188&quot; height=&quot;176&quot; align=&quot;center&quot;&gt;&lt;/a&gt;&lt;/p&gt; KingFishera 是一种能飞的鸟，它继承 Bird 类没问题。但是如果下面这样： 鸵鸟是一种鸟，所以它基于鸟基类。现在能飞么？不行，所以，这个设计违反了 LSP。所以，即使在真实世界中看起来很自然。但在类的设计中，鸵鸟不应该继承鸟类。应该有一种不能飞的鸟类，然后鸵鸟从这个类中继承。 Farhana: 好，我懂了 LSP，让我来指出为什么 LSP 这么重要： 如果 LSP 不满足，类继承关系将会混乱，如果一个子类实例被当作参数传到一个函数，奇怪的事可能会发生。 如果 LSP 不满足，单元测试中基类通过而子类通不过。 Shubho : 很正确，你能吧 LSP 原则当作一种验证工具，来测试你的继承层次是否正确。 The Interface Segregation Principle 接口分离原则 Farhana: 这是什么意思？ Shubho : 意思如下：客户代码应该不依赖他们不使用的接口。 Farhana: 解释一下。 Shubho : 当然，其意思就是，假设你要买一台电视机，现在有两台可供选择，一台有很多转换器和按钮，大部分你都不明白是用来干什么的。另一个只有少数几个按钮和转换器，对你来说很熟悉。你选哪一个？ Farhana: 当然是第二个。 Shubho : 是的，但是为什么？ Farhana: 因为我不需要那么转换器和按钮，那些我不明白，而且对我也没什么用嗄。 Shubho : 对，类似的，假设你有一些类，你要暴露一些接口给外界，这样外面的代码才能利用这个类。如果一个类的接口太多，也暴露了很多接口，这对于外界来说是比较混乱的。而且，方法太多的接口也是不利于复用的，这种”大而全”的接口导致类之间的紧耦合。这也导致一个问题，任何使用这个接口的类都需要实现那些方法，而有些对于这个类是根本没用的。所以这么做也带来了不必要的复杂性，导致维护的困难和系统的健壮性问题。接口分离原则保证接口设计得合理，他们都有自己的职责，这样简明、方便理解、利于复用。 Farhana: 哦，我懂了。你的意识是指接口只含又那些必须的方法，而不包括冗余的？ Shubho : 是的，来看个例子。下面这个例子违反了 ISP 原则。 注意，IBird 接口包含很多鸟的行为，还有 Fly() 行为，现在一个 Bird 类 (鸵鸟) 实现这个接口，它必须实现 Fly() 行为，这对于鸵鸟来说是不行的。 正确的设计是这个。鸵鸟实现 IBird 接口，而可以飞的鸟实现 IFlyingBird 接口。 The Dependency Inversion Principle 依赖倒置原则 Shubho : 是说：高层模块不依赖底层模块，两者都依赖抽象。抽象不应该依赖于细节，细节应该依赖于抽象。 让我们来看一个现实的例子，你的车子包括很多组成部分，有引擎、轮子、空调、还有其他东西，对吧？ Farhana: 是的。 Shubho : 好，每一件东西都是严格地独立地造的，而且每一样都是可以”插拔”的，所以你的引擎或者轮子坏了，你可以修它，甚至可以换掉它，但是其他部分不需要动。你换的时候需要保证配件和车子的设计是符合的，比如这车子需要 1500Cc 的引擎和 18 英尺的轮子。同时，你的车也可以使用 2000CC 的引擎，任何厂家的都可以。现在，想象一下如果你的车子不设计成这种可”插拔”的，会出现什么问题？ Farhana: 那真是太糟糕了！如果车子引擎坏掉你需要修理整个车子，或者卖一辆新的。 Shubho : 是的，那么”可插拔”是如何做到的？ Farhana: “抽象”是关键，对吧？ Shubho : 是的。在现实中，汽车是一种更高层次的实体，它依赖于一些第层次的实体，像引擎和轮子。而车子不依赖于具体引擎和轮子，依赖于这些概念。这样，任何符合这个概念的引擎或者轮子都能放进车子让车子跑动起来。看看下面这幅图，注意这里车子类中，有两个属性，都是接口类，而不是具体类。引擎是”可插拔”的是因为它接受任何满足这个抽象的具体实现，而不改变其他部分。 Farhana: 那么如果违反了 DIP 原则，将会有下面的风险。 破坏高层次的代码 当底层代码改动的时候，需要大量成本改变上层代码 代码复用不好 Shubho : 完全正确！ 总结 Shubho : 除了 SOLID，还有其他很多原则。 * “Composition over Inheritance”: This says about favoring composition over inheritance. * &quot;Principle of least knowledge&quot;: This says that &quot;the less your class knows, the better&quot;. * &quot;The Common Closure principle&quot; : This says that &quot;related classes should be packaged together&quot;. * &quot;The Stable Abstractions principle&quot;: This says that &quot;the more stable a class is, the more it must consist of abstract classes.&quot;&lt;/pre&gt; 设计模式是 OOD 的特例，DP 就像是对于特定场景的特定框架，而 OOD 则是说明。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Backup","slug":"Backup","permalink":"http://catcoding.me/tags/Backup/"},{"name":"OOD","slug":"OOD","permalink":"http://catcoding.me/tags/OOD/"}]},{"title":"在显示器前干了什么","date":"2011-02-22T11:43:00.000Z","path":"p/workingtime/","text":"时间啊时间 写论文头大，翻资料找到一个以前写的小东西。有段时间在实验室，一坐就是一整天，经常在网上找找资料，找着找着就从一个链接点到另一链接，从豆瓣到 Hoop，再弹出个 QQ，一整个上午就过去了。天天对这显示器，于是就想我整天呆在这大部分时间在干什么了，要是有个记录就好了。就想写这么一个小程序，来记录我一天在电脑前花的时间分布。 方法 怎么实现呢。要知道现在在干什么，就应该要知道我现在在活动程序，编辑或者鼠标点击的。如何知道现在活动的程序名，如果能获得当前活动的程序的可执行文件的路径就比较好办了。于是在网上找了找，在 Windows 下可以这样实现。 CString getProcPath(int PID)//返回 pid 进程的可执行程序名称{ HANDLE hModule; MODULEENTRY32* minfo=new MODULEENTRY32; minfo-&gt;dwSize=sizeof(MODULEENTRY32); hModule=CreateToolhelp32Snapshot(TH32CS_SNAPMODULE,PID);//对系统进程进行拍照 Module32First(hModule, minfo);//返回与进程相关的第一个模块信息 CString str; str=CString(minfo-&gt;szExePath); CloseHandle(hModule); if(minfo) delete minfo; &lt;span style=&quot;color: #00bfff; font-weight: bold;&quot;&gt;return&lt;/span&gt; str; } 得到了当前活动的程序名称就比较好办了，其实经常用的就是那么几个程序，稍加分析然后分类就能统计到我的时间分布。我这里分为了四类：编程、上网、看文档、QQ。用个定时器记录下来即可。实现个托盘最小化，就可以了。 void Report::Init(){ m_Programming.push_back(_T(“devenv.exe”)); m_Programming.push_back(_T(“Microsoft Visual Studio”)); m_Programming.push_back(_T(“vim”)); m_Programming.push_back(_T(“matlab”)); m_Programming.push_back(_T(“MATLAB”)); m_OnWeb.push_back(_T(“firefox”)); m_OnWeb.push_back(_T(“Chrome”)); m_OnWeb.push_back(_T(“IEXPLORE”)); m_OnWeb.push_back(_T(“opera”)); m_QQ.push_back(_T(“QQ”)); m_QQ.push_back(_T(“Tecent”)); m_Document.push_back(_T(“WINWORD”)); m_Document.push_back(_T(“Office”)); m_Document.push_back(_T(“CAJView”)); m_Document.push_back(_T(“hh.exe”)); m_Document.push_back(_T(“FOXITR”)); } 结论是个有点无聊的东西。其实可以稍微完善一下，比如加一个定时通知休息的功能、或者是上网过久的通知、便签之类的小功能也可以呵。代码 ：Workingtime ,匈牙利命名法好难看。","tags":[{"name":"Backup","slug":"Backup","permalink":"http://catcoding.me/tags/Backup/"}]},{"title":"《先知》- 纪伯伦","date":"2010-12-29T11:43:00.000Z","path":"p/theprophet/","text":"《先知》，纪伯伦。这本书买了一年，看了一遍，更多的时候是听其附带的朗诵，美和哲理，很让人内心平静。左上角的“憩于理性，行于热情”也是出于这。先知讲述的真理包括爱、婚姻、孩子、施与、饮食、工作、欢乐和悲哀、房子、衣服、买卖、罪与罚、法律、自由、理性和热情、痛苦、自知、教育、友谊、谈话、时间、善恶、祈祷、快乐、美、宗教、死。 为什么说是真理，当你相信的时候就是真理，不相信的时候就是建议。正如里面所说:“不能说我找到了真理，而应该说我找到了一条真理。” 这一个月里经常去参加教会的活动，得到的多是感动和宁静，虔诚的爱可以让生活变得不一样。如一位大哥所说，在这里的是新生，以前认为很重要的东西变得不重要，以前认为很不重要的东西重要起，迷途的羔羊们都弄反了。 论爱 假如你在你的疑惧中，只寻求爱的和平与逸乐， 那不如掩盖你的裸露，而躲过爱的筛打， 而走入那没有季候的世界，在那里你将欢笑，却不是尽情的笑悦；你将哭泣，却没有流干了眼泪。 爱除自身外无施与，除自身外无接受。 爱不占有，也不被占有。 因为爱在爱中满足了。 论工作 你们也听见人说，生命是黑暗的。在你疲劳之中，你附和了那疲劳的人所说的话。 我说生命的确是黑暗的，除非是有了激励； 一切的激励都是盲目的，除非是有了知识； 一切的知识都是徒然的，除非是有了工作； 一切的工作都是空虚的，除非是有了爱。 当你仁爱地工作的时候，你便与自己、与人类、与上帝连系为一。","tags":[{"name":"Books","slug":"Books","permalink":"http://catcoding.me/tags/Books/"}]},{"title":"内存泄漏","date":"2010-12-22T11:43:00.000Z","path":"p/c-mem-leak/","text":"以前写的一些程序运行一段时间后占用的内存越来越多，估计是内存泄露了。服务端的程序要长时间的运行，内存泄露是个很严重的问题。于是再检查程序，很崩溃的是还有另外一个模块不是自己写的，看起来很麻烦。看了半小时后发现一些问题，但是还是不能保证是否完全解决了。同事让我用以前他们写的一些函数，对应的为 MALLOC 和 FREE。仔细看了一下觉得很不错，其实就是把 malloc 和 free 函数封装了一下，用来记录申请空间的文件和代码位置，使用方法就是用 MALLOC 和 FREE 替代原来的函数。主要的数据结构是： typedef struct{ long pcode; //指针 char filename[128]; //申请空间的源文件名称 int line; //申请空间的代码所在的行 int ct; //内存状态: 0-未闭合，1-闭合，2-log/脚手架}mem_info;mem_info mem_in[MEM_SIZE]; //MEM_SIZE 最大指针数目int mem_in_id; //数组中已经占有的 mem_info 数目int mem_check_statue; //是否进行内存泄露检查然后有两个函数，一个是初始化函数 mem_check_init(),另一个为 mem_check_write(),这样就能检查者两个函数之间的代码是否有内存泄露，mem_check_write() 可以打印成一个表，所有申请了空间的代码的文件名称和代码所在的行数，以及运行到 mem_check_write() 这里的时候所有申请空间的状态，1 表示已经释放，0 表示申请未释放，2 表示的是脚手架的位置（用来方便检查哪一小段代码是否有内存泄露）。#define MALLOC(size) ck_malloc(size,FILE__,LINE) //FILE 文件 LINE 代码所在行void __ck_malloc(int size,char file,int line){ void p=malloc(size); if (mem_check_statue) return p; if (mem_in_id&gt;=MEM_SIZE) return p; mem_in[mem_in_id].pcode=(long)p; strcpy(mem_in[mem_in_id].filename,file); mem_in[mem_in_id].line=line; mem_in[mem_in_id].ct=0; // 状态: 0-未闭合 mem_in_id++; return p;}那么 FREE(p)，进行的操作就是现在数组中找到是否有这个 p，如果有就改变状态，变为 1 表示闭合了，也就是释放掉了。CALLOC 和 MALLOC 类似，是调用 calloc，函数 malloc() 和函数 calloc() 的主要区别是前者不能初始化所分配的内存空间，而后者能。REALLOC 有点不一样，调用 void np=realloc(p,size)，这里要注意 np 和原来的 p 有可能不一样，有可能一样，比较一下进行相应处理。最后 mem_check_write() 遍历上上面的数组打印出来表，其顺序就是按照代码执行的顺序了，其中脚手架可以比较方便的定位于申请了没有释放的代码行，也就是查找两个 2 之间的 0 所对应的行。这是一个很不错的方法，今天用这个办法找到了好多处不易发现的内存泄露错误。但这也有其缺点，即使完全通过也不能保证就完全没内存泄露了，除非测试时运行代码的覆盖率要保证所有代码都运行到了，这也是正规的、高质量的测试所要做到的程度。我们现在没有时间来做足够好的测试，以后再好好规范一下。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"C","slug":"C","permalink":"http://catcoding.me/tags/C/"},{"name":"内存泄漏","slug":"内存泄漏","permalink":"http://catcoding.me/tags/%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F/"}]},{"title":"老罗的扯淡极致","date":"2010-12-01T11:43:00.000Z","path":"p/luopanzi/","text":"昨晚上正准备睡觉时手贱点随便点击了个链接，然后就在这个《老罗全国巡回演讲完结篇：海淀剧场》里一直跟着欢乐到 2 点钟。大学时有一段经常听老罗语录，胖子嬉笑怒骂、语言犀利、愤世嫉俗、玩世不恭、理性的愤青，听来很过瘾。那时很流行的一句是：“彪悍的人生不需要解释”。时不时我们寝室几个人吃完饭就那么瞎坐在那里，放上几段经典的来笑笑。原来我电脑上是有老罗全集的，后面硬盘毁掉了。很久没这么长时间听这罗氏语调了，酣畅淋漓。 老罗在腾讯微博上很活跃，一如既往的内心强大，就中医是否伪科学和无数人争论到底，耐心相当之好。原来听过老罗语录的人应该会知道此人为什么会如此憎恨中医。这牛还出书了，《我的奋斗》，看过几章，还是挺不错的。原来听说老罗在办个英语培训学校——老罗和他的朋友们教育科技有限公司，没想到现在已成气候，每天醒来都能闻到钱的味道。这个老罗全国巡讲应该是最好的广告了。以前的一系列我都没看到，不过看了最后这个终点站的应该不用看前面的了。演讲的题目是《一个理想主义者的创业故事》，估计是演说了很多场了，这牛已经熟练到如火纯青的地步。原来还以为 ppt 是别人帮忙放的，后来才发现应该是自己手里握着个遥控器，期间基本很少看自己的 ppt，只有在自恋的时候转身对着花痴一下。笑过后也是有所收获，老罗分享了其创业以来的一些经历和想法。稍微总结一下。 1 企业的核心产品或服务。老罗英语培训，师资是关键，这个没办法，有的事只能钱来解决，用最好的薪资待遇请最好的老师。 2 营销策略和推广，这是最长也是最有趣的部分，都是一些有趣的案例。老罗是个偏执狂，只有偏执狂才能做出那么漂亮的宣传画和广告。小小窃喜一下，那个音乐节上的广告我也想到了那么个切入点，不过看的时候还是震撼了一把，完美，太有才了。还有一些平面广告在这里。 3 待遇、企业文化、愿景，这些东西是一个公司是否能留住人的关键，实实在在做产品或者服务的公司，即使在中国这样的创业环境下，还是有生存机会。我没上过老罗的辅导班，也没那钱力，觉得关于英语学习的任何辅导班都没什么用，学英语这事得靠自己。可这老罗英语培训机构做的确实很有个性。 4 即使是老罗这么内心强大的人也有挺不住的时候，这时候他的自恋和幻觉产生作用了。看来老罗最后居然有点哽塞，果真是讲到深处了。最后在商业机构里做一个理想主义者非常难，但赚钱不等于染铜臭。而又有“偏执狂才能生存”这么一个道理，要做一个牛逼的企业，还是需要理想主义的偏执狂。","tags":[{"name":"扯淡","slug":"扯淡","permalink":"http://catcoding.me/tags/%E6%89%AF%E6%B7%A1/"},{"name":"老罗","slug":"老罗","permalink":"http://catcoding.me/tags/%E8%80%81%E7%BD%97/"}]},{"title":"优化算法","date":"2010-11-20T11:43:00.000Z","path":"p/gene-alg/","text":"POJ 2714最近又在 POJ 上做题，碰上2714，题意是： 输入 N，和 N 个点 (x,y)，从原点开始一共可以走 N 步，每一步可以随机选择移动 (x,y)，或者 (-x,-y)。N 的范围为 1-100。输出最远能走到离开原点多远的地方，输出其距离。 分析一下，用迭代肯定可以，不过 2^N 的复杂度肯定太高了。每步有两种选择，其本质是求一个长度为 N 的 0、1 序列使得最后的值最大，为一个优化问 题。这里贪心不能求到最优解，稍微证明一下就能得出。如果不贪心，或者把贪心的范围扩大一点，求出每一步完后的凸包呢，然后再在这步的基础上继续扩展下一 些节点，再求凸包，继续如此，最后求得凸包中距离最远的。求凸包的复杂度位 O(nlgn)，即最后的复杂度为 O(N^2lgN)，是可以接受的。 随机搜索以前看过《集体智慧编程》这本书，这里有一章是说的优化。稍微回顾一下其中的几个算法。对于优化问题，首先得找到一个评价函数，对于其某个方案评价函数能给出某个值评估方案的优劣。至于返回值越大还是越好没有规定，对于特定的问题选择特定的评价函数。 随机搜索不是一种好的优化算法，但是却是后面的算法的根源。其基本思想是，我们随机长生一些解，看是否好，如果比当前更好，替换当前最优解，直到收敛了，或者猜测了足够的次数了。 do{ solution=rand_solution; value=eval(solution); if(value&gt;best) best=value; times++; //测试是否收敛}while(times&lt;max_iter&amp;&amp;(!limit_flag));这种盲目的猜测虽然有机会在某一次猜中最优解，但是效率肯定不怎么好。随机算法还是有一些问题可以适用，比如素数判定，如果能保证错误率很低很低也是可行的算法。 爬山法随机搜索不是一种好的优化方法，为什么？因为没有充分利用已经得出的当前最好解。对于上面这个问题，最优解可能和当前最优解有一些相近之处，可能是因为某一步当前最优解走错了，最后没有演变成最优解。其意思就是，如果把当前最优解稍微改变一下，可能会向最优解的方向靠 近。那么爬山法就是通过当前的最优解，在其附近找更好的解，知道当前没有更好的解为止。而随机搜索是跳越型的，所以没有这个优势。看下面这幅图，现实中很 多问题都会像这样，如果我们把所有解都算出来，按组合排列的顺寻作为 x 轴，评估函数得出的值为 y 轴，能得出稍微连贯的曲线。随机从某个初始点出发，沿着我们想要的方向寻找，能找到优解。 陷入局部最小 最优解为最低点 爬山法的缺点是，如过找到某个局部最优的地方，可能就被欺骗了，因为发现没有斜率了，以为是最优解。最后可能是个次优解。所以继续改进。 模拟退火爬山法总是接受当前最好解，也算是一种贪心的思想，正如贪心一样，有可能得不到最优解。如何改进呢？那就在选择的时候不止是选最好的，还要接受一些看其来不怎么好的解。模拟退火就是这样，“模拟退火”的原理也和金属退火的原理近似。其关键在于：如果新的解比当前解更优， 即换为当前最优解，如果不优，新的解仍然可能成为优解，但是要一定的概率接受。这个时候神奇的 e 派上用场了，这个接受的概率我们可以算 作：p=e^(-(highest-lowest)/(temprature))。刚开始的时候温度很高，所以 p 接近为 1，后面温度开始降低，表现出来的结果就是越是到后面接受较差解的机会就越小。就是因为接受一定的较差解，模拟退火能找到最优解的概率比较大。 遗传算法换一个思路，如果我们把搜索空间中的所有解看成一个个的物种，初始化随便初始化一些物种，然后随着自然的演变，我们需要最好的最强大的最优秀的最优生命力的物种保存下来。遗传算法就是这样，符合自然规律，符合进化论。和上面几种算法一样，随机初始化。为了得出优秀的后代，需要优秀的双亲进行杂交，或者称为配对、或者交叉。别想歪了，对于简单的二进制序列，就可以选 p1 的一部分和 p2 的一部分组合成为一个新的解，当然还有其他的方式。位了避免局部最优的陷阱，我们还需要变异，正如现实中人类总是需要变异的天才一样。对于序列，简单的变异就是改变其中的某一位或者几位。然后每一轮都进行排序，选择其中%10，或者%20 的优秀物种，继续上面的操作，直到解收敛或者达到一定的循环次数。这里可以改变的参数就比较多了， 最大筛选次数，生存的比率和选择的方法，变异的比率，杂交的函数选择，变异的函数选择等等。 总结上面的优化算法都是一个算法框架，如 A*算法一样，最后更多的细节比如评估函数或者参数的选择对算法的效果都有影响。 另外这些优化算法最后能生效都是基于这么一个事实：很多优化问题最优解附近的解也是比较优的解，比如上面的问题，另比如旅行商问题。但有的情况，如下图，就是一个可能不被优化的问题，最优解附近并不是好的解，对于上面的算法都有随机性，也许随机优化一下能找到这个解（概率很小），也许遗传算法能产生个变异，但这都是概率问题，不能保证。 难优化的例子 最优解为最低点 说明：上面的图来自《集体智慧编程》中，这是本不错的书，在网上有代码，python 写的，感兴趣的同学可以仔细看看。 我试着用遗传算法去解上面这个问题，参数调了很多次，最后还是能在一个可以接受的时间内得到所有正确的解。 代码在后面，写得很难看。gene_alg","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Algorithms","slug":"Algorithms","permalink":"http://catcoding.me/tags/Algorithms/"}]},{"title":"Emacs Muse 的使用","date":"2010-11-15T11:43:00.000Z","path":"p/emacs-muse/","text":"Muse 简介 Muse 的配置 Muse 中源代码高亮显示 Muse 来写主页和博客 Muse 简介 Muse 是由 EmacsWiki 衍生的，为 emacs 下的一个扩展模式，可以方便快捷的为文档生成各种格式，包括 html,pdf，latex 等等。Muse 的编辑规则很简单，而且支持“所见即所得”的编辑方式可以让文档编辑更轻松。我使用这个工具已经快一年了，强烈推荐。这个 html 文件就是从 Muse 调用 htmlize 生成的。 Muse 的配置 从这里下载最新版本的 Muse，比较简单的安装方法是解压后直接在目录下运行 make，然后把所有的文件都拷贝到 emacs 的一个加载目录下面 (比如～/.emacs.d/muse/)。设置.emacs 加入以下几行。 ;; 加载 muse (require 'muse-mode) (require 'muse-html) 然后就可以利用 Muse-mode 来方便地创建文档。这里有个QuickStarted，看一遍就基本掌握了编辑规则。编辑完成以后按键 C-u C-c C-t 即可发布该文档。 Muse 中源代码高亮显示 在 Muse-mode 中编辑时是所见即所得样式的显示，但是有一个问题是代码不能高亮显示，要贴代码就有点不方便，解决的方法是要下载 htmlize.el，而且需要 1.34 以后的版本才支持这个功能，在这里下载。使用方法也有说明。 Muse 来写主页和博客 很多搞学术的同学喜欢建一个看起来很严谨的静态主页，这样的主页用 Muse 来维护非常方便。对于 wordpress 的博客或者主页，一款离线撰写工具是必须的，在 windows 下可以用 WindowsLiveWriter,Linux 下也有相应工具。不过我大部分还是在自己电脑上用 Muse 来写完发布成 html 格式，然后再发布到主页上。首先我们需要建立一个主页的工程。比如我的： ;;==新建一个 wiki 工程 (setq muse-project-alist '((\"MainPage\" (\"~/document/blog/Home\" :default \"index\") (:base \"html\" :path \"~/document/blog/Home_Page\")) (\"Computer\" (\"~/document/blog/Home/Computer/\" :default \"index\") (:base \"html\" :path \"~/document/blog/Home_Page/Computer\")) (\"Sport\" (\"~/document/blog/Home/Sport\" :default \"index\") (:base \"html\" :path \"~/document/blog/Home_Page/Sports\")) (\"Other\" (\"~/document/blog/Home/Other\" :defualt \"index\") (:base \"html\" :path \"~/document/blog/Home_Page/Other\")))) 然后到相应目录下撰写 muse 文件，快捷键 C-c c-p 就发布了整个工程，在 Home_Page 相应的目录下生成了 html 的文件。看起来有点复杂，其实还是很方便的，代码高亮这个程序员都喜欢的功能肯定就不用操心了，同时在本机上留有个备份。这种 wiki 风格的网页还是很利于浏览。不过有一个弊端，图片插入虽然在撰写过程中能直接预览的，但是上传到 wordpress 上路径肯定会变，所以还是要再稍微编辑一下。","tags":[{"name":"Emacs","slug":"Emacs","permalink":"http://catcoding.me/tags/Emacs/"},{"name":"Tools","slug":"Tools","permalink":"http://catcoding.me/tags/Tools/"}]},{"title":"又是一些歌","date":"2010-11-14T11:43:00.000Z","path":"p/damien-rice/","text":"实验室的机子要被占，要搬出来，所以得把资料整理一下。发现一个原来研一英语课上做 representation 的 ppt，题目是介绍一位自己喜欢的歌手。那次第一次上台做英报告，呵呵。我喜欢缓慢而伤感，有些沉重的歌。在一位同学日记上看到介绍 Damien Rice 的，然后喜欢上了他的歌。研一那一年骑车时候基本都是这些歌，高中时最郁闷的时候经常听的是王菲和齐秦。一段时间狂听某些歌好像已经成了习惯，然后偶尔再听到的时候当时的情景自然就浮现了，音乐也是一种好的记忆载体。 Damien Rice Damien Rice is an Irish Rock singer.Two studio albums: O in 2003, and 9 in 2006.He was born and raised in Ireland,a country which is rich in country music, poets, singers. When He was young, music and drawing attract him. Rice was a member of the rock band Juniper.Having released the singles “The World Is Dead” and “Weatherman” in Ireland during 1998. Rice left the band to pursue a solo career. His Juniper band mates later became Bell X1. Rice’s first solo album is O, which was released in 2003 and a true contender for one of the best albums of 2003, won the Shotlist Music Prize.Rice’s style is simplity. The cover of this album is a beige hand painted portraits of the two small chiledren, which was drawed by himsefl. This is am simple folk album. This album contains a large number of hollow guitar chords , easy and simple percussion, drowning, backwards vocals, and low_key accompaniment . Rice is master of what critic called “the unknown tongue” — basically the musical equivalent of the “punctum” in photos, Rice’s emtional singing brings me a sad ,clean and sophisticated intimate space. Three years later, following extensive promotion of O in Ireland and further success worldwide, Rice released his second studio album 9 in 2006. 好听的专辑： 9 1. 9 crimes the animals were gone elephant rootless tree dogs coconut skins me, my yoke and i grey room accidental babies sleep don’t weep9 crimes 最好听，适合半夜失眠。MV 拍得很吸引人，在这里，我当时课上放的就是这个 MV，非常惊艳，课后还有同学问我要这个。另有个评论感觉写得非常不错。Cold water浮躁繁杂的时候，就来听听这样一首像诗歌般的曲子，这也是电影《偷心》的片尾插曲。木吉他很有感觉，以后有时间学学，呵呵。 还有这首The Blowers Daughter非常不错。","tags":[{"name":"Notes","slug":"Notes","permalink":"http://catcoding.me/tags/Notes/"}]},{"title":"给 C 瓜同学吧","date":"2010-10-27T11:43:00.000Z","path":"p/forc/","text":"C 瓜同学一直关注这个我这个小地方，下面是一些我面试中或者和同学讨论的一些不错的面试题，备份一下，也希望对你有用。 1：C++ 的多态是如何实现的？如果你用 C 如何来实现面向对象的多态？ 2：判断一个有向图中是否有环。上篇文章里面写的那个杯子倒水问题。给一个都是正整数的数组，和一个正整数 sum，求是否存在和为 sum 的子数列。 3：两个有大量 id 的集合 A 和 B，数量上亿级，如何求出两个集合的交集，A 中有的 B 中没有的，和 B 中有的 A 中没有的集合。 4：设计实现一个管理内存的小模块，接口为 void checkout(size_t size), void checkin(void ptr)。 5： 设计一个数据结构，存储一副象棋子的摆放，尽量压缩空间，使得方便通过传输到另外一台机子上然后恢复棋盘。 6：数组的众数问题，最长递增子序列问题。找大量数据中前 k 个大的数。找大量数据中第 k 大的数。 7：一个平面中有很多点，用最快的算法找出相隔最近的两个点。 8：select/poll 和 epoll，基本互联网公司都会提到这个东西。 9：给敏感词列表，和一大段文本，考虑一个敏感词过滤的算法。 10：海量数据问题，很多，一般方法就为分治、hash、位图。 很多没有标准答案，面试过程中的探讨很重要。找工作不难，找份好工作还是难的，基础知识很重要，数据结构和算法、操作系统、编程语言的掌握，数据库和网络。可以根据自己的喜好，偏向于某个方向。","tags":[{"name":"Notes","slug":"Notes","permalink":"http://catcoding.me/tags/Notes/"},{"name":"工作","slug":"工作","permalink":"http://catcoding.me/tags/%E5%B7%A5%E4%BD%9C/"}]},{"title":"有你的快乐","date":"2010-10-27T11:43:00.000Z","path":"p/haveyourfun/","text":"晚上睡在公司，这边除了晚上偶尔有施工的声音，一切都还不错。洗个热水澡，随便写写早点睡。嘈杂的音响放着这么王若琳的《有你的快乐》，标题就用这个吧，哈哈。关于工作：今年好像计算机专业的同学们还是非常好找工作，首先华为华赛来得非常早，然后就是腾讯，这几个公司就签了好多。成都很多同学都不想离开四川，所以进华为的很多。我开始找工作的时候也没有想法一定要留在这，只是周围一直有各种什么成都多好多好之类的言论，什么消费低，房价低，不排外，生活安逸之类的。渐渐地也不由自主地越发想留在这边。我找工作应该已经结束了，一共面了大概六个公司，一周三个公司，中间有一周觉得身体不是很舒服，就没怎么动。第一周面的华赛，前面已经说了很悲剧。然后腾讯，也很诡异，小概率事件发生了，面了终面没有给 offer。现在还不知道原因，可能还是二面的问题吧，二面的面试官问我平时是不是都很自我，当时我还没反应过来，后来才觉得不对劲。大公司都会有自己的企业文化，可能会因为这些把人刷掉也是正确的。没收到 offer 心里多少会有点失落吧，深圳是除了成都之外我比较想去的地方，毕竟那边认识的人比较多，离家也比较近。过了一周后，已经是找工作的高潮时段，我也安奈不住了，所有公司都想去试试。上海纳拓软件，因为何师兄的内推这个公司暑假就已经开始联系然后笔试了，最后因为实习没去上海面试，所以等到他们的校园招聘。前面三面技术面，一面 C++，两人一台电脑整程序。电工的校友大哥最后一个题目把我摧残了，模板类啊、嵌套类、友元类啊一看就紧张了。基本是他教我怎么改那个程序，从来没觉得自己 C++ 那么差了，我以前也只是把 C++ 当一个扩展了一点的 C 来用，所以当时备受打击。二面是师兄的算法，还是比较照顾我，给 tips，算是探讨了。三面数理逻辑，面试官很 nice，一点点教导，终于给那些最基本的文式图画出来了。纳拓的三个面试是我接触的最深的面试了，一路下来感觉很辛苦。联发科，据说要在成都建立分公司，去试试。面试官很多都是台湾人，感觉很有礼貌，他们要求也不是很高，还是吸引了不少想留成都的同学。另外当晚面了创新工场，感谢欧阳大哥的内推，还有 Xiaoxiao 同学的面试也很有水准，又有点受打击，后面的那个程序实在做得不尽如人意，最后还是让我进了二面。然后和 Billy 大概 40 分钟的聊天，交流了一些想法。创新工场到底怎么样我不是很了解，网上的看法是两个极端，要么是说很好的，要么是说一个空壳，但是我知道很多很强的同学在里面做得都非常有激情，非常有干劲，技术氛围也都不错，所以我也动心了。过了两天是纳拓那边的技术四面，刘大哥很和蔼，一起吃了个晚饭然后才面试。也是首先谈谈项目，没说多久就指出了我的东西是 over design 了，呵呵。然后交流了各自的看法，感觉很投机。纳拓软件虽然只有 10 个人左右，但肯定是个非常出色的团队。然后是他们老板的电话终面，他也没怎么太为难我，连老板都在问技术问题，呵呵。总是面完后感觉找到了中意的公司，所有后面也没有再去继续找了。在同一天收到创新工场和纳拓的 offer，当天比较纠结。北京和上海，不知道去哪个了。真的也想去北方那边闯闯，创新工场那边应该是个不错的平台。还有欧阳大哥每周教会聚会的短息发到我手机上，我也会时不时想如果我在北京一定要去参加他们的聚会。最后综合各方面的意见，我应该还是签纳拓吧，因为对他们那边感觉很投机投缘，而且也很可能会过一年后在成都开 branch。那么，两周的找工作日子算是过去了，没太努力，不过还是认为找到了适合自己的公司。实验室的同学们都找到了自己满意的工作，突然觉得我身边一个个是大牛啊，哈哈。今年的行情真的非常好了，国内的 IT 公司都在大规模扩招，外企倒还招得少，我们陶瓷国的 IT 虽然一直说做不到核心，但也确实在进步啊。 最近不知道为什么，非常淡定，也许在这边公司做得比较安稳。我喜欢这种一小群人做东西的感觉，大家一起讨论争论，努力想把一个东西做好的感觉。也可能是因为在这边受到了一些熏陶，所以找工作也想去小的公司或者创业型的公司。第一份工作工资不是主要考虑的，因为我想想即使一年赚 20w(应该对应届生算不错的待遇了吧),除去平时花费一年能攒多少钱呢？多 1k，2k 对于生活也本质的提高，所以在能养活自己的情况下，找些觉得适合自己、能多锻炼、能让人有动力的公司挺好的。况且，如果把工作看严肃点，我应该找的是一群得整天相处的人，所以投机很重要，^^。感谢找工作这段时间所有给予我帮助的所有人，虽然你们不一定能看到，^^。熊师兄，两位何师兄，欧阳大哥。王骆驼，傅骆驼，yyl，寓于其中以及实验室的各位师兄师姐们，哈哈。","tags":[{"name":"Notes","slug":"Notes","permalink":"http://catcoding.me/tags/Notes/"}]},{"title":"面试：杯子倒水","date":"2010-10-14T11:43:00.000Z","path":"p/beizidaoshui/","text":"前些天纳拓的面试有一道题目： 给你一个 3 升的杯子和一个 5 升的 (杯子是没有刻度的)，要你取 4 升水来 (水可以无限取)，请问该如何操作。这个题目今年面试出现了很多次，不过这次变化了一些。如何抽象出一个模型，如果写程序如何解，如果要求得杯子倒水的过程如何做？ 当时并没有一下想出来，看起来有点像取石子那样的游戏，想找规律。然后被提示搜索，对，搜索问题。 搜索得确定状态的表示，状态之间的转移方式，起点和终止状态，如果这些都确定那么就基本完成了。 如果我要求最快的解法，BFS。如果要求所有的解法，递归 DFS。这里状态的总数目比较少，如果用一个整数来表示，10 位表示 A 杯子的水量，个位表示 B 杯子的水量，这样要的空间最大也为 60 个整数。再想想如果用两个整数，最多 64bit，也能表示出状态，能省下空间。 很久没做题了，有些生疏了，看来还得好好补一下。 代码_下载","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"工作","slug":"工作","permalink":"http://catcoding.me/tags/%E5%B7%A5%E4%BD%9C/"}]},{"title":"找工作小结","date":"2010-09-30T11:43:00.000Z","path":"p/forjob/","text":"又是很久没更新了，这段时间比较忙碌，各种笔试面试各种奔波，终于体会到了找工作到艰辛。而这还只是开始。国庆这些天应该要轻松一点，很多公司都是国庆后再来学校。总得来说最近这两个月还算比较充实，即将面临走出校园，还是得去考虑各种选择。另外，尝试着离开实验室后又淡定了不少，哈哈。虽然还没完全结束找工作这些事，但还是记录一下面试的感受吧，其实我面得还算少，才三个公司。 首先华赛就悲剧了，本来打算去积累点面经的，又不是特别重视，那面试官估计也看出来了，其中各种不爽，自己的交流方式也有问题，让他觉得这人有些傲吧。呵呵，本来我是个多不自信、多自我怀疑的人，硬是装作很自信的样子就出问题了。最后面试官说今天就到这里吧，你回去等通知吧。我说把我简历还给我，汗，我当时居然还说了这么句话，想起就无语呀。 TX 的笔试感觉很细，做完后不怎么确定能不能有面试机会了，不过第二天就发来了短消息，笔试还是没怎么刷人。一面人山人海，岷山饭店还没个坐的地方，等了两个小时腿都酸掉了。据说王骆驼碰上个年纪比较大的，问得比较刁，自我感觉是挂掉了。最终，我碰上一个比较年轻的，一看就搞技术的，笑得很贼，哈哈。问题都中规中举，有的没答出来，不过还是说了一下自己到思路。最后讨论了前段时间自己在做到多线程的缓存，嘻嘻。这里不得不再说一下，在公司这段时间虽然比较短，但还是实在地做了一些事，对这一块至少说有一些体验，还是可以和面试官聊聊。面完后心里貌似有个底了，应该有二面机会。果然，第二天早上不到 6 点怎么就自然醒了，睡不着，于是就想一面时候的一个问题，觉得貌似想到了优化方法，哈哈，这时手机震动，于是下床一看果然有二面 (赞一下 tx 的招聘人员敬业精神，早上 1 点半给你发短信)。二面在成都 TX，第一次去了躺软件园，人挺多。TX 的工作环境貌似还不错，装饰看起来比较鲜艳。走之前向何老大打听了一下，据说二面就是狂问技术，各种方面的都有，于是心里有点点发毛。等了近四十分钟，最后碰上六号面试官，很奇怪的是后面感觉一直在聊天，项目方面都是泛泛而谈，没怎么问我很深入的技术问题，气氛还可以。大概二十多分钟就结束了。等王骆驼面完一起回，他又碰上个狂刁钻的，各种效率不高，速度不行…..然后我觉得诡异了，说你机会可能更大点。 晚上去面了一下中兴移动，面 C++，刚开始那年轻到面试官一副很凶很高深的样子：“学过 UML 吧，把你这个项目中所用到到类图和关系画出来..”。顿时很无语，在纸上边说边画，心里觉得不爽，这么累了本来是想来打打酱油的，还得慢慢回想一下那折磨了我两年的各种不感兴趣的对象。然后那人问：“你这个项目中只用了两层继承关系吗？”呃，我这正有点郁闷，突然想起哪本书说的，于是就随口说：“面向对象不是银弹，设计得好两层就够了，设计不好十层也不够”。 他居然没继续问了，原来适当地装装也能唬住人的。然后聊了聊状态模式，我说得比较清楚，因为这个模式还是有点体会的。不爽，面试过程中还换了个房间。然后再下面就是聊天了，这下感觉平等多了，聊了聊他们是做什么的，做手机终端各种底层和上层吧。然后就来了个人力资源的面试吧，比较和蔼，就说我们待遇比中兴好。完后站在电梯旁边，王骆驼要强面，两个人一副喝茶的姿势聊得很 high，我在旁听了一下，觉得很无语。一个 40 岁左右的貌似技术人，在王骆驼各种项目忽悠了一顿后，说：“恩，UDT 这个东西这么好，我在哪里找到呢？”王骆驼：“在网上下载”。然后面试官最后问了句：“在你编译的时候出现了一大堆到错误提示，你怎么解决？”，王骆驼：“我从第一个错误开始改“。面试官露出了找到知己的那种兴奋表情，最后站起来总结一番：”好，我觉得你对 C 语言理解很深刻，我去给你安排第二轮面试”。回来时王骆驼一副神清气爽，之前 TX 被问得不知所云，这会劳累全没了，反差啊，哈哈！然后第二天中兴移动就让人同学们去签就业意向了，估计很多人都不去。 继续 TX，说着觉得诡异了，果然晚上王骆驼进入了三面，我就没了名字。后来想想估计还有一批，我就不相信就这么悄无声息地挂掉了，如果挂掉我真不知道原因在哪里了。晚上跑到公司睡了一觉，好久没来公司了，还有一些工作要做。另外如果还有三面，从这边过去软件园也方便。晚上 9 点多看到一条短信，估计是来消息了，果真自我感觉还是有点点灵验的，第二天九点三面。三面就更是聊天了，没有经历过群 P，不过今天到碰上了类似的问题，例举出三个自己的缺点。呵呵，总不能继续各种老套太过追求完美吧。比较属实的三点：稍微有点害羞，作息时间不怎么好，有时候有些马虎。最后就等消息吧，感觉面试就和聊天一样，聊得好就好。另外根据王骆驼的经历，面试过程中不一定都要马上答出最好的答案，其中的讨论过程很重要，而且可能问题本来没有最好的解法，只能折中。韩 sir 说：“一般招人技术不是最重要的，应聘者是否是一个口味的很重要“。恩，有道理。 嗄，外面乌云一片，正考虑今天要不要回学校。","tags":[{"name":"Notes","slug":"Notes","permalink":"http://catcoding.me/tags/Notes/"},{"name":"Backup","slug":"Backup","permalink":"http://catcoding.me/tags/Backup/"}]},{"title":"Emacs 自虐","date":"2010-08-21T11:43:00.000Z","path":"p/emacs-for-fun/","text":"无意中用了一下 C#,发现 VS 下面有一个功能还是非常好的，就是每次按下回车键盘的时候，都可以把刚刚输入的那行代码自动排版一下， 看起来要清晰一些。比如 int a=0; ==&gt; int a = 0;struct Node p=&amp;node; ==&gt; struct Node p = &amp;node;a+=b; ==&gt; a += b;int p=&amp;a; ==&gt; int p = &amp;a;int a=b+c+d+f; ==&gt; int a = b + c + d + f;for(a=0,b=0;a&lt;10;a++) ==&gt; for(a = 0, b=0; a&lt; 10; a++)if(a==b) ==&gt; if(a == b)if(pbuf!=0) ==&gt; if(a != b)fwrite(buf,1,size,fp); ==&gt; fwrite(buf, 1, size, fp);printf(“%d %s\\n”,len,buf); ==&gt; printf(“%d %s\\n”, len, buf); //引号内的不变，引号外的”,”后面加空格if(p&gt;=allocbuf&amp;&amp;p&lt;buf+size) ==&gt; if(p &gt;= allocbuf &amp;&amp; p &lt; buf + size)return (b!=0)?gcd_ver2(b,a%b):a; ==&gt; return (b != 0) ? gcd_ver2(b, a % b) : a;同时要注意的情况，还有些情况下我不想让符号两边加空格： #include &lt;stdio.h&gt; //&lt; &gt; 两边不加 printf(“%d%d%d\\n”,n,m,k);//这个%两边不加 检测是否在引号内部a++; //不加空格int p; //不加空格return manip(this); //这个两边不加 找到前面或者后面是否为 (strcpy(mode,“w+”); //引号里面的不变 检测是否在引号内部我以前写代码习惯都不加空格，感觉不加要写得快一些，可是这不是个很好的习惯。linux 下有 indent 这样的工具，不过是针对于最后完成的源程序来排版。在写程序的过程中像赋值操作符两边加上空格会显得比较清晰，Emacs 里面好像还没这么个插件，那我来折腾一下自己写了一个。原来还是比较复杂的。应该好好学学正则表达式，这就是一个正则匹配和替换的过程。呜，括号看得头都晕呼呼的，不过还好，最终有这么一个东西用起来比较顺手了。 首先定一个关键字和替换列表： (setq beautifly-line-list ‘( (“+” . “ + “) (“-“ . “ - “) (“=” . “ = “) (““ . “ “) (“/“ . “ / “) (“%” . “ % “) (“&lt;” . “ &lt; “) (“&gt;” . “ &gt; “) (“,” . “, “) (“+=” . “ += “) (“=” . “ = “) (“/=” . “ /= “) (“%=” . “ %= “) (“==” . “ == “)))一个用来测试 dest 是否为上面关键字的函数，后面用 char-after 来获取一个 point 的字符，对应的是 asci 码。 (defun test-valid(dest) (interactive) (if(or (equal dest 43) (equal dest 45) (equal dest 42) (equal dest 47) (equal dest 37) (equal dest 62) (equal dest 60)) ;;&lt; t nil)) ;;打印出当前位置的字符 调试用(defun print-pos-char () (interactive) (setq value (char-after (point))) (print value)) ;;从 point-pos 位置开始 到这一行的尾部，检测是否有”，即检测是否在” “内部(defun test-in-quote (point-pos) (interactive) (move-end-of-line 1) (setq end-pos (point)) (goto-char point-pos) (setq ret-value nil) (if (search-forward “\\”” end-pos t) (setq ret-value t) ) (goto-char point-pos) ret-value) ;;这个函数先调用我的排版函数，然后调用原来的 new-line-and-indent(defun my-new-line-and-beautyfly () (interactive) (beautifly-line) (newline-and-indent)) ;;在 my-c-mode-common-hook 下面加上这么一句，表示把回车键绑定在上面那个函数上。 (define-key c-mode-base-map [(return)] ‘my-new-line-and-beautyfly)下面就剩下这两个函数了，写的太过复杂，可惜不会用高级一点的正则表达式，所以显得不好看。其想法比较简单，按照上面那个列表，一次查找，我要找一个两员操作符，其两边都是空格，在其两边加上空格，注意排除掉 ++,—操作。然后识别 +=,-=,*=等符号，再两边加上空格。用起来还可以。逐渐写了些 elisp，感觉特别适合自底向上的方式进行，通过一些小函数，逐步累积成一个功能，再最后只用一个上层函数来调用这个功能。每个小函数除了返回结果不改变函数外的其他变量 (无副作用)。同时写一个小的函数可以马上写一个测试函数，保证其正确无误。 最后 bueatifly_line 的代码有点点长，不贴咯。","tags":[{"name":"Emacs","slug":"Emacs","permalink":"http://catcoding.me/tags/Emacs/"},{"name":"Linux","slug":"Linux","permalink":"http://catcoding.me/tags/Linux/"},{"name":"Backup","slug":"Backup","permalink":"http://catcoding.me/tags/Backup/"}]},{"title":"using automake","date":"2010-08-21T11:43:00.000Z","path":"p/using-automake/","text":"以前都是手写 makefile，没使用 automake 之类的工具，今天看了一些相关资料，简单地总结一下，留个备份。 使用 Makefile unix/linux 下面使用相当广泛，对于简单一些的程序，手写 makefile 还是比较容易的，只要指定清目标文件，最后可执行文件的依赖关系。使用一些高级一点的功能更方便，比如下面这个就比较好用，稍微编辑一下就可以用于常用的小工程。这个 Makefile 把所有.cpp 的文件编译成相应的.o 文件，然后链接为 Targetfile 文件。 CC = g++ -O2LD = g++TARGET = TargetfileSOURCES = $(wildcard *.cpp)OBJS = $(patsubst %.cpp,%.o,$(SOURCES)) %.o:%.cpp $(CC) $(CFLAGS) -c $&lt; -o $@ Targetfile:$(OBJS) $(CC) $(OBJS) -lglut -lglui -o Targetfile clean: @/bin/rm *.o 使用 automake 等工具 1. 首先运行 autoscan，这之后会生成一个 configure.scan 文件，修改为 configure.in，并编辑。典型的一个文件如下，AC_CONFIG_SRCDIR,AC_CONFIG_HEADER 这两项还不知道干什么用的，如果不注释掉后面 automake 会出现错误，那就先注释掉吧。重点修改 AC_INIT，AC_INIT_AUTOMAKE。AC_CHECK 那些不用管，后面提示-lglui 提示要注意，这是需要链接的库文件，这里链接 glui 这个库。 # -- Autoconf --# Process this file with autoconf to produce a configure script. AC_PREREQ(2.61)AC_INIT(TSPdemo, 1.0, moorekang@gamil.com)AM_INIT_AUTOMAKE(TSPdemo, 1.0)#AC_CONFIG_SRCDIR([Elastic_Alg.cpp])#AC_CONFIG_HEADER([config.h]) # Checks for programs.AC_PROG_CXXAC_PROG_CC # Checks for libraries.# FIXME: Replace main&lt;span style=&quot;color: #deb887;&quot;&gt;&#39; with a function in-lglui’:AC_CHECK_LIB([glui], [main])# FIXME: Replace main&lt;span style=&quot;color: #deb887;&quot;&gt;&#39; with a function in-lglut’:AC_CHECK_LIB([glut], [main]) # Checks for header files. AC_HEADER_STDCAC_CHECK_HEADERS([stdlib.h]) # Checks for typedefs, structures, and compiler characteristics.AC_HEADER_STDBOOLAC_C_CONSTAC_C_INLINEAC_TYPE_SIZE_T # Checks for library functions. AC_CHECK_FUNCS([sqrt])#AC_CONFIG_FILES([makefile])AC_OUTPUT(Makefile) 编写 Makefile.am，如下面这样。和 makefile 一样，写上可执行文件依赖于的源文件，_LDADD 是要链接的库文件名。AUTOMAKE_OPTIONS=foreignbin_PROGRAMS=TSPdemoTSPdemo_SOURCES= Elastic_Alg.cpp MyMap.cpp mathlib.cpp \\Elastic_Alg.h MyMap.h mathlib.h \\LaoMan.cpp SOM.cpp pointdef.h \\LaoMan.h SOM.h main.cppTSPdemo_LDADD = -lglut 然后执行 aclocal，和 autoconf，最后 automake —add-missing 生成 configure 文件。这就完成了，下面就是 unix 下编译安装软件的三个步骤了，./configure，make,makeinstall 等。 写得比较粗略，详细查看这个文档。","tags":[{"name":"Linux","slug":"Linux","permalink":"http://catcoding.me/tags/Linux/"},{"name":"Backup","slug":"Backup","permalink":"http://catcoding.me/tags/Backup/"},{"name":"makefile","slug":"makefile","permalink":"http://catcoding.me/tags/makefile/"}]},{"title":"折腾记录","date":"2010-08-20T11:43:00.000Z","path":"p/zheteng/","text":"centos 环境变量 在配服务器 web 环境的时候，因为这个问题花费了不少时间。tomcat 找不到 java 的其他开发包，开始以为是服务器是 64 位的问题。最后因为在/etc/profile 文件里面设置为 export CLASSPATH=…,这个 export 貌似不能少。或者是因为命令 prelink -a 的作用起了效果，这个命令好像只是起到加速到作用。orz，我是被 ubuntu 宠坏了，什么 linux 命令都没怎么用咯。 mysql mysql 配置局域网内都能访问。 1 mysql -h localhost -u root2 mysql&gt;GRANT ALL PRIVILEGES ON . TO ‘root’@‘%’WITH GRANT OPTION3 mysql&gt;FLUSH PRIVILEGES4 mysql&gt;EXIT 这样就可以在其它任何的主机上以 root 登录，其他用户类似。但是连上以后速度比较慢，在 my.cnf 文件里面配置一下啊， 把缓存那些改大一些，加上这么一行：skip-name-resolve。 centos 双网卡路由问题 centos 能 ping 通局域网，但是不能上外网，最后查处是因为双网卡到问题，添加一个默认的网关就可以了。使用命令： route add defualt gw 192.168.1.1netstat -nr 查看内核 iP 路由表。 two or more data types in declaration specifiers C 编译器这个错误指向到行会不准确，有一种情况最容易出现这样的错误，那就是在你的程序里少了个”;”号，有可能在你的头文件里，也有可能在本文件中。","tags":[{"name":"Linux","slug":"Linux","permalink":"http://catcoding.me/tags/Linux/"},{"name":"Backup","slug":"Backup","permalink":"http://catcoding.me/tags/Backup/"}]},{"title":"《编程珠玑》：代码优化","date":"2010-08-05T11:43:00.000Z","path":"p/programming-peal/","text":"编程珠玑里面代码优化这一章。问题 1 函数，宏，内联代码#define max(a,b) ((a)&gt;(b)? (a):(b))float max(float a,float b){ return a&gt;b? a:b;}inline float max(float a,float b){ return a&gt;b? a:b;}上面这个函数到底哪一个快一些？测试了一下。宏效率是高一点，但是对于加上编译器优化以后基本没什么区别了。 问题 2 顺寻搜索 int search1(int v){ for(int i=0;i&lt;N;i++) if(vec[i]==v) return i; return -1;} int search2(int v){ vec[N]=v; int i; for(i=0; ;i++) if(vec[i] == v) break; if(i==N) return -1; return i;} int search3(int v){ vec[N]=v; int i; for(i=0; ;i+=8) { if(vec[i]==v) break; if(vec[i+1]==v) {i+=1; break;} if(vec[i+2]==v) {i+=2; break;} if(vec[i+3]==v) {i+=3; break;} if(vec[i+4]==v) {i+=4; break;} if(vec[i+5]==v) {i+=5; break;} if(vec[i+6]==v) {i+=6; break;} if(vec[i+7]==v) {i+=7; break;} } if(i==N) return -1; return i;} 这三个函数哪一个效率最好？据说第二个提高 5%，第三个会提高 10%~20%(对于老实计算机)。在我的机子上测试了一下，N=10000000。并不如书上说的能提高多少， 反而最原始的写法在优化后效率更高，确实是这样的数据。 问题三 二分查找 数组大小为 1000。 单位 ms。 确实第二个版本提高了一些，第四个版本甚至提高了一半的效率。测试是一个麻烦的事情，因为同一时间处理器调度了其他进程，但多次测试还是能给一个大概的印象。第二个例子的优化没起什么作用，也许现在的编译器优 化技术比以前更好的，得出的结果并不如书上所说。在一个算法复杂度确定的情况下改变一些写法会有一点提升，但是对于不同的输入规模也许就得不到什么提高， 而且编译器优化以后基本差别就更小了。为了那么一点效率的 提升增加了代码的复杂度得不偿失。原理那章也说了，不成熟的优化是大量编程的祸害，会危机程序的正确性、功能性、和可维护性。 王道还是改变数据结构或者算法，除非确定一个部分的代码会经常被调用很多次，在这里可以花一些功夫去优化。优化是把双刃剑，玩火者，小心自焚，哈哈。","tags":[{"name":"Books","slug":"Books","permalink":"http://catcoding.me/tags/Books/"}]},{"title":"A*算法与 K-shortest path 问题","date":"2010-08-02T11:43:00.000Z","path":"p/astart-k-shortest-path/","text":"那天师兄给面试，面到一道图算法题目，求图中两个点的前 K 短路径。当时觉得用 Dijkstra+heap 应该可以，不过也没想清楚。以前看到过这个，那时还没怎么仔细看图算法所以丢一边了， 今天好好看了一下。简单一点的解法是用 Dijkstra+Astar。典型的题目就是POJ 2449。 A* 算法 再谈 A算法。A算法中的评估函数为 f(N)=cost(N)+h(N)。其中 cost(N) 为从源点到 N 点的距离，h(N) 为 N 点到终点的的一个评估路径长度，设 h(N) 为实际 N 点到终点的路径长度。只要满足条件： h(N)&lt;=h(N)，那么用这个评估函数找到最短路径。具体证明看这篇论文A Formal Basis for the Heuristic Determination of Minimum Cost Paths。 其优势在于在选择每个路径 上的点的时候给予了 h(N) 这个启发，在搜索空间中尽量选择可能最有可能产生最优解的下一个状态，使得搜索的时间都相应地减少。A算法的思想也是贪心 的，Dijkstra 是 A的一个特例，当 h(N)=0 时，A*就退化成了 Dijkstra 算法，那么就是盲目的扩展当前最短路径了。 来个例子，下面这是一个城市的公路图网，一共有 18263 个点，23874 条边，视为无向图。我们知道起点和终点的坐标，现在我们要求某两点之间的最短路径。 1. 用 Dijkstra 算法来，其中白色的点表示搜索过程中访问了的点。可以看出 Dijkstra 算法有点像 BFS 向周围扩展，做了很多无用的搜索。当然这与图的形状也有一定关系。 [Dijkstra 访问 18191 个点] 2. 用 A算法，设 S 为起点，T 为终点，启发函数为 F(N)=Path_Dist(S-&gt;N)+Dist(N-&gt;T)。在搜索过程中 Path_Dist 一直维持着 S-&gt;N 的路径长度，Disk(N-&gt;T) 的计算可以有多钟选择，这里我选择 Dist(N-&gt;T)=sqrt(|Xn-Xt||Xn-Xt|+|Yn-Yt||Yn-Yt|),这个为两点之间的理论最短路径，肯定是满足条件 h(N) &lt;= h(N) 的，那么能得到最优解。可以看到搜索偏向于目标点的方向。 [A* 两点之间距离为评估函数 访问 4398 个点] 3. 另外 (x+y)/2 &lt;= sqrt(x^2+y^2)，所以也可以选择 (|Xn-Xt|+|Yn-Yt|)/2 作为启发函数。但为了节省这个 sqrt 的操作，代价就是访问了更多的点。 [A* (x+y)/2 作为启发函数 访问 14374 个点] 4. 可以做得更好，修改启发函数。Dist(N-&gt;T)=|Xn-Xt|+|Yn-Yt|，这为曼哈顿函数，这样就不满足条件 h*(N)&lt;=h(N) 了。所以得不到最优解，但是速度上会快很多，搜索的点也会减少很多。 [A* 曼哈顿距离作为启发函数 访问 296 个点] 大概能得到一个规律，搜索效率依赖于 h(N) 的启发作用，当 h(N) &lt;= h(N) 时候，我们能得到最优解，用第二种启发函数能也满足最优解的条件，但是因为启发用少了所以访问了更多的点。当 h(N)&gt;h(N) 时，得到的可能是比较优的解 (非最短路径)，可以认为因为得到的启发更多 (多到超出了得到最优解的条件限制)，所以能取得更快的效率。这又是一个普遍的问题，在速度、精确度两者之间经常会只能二选一，对于不同的应用从中作出折中。上面那篇论文证明了，对于刚才举例的这个问题，用两点之间的直线距离最为启发函数的 A算法是所有能得到最优解的算法中访问点最少的。启发函数对于特定的问题有特定的取法，那么 A*作为一个搜索的算法框架用处还是挺多的。 Dijkstra＋A* 求 k 短路径 当然这个算法不是我想出来的，这里只是说一下看后自己的理解。在 A算法中，优先队列出来的点如果扩展到了终点，那么 就得到了最短路径。如果能得到实际的评估函数 (也就是 h(N))，那么第二次 从优先队列里面弹出来的就是第 2 段的路径，依次直到 k 短。如何得到 h(N),就是图中各个点到 T 的实际最短路径距离，可以从图的反向图以 T 为源点进行 Dijkstra 算法，最后 Dist[N] 就可以作为 h(N)。然后以 cnt[N] 表示 N 点从优先队列里面弹出来的次数。K-shortest 问题还有更快的解法，不过还没看，这里有大把论文。这里还分结果路径中是否可以有环，像现实中公路网肯定是要求无环的 k-shortest path。下面这个算法是可以有环的。 完整代码如下： //7040K 282MS#include &lt;iostream&gt;#include &lt;queue&gt;#include &lt;vector&gt;#include &lt;stdio.h&gt;#include &lt;cstring&gt;using namespace std;const int MAXN=1001;const int INF=(1&lt;&lt;20);int N,M; //N 个点 M 条边int S,T,K; //起点和终点typedef struct _Edge&#123; int v;//边顶点 int len;//边长度&#125;Edge;int dist[MAXN];int cnt[MAXN];bool mark[MAXN];struct Node&#123; int v,len; Node() &#123;&#125;; Node(int a,int b):v(a),len(b) &#123;&#125;&#125;;bool operator &lt; (const Node&amp; a,const Node&amp; b)&#123; return (a.len+dist[a.v] &gt; b.len+dist[b.v]);&#125;vector&lt;Edge&gt; Adj[MAXN];//图的邻接表表示vector&lt;Edge&gt; Rev[MAXN];//图的逆图void Init_graph()&#123; int u,v,l; Edge edge; scanf(&quot;%d%d&quot;,&amp;N,&amp;M); for(int i=0;i&lt;M;i++) &#123; scanf(&quot;%d%d%d&quot;,&amp;u,&amp;v,&amp;l); edge.v=v; edge.len=l; Adj[u].push_back(edge); edge.v=u; Rev[v].push_back(edge); &#125; scanf(&quot;%d%d%d&quot;,&amp;S,&amp;T,&amp;K);//计算 S 到 T 的第 K 短路径 if(S==T) K++;&#125;//Dijkstra 算法 找出各个点到 T 的最短距离void Dijkstra()&#123; memset(mark,false,sizeof(mark)); for(int i=1;i&lt;=N;i++) dist[i]=INF; dist[T]=0; int u,v,min; while(1) &#123; u=-1,min=INF; for(int i=1;i&lt;=N;i++) if(!mark[i] &amp;&amp; dist[i]&lt;min) &#123; min=dist[i]; u=i; &#125; if(u==-1) break; mark[u]=true; for(int k=0;k&lt;Rev[u].size();k++) &#123; v=Rev[u][k].v; if(!mark[v] &amp;&amp; dist[v]&gt;dist[u]+Rev[u][k].len) dist[v]=dist[u]+Rev[u][k].len; &#125; &#125;&#125;int Astar()&#123; if(dist[S]==INF) return -1; memset(cnt,0,sizeof(cnt)); priority_queue&lt;Node&gt; Q; Q.push(Node(S,0)); while(!Q.empty()) &#123; int len=Q.top().len; int v=Q.top().v; Q.pop(); cnt[v]++; if(cnt[T]==K) return len; if(cnt[v]&gt;K) continue; for(int i=0;i&lt;Adj[v].size();i++) Q.push(Node(Adj[v][i].v,len+Adj[v][i].len)); &#125; return -1;&#125;int main()&#123; Init_graph(); Dijkstra(); int ans=Astar(); printf(&quot;%d\\n&quot;,ans); return 0;&#125;","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"A* k-shortest","slug":"A-k-shortest","permalink":"http://catcoding.me/tags/A-k-shortest/"}]},{"title":"一个小题目","date":"2010-08-02T11:43:00.000Z","path":"p/findsum/","text":"前些天在班级群里看到一个笔试题： 从 1 到 100000 中任意拿掉两个数字，把剩下的 99998 个数顺序打乱，并且放入数组 A 中。要求只扫描一遍，把这两个数找出来；可以使用最多不超过 5 个局部变量，不能使用数组变量，并且不能改变原数组的值。也想不到什么更好的解法，原解法是顺序扫一边求得所有数的乘积 (mul_res)、和 (sum_res)。用 (N!)/mul_res 得到两个数的乘积，1 到 100000 的和减去 sum_res 得到两个数之和。 解这个方程得到两个数。关键是 N！太大了，C 会溢出。刚开始想想乘积每次模 100000，后来写了一下还是不对的，因为模 100000 中可能就出现了 0，后面全为 0 了。最后想到这么一个办法，不过中间 除法和比较多。也许有更快的解法。 file:///home/heipang/document/wiki/Home_Page/Computer/笔试题.html //1 到 100 000 #include &lt;iostream&gt; #include &lt;math.h&gt; using namespace std; #define N 100000 typedef long long LL; LL a; LL b; LL vec[N]; int cnt; LL MAX_MUL; void Find(const LL* vec) { int sum=0; LL mul=1; LL Now=1; for(int i=0;i&lt;cnt;i++) { sum+=vec[i]; while(mul%vec[i]!=0) mul*=(++Now); mul/=vec[i]; } while(Now&lt;100000) mul*=(++Now); LL diff=((1+N)*N)/2-sum; cout&lt;&lt;diff&lt;&lt;\" \"&lt;&lt;mul&lt;&lt;endl; LL a=(diff+sqrt(diff*diff-4*mul))/2; cout&lt;&lt;a&lt;&lt;\" \"&lt;&lt;diff-a&lt;&lt;endl; } int main() { srand(time(NULL)); a=(rand()%100000)+1; b=(rand()%100000)+1; cnt=0; for(int i=1;i&lt;=N;i++) { if(i!=a&amp;&amp;i!=b) vec[cnt++]=i; } cout&lt;&lt;a&lt;&lt;\" \"&lt;&lt;b&lt;&lt;\" \"&lt;&lt;endl; cout&lt;&lt;a+b&lt;&lt;\" \"&lt;&lt;a*b&lt;&lt;endl; Find(vec); } ---------------------------------------------------------- 经熊师兄指点，上面的解法还是不对，如果 vec 前面刚好为比较大的素数，mul 就溢出了。正确的解法应该为求 x+y=B, x^2+y^2=A, 1-100000 的平方和可以用 double 存下来，然后减去 vec 里面的平方和就得到 x^2+y^2 的值。 void Find(const LL* vec) { double sum=0; double square_sum=0; for(int i=0;i&lt;cnt;i++) { sum+=vec[i]; square_sum+=(vec[i]*vec[i]); } double diff=((1+N)*N)/2-sum; double square_sum_diff= ((double)N*(N+1)*(2*(double)N+1))/6 - square_sum; cout&lt;&lt;diff&lt;&lt;\" \"&lt;&lt;square_sum_diff&lt;&lt;endl; a=(2*(diff)+sqrt(8*square_sum_diff-4*diff*diff))/4; cout&lt;&lt;a&lt;&lt;\" \"&lt;&lt;diff-a&lt;&lt;endl; }","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"}]},{"title":"魔法书：SICP","date":"2010-07-27T11:43:00.000Z","path":"p/sicp/","text":"《计算机程序的构造与解释》，SICP。这本书号称魔法书，真的是本非常有趣的书。为什么要看这本书，豆瓣上面有很多推荐，书评写得都很好，在这里。我最初看的是英文版， 在网上很好找到，MIT 开源课程的网站上面有很多相关资料。从 80 年开始 MIT 就是用这门课程作为计算机的入门课程的 (MIT 真是个神牛云集的地方，看这个神牛的博客http://blog.vgod.tw/category/divine-code/ ,神乎其乎)，不过 现在这门课程的编程语言换作 Python 了。所以曾经风靡一时的 scheme 和 Lisp 学的用的人就更少了。这最古老的一种编程语言之一 在慢慢要消失，不知那帮做人工智能的还用这个不？关于语言的发展参考这个牛人的一系列博文 (http://blog.youxu.info/)。 这本书 06 年看过一点，不过那时候没怎么看懂，到前两章就没看下去了。大四的暑假进了实验室，怎么就偶然又想好好看看，学校图书馆三楼有这本英文原版的，纸张非常之好，看起来是相当舒服。有中文 版的，不过翻译有时看起来会有点点别扭。大学期间没写过很大的工程，当时也不知道这本书的内容的深度，因为之前一段时间看了Concrete Abstraction 吧，所以看起来没 06 年那么吃力了。 反正只是觉得好玩，正如书的前言中所说，编程应该是充满艺术性以及美感的。后来又在寝室下了 MIT 的课程视频，两个老师讲课都非常好，很奇怪那些老师都会用粉笔在黑板上狂写代码，或者是当时在键盘上敲代码，分析来分析去的，反正极少用 ppt 之类的东西。 国内的大学老师大多是不怎么用粉笔了。总之这本书的内容还是相当广泛，我花了近两个月看了四章多点，慢慢做每章后面的习题，感觉收获不少，函数、算法、面向对象、高阶函数、泛型、并发、流、惰性求值、解释器和编译器、一些编程风格和方式的解释等等。 很多高级语言里面的特性在那里都已经提及过，比如 STL 里面不就有高阶函数吗，现在的动态语言还支持 lambda。理论支撑实现，实现很多内容看起来很高深，不过因为有具体的代码可以实现一下就比较好理解了。 当时看的时候有的地方还是没理解，后来看到一个书评说多年的编程经验才能完全理解其中的内容。虽然现在除了 Elisp 也很少用函数式语言，但通过看这本书和做习题来让我对编程有了更多的兴趣。以后有时间再好好看看后面两章，因为第五章还没看完。有的题目有些难， 做的时候参考了这个博客 (http://eli.thegreenplace.net/)，估计这人是第一个在网上放出 SICP 绝大部分习题解答的吧，他用的是 Lisp。下面的附件是我做习题的代码，不保证全部都正确，如果有错误或者更好的解法请给我指出来 (moorekang@gmail.com)。 前面三章用的环境是 PLT scheme 的集成环境，后面用的是 mzscheme，不过应该是没有问题的，我把一些运行结果也放到里面了。sicp(1~4)_exercise","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Books","slug":"Books","permalink":"http://catcoding.me/tags/Books/"},{"name":"Lisp","slug":"Lisp","permalink":"http://catcoding.me/tags/Lisp/"},{"name":"SICP","slug":"SICP","permalink":"http://catcoding.me/tags/SICP/"}]},{"title":"走出迷宫 - 路径搜索","date":"2010-07-22T11:43:00.000Z","path":"p/maze/","text":"上次把那个迷宫弄出来，然后想了想解法，找了些资料。再把界面上弄了一下，右边迷宫大小，然后有一个选项 percent，是代表要推倒的墙占的总百分比，如果数字越小生成的迷宫就越稀疏，有可能有多条 通路从起点到终点，数字大那么生成的迷宫就越密集，但至少有一条通路。 单迷宫解法迷宫第一定律：一般而言，只要在出发点单手摸住一面墙出发，手始终不离开墙面，总可以找到迷宫的出口。对于单迷宫而言，这一种万能的破解方法，即沿着某一面墙壁走。 或者换句话说，你在走的时候，左（右）手一直摸着左（右）边的墙壁，这种方法可能费时最长，也可能会使你走遍迷宫的每一个角落和每一条死路，但你绝不会永远困在里面。 直觉上好像是可以，实现一下也确实能找到终点的，也就是靠着墙，一直靠左或者一直靠右。实现的时候甚至都不用记录哪些点已经访问过了，哪些点还没访问过。 这也是一种人能来做的算法，毕竟人不可能像计算机一样 DFS、BFS。 BFS用 BFS 肯定也是可以的，如果是单路径的迷宫，用 BFS 实在是太慢了，它会把大部分的点都遍历一边。感觉就像是一颗石子掉到水中，要找岸边的终点那得等波纹波及到岸边。 非常之慢。但如果是有多条通路的迷宫，BFS 是能保证找到最短路径的。也许双向 BFS 会好一点，不过猜想对于单迷宫，也提高不了多少。 DFS那用 DFS 也是可以的。不过效率还是很差，像苍蝇一般在迷宫的各个角落转悠，直到大部分点都遍历了。稍微改变一下 DFS 优先搜索的方向会有一些提高，比如我这个图优先走下方或者优先走左方。 A* 算法A* 是一种启发式搜索算法，在这里我用点与点的曼哈顿距离来作为启发函数，效果不好，因为曼哈顿距离也就大概的告诉了搜索路径现在应该往哪个方向走比较好。不过总得来说 这么一点启发得到的效果还是要比 BFS 和 DFS 要好些。评估函数选择合适也是能找到最短路径的，曼哈顿是可以的。如果墙比较稀疏 (肯定有多条路径)，那么 A* 算法会快得许多。 用键盘走呵呵，对于小点的迷宫用键盘来移动可以比较快解决，人是有直觉和经验的，在合适复杂度上面这种直觉给的启发可比上面好，但是如果迷宫太大了就不行咯。或者还有其他算法去走出迷宫么？","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"迷宫","slug":"迷宫","permalink":"http://catcoding.me/tags/%E8%BF%B7%E5%AE%AB/"},{"name":"路径搜索","slug":"路径搜索","permalink":"http://catcoding.me/tags/%E8%B7%AF%E5%BE%84%E6%90%9C%E7%B4%A2/"}]},{"title":"《C 深度探索》笔记","date":"2010-07-20T11:43:00.000Z","path":"p/c-deep/","text":"最名不副实的关键字 static这个关键字在 C 语言里面有两个作用，C++ 对这个关键词进行了扩展。1：修饰变量，又分为局部变量和全局变量，被修饰的变量都存储在静态的内存区域。 修饰静态变量，那么只有在这个文件内可以引用它，在其他文件里面即使使用 extern 也不能进行访问。所以一般是放在文件头部分。 修饰局部变量，只有在定义的函数内访问，函数外不能访问，即使是在同文件内。2：修饰函数，在函数前面添加 static，那么这个函数只能在该文件内使用。这样，不同人编写的函数，如果不在同文件内，可以不用担心函数名字 相同。main.cint main()&#123; Func(); reutrn 0;&#125;Def.cstatic void Func()&#123; printf(&quot;Func called\\n&quot;);&#125;编译: gcc main.c Def.c -o main 链接错误变量的命名min-length&amp;&amp;max-information低精度数据向高精度数据扩展。被冤枉的关键字 sizeof 用法：sizeof(int), sizeof(i), sizeof i;if ,else float 类型值与 0 值比较，定义一个很小的数，在某个范围内。同时不要在一个很大的浮点数和很小的浮点数之间进行运算。循环注意点嵌套循环中，长循环放在内，短循环放在外面，这样可以减少 cpu 跨切循环层的次数，利用 cpu cache。 循环里面的代码尽量短，一般不超过 20 行。如果不行就改为循环调用函数。void主要作用在于对函数参数的限定和函数返回值的限定。不能对 void 进行算法操作。const修饰指针的时候的记法，就近原则。 const int p ; p 可变，指向的对象不可变 int const p ; p 可变，指向的对象不可变 int* const p; p 不可变，指向的对象可变struct 和 class 的区别在 C++ 中 struct 关键字与 class 一般可以通用，一个区别就是 struct 的成员默认情况下是 public 的，而 class 的是 private 的。union一个 union 只配置一个足够大的空间来容纳最大的数据成员，union 的作用在于压缩空间。存储的大小端：union&#123; int i; char a[2];&#125;*p,u;int main()&#123; p=&amp;amp;u; p-&amp;gt;a[0]=0x39; p-&amp;gt;a[1]=0x38; printf(&quot;%d\\n&quot;,p-&amp;gt;i); PrintBinary(14393); PrintBinary(56); PrintBinary(57); if(CheckSystem()==1) printf(&quot;Little endian\\n&quot;); else printf(&quot;Big endian\\n&quot;); return 0;&#125;11100000111001111000111001Little endian 低字节存储在低地址指针，访问内存的钥匙前段时间听过一个面试题，就是如何读写某人地址，答案就是指针？#include &lt;stdio.h&gt;int main()&#123; int i=0; int pp=&amp;i; printf(&quot;%x\\n&quot;,pp); int p=(int)0x12ff60; printf(&quot;%x\\n&quot;,p); *p=1; printf(&quot;%d\\n&quot;,i); getchar(); return 0;&#125;这段代码在 vc 中编译是能够运行的，但是在 gcc 中不行，gcc 中编译后 i 的地址并不是固定的，这样直接给指针赋值，写指向的地址出现访问越界。a 和&amp;a 的区别 int main()&#123; int a[5]=&#123;1,2,3,4,5&#125;; int* ptr=(int*)(&amp;amp;a+1); int* p=(int*)(&amp;amp;a); printf(&quot;%x\\n&quot;,ptr); printf(&quot;%x\\n&quot;,p); printf(&quot;%d,%d\\n&quot;,*(a+1),*(ptr-1)); return 0;&#125; bfeae860 bfeae84c 2,5 说明 ptr 和 a 的地址相差 5*4=20 个 byte。 定义数组 int a5; a 表示的是数组中首元素的地址，&amp;a 才是数组的首地址，两者的值是一样的，但是意义却不同。 数组当作函数参数传递传递的是指针，也就是数组的地址，但注意如果把指针本身传递进函数的时候进行了数组的拷贝，传递的是一个拷贝。 void func(char* p)&#123; char c=p[3]; *(p+3)=&#x27;X&#x27;; printf(&quot;%c\\n&quot;,c);&#125;int main()&#123; //char* p=&quot;abcdef&quot;; char p[]=&quot;abcdefg&quot;; func(p); printf(&quot;%s\\n&quot;,p); return 0;&#125; 注意上面的区别，如果是 char* p=”abcdef”，那么 p 为 main 函数的局部变量，”abcdef”的存储空间在静态内存中，func 函数中可以通过指针 p 去访问其内容， 但如果改变其内容会发生访问越界。而 char p[]=”abcdefg”，其数组的内容是在栈上。 内存管理静态区：保存自动全局变量和 static 变量 (包括 static 全局和局部变量)。静态区的内容 在总个程序的生命周期内都存在，由编译器在编译的时候分配。 栈 (堆栈):保存局部变量。栈上的内容只在函数的范围内存在，当函数运行结束，这些内容 也会自动被销毁。其特点是效率高，但空间大小有限。 堆：由 malloc 系列函数或 new 操作符分配的内存。其生命周期由 free 或 delete 决定。 在没有释放之前一直存在，直到程序结束。其特点是使用灵活，空间比较大，但容易出错。","tags":[{"name":"C","slug":"C","permalink":"http://catcoding.me/tags/C/"},{"name":"Books","slug":"Books","permalink":"http://catcoding.me/tags/Books/"}]},{"title":"《Concrete Abstractions》的一些解答","date":"2010-07-20T11:43:00.000Z","path":"p/concrete-abstractions/","text":"这本书名中文名字叫什么呢，有本《具体数学》，那么这本书“具体抽象”，矛盾了。副标题是 An Introduction to Computer Science Using Scheme。可以看出这是本引论性质的计算机理论书籍。《冒号课堂》里面说过，编程中最重要的能力是抽象的能力，这本书也在培养这么一种能力，并且能代 码实现去辅助说明。这本书是美国一个大学用的一本教材 (具体哪个忘记了，可以到书的主页上去看看),貌似很多大学都使用 scheme 作为第一门程序设计语 言，历史悠久，属于 Lisp 变种。像这种函数式语言虽然效率不是很高，但是语法简单，而且功能强大，支持多种程序设计方法。在这里程序就是数据，数据就是 程序，在 sicp 中一段不长的 scheme 代码就能成为一个 scheme 解释器。Scheme 很简单，和下棋一样，人们能很快就学会其语法，这里有个很好 的教程t-y-scheme。 貌似以前美国很多大学都是用这个作为第一门程序设计语言来教学，现在用 Python 的更多了，函数式语言还是在渐渐被遗忘。作为引论性质的课程，广度和高 度都达到一定程度，甚至让学生站了语言设计者的角度去思考问题。其中的主线是：过程抽象，数据抽象，和状态抽象。内容涉及：递归和推导，迭代，高阶函数， 数据结构，泛型操作，实现程序设计语言，动态规划，面向对象范型等等。SICP 包含这些内容，并且思想上更深入。所以先大概看看这本书对于阅读 SICP(《计算机程序的构造和解释》) 有很大的帮助。大学的时候看到第五章，做了其中大部分习题，有些题目很有启发。我大四的时候做的 1~5 章的练习题。在这里下载。不保证所有的解法都是正确并最好的，网上这本书的相关资料比较少，而 SICP 的解答到是有比较多可以参考。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Scheme","slug":"Scheme","permalink":"http://catcoding.me/tags/Scheme/"}]},{"title":"指针指针","date":"2010-07-20T11:43:00.000Z","path":"p/pointerbug/","text":"今天由一个函数加深了对指针的理解，是这么一个函数： void BST_Delete(BITREE y) //删除节点 y&#123; if (y-&gt;lch==NULL &amp;&amp; y-&gt;rch==NULL &amp;&amp; y-&gt;p) &#123; if(y==(y-&gt;p)-&gt;lch) (y-&gt;p)-&gt;lch=NULL; else (y-&gt;p)-&gt;rch=NULL; &#125; else if (y-&gt;rch==NULL &amp;&amp; y-&gt;p) &#123; if(y==y-&gt;p-&gt;lch) y-&gt;p-&gt;lch=y-&gt;lch; else y-&gt;p-&gt;rch=y-&gt;lch; &#125; else if (y-&gt;lch==NULL &amp;&amp; y-&gt;p)&#123; if(y==y-&gt;p-&gt;lch) y-&gt;p-&gt;lch=y-&gt;rch; else y-&gt;p-&gt;rch=y-&gt;rch; &#125; else &#123; BITREE t=BST_Successor(y); y-&gt;data=t-&gt;data; BST_Delete(t); y=t;//y=NULL &#125; free(y);&#125; 在最后一个 else 内，如果二叉搜索树中有左右孩子，那么找这个删除节点的后继，把内容互换，然后删除后继 节点，因为后继节点一定只有一个孩子或者没有孩子。最后只有一个 free() 操作其实是为了代码简洁，可以把前面每一个 else if 后面加一个 free， 最后不写 free() 操作。但是这么写运行起来会有问题，y=t，就是所指向的地址相同，但是因为是 递归操作，t 指向的地址在调用 BST_Delete(t) 的时候已经被 free 掉了，所以如果再删除一次就会 出现内存错误，修改方法是 y=NULL，或者修改函数参数，用指针引用的形式 void BST_Delete( BITREE&amp; y)，然后再在 free(y) 后面增加一句 y=NULL。以前以为两次调用 free(p) 是不会出现问题的，free() 在释放掉 p 指向的内存以后，会 自动将 p 赋值为 NULL，其实没有这部分操作。 前些天还看到一个面试题目，malloc 申请的空间用 delete 删除会有什么问题？一般来说没有问题， 内存会释放掉，而且即使是有析构函数的对象指针，用 delete 删除的时候同样会调用析构函数。这说明 c++ 的 delete 操作其实是在 c 的基础增加了一些操作，先调用析构函数，然后释放空间。良好的编程风格 就是 free/malloc，new/delete 一一对应，甚至不要出现一次调用，多次释放，像上面那样的因为递归 而产生的多次释放并不是很好发现","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"C","slug":"C","permalink":"http://catcoding.me/tags/C/"}]},{"title":"The Game of Life","date":"2010-07-20T11:43:00.000Z","path":"p/the-game-of-life/","text":"简介 Game of Life是 Princeton 的一个数学家发明的游戏，这个不像一般的小游戏，有胜负，这只是一个规则很简单的模拟游戏， 规则很简单，但是过程和结果都很有趣，大三时看到一个同学实现过，去年无聊时也写了个实现，挺好玩的，最后形成的图案很有趣。 rule平面中的一个小方格分为生和死的状态，规则是： 如果一个死的细胞周围有三个细胞是活的，在下一轮中这个位置出现一个活的细胞。 如果一个活的细胞周围有两个或者三个活的细胞，在下一轮中或者，否则下轮中该细胞死掉。 其他情况该位置维持不变。这里的 周围 是指一个方格的周围 8 个位置。 规则很简单，结果也很完美，甚至是符合现实世界中生命的生死规律，一个群种只有在保持平衡的状态下才能实现良性循环。 不可能有一种初始状态使得活着的细胞数量一直增加，如果你找到一种，可以向原作者所要一笔钱，哈哈。不管初始状态如何，真个世界在经过一段时间的演变之后都会逐渐稳定下来。稳定的状态有很多中，分为静止的和“颤抖”的。 另外发现一些的简单规律：并不是初始或者的数目越多最后或者的数目就越多，测试表明初始或者的数目为总量的一半的时候活着的比较多。 还有很多规律在其主页上可以找到。 实现我这个是 Linux 下 OpenGL 实现的，红色代表死的细胞，蓝色代表活着的细胞，稳定以后世界","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"Life Game","slug":"Life-Game","permalink":"http://catcoding.me/tags/Life-Game/"}]},{"title":"迷宫生成算法–并查集","date":"2010-07-20T11:43:00.000Z","path":"p/union-set-maze/","text":"好书好书 在看《数据结构与算法分析》这本书的时候看到后面的一个关于并查集的有趣应用，是个生成迷宫的算法，看起来非常有趣，所以就实现了一下。顺便把几种走迷宫的算法都整了 进去。八卦一下，这本书的作者是Mark Weiss,这牛写了几本数据结构和算法的书，各种语言版本 (C,C++,Java)，原来是师出名门啊，在他的主页上一看，原来是Robert Sedgewick 的学生。Sedgewick 更是师出名门，在 Princeton 跟高纳德神牛读的博士，也写了 N 本算法和数据结构的书。这两人写的书都还不错，对于初学者和中等水平来说很好，覆盖了一般的数据结构和算法，同时带有一定的理论分析还有特定的语言实现。 并查集 可能一般的大学教材上面没有说这个数据结构，这是个很有趣的东西。《算法导论》上面用这个来作为均摊分析的例子吧。在 ACM/ICPC 中这个数据结构经常出现，有可能是一个小题（难点的就是要维护节点之间关系的那种），或者是有的图论算法中实现要用，比如实现 Kruskar 算法求最小生成树。并查集本身比较简单，主要是用来操作元素集合，支持的操作有： UnionSets(int root1,int root2), 用来合并两个根节点。 FindSet(int x) , 用来查找 x 所属的根节点。 一并一查，所以叫作并查集。实现时候可以通过按秩合并 (union by rank)，和路径压缩 (path compression) 来增加效率，可以获得几乎与总操作数 m 成线性关系的运行时间。 int rank[MAXSIZE]; // 节点高度的上界int parent[MAXSIZE]; // 根节点void Init(void)&#123; memset(rank, 0, sizeof(rank)); for(int i=0; i &lt; MAXSIZE; ++i ) parent[i] = i;&#125;int FindSet(int x)&#123;// 查找 + 递归的路径压缩 if( x != parent[x] ) parent[x] = FindSet(parent[x]); return parent[x];&#125;​void UnionSet(int root1, int root2)&#123; int x = FindSet(root1), y = FindSet(root2); if( x == y ) return ; if( rank[x] &gt; rank[y] ) parent[y] = x; else&#123; parent[x] = y; if( rank[x] == rank[y] ) ++rank[y]; &#125;&#125; 迷宫的实现 上面那本书上的习题上给了提示，比如首先所有的墙都没有去掉，那么是一个一个的方格，每一个方格为并查集合的一个元素，已经连通的元素是在并查集的一个集合中，有相同的根节点。 随机的选择一个墙，在并查集中查询这两个元素是否已经连通，如果已经连通则另选一个墙，如果不连通，union 两个节点的根节点，这样操作以后这两个方格已经连通。继续上面的操作， 直到入口和出口连通位置，那么这就形成了一个只有一条合法路径的迷宫，称为单迷宫。如下图所示。 左上角起点 右下角终点","tags":[{"name":"Programming","slug":"Programming","permalink":"http://catcoding.me/tags/Programming/"},{"name":"迷宫","slug":"迷宫","permalink":"http://catcoding.me/tags/%E8%BF%B7%E5%AE%AB/"}]},{"title":"Emacs: keyboard macros","date":"2010-07-17T11:43:00.000Z","path":"p/emacs-keyboard-macros/","text":"宏编辑以前知道 Emacs 有一个 keyboard macros，不过一直没认真看一下，今天算是粗略懂了一些。宏编辑很早就有了，很多编辑器都有这种功能，word 好像是有的，不过没用过，格式刷算宏编辑不？甚至 Emacs 的起名有一种说法就是 Edit MACroS，最初是作为一个叫作 TECO 编辑器上的一套宏而编写，然后就是重写了 N 次，现在 Emacs 上还有个模拟 TECO 的模式：）。kbd macros 就是把一系列要做的动作集合成一个，然后可以执行多次。以前有时在网上拷贝代码，但是前面都加有行好，不编辑一下不能编译，这种情况 就可以用这个 kbd macro 一下就解决了。 先来一个例子，比如说有这么一段文字：Newton, IsaacEinstein, AlbertMaxwell, JamesTuring, Alan…现在要变成这个样子Isaac NewtonJames MaxwellAlan Turing…在 Emacs 下可以执行下面一系列快捷键来处理一行。如果行数不多，那么敲几下键盘就可以了，如果是很多行呢，总不可能一直这样用手动的吧。上次遇到那个几百行的代码，每 行前面都有一个表示行数目的数字，一狠心写了个 C 程序来处理，囧。为了不让手指报废，定义一个 kbd macro 是很快速的方法。也就是在我处理的一行的之前按 F3(或者”C-x (“ ),在处理第一行的时候 Emacs 已经在记录这即个命令，结束完一行的处理就可以按 F4(或者”C-x )”。这样就已经完成了定义。使用宏 定义好以后下面的很多行都可以使用这个宏去操作，只要按 C-x e 就是执行上一次定义的宏，C-u 20 C-x e 执行 20 次，甚至可以选中一个区域然后执行 M-x apply-macro-to-region-lines (或者 C-x C-k r)。但这个时候宏里面别加 go-to-the-next-line，因为上面这个命令就已经是逐渐移动区域的每一行，执行上面的宏，如果再加 goto 命 令就会跳过一些行。另外还可以手动编辑这个宏，命令 M-x edit-kbd-macro，会让你选择要编辑的宏，比如说选刚才保存的那个宏，得到： ;; Keyboard Macro Editor. Press C-c C-c to finish; press C-x k RET to cancel.;; Original keys: C-a M-d 2*C-d C-e SPC C-y C-nCommand: last-kbd-macroKey: noneMacro:C-a ;; move-beginning-of-lineM-d ;; kill-word2*C-d ;; delete-charC-e ;; move-end-of-lineSPC ;; self-insert-commandC-y ;; yankC-n ;; next-line 编辑完后按 C-c C-c 完成。 如果这个操作经常会用到 (比如清楚带行号的代码)，还可以把这个操作保存下来，以后都可以用。在.emacs 或者自己的配置文件中增加： (fset &#x27;foo [?\\C-a ?\\M-d delete delete ?\\C-e ? ?\\C-y ?\\C-n])","tags":[{"name":"Emacs","slug":"Emacs","permalink":"http://catcoding.me/tags/Emacs/"}]},{"title":"胡乱想想","date":"2010-07-15T11:43:00.000Z","path":"p/thinking/","text":"哈哈，终于还是弄了独立空间，yo2 还在崩溃中，没前的还没转过来。新的空间速度不错，服务也可以，可是在教育网内不能访问，算了，教育网内能访问的就那么几个。 中午下了场雨，可还是很闷，下午在看《The Practice of Programming》，不错的书。两天没去实验室了，那里闷得慌。这个月还是打算在学校待着，8 月份回家一趟。昨天一个校友从上海回来，大家一起聊了会，对他们那公司挺感兴趣的，准备有机会去面试一下。这些天经常睡不着，睡着也做梦。我就是这样，在生活的链接点比较焦虑，比如说升学时，这会是找工作了。一些朋友会说，你那么当心干什么，找份工作应该不难，况且你又平常又不是懒人，还是学了点东西的。呵呵，我是天生有点悲观吧，总会忍不住去想结果。这会倒比较轻松，工作有好坏之分么，适合自己的工作才是最好的吧，做自己想做的领域才会有激情，现在工作的愿望比两年前强多了。同时我也比较能看得到自己的弱点。我很清楚自己不是想搞科研，可能也不是很适合。对于写论文，我更倾向于写代码。我不适合做市场，同人打交道好像要比同机器打交道要难。我不适合做管理，尽管有时候想改变自己的一些性格特点，现在回想起来勉强自己做的那些并没什么好的效果。总之，既然想搞所谓的挨踢行业，想走技术路线，那还是好好的坚持吧，The lyf so short, the craft so long to lerne.. 在学校还能好好看看想看的书，以后就是 MOP 了，珍惜珍惜！ 控制自己的思绪和情绪是件比较重要的事情，“憩于理性，行于热情”这是我所期望的，抓紧时间好好享受这段最后的单调的校园生活。面包会有的，哼哈。","tags":[{"name":"Notes","slug":"Notes","permalink":"http://catcoding.me/tags/Notes/"}]},{"title":"Hello world!","date":"2010-07-13T11:43:00.000Z","path":"p/hello-world/","text":"欢迎使用 WordPress 。这是系统自动生成的演示文章。编辑或者删除它，开始您的博客！","tags":[{"name":"Notes","slug":"Notes","permalink":"http://catcoding.me/tags/Notes/"}]}]