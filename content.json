[{"title":"案例分析-程序员如何站着赚钱","date":"2020-10-27T21:57:00.000Z","path":"2020/10/27/programmer-out-of-normal-job.html","text":"Daniel Vassallo 是我最近一年都在关注的一个推特用户，我几乎看了他发的所有 Twitter 和文章。 这位程序员去年离开了亚马逊的一份轻松而多金的工作。他在亚马逊干了 8 年，尽管不断获得晋升、薪酬、表彰和表扬等奖励，薪水从 7.5w 刀一路涨到 50w 刀，但他没有足够的动力再干一年。 至于为什么离开亚马逊，他写了一篇很好的文章来解释：只有内在动力才能持续. 主要原因是随着级别的提高，工作的自由度减少了，得平衡各方利益，说服其他人来完成特定的目标。这很正常，在大公司工作有很多固有的限制，关于如何做工作，做什么工作，设定什么目标，以及什么业务值得追求。很多时候会迫使我们去做不想做的事情，而想做的可能也无法施展。 总之，在公司赚钱肯定是比较稳定，收入也不错。只是时间、精神上谈不上自由。为大公司工作是一种稳定的状态，就像是围城一样。 如何站着把钱挣了？ 什么动力才能持久？动力分为外部动力和内部动力： 外部动力可以称之为棒子或者萝卜。举例来说，缴税是棒子，虽然我们不想做，但是必须得完成。为了买一辆豪车，努力加班加点赚钱，这就是萝卜。两者都是外在因素迫使我们不断地有『动力』去执行。 内部动力是持久动力，就是自己心甘情愿去做，并且乐于其中。这位程序员的兴趣在于写代码，卖自己的作品。而互联网时代就是最好的舞台，个人可以专注于自己专业领域，完成自己的作品，并获取关注和收入。当然最重要的是作品的质量，以及推销的手法。 找到自己的切入点通过自己的作品来赚钱，听起来很简单，但实现起来难度其实是巨大的。 辞职后开始做的一个项目叫做 Userbase， 为静态网站增加持久化存储。另外开始和朋友做的是一本电子书：The Good Parts of AWS。售价25美金一份。10个月总共花费 3w 多美金推广，收入 25w 美金。 这本电子书包含一些经验性的东西，对基于 AWS 做技术架构的人挺有用的。对于在 AWS 上工作了10多年的人写出这样一本小册子肯定是不难的，但是难的是如何做推广。 这也是作者做得挺好的一点，在 Twitter 上经营固定的读者。他每天都会发一些作为 Indie 的一些感想，关于工作、生活、经济、创业方面的。14 个月时间从 150 的 follower 涨到了 49000 多。他经常会把一些自己项目的数据贴出来给大家分享，这样显得特别真实、真诚。这种推广套路营造出一种类似《楚门的世界》的观感效果，读者看着他从第一天辞职，然后不断经营自己的项目，就会有动力一直去关注后面的进展。 然后作者把自己最近一年左右的 Twitter 推广实践经验又录成了视频： Everyone Can Build a Twitter Audience， 售价 50 美金。这一连贯手法真是越来越溜了。 当然，除了营销外之外能力是最重要的，这位同志的写作能力一流。可以从第一篇辞职撰文可以看出，用词、表达清晰有据。 总结有人可能认为，这赚得看起来还没他自己上班多啊！ 但是，为自己工作的自由度、成就感、安全感是完全不同的，而且这还只是一个开始。 很多人丢掉了自己的全职工作之后，完全不知道如何打造自己的另外一份收入，陷入等米下锅的状态。总结起来都是很简单的道理，只是做到的人很少： 跳出自己的舒适区，向自己期望的生活方式改变 找到自己的兴趣点和优势，寻找自己能满足的实际需求 相信时间的复利效应，做有积累的事情 付费意识还是挺重要的，这点不可否认英文环境相对来说会更好一些","tags":[]},{"title":"DHH - 关于软件开发的少数派","date":"2020-10-10T22:50:38.000Z","path":"2020/10/10/dhh-on-software-dev.html","text":"David Heinemeier Hansson, Software Contrarian 是 Podcast 频道 corecursive 在 2020.2.1 发布的一个 DHH 关于软件开发相关的访谈。 DHH 不用介绍了，Rails 创始人。 可以说之前 Ruby 的流行很大程度上依赖于 Rails 的兴起。Rails 确实影响了很多后来的 Web 框架的设计和实现，并给软件开发带了一些全新的理念。 这期是我之前当作练习英语的材料来听的。DHH 的口音非常清晰，表达方式也是非常直接。因此这期听起来有一种类似 Rap 的快感。 为什么 Rails 成功了Rails 的出现改变了软件开发，至少在 2006 年，当 Java，C# 大行其道的年代。Rails 以其优异的开发效率震惊了不少开发者。Rails 的成功无非是在恰好的时机做了恰当的事情。 DHH 总结了从 Java、PHP 的开发经验。Java 阵营里都是聪明人，有很多好想法，但是他们却在一个糟糕的开发环境里工作，不容易让新人轻易上手。而 PHP 却很简单明了，你直接把一个文件拖入特定的文件夹，就可以生成对应的网页。Rails 的第三个元素就是 Ruby，Ruby 是极其容易安装，容易上手而直接的编程语言。DHH 当时正在写 Basecamp，所以一切都是从实际使用出发的，自己构建工具，然后再用这个工具构建 Basecamp。 而且 DHH 当时也是一个 Ruby 新手(那时的 Ruby 老手估计也没几个?) 新手的好处在于，他不知道 Ruby 的极限在哪里，哪里可能面临挑战。这样可以随着自己的性子，满足自己的期望来构建 Rails 了。在写 Rails 的过程中，DHH 更关注的是作为用户的感受是什么？编程就像是做菜一样，厨子需要关注的色香味俱全。 Ruby 最大的洞见是: 程序员不仅仅是程序员，同时也是人。 依据这个原则，在设计 Ruby 中最重要的事情和设计标准就是：编程语言使程序员更快乐。 最开始如何开始接触 RubyRuby 是日本人 Matz 于 1995。但是直到 2003，这门编程语言仍然是非常小众而神秘的。DHH 也是那段时间在看到些 Martin Fowler 和 Dave Thomas 写的技术文章，他们俩个都选择了 Ruby 作为编程语言介绍一些概念。这引起了 DHH 的兴趣，所以开始关注 Ruby，并去参加了 Ruby 2004 Conf。 那届 Conf 大约也就 42 人吧…. 但是随后几年的 Rails Conf 就开始有 2500 人了。 关于编程语言的选择很多程序员因为喜欢上编程，就是刚好碰到了符合自己口味的编程语言，并激发对编程的巨大乐趣。所以，语言的选择说不重要也不对。如果你还没找到自己的最爱，继续尝试吧。 但并不意味着，在一个小众的编程语言过多投资可能会带来其他的回报。语言的流行有很多其他的因素。Rails 的初衷并不是完全用来满足自己的创造轮子的快感的，而是依据自己的实际项目出发的。 这给我们的不错启示：从实际的需求出发，使用新的工具造轮子。 关于微服务的吐槽DHH 对微服务保持否定态度，认为业界这么流行微服务其实是有害的。 大多数情况下，一个人可以完全理解、部署的单一应用，比微服务更容易维护。 微服务的优势在于，如果团队足够地大，我们需要给开发者一些界限。 不要盲目地沿用大公司的套路，因为解决的问题不同！ 关于 TDDTDD 也是 Rails 社区很流行和推崇的，但是 DHH 其实对此并不太感冒。并不是 TDD 就能写出更好的，更健壮的软件。 事先写测试用例还是事后写并不重要，重要的是自动化测试。","tags":[]},{"title":"网络相关","date":"2020-09-08T20:59:08.000Z","path":"2020/09/08/networking-notes.html","text":"DNS 域名解析分为递归解析和迭代解析 https://blog.csdn.net/lycb_gz/article/details/11720247 APR 欺骗ARP 欺骗是一种在局域网中常用的攻击手段，目的是让局域网中指定的（或全部）的目标机器的数据包都通过攻击者主机进行转发，是实现中间人攻击的常用手段，从而实现数据监听、篡改、重放、钓鱼等攻击方式。 TCP/IP 报文长度和格式IP 头部信息：头部长度：通常 20 字节，有选项时更长，总共不超过 60 字节。IP 数据报长度：65535 字节。 TCP 协议，在传输层。特点：可靠性。通过连接管理（三握四挥），序列号，确认号，拥塞控制，重传控制来保证可靠性。头部长度：一般为 20 字节，选项最多 40 字节，限制 60 字节。 TCP 最大报文长度 (MSS)https://blog.csdn.net/codejoker/article/details/5437141 TCP 提供的是一种面向连接的，可靠的字节流服务，TCP 提供可靠性的一种重要的方式就是 MSS。通过MSS，应用数据被分割成 TCP 认为最适合发送的数 据块，由 TCP 传递给 IP 的信息单位称为报文段或段(segment)。代表一个 TCP socket 的结构体 struct tcp_sock 中有多个成员用于确定应用数据被分割成最大为多大的数据块较为合适(最大报文段长度 MSS)。我们不难联想到，跟最大报文段长度最为相关的一个参数是网络设备接口的 MTU，以太网的 MTU 是 1500，基本 IP 首部长度为 20，TCP 首部是20，所 以 MSS 的值可达 1460(MSS 不包括协议首部，只包含应用数据)。 本地以太网中 MSS 为 1460 的说法并不正确，它还会动态变化，如果 IP 首部和 TCP 首部中出现选项，则 MSS 要相应的减小，一般 TCP 首部中会 有 12 字节的时间戳选项(外加两字节的填充选项)，这时的 MSS 就等于 1448。MSS 的主要作用是限制另一端主机发送的数据的长度，同时，主机本身也控制自己发送数据报的长度，这将使以较小 MTU 连接到一个网络上的主机避免分段。 如果使用 TCP 希望传输一个复杂的对象应该怎么传输？TCP 中的流是指流入进程或者从进程中流出的字节序列。所以向 Java/golang 等高级语言在进行 TCP通信是都需要将相应的实体序列化才能进行传输。 TCP/IP 中如何解决粘包问题？如果一直传输数据怎么拆包?应用层协议，不管是标准的还是自己定义的。“粘包”问题是伪问题。 http://www.hchstudio.cn/article/2018/d5b3/ https://img.hchstudio.cn/TCP.gif TCP 连接和断开的状态图connect: disconnect: 为什么 TCP 连接断开的时候要进行四次握手： TCP 四次挥手的 TIME_WAIT时间段长为 2MSL（报文段最大生存时间） TIME_WAIT 存在的理由之一是尽可能护送最后的 ACK 达到对端，保证可靠地终止 TCP 链接。 假设 tcp 连接是： A(1.2.3.4:8888)——B(6.7.8.9:9999), 这就是一个 tcp 四元组。当 tcp 连接关闭后， 四元组释放。TIME_WAIT 存在的理由之二是新旧四元组互不干扰。 RPCRPC（Remote Procedure Call）—远程过程调用 ，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。RPC 协议假定某些传输协议的存在，如 TCP 或 UDP，为通信程序之间携带信息数据。在 OSI 网络通信模型中，RPC 跨越了传输层和应用层。RPC 使得开发分布式程序就像开发本地程序一样简单。","tags":[]},{"title":"程序员如何提高英文写作","date":"2019-11-07T08:45:53.000Z","path":"2019/11/07/improve-english-writing-as-progammer.html","text":"最近几个月坚持了一段时间英文写作，兴趣和自信心都大为增强。为什么突然想锻炼自己的英文写作能力呢，是因为工作中要写个什么英文的白皮书，然后发现懂技术的不太会写，会写英文的不太懂技术。最后找了团队中的一个留学生帮忙，大家跌跌撞撞把工作完成了。仔细想想这就是稀缺能力啊，按照刻意练习的套路，我应该好好提高一下自己的英文写作能力。 然后，我就开始在一些社区，比如 dev.to 写技术文章，在 Quora 上回答问题等，这些坚持了两个月左右，自我感觉收获不少。至少，现在让我写一篇英文类的长文，我是好无压力并且有些享受的(可能还处于自我感觉良好的时期的缘故)。 下面总结一下关于英文写作的一些自我心得。 抛去恐惧心理这是很多人要克服的第一关，想着中文都写不溜，英文如何写？写作这个东西就是需要不断练习的，即使文笔不行，首先要做到的是写出来，并且简明扼要。文章最重要的目的是表达自己，并且让人易懂，更高的要求才是让人产生读的乐趣。对于绝大部分科技类的写作来说，准确是第一要素。 如何抛去恐惧心理？唯一的办法就是多读、多写，并且让大家看，收集反馈然后不断改进。 在哪里写像我刚才说的，有很多不错的技术社区，比如 Github、StackOverflow、Quora, 这些都是英文表达的场所，也是一个很好的锻炼自己英文写作的平台。从小处开始，可以写一个英文的 README，代码中使用良好的英文注释？在 Quora 上回答问题是更好的方式，因为这是一个互动的平台，你的回答会被多个人看到，这样可能会有一些反馈。 比如这个找 Quora 里的回答，题主问的是学习编程是否需要很多数据技巧？这对于我们这样的多年程序员来说，自然是有一些心得的，然后我就写了一些自己的想法作为回答。后面有一位朋友写了另外一个回答： “题主，数学技能是次要的，你应该好好学学英文写作，这样至少不会让你像上面这位回答者这一样犯一些低级的错误。” 没多久我就看到了这条回答，然后看了看自己真的是犯了一些很明显的语法错误，修正后再回复了一下这位朋友，他表示自己也有点刻薄了，哈哈。其实大家对这种“助人助己”的学习方法是很乐于接受的，只要是给社区提供有用的东西。 在 Quora 上还碰到另外一个瑞典的伙计，也帮我提出了一些建议。然后第二天还帮我一句一句做了一个修改版本，发到了我的邮箱。英语不是母语的人写的文章，如果不是让英语为第一语言的朋友阅读，这些表达方面的问题是不容易看出来的。 一些技巧词汇很多人对于自己的词汇量没有信心，觉得词汇量不够不足以表达自己的想法。这是不对的，其实你看看大部分技术类英文文章，对于接受过大学教育的技术人人员来说，应该是 95% 以上的单词都是认识的。对于不认识的单词来说也可以根据上下文来推测的，所以至少词汇不会构成阅读障碍。对于英文写作来说，基于简明表达自己的要求，我们那点四六级词汇也很够玩的。词汇在于平时积累，我现在也在着重注意积累一些词汇。日常使用过程中，多注意一些应文的惯用词汇。有一个 Chrome 插件叫做“单词小卡片”，可以把日常浏览网页的过程中发现的不太熟悉的单词加入列表，可以日后以便回顾。 阅读 阅读和写作是分不开的，只有多读才会发现更多套路。上面提到的那些社区都有很多不错的英文内容可以读，另外要特别提到一个的是 medium.com，类比为国内的简书。不过个人感觉质量比简书的内容好很多，可能是我阅读了付费内容的缘故。这个付费也挺便宜的，一个月 5 美金。 作为程序员，另外要多阅读就是技术类的书籍。这些年我买了不少英文类的技术书籍，大多是翻过的，而且有少部分是精读完了。其实只要你能坚持阅读完一本 300 页左右的技术书籍，第二本就很简单了。如果是非技术类的英文文章，要数量阅读就需要提高词汇。 撰写其实写作无非是表达自己，中文和英文写作有很多都是相通的。 撰写过程中需要时刻明白，写的东西是给其他人看的。所以排版也很很重要，如果文章比较长，需要让人看得不至于疲累。适当地配一些贴近情景的图片也非常有助于提高可读性。段落要分明，不要某些段落太长。 最后，即使是英语是母语的人也很容一些常见的语法错误。所以我们需要工具来减少这类问题，grammarly.com 就是非常有用的工具，即使是免费版本对于日常使用来说也是足够了的。 建议不断练习，收集反馈，持续改进。唯此而已。 有两本书可以看看。 《七十二堂写作课》 《风格的要素》","tags":[]},{"title":"C 语言的 typecheck","date":"2019-08-06T01:31:18.000Z","path":"2019/08/06/type_check_in_c.html","text":"类型保证强类型的编程语言通常编译器自带一些类型检查，保证代码编译后不会出现类型方面的错误，比如 Rust 之类的甚至做了变量的生命周期检查，以防止内存出错或者未定义行为。常见的变成语言类型如下： typecheck 但是 C 为弱类型语言，弱类型语言，类型检查更不严格，如偏向于容忍隐式类型转换。譬如说 C 语言的 int 可以变成 double。 这样的结果是：容易产生 forbidden behaviours。为了解决类似问题，Linux 内核中的这个宏比较有技巧。 #define typecheck(type,x) \\ (&#123; type __dummy; \\ typeof(x) __dummy2; \\ (void)(&amp;__dummy == &amp;__dummy2); \\ 1; \\ &#125;) 使用的时候可以保证某些变量为特定的类型： int a;typecheck(char, a); 这样就会报出一个编译错误：","tags":[]},{"title":"My org-mode stuff","date":"2019-08-01T19:31:24.000Z","path":"2019/08/01/org_mode_stuff.html","text":"I switched to org-mode from EverNote recently, and the experience imrpoved much for note and journal writing, especially for technical notes. After the whole tool is set appropriately, I am even addicted to writing. During my setting up for org-mode and related tools, I found these code snippets are really handy, so let’s have a share. Insert Pic from paste You need to install pngpaste first, then with this elisp function, we can copy the picture from paste very quickly, the picture will store on current directory’s img sub-directory, it will create it if img directory is not exists. (defun org-insert-image () (interactive) (let* ((path (concat default-directory \"img/\")) (image-file (concat path (buffer-name) (format-time-string \"_%Y%m%d_%H%M%S.png\")))) (if (not (file-exists-p path)) (mkdir path)) (shell-command (concat \"pngpaste \" image-file)) (org-insert-link nil (concat \"file:\" image-file) \"\")) ;; (org-display-inline-images) ;; show inline picture ) Using org-ruby for Hexo publishing I using Hexo for blogging, the default format is markdown in Hexo, so I need to convert org format to markdown format very conveniently, and finally org-ruby solve it. I did some dirty hacks on the codebase, please have a look at this PR, this PR solve three issues. Add title and path attributes in org file, and the ruby script will extract it for dumping markdown file. Fix the fill paragraph problem, I don’t need the blanks which will broken the paragraph layout. Copy the images to proper directory for Hexo, support image size attributes. Then I added an elisp function for auto publish it after saving file whenever “#MD_TITLE:” is founded in buffer: (defun org-publish-to-hexo () (interactive) (shell-command (concat \"org-ruby \" \"--translate \" \"markdown \" \"-a \" (buffer-name))))(defalias 'op 'org-publish-to-hexo)(defun buffer-contains-substring (string) (save-excursion (save-match-data (goto-char (point-min)) (search-forward string nil t))))(defun org-auto-publish-save-hook () (when (and (eq major-mode 'org-mode) (buffer-contains-substring \"#+MD_TITLE:\") (buffer-contains-substring \"#+MD_PATH:\")) (message \"publishing to Hexo markdown\") (org-publish-to-hexo)))(add-hook 'after-save-hook #'org-auto-publish-save-hook)(defun org-before-save-hook () (when (eq major-mode 'org-mode) (message \"saving org-file\") (pangu-spacing-space-current-buffer) ;;(fill-region (point-min) (point-max)) ))(add-hook 'before-save-hook #'org-before-save-hook) pangu-spacing This package will add spacing between Chinese word and English word, so I hooked it before save org file: (require 'pangu-spacing)(global-pangu-spacing-mode 1);;(setq pangu-spacing-real-insert-separtor t)(defun org-before-save-hook () (when (eq major-mode 'org-mode) (message \"saving org-file\") (pangu-spacing-space-current-buffer) ))(add-hook 'before-save-hook #'org-before-save-hook) org-capture And the best thing is org-capture, with this we can write all kinds of tempaltes, for journal writing, I need to generate file according to date and time: (defun create-code-file () (interactive) (let ((name (concat (format-time-string \"%Y_%m_%d_\") (read-string \"file-name: \")))) (expand-file-name (format \"%s.org\" name) \"~/Dropbox/org/snippets/\")))(defun gen-date-file () \"Create an org file in ~/notes/snippets.\" (format-time-string \"~/Dropbox/org/journals/%Y_%m_%d.org\"))(setq org-capture-templates '((\"t\" \"Todo\" entry (file+datetree \"~/Dropbox/org/work.org\") \"** TODO %?\\n %i\\n \" :empty-lines 1) (\"x\" \"Task\" entry (file+datetree \"~/Dropbox/org/work.org\") \"** TODO %^&#123;priority|[#A]|[#B]|[#C]&#125; %?\\n\") (\"e\" \"Task\" entry (file+datetree \"~/Dropbox/org/life.org\") \"** TODO %^&#123;priority|[#A]|[#B]|[#C]&#125; %?\\n\" :empty-lines 1) (\"l\" \"Todo\" entry (file+datetree \"~/Dropbox/org/learn.org\") \"** TODO %?\\nEntered on %U\\n %i\\n\\n \" :kill-buffer t :empty-lines 1) (\"k\" \"Todo\" entry (file+datetree \"~/Dropbox/org/learn.org\") \"* TODO %?\\n %i\\n %f\\n %a\" :empty-lines 1) (\"j\" \"Journal\" entry (file+datetree \"~/Dropbox/org/_journal.org\" ) \"** %?\\nEntered on %U\\n %i\\n\" :empty-lines 1) (\"J\" \"Journal\" entry (file gen-date-file) \"** %?\\nEntered on %U\\n %i\\n\" :empty-lines 1) (\"c\" \"Code snippet\" entry (file+headline \"~/Dropbox/org/_code.org\" \"Code\") \"** %^&#123;desc&#125;\\n#+BEGIN_SRC %^&#123;language|ruby|shell|c|rust|emacs-lisp&#125;\\n%?\\n#+END_SRC\" :empty-lines 1) (\"C\" \"Notes\" entry (file create-code-file) \"** %^&#123;desc&#125;\\n#+BEGIN_SRC %^&#123;language|ruby|shell|c|rust|emacs-lisp&#125;\\n%?\\n#+END_SRC\" :empty-lines 1) ))","tags":[]},{"title":"满足感源自细节","date":"2019-07-31T23:40:03.000Z","path":"2019/07/31/details_matter.html","text":"最近自我感觉生活质量提高了不少，并不是突然撞大运发大财了，总结下来居然都是一些小细节，奇怪正是这些小细节每次都会让我会心一笑。 org-mode作为一个近十二年的 Emacs 用户，最近开始使用 org-mode 了。之前一直偶尔看到说什么单独为了org-mode 而花时间熟悉 Emacs 也是值得的，不过我一直没认真看，因为我认为在 Emacs 下不太适合大量编辑中文，快捷键太多在中文输入的过程中会有一些影响。 最近因为杂事比较多，我特别想要一个结合了日程管理和文档管理的软件。之前用过 Bear，这款软件的好处在于其编辑支持得特别好，但是 Bear 没有日程管理。后来又重新用回 EverNote，这东西的文字编辑支持有点弱，日程管理就是个最基本的清单。还有一些代码嵌入方面的问题，拷贝进去支持再拷贝出来居然其中嵌了部分中文符号。 最后我终于花了点时间来看看这个传说中的 org-mode 到底神奇在何处。结果真的符合了好香定律，我怎么不一开始用 Emacs 就着手用这呢，后悔万千！ 其实不管日程管理也好，日志、技术笔记等也好，本质上都是文字。org-mode 的日程和笔记都是存储的最原始的文本格式，而 org-mode 的编辑模式类似 Bear，写起来非常容易上手。和 Markdown 类似属于「易读易写」的轻量级标签格式。 日程管理也有一些记录时间、统计时间，培养习惯的打卡类日程计划。配合 org-agenda 的各种视图，org-capture 的可定制的模板，用起来真是简洁而又迅速。自己再定制一些函数和脚本，实现从剪切板拷贝图片，使用修改过的 org-ruby 自动从 org 转换为 Markdown，反正只要是文本其可塑性就非常强。 这才是对程序员最友好、最强大的文档和日程管理工具，其满足点在于『可定制』。 全屏中小红点当我开始大量使用 org-mode 记录之后，就不可避免地需要在全屏的 Emacs 下输入中文。而这经常会被打乱，总结一下发现其实是因为全屏状态下我经常会不知道目前是否启用了中文输入法。全屏模式下看不到输入法的任何图标，Baidu 的 Mac 输入法这个浮动状态栏不会在 Emacs 全屏的模式下显示，而且那个辐条本身看起来也太占空间了。在没有图标的情况下只有靠 Shift 或者 Ctrl blank 瞎切换了，非常让人厌烦。 这个困扰很久的问题最近也终于解决了， 这个 ShowEdge 工具可以根据不同的输入法，配置不同的颜色，而且在任何全屏状态都根据输入法显示颜色。我的屏幕顶部就配置了这么一个小红点： 从此输入中文的体验大幅提高！虽然这是非常细节的一个地方，但是当你想到折磨自己的问题，其他人也关注到了，并且用了极其符合自己使用习惯的开源软件解决了，顿时觉得世界真美好！ 这里的满足点在于『可控性』。 黑暗中的黄色光这东西犹如黑暗中的萤火虫，让人温暖，哈哈，其实就是小米的一款感应夜灯。我对小米的这种小的智能家电比较感兴趣，比如小爱同学也不错。这款夜灯的好处在于自动感应，进洗手间自己就亮，我每次都是比较晚才去洗漱刷牙，这灯不太亮也不太暗，而且可以根据声音、移动、和自然光亮度自动开关。其实功能很简单，符合软件设计中的哲学：专注唯一功能，但是功能做到极致。 这应该是简单地满足了『确定性』的心理需求，为什么像语音助手这类东西虽然看起来比较炫酷，但用的人并不多，因为语音识别在日常使用过程中还是会存在各种干扰，最终造成使用过程中存在一些不确定性，从而影响了根本的使用体验。 Entered on [2019-07-26 五 23:31]","tags":[]},{"title":"保存 kmacro ","date":"2019-06-23T23:48:42.000Z","path":"2019/06/23/2019-06-23-random-notes.html","text":"宏是很强大的编辑方法，如果要长久保存一些宏可以使用下面的办法： M-x start-kbd-macro 开始记录宏，通常快捷键为”C-x (“, 结束的快捷键为 “C-x )”。 然后使用命令: M-x kmacro-name-last-macro 可以把这条宏给命名，如果要保存这个宏以便日后使用，需要打开 init.el 继续使用命令： M-x insert-kbd-macro 选中命名的宏，这样就在 init.el 里面插入了刚才的宏，这个名字也就可以当作日常命令使用了。 例如我新建一个宏，作用是查找测试文件中的 “#[ignore]”，并删除掉那行： (fset &apos;rust-ignore (lambda (&amp;optional arg) &quot;Keyboard macro.&quot; (interactive &quot;p&quot;) (kmacro-exec-ring-item (quote ([12 115 101 97 114 99 104 return 35 91 105 103 110 111 114 101 return 1 11 11 14] 0 &quot;%d&quot;)) arg))) 如果要重复执行，则需要运行： C-x z 当然后面可以连续按 z z z …. ， 执行多遍。 参考: https://emacs.stackexchange.com/questions/70/how-to-save-a-keyboard-macro-as-a-lisp-function","tags":[{"name":"Notes","slug":"Notes","permalink":"http://chenyukang.github.io/tags/Notes/"},{"name":"Emacs","slug":"Emacs","permalink":"http://chenyukang.github.io/tags/Emacs/"}]},{"title":"2019，愿你也健康","date":"2019-01-23T23:48:42.000Z","path":"2019/01/23/2019-wishes.html","text":"坚持最近在坚持养成每天尽量花一小时锻炼的习惯，因为我想在 2019 年有个更健康、有活力的身体。 随着年纪的增长，身体的一些反馈还是如实地告诉自己在变老。衰老就是能力不断地退化、消失。之前打球能蹦蹦跳跳的，现在多跑跑就会喘气；之前精力更好、更喜欢到处走动，现在更倾向于静静休息。去年有的时候身体感觉不太好，有段时间特别疲劳，甚至也体验过一段低迷的至暗时刻。大概是因为生活不规律，而且基本没有怎么锻炼，体重也不断上升。因为在 2017 年初打篮球的时候把膝盖伤了，后来也不能激烈打球了。现在比较适合自己的运动方式就是跑步、游泳、散步之类的。 人总是会忘掉这件事当然锻炼养生也不能抵抗衰老，这是个自然过程，锻炼至少能有助于健康。健康是所有幸福的最大基础，比什么都重要，俗话说『宁做健康的乞丐，也比做病恹恹的国王快活得多』。人更无法逃避的是死亡，这是所有生物的最终归宿和命运。只是人总会渐渐忘记自己会死，梁文道说的一个故事： 很多年前，一位德国摄影师跟一个记者合作的拍摄计划，很有意思。那个摄影师去很多的临终病房，拍摄一些快要死去的人，趁他们还在世的时候，拍下他们的遗照。然后他们刚刚离开，合上眼睛的时候，又为他们再拍一张照片，两张照片放在同一版上，前面则是文字记者做的采访。 在这一系列的采访跟摄影当中，其中一个已死的老太太，在她的采访里面说的一句话，他一辈子都不会忘记。她说什么呢？她跟文字记者说，“你看，你看”，就指着病房玻璃外面楼下对面马路的一个超级市场，她指着那个超级市场跟摄影师和记者说：“你看那里头的人们，天天进进出出买东西，买面包、买肉、买卫生纸，你看他们的样子，他们好像从来不觉得自己会死。” 读《最后的告别》这本书很多人都推荐过，我最近刚好也看了一遍。这里面谈了一些人在最终衰老、告别时必须面对的问题和思考，其中也有一些作者所经历的老人故事，还有自己的父亲最后的抗争。其中有一个故事印象深刻，看完后我又查了查还真有这么个人和事。 1980年3月，当附近火山已经开始冒水汽、隆隆作响时，这位83岁的老人却仍然拒绝撤离他在华盛顿奥林匹亚市附近圣海伦山脚的家。他是第一次世界大战时期的飞行员、禁酒时期的私酒制造者，已经在灵湖的这所房子里住了半个多世纪了。5年前，他成了鳏夫。所以，当时，在山脚这处300多亩的地盘上，只住着他和他的16只猫。三年前，他在屋顶铲雪的时候掉下来，摔断了腿。医生说他是个“该死的傻瓜”，在这样的年龄还爬到房顶去做事。 “该死！”他给医生骂回去，“我都 80岁了！我有权做决定，有权做我想做的事。” 由于受到火山喷发的威胁，官方要求附近居民全部撤离，但是杜鲁门哪儿都不去。火山闷烧了两个多月，官方把撤离区域扩大到火山周围16千米。杜鲁门固执地不肯离开。 “如果这个地方要毁灭，那我想跟它同归于尽，”他说，“反正如果失去它，我也会在一周之内结果我自己。”他直率、不和悦的讲话方式吸引了记者。他说起话来滔滔不绝，头戴一顶绿色的约翰·迪尔棒球帽，手拿一大高脚杯波旁威士忌和可乐。当地警察考虑为了他好而逮捕他，但是，由于他的年龄以及他们必须得承受的负面新闻，只好作罢。他们提出但凡有机会就带他离开，但他坚决予以拒绝。他告诉一位朋友：“如果我明天死去，我也已经度过了愉快的一生。我能做的事都做了，想做的事都做了。” 1980年5月18日早上8点40分，火山终于爆发了，其威力相当于一颗原子弹。巨量的岩浆流吞没了整个湖，埋葬了杜鲁门、他的猫和他的家。事后，他成了偶像——一个老头留在自己家里碰运气，在这种可能性似乎已经消失的年代，他按照自己的方式生活。 相对书中的很多老人来说，这位老人的选择充满了勇气，他以决绝的选择来面对衰老和死亡，并没有经受医院的无尽折磨。年轻人看起来这算是是自杀吧，加缪认为自杀是唯一严肃的哲学问题，看来老人对此已经有了答案。能有多少人老了能还以自己喜欢的生活方式活着，并在最终告别的时候心里都是满足：我已经愉快地度过了一生。 孔子说『未知生，焉知死』，反过来如果没有认真思考过死这件事，人又能真的知道怎么活。 最后最近大环境不太好，很多人都在纠结于今年能拿到多少年终，好多事情并不是个人所能决定，自己能最能把握的是自己的身体，珍惜生命、保护好自己，以免年纪轻轻落得一身病，年纪大了用钱换命。 最后推荐一个纪录片：《人世间》。每天都有无数的人在和疾病、死亡抗争，活着对很多人来说其实真不是件容易的事。 日子中很多艰辛和苦难，和生死比起来那就不是事。","tags":[{"name":"Notes","slug":"Notes","permalink":"http://chenyukang.github.io/tags/Notes/"}]},{"title":"Rust 的 dbg! 宏","date":"2019-01-18T00:23:24.000Z","path":"2019/01/18/rust-dbg.html","text":"前几天在群里看到有人讨论 dbg! 宏已经在 Nightly 可以使用了，最近发布的 stable 版本 1.32.0 也可以使用了。 翻看了一下并玩了玩，这个简单的宏确实是调试好帮手，特别是适合我这样的喜欢打印调试的开发者。这个提议从 2017 年 10 月开始，从 https://github.com/rust-lang/rfcs/pull/2173 可以看到，为了增加这个宏很多贡献者经过了无数次的讨论和回复。真是太佩服 Rust Team 的开发者，付出了这么多时间来增加这个看似很小又实用的功能。 使用先看看这个调试宏是怎么使用的，目前使用这个宏需要切换到 Nightly 版本或者最新的稳定版，已经安装了 rustup 的话就很简单了： rustup default nightlyrustup update 然后很简单就是把一个表达式当作参数传入: fn factorial(n: u32) -&gt; u32 &#123; if dbg!(n &lt;= 1) &#123; dbg!(1) &#125; else &#123; dbg!(n * factorial(n - 1)) &#125;&#125;fn main() &#123; dbg!(factorial(5));&#125; 运行结果如下： [src/main.rs:4] n &lt;= 1 = false[src/main.rs:4] n &lt;= 1 = false[src/main.rs:4] n &lt;= 1 = false[src/main.rs:4] n &lt;= 1 = false[src/main.rs:4] n &lt;= 1 = true[src/main.rs:5] 1 = 1[src/main.rs:7] n * factorial(n - 1) = 2[src/main.rs:7] n * factorial(n - 1) = 6[src/main.rs:7] n * factorial(n - 1) = 24[src/main.rs:7] n * factorial(n - 1) = 120[src/main.rs:12] factorial(5) = 120 实现原理当然也就是把表达式和位置打印出来，但是这里有个技巧，在宏里面使用 match，这是为了避免参数被调用多次，因为宏在编译之前会被展开。Rust 的宏比较复杂，也不可避免会有些 hacky，对于喜欢爱折腾的程序员还是有吸引力。再看看这个宏是怎么实现的，代码很少。： macro_rules! dbg &#123; ($val:expr) =&gt; &#123; match $val &#123; tmp =&gt; &#123; eprintln!(\"[&#123;&#125;:&#123;&#125;] &#123;&#125; = &#123;:#?&#125;\", file!(), line!(), stringify!($val), &amp;tmp); tmp &#125; &#125; &#125;&#125; 可以看到目前这个实现是只支持一个参数的，如果传入的参数类型没有实现 Copy Trait，可以传入引用。另外如果想同时打印多个参数，可以使用类似这样的做法： dbg!((exp1, exp2))","tags":[{"name":"Rust","slug":"Rust","permalink":"http://chenyukang.github.io/tags/Rust/"}]},{"title":"《见识》阅读笔记","date":"2019-01-10T23:22:40.000Z","path":"2019/01/10/book-review-wujun.html","text":"到年底小组内还有多余的预算，于是大家都在网上选书。看到吴军出了两本新书，出于对作者的信任就直接下单了。上个周末就花了些时间很快地看完了两本。内容稍微有些重合，主要是有的例子会拿来阐述多个道理。所以两本连着看会有些作者凑书的感受。当然两本都还是不错的，读完《态度》对于我这个新手爸爸来说也是收获不少。个人更推荐《见识》这本书。 《见识》更多关注个人成长、看待问题的视角、工作职场中的一些经验。其中几个主题： 人生是一条河每个人都希望自己这条河能够更宽一点、更深一点、更长一点。只有给予才能带来幸福感。 认识到生命是有限的，应该挑重要的事做，向死而生。 人生需要做减法不做选择的幸福，从另外一个角度去解释为什么印度人在硅谷更容易成功。我觉得是有一定道理的，印度人因为名族的阶级观念，在生活工作中少了一些选择，却能一直在某个领域坚持数十年。第一份工作的过程中，接触了不少印度人。其中一位从印度到硅谷，一直都是在一个公司工作了 14 年左右，我问他为什么不跳槽，他倒觉得无所谓，安家乐业地每天过得很稳。少了选择就不容易思前想后，一门子扎进去了。在工作上，很多人都不能坚持一直耕耘于某个特定的领域，坚持下来的就成了。 做人与作诗：这章讲的道理类似于『出世』与『入世』，让我想起《月亮和六便士》里的画家。 要会做减法，为“做重要的事”服务，同时认清什么是重要的事。 西瓜与芝麻想起骚年的时候总是花时间去找些破解软件，舍不得一点钱买些软件或者工具，渐渐地意识到了这就是为了芝麻丢西瓜的事。类似的还有很多，现在则改变了认知，能付费节约时间则付费，能花钱买到更好的则花钱。 生也有涯 知也无涯正因为如此，生活、学习、工作中需要聚焦，别分散精力。人能在某一段时间内做好一件事，并且做得比其他人好，好到自己觉得不能更好为止。也正是因为『知也无涯』，不要为了自己的未知而焦虑，因为这是再正常不过的了，自己学起来就好，别丢掉好奇心。 我们一定比 18 世纪的人过得幸福么？显然，当代人并不幸福，特别是我们这些年轻的一代。物质上倒谈不上匮乏，而是没有自己的时间，然后则是人到中年必不可免的生活压力和焦虑。EB的说唱里有段歌词『所有人都忙着想要更多的东西 所以得到之后就没有精力去珍惜 情歌越来越多 真情却越来越少 巧克力的保质期越来越长 爱情的保质期却越来越短 生活变得越来越丰富多彩 于是越来越多的人变得分不清黑白』。 我们与天才差多远我们绝大部分人成长过程中，迟早会意识到自己不过是芸芸众生中的普通人。硅谷中，我认为有一种气氛特别好，就是对聪明人的崇敬。之前的老板应该已经算是又聪明又勤奋的那种，谈话中总是会说起自己碰见过的聪明人，聪明到如何程度，以及一些小故事。有的生理上的差异是解释不清的，比如有的人就是善于计算，有的人精于细节。不过天才的见识、勇气、或者方法上有的是值得学习的。","tags":[{"name":"Books","slug":"Books","permalink":"http://chenyukang.github.io/tags/Books/"}]},{"title":"使用 Markown 编辑公众号方法","date":"2019-01-06T23:48:39.000Z","path":"2019/01/06/wechat-tools.html","text":"技术人员很多都喜欢使用 Markdown 格式来编辑文档，但是公众号后台默认不支持。 所以关于工具和流程，最近我摸索出来目前最适合自己的一套是： 还是维护之前 Hexo 那套，像代码那样使用 Git 管理，内容会上传到 Github 上。 继续使用 Typora 编辑 Markdown 文件。注意使用图片工具 IPic 来方便地把图片上传到图床上，其实免费的微博图床就足够。然后使用在线的转换工具md.codingpy.com即可很方便地把 Markdown 转成适合公众号的内容，复制粘贴到后台编辑器里。 这样在个人网站和公众号里都会有相同的内容，而且格式之类的都比较统一。 这里再次推荐 Typora: https://typora.io/ 这个工具，会让人特别有写东西的冲动。","tags":[]},{"title":"开始写公众号","date":"2019-01-04T22:57:24.000Z","path":"2019/01/04/try-wechat-blog.html","text":"2018 过得很快，对于自己来说有点颓废、也很辛苦。说是颓废因为花了一些时间在游戏上，还有不少焦虑。最近看书，翻到胡适 1932 年一篇《寄语即将毕业的大学生》中写到，人到社会容易丢掉求知的欲望、抛弃学生时代的理想追求，为了防止堕落文中给出三点建议。读来觉得颇有道理，这三点建议放在现在也合适： 总得时时寻一两个值得研究的问题 总得多发展一点非职业的兴趣 你总得有一点信心 新的一年想着尝试做些改变，逼着自己再做一些其他尝试，不然生活除了工作和日常，真是过得有些索然无趣了。业余写些东西是很好的积累，从 2006 年左右开始一直都有写博文的习惯，从搜狐、Yo2、WordPress， 一直到后来的 Hexo 托管到 Github 上。个人域名 http://cyukang.com 用了多年，其中的文章大概也有 140 来篇。在这么多年写博客的过程中收获不少，认识了一些朋友，也锻炼了自己的文字能力。 平台和工具一直在变化，文字只是一种表达的方式，能写出来还是得靠自己平时所想、所做。之前写的技术类的文章偏多，因此一直觉得公众号这种生态圈有些封闭，不利于检索。不过终究是大众的选择，公众号里好的内容也很多。如果要逼着自己写，有些人看、有些互动自然是更好的。不求有多少关注，但愿自己能坚持多写写而已。 关于写什么，我也还不太清楚。在技术方面可能涉猎较多，精通的不算多。总之算得上技术爱好者，还未丢掉这块兴趣。所以这里多是关于工作、技术的一些学习总结、实践等。把技术相关的东西写得通俗易懂绝非易事，希望在这方面能有更多进步。另外我更想拓展自己在其他方面的知识和积累，所以公众号上会写更多读书笔记和思考。『构成我们学习的最大阻碍是已知的东西，而非未知』，局限于技术角度并非好事。 关于公众号名字『递归说』，这是乱想的，刚好在取名的时候想到了而已。听起来比较好念，而且递归真是计算机里一个很简洁、优美的概念，也是解决问题的一种方法，还可以延伸理解为『自我进化』吧。人这一辈子不也像一个递归么，过一年就像过了一个迭代，而且都是有终点的。 先写起来再继续摸索找方向吧，总得对自己有些信心。 扫描关注：","tags":[{"name":"WeChat","slug":"WeChat","permalink":"http://chenyukang.github.io/tags/WeChat/"}]},{"title":"使用 peco 飞起 zsh","date":"2019-01-04T22:55:22.000Z","path":"2019/01/04/peco-for-zsh.html","text":"pecopeco 是一个能做交互式 filte 的工具，是 percol 的 Go 实现。特别适合在 shell 里做一些过滤操作，当然适合做日志方面的过滤。典型的使用方法是： zsh 配置下面这个配置主要增强了 zsh 的 history 补全，以及pwdf可以用来迅速找一个文件，并拷贝其全路径： function exists &#123; which $1 &amp;&gt; /dev/null &#125;if exists peco; then function peco_select_history() &#123; local tac exists gtac &amp;&amp; tac=\"gtac\" || &#123; exists tac &amp;&amp; tac=\"tac\" || &#123; tac=\"tail -r\" &#125; &#125; BUFFER=$(fc -l -n 1 | eval $tac | peco --query \"$LBUFFER\" --layout=bottom-up) CURSOR=$#BUFFER # move cursor zle -R -c # refresh &#125; zle -N peco_select_history bindkey '^R' peco_select_historyfiOS_NAME=`uname`function pclip() &#123; if [ $OS_NAME = \"CYGWIN\" ]; then putclip \"$@\"; elif [ $OS_NAME = \"Darwin\" ]; then pbcopy \"$@\"; else if [ -x /usr/bin/xsel ]; then xsel -ib \"$@\"; else if [ -x /usr/bin/xclip ]; then xclip -selection c \"$@\"; else echo \"Neither xsel or xclip is installed!\" fi fi fi&#125;function pwdf() &#123; local current_dir=`pwd` local copied_file=`find $current_dir -type f -print | peco --layout=bottom-up` echo -n $copied_file |pclip;&#125;","tags":[{"name":"Linux","slug":"Linux","permalink":"http://chenyukang.github.io/tags/Linux/"}]},{"title":"编译脚本到二进制","date":"2019-01-01T22:55:22.000Z","path":"2019/01/01/compile-script-to-binary-for-obfuscation.html","text":"缘由因为自己习惯使用 expect 脚本登录各种服务器，有一段时间因为要登录的服务器太多了，所以之前写过一个程序来管理各种 expect 脚本。实现思路是根据配置文件，用一个程序来动态生成脚本，执行完之后再删除。这样临时生成的文件里也是包含密码等信息的。最近突然想是不是可以直接写一个程序，把所有脚本类的程序转换为二进制可执行文件^image。我不想把密码之类的直接写在固定的脚本里面，所以密码也是被编译在可执行的二进制文件里的，这样能达到一些代码混淆的目的。 rshc 的开发这个程序看起来有些好玩，所以先我先搜了一下是否之前有其他人这样做过。于是找到了 shc 这个开源程序，这个最初版本是 96 年用 C 写的，最终执行的时候还是用 execvp 调用解释器执行各种脚本。我使用了一下发现居然不支持 expect 之类的。然后想着自己写个玩玩，顺便再动手用用最近看得又心痒的 Rust，最后用搞出来一个初版: rhsc。 目前我这个程序只是能把脚本程序，转换为 Rust 代码，然后使用 rustc 来编译为二进制，为了做一些代码混淆，其中也类似 shc 使用了 RC4 算法来做了一个简单的转换，加密用的 key 是随机生成的。然后也做了另外一个增加密码的模式，这样可以为任何脚本增加密码校验功能，最终使用 Process 来执行解释器。当然也谈不上多安全，如果要破解可以使用一些类似 ptrace 或者其他方式来试试。以后我会继续完善这方面的防御。另外，为了在生成代码之后尽量减少依赖，所以目前密码输入时还未做到隐藏输入。 安装使用使用方式非常简单，先安装： cargo install rshc 然后使用命令： rshc -f demo.sh -o demo.rs// add a passowrd when compile it, // then binary will prompt for correct password before executionrshc -f demo.sh -o demo.rs -p 其他时隔两年再用 Rust 写一些小项目，发现整个语言还是成熟很多： 工具链很好用，特别是 cargo 之类的，从开发到发布都非常方便 相关的库和文档也多了起来，相对来说更加容易上手写一些东西了 编译器的错误提示特别好，可以通过错误索引号找到示例","tags":[{"name":"Rust","slug":"Rust","permalink":"http://chenyukang.github.io/tags/Rust/"}]},{"title":"SQL Injection attack","date":"2018-03-10T20:51:40.000Z","path":"2018/03/10/sql-injection-attack.html","text":"注入原理SQL注入一直是 Web 应用的一大安全隐患，注入的基本原理是通过修改输入的参数来操作后台执行的 SQL，注入可能会导致数据库被恶意修改、数据被恶意读取等严重行为。所以如果一个参数有漏洞，通过小心的构造注入点即可利用，这里的渗透攻防Web篇-SQL注入攻击初级有一些编写注入点的教程。 最初的时候我在一个用 C 写后台的项目里待过，现在回想起来我们当时根本没注意SQL 注入，C 拼接处 SQL 的字符串很常见。不过现在大多数 Web 框架都已经有 ORM 了，ORM 可以在很大程度上避免注入的产生，因为程序员通常来说不用写纯的 SQL 了， 在最佳实践的前提下 ORM 会生成安全的 SQL。当然什么工具最终还是依赖程序员，比如下面的 Ruby 代码即会有问题: User.where(\"email = #&#123;params[:email]&#125;\").first 更多作死的办法可以参考： https://rails-sqli.org/ WAF通常我们会使用一些 WAF 来阻挡 一些SQL 注入，但是 WAF 也有其局限性。WAF 一般是通用的，不会局限于某个特定的框架。我们可以实现在 Nginx 上，或者使用一些商用的 WAF，通常来说对于应用也不用修改其代码。不过 WAF 的问题在于其实基于规则的，而 SQL 本省是比较复杂的，可以看看2003 SQL BNF 的描述有多么的长。所以 WAF 的规则大多数是一大堆较难维护的正则表达式，比如： Nginx Waf示例，注意这个项目用不太成熟，初步看会有比较严重的性能问题。正因为规则是固定的，会导致存在很多误拦截的情况，所以我在 Kong 上实现的 WAF 就还不敢用起来。例如现实情况中出现过包含select的 uri被拦的情况，一脸忧伤。 静态代码扫描静态代码扫描会发现一些 SQL 注入，比如 Brakeman 之类的。不过通常静态代码扫描的问题也是分析得不够精准，会漏报、也会出现误报比较多，扫描的结果需要进行人工审计。当然这些工具也在逐步改进。 RASP 工具RASP 的意思是Runtime Application Self Protection，这个概念近些年才提出，目前已经有一些安全公司做出了对应的产品，比如Sqreen, 百度最近也新开一个开源项目叫做OpenRASP，目前来说只支持 Java，开发者可以自己使用 Javascript 编写自己的插件。RASP 除了自己的规则还会依据请求时候的上下文来进行分析，这篇文章里有一些描述，这样误报的问题会大大减少。","tags":[{"name":"security","slug":"security","permalink":"http://chenyukang.github.io/tags/security/"}]},{"title":"Kong集群Left Cluster Node问题","date":"2018-03-04T11:02:32.000Z","path":"2018/03/04/kong-cluster-left-node.html","text":"问题Kong在实践中会有一些疑惑的地方，这里记录一下。注意这里记录的Kong集群部署的问题是0.10.3版本的，最新Kong版本已经不是通过serf来管理不同节点之间的配置同步问题。 在Kong多节点部署的时候，有时候某个节点停掉后，我们在后台可以看到left的信息，而且这个left信息会保留一段不短的时间。类似于如下： 分析管理后台Konga是通过api获取的节点信息，在kong/kong/api/routes/cluster.lua文件里可以看到如下路由处理逻辑： GET = function(self, dao_factory, helpers) local members, err = singletons.serf:members() if err then return responses.send_HTTP_INTERNAL_SERVER_ERROR(err) end local result = &#123;data = &#123;&#125;&#125; for _, v in pairs(members) do if not self.params.status or (self.params.status and v.status == self.params.status) then table_insert(result.data, &#123; name = v.name, address = v.addr, status = v.status &#125;) end end result.total = #result.data return responses.send_HTTP_OK(result)end, 具体serf:members()的实现在serf.lua里面可以看到，就是执行了serf cluster members命令获取结果然后返回JSON。所以我们在服务器上执行这个命令其实也可以看到类似的结果： 那么问题的根源当然是在Serf本身里面，通过看文档发现原来确实是有一定延迟的。 Serf keeps the state of dead nodes around for a set amount of time, so that when full syncs are requested, the requester also receives information about dead nodes. Because SWIM doesn’t do full syncs, SWIM deletes dead node state immediately upon learning that the node is dead. This change again helps the cluster converge more quickly. 参考serf文档» serf的具体实现接着稍微看了一下Serf的代码，果然Go的项目代码直观好读。在Serf这个结构体里面保存了一个leftMembers的状态列表，每次收到left事件的时候处理逻辑是： // handleNodeLeaveIntent is called when an intent to leave is received.func (s *Serf) handleNodeLeaveIntent(leaveMsg *messageLeave) bool &#123; .................. // State transition depends on current state switch member.Status &#123; case StatusAlive: member.Status = StatusLeaving member.statusLTime = leaveMsg.LTime return true case StatusFailed: member.Status = StatusLeft member.statusLTime = leaveMsg.LTime // Remove from the failed list and add to the left list. We add // to the left list so that when we do a sync, other nodes will // remove it from their failed list. s.failedMembers = removeOldMember(s.failedMembers, member.Name) s.leftMembers = append(s.leftMembers, member) ................ return true default: return false &#125;&#125; 通过索引变量发现这个列表会定时通过handleReap函数更新，逻辑如下： // handleReap periodically reaps the list of failed and left members, as well// as old buffered intents.func (s *Serf) handleReap() &#123; for &#123; select &#123; case &lt;-time.After(s.config.ReapInterval): s.memberLock.Lock() now := time.Now() s.failedMembers = s.reap(s.failedMembers, now, s.config.ReconnectTimeout) s.leftMembers = s.reap(s.leftMembers, now, s.config.TombstoneTimeout) reapIntents(s.recentIntents, now, s.config.RecentIntentTimeout) s.memberLock.Unlock() case &lt;-s.shutdownCh: return &#125; &#125;&#125; 所以看起来这里相关的Timeout是s.config.TombstoneTimeout, 接着需要看看reap到底做了什么，这里果然是把到了一定时间间隔的节点删掉了： // reap is called with a list of old members and a timeout, and removes// members that have exceeded the timeout. The members are removed from// both the old list and the members itself. Locking is left to the caller.func (s *Serf) reap(old []*memberState, now time.Time, timeout time.Duration) []*memberState &#123; n := len(old) for i := 0; i &lt; n; i++ &#123; m := old[i] // Skip if the timeout is not yet reached if now.Sub(m.leaveTime) &lt;= timeout &#123; continue &#125; // Delete from the list old[i], old[n-1] = old[n-1], nil old = old[:n-1] n-- i-- .......... &#125; return old&#125; 那么这个时间间隔是多久呢，在serf/config.go有一个默认配置： TombstoneTimeout: 24 * time.Hour, 其他serf这个软件值得好好分析一下，节点的状态同步和事件处理都是分布式软件的基础，后续继续看看这个gossip protocol based on SWIM的具体实现。另外hashicorp这个公司的开源代码和文档都非常好，值得学习一番。","tags":[{"name":"Tools","slug":"Tools","permalink":"http://chenyukang.github.io/tags/Tools/"},{"name":"Kong","slug":"Kong","permalink":"http://chenyukang.github.io/tags/Kong/"},{"name":"Golang","slug":"Golang","permalink":"http://chenyukang.github.io/tags/Golang/"}]},{"title":"Docker compose初始化失败问题","date":"2018-03-02T23:17:35.000Z","path":"2018/03/02/docker-postgres-password.html","text":"问题今天在Docker Postgresql用户名和密码授权的问题上花了一些时间，问题是： psql: FATAL: password authentication failed for user \"postgres\" admin的用户名和密码是可以在docker-compose.yml里设置的，通常我们可以配置为： postgresql: image: postgres:latest ports: - \"5434:5432\" volumes: - ./data/pgsql:/var/lib/postgresql/data - ./initialize/pgsql:/docker-entrypoint-initdb.d environment: POSTGRES_USER: postgres POSTGRES_DB: postgres secrets: - pg_superuser_password 某个用户的密码可以在./initialize/pgsql目录的脚本里设置： #!/bin/bashset -epsql -v ON_ERROR_STOP=1 --username \"postgres\" &lt;&lt;-EOSQL CREATE USER user WITH PASSWORD 'the-password'; ALTER USER user CREATEDB;EOSQL 只是今天碰巧想修改一下这个密码，所以就把这个脚本里的密码修改了，然后执行命令： docker-compose up --build -d --force-recreate 而后就一直出现上面的用户授权失败。 原因刚开始一直认为是可能dockerfile配置得不对，结果花费了些时间。后来突然想到了，PG里数据初始化应该只是第一次做了，后续如果发现/var/lib/postgresql/data里已经有数据了就再也不会重新设置密码，这里是配置volume的，如果还未有重要数据把./data/pgsql删除了即可，或者应该是可以通过attach进入容器通过pg命令修改。 总结最近在自己工作的项目都完全Docker化，感觉是配置来折腾用起来飞。最近也在做一个重度依赖Docker的项目，所以Docker的文档需要看完，特别是网络和数据存储那块，否则会花费不少时间折腾。","tags":[{"name":"Tools","slug":"Tools","permalink":"http://chenyukang.github.io/tags/Tools/"},{"name":"Docker","slug":"Docker","permalink":"http://chenyukang.github.io/tags/Docker/"}]},{"title":"使用overcommit生成git hooks","date":"2018-02-26T19:02:14.000Z","path":"2018/02/26/overcommit.html","text":"git hooks很方便地可以在git操作流程的各个阶段加入hooks，比如执行一些脚本来检查代码风格、跑单元测试、做代码静态检查等。git hooks的试用方法是在.git/hooks目录下写各种脚本，但是.git目录的这些脚本是不会checkin到repo里的，所以如果一个代码如果被多个开发人员共享就会显得不太方便同步hooks。 当然也有一些其他方法来解决这个问题，比如配置links或者对于git 2.9以后也可以使用来定制hooks的目录: git config core.hooksPath hooks 对于熟悉Ruby的同学可以使用overcommit这个gem来解决。使用方法就是通过配置.overcommit.yml，比如: PreCommit: RuboCop: enabled: true command: ['bundle', 'exec', 'rubocop'] # The shell command should run AuthorName: enabled: false 然后执行命令: overcommit install 来自动生成各种hooks，通常后面的修改都是修改这个yaml文件即可，不过记得修改后需要overcommit --signed来重新生成hooks。","tags":[]},{"title":"Nginx https too many redirect","date":"2018-02-23T17:38:44.000Z","path":"2018/02/23/nginx-https-too-many-redirect.html","text":"Http请求在经过多层Nginx的时候，通常强制http跳转到https的时候会这样配置: return 302 https://$host$request_uri; ## 需要注意这里是request_uri而不是uri，否则会引起安全问题 但是如果是多层Nginx，前面的Nginx需要把用户原始请求的scheme传递到后端，可以加上头部设置： proxy_set_header X-Forwarded-Proto $scheme; 后面的Nginx再判断一次: if ( $http_x_forwarded_proto != 'https' ) &#123; return 301 https://$host$request_uri;&#125; 否则强制https经常会出现类似ERR_TOO_MANY_REDIRECTS 将您重定向的次数过多这样的问题。 可是在实践过程中偶尔也碰到过一些ELB会丢掉scheme的问题，比如在这样的请求链路情况下elb =&gt; nginx =&gt; nginx =&gt; application第二层Nginx获取的scheme就有问题了，这也可能会导致too many redirects问题。 可以尝试在第二层Nginx上这样解决： proxy_set_header X-Forwarded-Proto $http_x_forwarded_proto; 当然强制https这样的跳转逻辑尽量放在请求链路的最外层，这样问题会少一些。","tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://chenyukang.github.io/tags/Nginx/"}]},{"title":"Linux 当前 shell 执行命令","date":"2018-02-22T21:46:33.000Z","path":"2018/02/22/linux-source.html","text":"Linux shell 执行脚本的时候一般是会 fork 出一个子 shell，这样在有的时候就不方便了，比如要unset 当前shell 的环境变量等， #!/usr/bin/env zshif [ -z $http_proxy ]; then echo \"not using proxy, set it now ... \"; export http_proxy=\"http://127.0.0.1:1087\"; export https_proxy=\"https://127.0.0.1:1087\"; echo $http_proxy;else echo \"using proxy now, unset it now ...\"; unset http_proxy; unset https_proxy; echo $http_proxy;fi 这时候需要执行 . ./proxy_toggle.sh 或者 source ./proxy_toggle.sh。 . (a period) is a bash shell built-in command that executes the commands from a file passed as argument, in the current shell. source is a synonym for . From Bash man page: . filename [arguments]source filename [arguments] Read and execute commands from filename in the current shell environment and return the exit status of the last command exe‐ cuted from filename. If filename does not contain a slash, file names in PATH are used to find the directory containing file‐ name. The file searched for in PATH need not be executable. When bash is not in posix mode, the current directory is searched if no file is found in PATH. If the sourcepath option to the shopt builtin command is turned off, the PATH is not searched. If any arguments are supplied, they become the posi‐ tional parameters when filename is executed. Otherwise the positional parameters are unchanged. The return status is the status of the last command exited within the script (0 if no commands are executed), and false if filename is not found or cannot be read.","tags":[]},{"title":"Ruby的 open 函数导致命令执行","date":"2018-02-12T20:39:46.000Z","path":"2018/02/12/ruby-open-vul.html","text":"说明首先看看 open 函数的文档说明， https://apidock.com/ruby/v1_9_3_392/Kernel/open/class： If path starts with a pipe character, a subprocess is created, connected to the caller by a pair of pipes. The returned IO object may be used to write to the standard input and read from the standard output of this subprocess. If the command following the “|” is a single minus sign, Ruby forks, and this subprocess is connected to the parent. In the subprocess, the open call returns nil. If the command is not “-”, the subprocess runs the command. If a block is associated with an open(“|-”) call, that block will be run twice—once in the parent and once in the child. The block parameter will be an IO object in the parent and nil in the child. The parent’s IO object will be connected to the child’s stdin and stdout. The subprocess will be terminated at the end of the block. 其中说明了如果以|开头则会 fork 出一个进程，| 后面的内容则会当成一条命令执行，比如： cmd = open(\"|date\")print cmd.getscmd.close=&gt; 2018年 2月12日 星期一 21时37分45秒 CST 漏洞正因为这样，这个 open 函数真的是很容易出错，最近的这个 PR： https://github.com/ruby/ruby/pull/1777 之前我们的项目里也出现过类似的情况，直接相当于一个 webshell，任意执行命令。这样的 command injection 当然也很好检测，brakeman 之类的就可以。所以 Rails项目还是时不时地扫描一下比较好。 Ruby 里面有几个 Open，这里有比较明晰的解释，Kernel.open 这个函数就是一个 wrapper，根据不同的情况做对应的处理。趟多了坑之后，才会觉得这样的特性其实是增加了程序员的负担，比如这个|特性可能有的人就没注意到，即使是看过文档也可能看到了老版本的文档，从而不知道这个边边角角。 当然同样的 system这样的命令执行函数也是类似的情况，比如railsgoat 里的这个 command injection。原则是对于任何用户输入的参数，都需要做不安全的假设，做好检查。 https://github.com/OWASP/railsgoat这个项目里有各种 Rails漏洞，值得看看。","tags":[]},{"title":"BuckleScript and Reason","date":"2017-09-17T22:47:27.000Z","path":"2017/09/17/bucklescript-and-reason.html","text":"BuckleScript虽然我不是前端工程师，不过因为喜欢 OCaml，所以偶尔关注 BuckleScript 有一段时间了，今天又花时间看了看文档和代码。BuckleScript 是张宏波主导开发的开源项目，『有希望成为第一个完全由国人设计主导实现并被世界各地广泛使用的编译器』，不过是否能广泛被使用还得看后续推广。 简单来说BuckleScript 是一个代码转换器，把你写的 OCaml 代码生成为纯 JS 代码。这样做的好处和必要性在于： JS 太牛了，这个跨平台语言正在吞噬着所有软件领域 JS太难维护了，大规模的 JS 代码更是噩梦。不管是从开发者角度和是从代码安全的角度，JS 需要类型！微软的 Typescript 和 FB 的 Flow ，甚至是Elm都是为了给 JS 带来类型。 OCaml类型系统稳定可靠，关键是编译器速度快，并且可以编译在多个平台上。 就我个人而言非常喜欢 OCaml，之前也有一些自己的小项目用过 OCaml。BuckleScript从技术角度来说是非常好的，我看了一些生成的代码可读性比很多代码生成器要好。并且除了直接翻译代码，这个编译器也做了很多代码优化的工作，生成 size 更小，performance 更好的 JS 代码。遗憾的是目前还不支持 Core 这个库，我之前用 Core 比较多，ಥ_ಥ。 关于代码生成，想起我们原来做过的 Gorazor，从技术角度来说还是有些挑战的，不过从使用角度我个人持保留态度。代码生成毕竟会引入新的语法，我发现很多前端程序员其实并不怎么熟悉函数式编程那套，OCaml 的语法是否能在前端程序员中推广开来是个问题。BuckleScript的文档有待改进，可以给更多大一点的完整的例子。 关于BuckleScript和js_of_ocaml 的区别，从文档上来看js_of_ocaml 可以把 bytecode 转换为 JS 代码，而BuckleScript是在从编译器里面的rawlambda生成代码，所以理论上来说 js_of_ocaml 对 OCaml 的兼容性更好，而BuckleScript 能生成更可读的 JS 代码，目标在于兼容npm平台。 ReasonMLReasonML的来由是之前我说的 OCaml 独特的语法，在很多人看来并不是很友好，所以FB 的这群人做了一个更符合大众品位的方言。然后可以通过 BuckleScript 再翻译为 JS 代码。好绕啊！不过据说 FB 已经在生成环境使用这些了。ReasonML 的开发者移植了一个之前用js_of_ocaml 写的mario 的例子，看了一遍觉得reason 的语法其实改动并不大，可能对 JS 的程序员来说更友好吧。reason 和 OCaml 的关系类似于 Elixir 和 Erlang 之前的关系，为了讨好一类程序员，又为了利用一个已经非常成熟可靠的现有平台。 在 HN 上有一个比较老的讨论帖，有时间也可以再看看。 Why bucklescript matters for Javascript platform","tags":[{"name":"OCaml","slug":"OCaml","permalink":"http://chenyukang.github.io/tags/OCaml/"},{"name":"Javascript","slug":"Javascript","permalink":"http://chenyukang.github.io/tags/Javascript/"}]},{"title":"《深度工作-如何有效使用每一点脑力》读后","date":"2017-09-14T22:20:14.000Z","path":"2017/09/14/deep-work.html","text":"深度工作这本书主要讲解了一些时间和精力管理方面的东西，人到了一定年龄就会觉得时间不够用，日子过得太快，每天觉得都没干什么就过去了。工作几年后这种感觉时不时袭来。反而是如果某段时间一直有一个阶段性的目标，就会觉得很踏实，进度和效率也可以。那种完全沉浸在思考中的状态真的也并不是累，相反所得到的结果往往是真实的收获和进步。用这本书里的术语可以称之为『深度工作』的阶段吧。 说起来也有道理，如果自认为我们是知识工作者，那么大多数时间处于浮潜的工作状态就得不到什么深刻的结果。作为程序员，我也有时候感觉自己并不是在做什么高深的工作，那么这样长久下去会怎么样呢，随之而来的是不可避免的压力。 这里讲的四个准则，任何一个都值得好好修炼，对于大多数人而言，大脑都已经被互联网和手机训练得愚钝和不可专注了： 工作要深入拥抱无聊远离社交媒体摒弃浮浅 深入工作的价值在当今社会格外突出，因为机器的迅猛发展，特殊的技能所展现的价值越发明显。『连续听一系列中等水平的歌手唱歌并不能累加成一场无与伦比的演出— 换言之，才能并非一种商品，你不可以通过大批购买，然后累积起来达到一定水准，只有成为最优秀的才会得到额外奖励』。我们所面临的时代需要掌握一些更为复杂的工作和技能，而这些技能并不是随便看看就能轻易得到的。深入的东西只有静下心来，持续花大量时间和精力才能逐渐掌握。 想要进入深度工作，会有两个方面需要注意: 时间分配，如何避免被频繁打断，如何尽量延长一大段可以持续的时间 学习和锻炼持续专注的能力 关于时间分配，我之前尝试过番茄工作法，但是感觉并不好。因为仪式感太强和太频繁，在我正在进入工作状态的时候可能就到了节点。对于大多数程序员来说晚上可能是最能安静的写程序和思考的时间，不过随着更多的家庭责任，晚上的时间也短了。所以现在我打算早上尽早起来，这样还有一两个小时加以利用。 关于专注能力这块： 不断地切换注意力会对大脑产生长久的负面影响 这个结论应该大家都有体会，持续专注的能力往往决定人的能力，有的人可以一直脑袋里想着问题，即使是在走路或者吃饭的时候。之前在学校我也有过一段时间，脑袋里一直在想着要找的答案，那种体验已经好久没有了。 总之，这本书还不错，推荐有时间的话看看。","tags":[{"name":"Books","slug":"Books","permalink":"http://chenyukang.github.io/tags/Books/"}]},{"title":"Kong的0.11.0版本","date":"2017-09-12T14:43:00.000Z","path":"2017/09/12/kong-new-release.html","text":"Kong发布了新的版本0.11.0，从这里开始区分了社区版本和商业版。这次改动比较大的是丢弃了serf，这样整个Kong节点之间的缓存同步方式变化了。开发者给出的理由如下： 依赖serf，serf并不属于Nginx/OpenResty 这种依赖相互间通信来同步的机制对于deployment和容器化都有些不便 在运行的Kong节点触发serf需要一些租塞的I/O 新的实现的思路是以数据库作为中心，增加一个cluster events的表。任何Kong node都可以向数据库发送变更消息，其他节点polling数据库改动，然后来更新缓存内容。这个改动非常大，不过最终Kong终于实现了节点无状态，之前那个数据库里的nodes可以丢弃掉了，任何时候节点重启只要连上数据库即可工作。我们需要担心的是这么多节点去polling数据库(当然这些动作都是在后台)，是否是一个比较耗时的工作。 Kong增加了新的配置选项db_update_frequency，默认为5s，表示多长时间polling一次，这需要用户自己权衡效率和及时性了。对于我们的业务来说及时性还是很重要的，比如我们新品发布时间精确到秒，那么我们就需要尽量调低这个参数。 所有的改动在https://github.com/Mashape/kong/pull/2561/files， 我大概看了一下代码，一些值得注意的地方如下： cluster相关的API和cmd都被移掉了，启动部分和serf信号处理部分都删掉了不少代码。 polling需要避免一个问题，比如上一次polling还未执行完成，下一次polling就不应该启动，所以这里需要锁来处理。kong/cluster_events.lua实现了polling的主要过程。 kong/cluster_events/strategies/postgres.lua目前polling还不支持分页，cluster_events是一个新建的表用来存储缓存更新事件，Kong节点就是来查询这些事件。 缓存部分换成了lua-resty-mlcache，原来还是和之前分析的类似 L1级别缓存为一个LURcache，在LuaVM里可见， L2级别的缓存为lua_shared_dict，同一个Nginx下的所有worker可见， L3就是缓存未命中的情况，需要调用其他hookup的函数去获取数据然后缓存在L2。只是这里个ipc并不是用的lua-resty-mlcache里的，而是使用的resty.worker.events。 事件处理部分分两部分，worker之间的事件和node之间的处理，分别由worker_events和cluster_event.lua来处理。","tags":[{"name":"Kong","slug":"Kong","permalink":"http://chenyukang.github.io/tags/Kong/"},{"name":"Lua","slug":"Lua","permalink":"http://chenyukang.github.io/tags/Lua/"}]},{"title":"Lua时间处理","date":"2017-09-12T09:51:00.000Z","path":"2017/09/12/lua-time-related.html","text":"我需要用Lua处理一个与时间相关的问题，比如我们在配置文件里面配置一个日期(北京时间)，然后在Openresty里面判断当前时间是否在这个日期之前或者之后来做对应的逻辑。 Lua的时间处理还有点麻烦，主要是自带的相关库函数比较少。 os.time() &lt;== 返回当前系统的日历时间， 1505181586os.date() &lt;== 返回本地化的时间字符串，Tue Sep 12 09:59:56 2017os.clock() &lt;== 返回执行该程序CPU花去的时钟秒数，这里是1156.726 我首先需要一个日期字符串转换为时间戳的函数，找来找去有了这么一个函数，使用正则表达式然后组成表： function convert_time(time_str) -- Assuming a date pattern like: yyyy-mm-dd hh:mm:ss -- Assuming timezone is Beijing local pattern = \"(%d+)-(%d+)-(%d+) (%d+):(%d+):(%d+)\" local year, month, day, hour, minute, seconds = time_str:match(pattern) if not (year and month and day and hour and minute and seconds) then return nil end local converted_timestamp = os.time(&#123;tz = \"CST\", year = year, month = month, day = day, hour = hour, min = minute, sec = seconds&#125;) return converted_timestamp end 然后我们可以使用os.time()获取当前时间戳来对比。但是必须注意时区问题，Lua里面要获取当前时区和UTC里面的offset可以使用一个比较笨拙的办法： function get_timezone_offset_with_utc() local now = os.time() return os.difftime(now, os.time(os.date(\"!*t\", now)))end 使用这个函数获取时区的offset之后，对convert_time返回的结果做一下偏移即可和os.time()做对比。有个问题是上面的函数居然调用了三次系统调用，开销是比较大的。 在 OpenResty 的世界里，不推荐使用这里的标准时间函数，因为这些函数通常会引发不止一个昂贵的系统调用，同时无法为 LuaJIT JIT 编译，对性能造成较大影响。推荐使用 ngx_lua 模块提供的带缓存的时间接口，如 ngx.today, ngx.time, ngx.utctime, ngx.localtime, ngx.now, ngx.http_time，以及 ngx.cookie_time 等。 Penlight库也有很多日期相关的函数封装，不过大多也都使用了os相关函数。为了避免多次调用get_timezone_offset_with_utc\u001b我使用了Kong里面自带的cache相关函数做一下缓存： -- 缓存上面的时区差，减少系统调用local offset_with_cst, err = cache.get_or_set(\"timezone_offset\", nil, get_timezone_offset_with_utc, nil)","tags":[{"name":"Lua","slug":"Lua","permalink":"http://chenyukang.github.io/tags/Lua/"}]},{"title":"使用 exercism 来练手学语言","date":"2017-08-22T12:12:02.000Z","path":"2017/08/22/pl-practice-with-exercism.html","text":"有时候我们想学一门编程语言，但是光看看书和代码用例总是找不到感觉，这时候我们应该尝试写点不短不长的程序片段，可能是一个函数，或者是实现一个简单的算法。最近我发现这个叫做exercism.io的网站不错，自己也在闲余时间在上面看看。 这里支持30多种编程语言，每种语言大概有80个左右的小问题，每个题目已经写好了对应的测试用例。这些题目不是专门的算法题目，但会涉及到编程语言相关的基本方面，单元测试、字符串，数字处理，代码风格等。我们可以随机的找一些来练练手，提交自己的代码后也可以看看别人的代码。然后再对自己的代码进行一些改进。其他人也可能会对我提交的代码 review 并提交改进评论。多写和多看确实就是学习编程的最好途径。 http://exercism.io/当然是开源的，大家都可以提供题目和测试。具体使用起来可以参考文档，其中有已经实现好的 cli 工具，每做一个 fetch 一下即可看到下一题。如果你对数学或者算法方面的问题更感兴趣，也可以试试https://projecteuler.net/，这个则不限语言，只需要最终结果即可。","tags":[{"name":"PL","slug":"PL","permalink":"http://chenyukang.github.io/tags/PL/"}]},{"title":"从 Jekyll换成Hexo","date":"2017-08-12T08:38:00.000Z","path":"2017/08/12/migrate-to-hexo.html","text":"昨天看到自己的 Blog 在移动端显示丑死了，所以想着优化一下，找一个 mobile first 的风格试试。顺便把 blog 从 jekyll 换成了 Hexo。最后找到这个 hexo 的主题非常顺眼，便拿来用了，感谢yanm1ng为大家提供如此优秀的主题。回想起自己之前用过搜狐博客，然后是 yo2，然后是 wordpress 自己搭，后来又出现了 jekyll，最终才找到最适合的写日志的方式。这次我把之前残留的 html 完全转换为了 markdown，并保留了创建日期，没想到这么多年来断断续续已经写了100来篇文章了。 hexohexo 其实和 jekyll 非常类似，只是迁徙过程中还是需要做一些处理。hexo 的文章排序选择了 date 倒序排，但是依赖于_post 里的文件创建时间，为了解决这个问题，然而 git 是不管理文件的时间戳的。结果会出现一些诡异的问题，文章的顺序会变乱。后来才发现 hexo 为了解决这个问题引入了一个叫做 db.json 的文件，存的内容大概是文件的时间戳之类的。为了保持之前的文章链接有效，写了一些小脚本处理文章。 gitment关于评论还发现一个很好的解决方案，那就是使用gitment，这个方案是专门针对 github 上 host 的博客系统的，唯一不爽的地方在于需要自己为新增文章初始化创建一个 issue，每一条评论会增加对应文章 issue 的comments。当然结果也导致了只有 github 帐号才能评论。不过我觉得这还是挺不错，毕竟 github 作为程序员的社交系统已经如此流行。 typora另外经大家推荐尝试使用 markdown 编辑软件Typora。之前因为自己使用的 markdown 格式稍微有点差别， 而且也习惯了用 Emacs，所以并没用深度使用 Typora。这次好好尝试了一下，发现其可见即可得还是非常方便的。另外就是插入图片的时候可以直接拖入，并且配置一下图片的根目录，自动拷贝到图片目录(或者上传到图床)。这个功能真的很暖心，typora 的作者肯定也是用 git来管理自己的日志。","tags":[{"name":"Blog","slug":"Blog","permalink":"http://chenyukang.github.io/tags/Blog/"}]},{"title":"Kong源码分析: 事件","date":"2017-07-23T08:38:00.000Z","path":"2017/07/23/kong-intro-5.html","text":"Kong的缓存更新很多依赖于事件，而事件看起来是相对来说比较复杂、也是最有趣的一部分。 worker模型假设我们对Kong做了一个更改的请求，这个请求通常是通过admin_api这个路由处理的。也就是说最终执行数据库操作的动作是在一个Nginx worker进程里。因为操作了数据库所以我们需要刷新这个Kong节点的所有worker的缓存，而且要把事件分发给其他Kong节点，让其他Kong节点刷新所有worker的缓存。 这就涉及到两部分: Kong节点之间的消息通信, 这是使用serf来实现的 Kong每个节点内部，也就是Nginx worker之间的通信，这是使用lua-resty-worker-events来进行。 发布订阅模式发布订阅是实现事件的一种经典设计模式，主要需要有两类操作： 发布消息 订阅消息，收到消息后触发指定的函数。 Kong使用的是一个叫作mediator_lua，mediator中文意思为”中间人”，很符合项目的意思。可以看到kong/core/events.lua里面实现如下： function Events:subscribe(event_name, fn) if fn then self._mediator:subscribe(&#123;event_name&#125;, function(message_t) fn(message_t) return nil, true -- Required to tell mediator to continue processing other events end) endendfunction Events:publish(event_name, message_t) if event_name then self._mediator:publish(&#123;string.upper(event_name)&#125;, message_t) endend Kong.init初始化的时候会调用一个叫做attach_hooks的函数:attach_hooks(events, require \"kong.core.hooks\") 在load插件的时候也会把插件对应hooks绑定上： -- Attaching hookslocal ok, hooks = utils.load_module_if_exists(\"kong.plugins.\" .. plugin .. \".hooks\")if ok then attach_hooks(events, hooks)end 事件的来源上面说过，Kong节点之间通信是通过serf发送的。我们来看看事件是如何触发发出通知的。事件来于源数据库的修改，那就应该在数据库代码部分有触发事件的代码，查看dao/dao.lua这个文件里的代码，我们可以看到在insert、update、insert执行的时候都调用了一行代码 event(self, event_types.ENTITY_DELETED, k, v.schema, entity) 这个函数的实现如下，这里做了数据的序列化，然后发布了一种叫做CLUSTER_PROGATE类型的消息： local function event(self, type, table, schema, data_t) if self.events_handler then ..... 执行数据序列化 self.events_handler:publish(self.events_handler.TYPES.CLUSTER_PROPAGATE, payload) endend 在core/hooks.lua接受消息部分，events.TYPES.CLUSTER_PROPAGATE对应的处理部分是singletons.serf:event(message_t)，所以我们看serf.lua这个源文件，最终event调用了invoke_signal，这个函数会运行一个serf命令，类似于这样： serf event -coalesce=false -rpc-addr=127.0.0.1:7373 kong '&#123;\"type\":\"ENTITY_UPDATED\",\"primary_key\":[\"id\"],\"collection\":\"apis\",\"entity\":&#123;\"id\":\"94acca76-d61a-429e-86a9-5abf2c61ee31\"&#125;&#125;' 这就出发了一个serf event，其他Kong节点会收到此消息。 serf: Kong节点之间通信那么Kong节点收到消息之后是如何处理的呢？Kong在启动的时候会在后台执行一个serf进程，类似这样： serf agent -profile wan -bind 0.0.0.0:7946 -log-level err -rpc-addr 127.0.0.1:7373 -event-handler member-join,member-leave,member-failed,member-update,member-reap,user:kong=/usr/local/kong/serf/serf_event.sh -node Kang.local_0.0.0.0:7946_be3b9352808e4839a272f30ca6025650 可以看看serf_event.sh这个脚本，内容如下： PAYLOAD=`cat` # Read from stdinif [ \"$SERF_EVENT\" != \"user\" ]; then PAYLOAD=\"&#123;\\\"type\\\":\\\"$&#123;SERF_EVENT&#125;\\\",\\\"entity\\\": \\\"$&#123;PAYLOAD&#125;\\\"&#125;\"fiCMD=\"\\local http = require 'resty.http' \\local client = http.new() \\client:set_timeout(5000) \\client:connect('127.0.0.1', 8001) \\client:request &#123; \\ method = 'POST', \\ path = '/cluster/events/', \\ body = [=[$&#123;PAYLOAD&#125;]=], \\ headers = &#123; \\ ['content-type'] = 'application/json' \\ &#125; \\&#125;\"/usr/local/openresty/bin/resty -e \"$CMD\" 可以看到serf收到消息后会触发这个脚本，然后把消息发送到本节点的/cluster/events这个路由。api/routes/cluster.lua这个文件里有收到消息后的处理代码，其中最关键的是： -- Trigger event in the nodeev.post(constants.CACHE.CLUSTER, message_t.type, message_t) 就是通过resty.worker.events publish出收到的消息，本节点的worker会处理这些消息。 worker刷新缓存假设当前Kong节点收到一个消息，这个消息是如何分发给各个worker的？从代码看出，在Kong初始化的时候有调用一个叫做kong.lua里面的Kong.init_worker()函数，其中有一段代码注册了event handler:local worker_events = require \"resty.worker.events\"local handler = function(data, event, source, pid) if data and data.collection == \"apis\" then assert(core.build_router()) elseif source and source == constants.CACHE.CLUSTER then singletons.events:publish(event, data) endendworker_events.register(handler) 可以从上面的handler代码看到，一个worker接收到消息之后执行的是： singletons.events:publish(event, data) 也就是通过mediator_lua再把消息publish。之前初始化的时候已经attach_hooks了各种handler，这时候那些注册的函数才会被最终执行，比如核心的刷新缓存部分代码在core/hooks.lua的invalidate函数里面。 回顾总的来说Kong事件部分的代码相当精妙，也很统一。比如当前worker做了修改，这个事件会发送给各个节点，包括当前自己所在的节点。通过发布订阅模式，写代码的时候只需关心消息发送、接受消息索要处理的逻辑。","tags":[{"name":"Lua","slug":"Lua","permalink":"http://chenyukang.github.io/tags/Lua/"}]},{"title":"Kong源码分析: 缓存","date":"2017-07-22T08:38:00.000Z","path":"2017/07/22/kong-intro-4.html","text":"Nginx里的缓存使用在Kong里面我们缓存的内容大部分是配置，不管是API本身的配置还是插件相关的配置，缓存之后就存储在内存中。 Kong里的缓存基础代码在tools/database_cache.lua文件里面。这里又分两种类型的缓存，一种是shared dict, 一种是使用lua-resty-lrucache。这两者之间是有区别的: shared dict如同其名字一样是Nginx worker之间共享的，而lrucache是worker级别的，内存空间在Lua VM里由GC管理，不能在进程之间共享，自然也不会在Nginx worker之间共享。 具体我们开发中使用哪一种由具体场景分析，比如在Kong的插件rate-limiting里就使用了共享缓存，因为我们需要针对一个Nginx所有的worker做请求数统计。 share dict最常规的使用方法是: http &#123; lua_shared_dict dogs 10m; server &#123; location /set &#123; content_by_lua_block &#123; local dogs = ngx.shared.dogs dogs:set(\"Jim\", 8) ngx.say(\"STORED\") &#125; &#125; location /get &#123; content_by_lua_block &#123; local dogs = ngx.shared.dogs ngx.say(dogs:get(\"Jim\")) &#125; &#125; &#125;&#125; lrucache的使用方法如文档所示。 Kong里的多级缓存实现有了上面的了解，看database_cache.lua这个文件就比较直观了，这里Kong会分多类缓存: apis, consumers, plugins等。具体这样分是因为如果我们对配置做了修改，需要发出serf消息来指名这次改动涉及到哪些，其他Kong节点收到消息后自然只更新对应的缓存部分。所以Kong里申明了一个列表CACHE_KEYS来存要缓存的数据类别，同时写了不少生成缓存key的方法，比如: api_key，plugin_key等。 仔细查看database_cache.lua，我们发现其实这里是做了两级缓存。Kong要从缓存里取出一个key/value，首先从lrucache里取，如果有则返回。如果没有则从share dict里去取，如果取到则deserialize然后存储在lrucache里，然后返回。如果shared dict里也没有，则返回nil。标准的两级缓存流程，这样做的好处在于减少deserialize的次数，而且shared dict可能被多个worker同时修改，要修改的时候需要加互斥锁。 这里最常用的方法是get_or_set，尝试获取一个key的值，如果没有就执行对应的callback，返回结果当做value设置到缓存里，并把value作为最后的返回结果。这里的callback函数通常做的当然是从数据库里读取内容。 如何避免缓存失效风暴我们在实现缓存的时候缓存失效风暴问题需要谨慎考虑。agentzh在这里详细描述了加锁解决的策略，ngx.shcache这里也使用了相同的方法，具体可以好好研究一下那个图。 主要注意的是在加锁后，再尝试去读取一次key，因为可能在加锁之前其他worker刚好把数据更新到了缓存里。","tags":[{"name":"Lua","slug":"Lua","permalink":"http://chenyukang.github.io/tags/Lua/"}]},{"title":"Kong源码分析: 插件","date":"2017-07-16T11:43:00.000Z","path":"2017/07/16/kong-intro-3.html","text":"插件的强大之处在我自己使用 Kong 的过程中，最方便的还是在于 Kong 的强大的插件机制。 Nginx 本身提供了提供模块开发机制，但是相对来说更底层一些，并且需要使用 C/C++ 来开发，对于很多开发人员来说 Nginx 仍为一个黑盒。OpenResty 集成了很多好用插件，并提供了通过 Lua 扩展 Nginx 的机制，所以 OpenResty 相对来说更灵活。而 Kong 在 OpenResty 基础上提供的插件机制更灵活，在于： ​ 复用：OpenResty 的复用在于函数级别，我们可以把一些通用的 Lua 函数引入各个项目。而 Kong 的插件复用可以通过 API 修改一下配置即可。是否启用某个插件，这只是数据配置问题，启用与否不会涉及到代码的改动。 抽象、统一: Kong 实现了基础的插件配置的存储和更新机制，所以我们只需按照要求定义插件配置的数据类型，插件实现的时候不用再去关心这些细节。 灵活、组合: OpenResty 的一些处理部分有限制，比如 access_by_lua 在同一个 location 能调用一次， 当然我们可以把多个处理逻辑都放在这里，这又涉及到代码改动。 而 Kong 可以依次调用各个插件对应的 phase，并且通过引入优先级来解决前后顺序问题。 插件开发的原则是提供机制，而非实现，在做插件开发的时候一定需要考虑这个插件能否满足一类相似的需求，这样我们只需要做一下参数的配置就能把插件启动在另外一个站点上。 对于插件这块我的疑问在于这套机制如何运行的？如何找到站点对应的插件？如此多的插件是否会有性能问题？​ Kong插件的运行机制在上一文 Kong 初始化分析中，我们看到 nginx_kong.lua 模板文件里面有这么一段代码： location / &#123; rewrite_by_lua_block &#123; kong.rewrite() &#125; access_by_lua_block &#123; kong.access() &#125; header_filter_by_lua_block &#123; kong.header_filter() &#125; body_filter_by_lua_block &#123; kong.body_filter() &#125; log_by_lua_block &#123; kong.log() &#125;&#125; 在 kong.lua 文件里面， kong.access 的实现是这样的: function Kong.access() core.access.before() for plugin, plugin_conf in plugins_iterator(singletons.loaded_plugins, true) do plugin.handler:access(plugin_conf) end core.access.after()end 从这里可以看出 Kong 的插件运行机制就是从 loaded_plugins 里面依次执行。 学习 Kong 插件开发的方法是参考现有的一些插件实现，学着写几个就会了。用户自己定义的插件是在 base_plugin 基类上继承而来。Kong 里面使用的了 这套 class 机制，可以看到使用 Lua 实现面向对象还是很简单的。 singletons.loaded_pluginssingletons.loaded_plugins在这里初始化的，在具体实现过程中就是从数据库里面把插件配置读出， local ok, handler = utils.load_module_if_exists(\"kong.plugins.\" .. plugin .. \".handler\") 在每一个插件在 handler.lua 的最后都是 return XXXXHandler，所以在调用 handler()后我们在内存中导入了插件的对象。另外在初始化后需要按照优先级来排序，以此来保证各个插件之间的执行顺序。 从上面的分析上看出，插件导入后都会在内存中的全局对象中存储，后面的开销在于依次迭代插件。 plugins_iterator我们再来看看某个站点是否启用某个插件是如何处理的，最主要的实现在于 plugins_iterator 这个函数。首先我们得理解如何确定当前 request 对应的唯一标识符， 在core.handler.access的过程中保存了经过路由后的 api在ngx.ctx 里，这个 ngx.ctx 会在整个request 处理过程中反复被使用。再回到 plugins_interator 函数，这个函数的参数有两个，后一个叫access_or_cert_ctx， 因为对于一个 request处理中 plugins_iterator 会调用多次，这个参数的作用在于判断是否是第一个调用这个函数。第一次调用可能发生在ssl_certificate或者access 阶段， 因为在 ctx 里面 Kong 还是初始化了一个叫做ctx.plugins_for_request的变量来存储当前 request 启用的插件，这样后续 iterator 阶段就完全不会去重复 load 插件配置，这样做当然是为了性能上的考虑。 读取插件配置的函数调用是： if api then plugin_configuration = load_plugin_configuration(api.id, consumer_id, plugin.name)end load_plugin_configuration也会首先尝试从内存缓存中取，如果取不到再从数据库中取出，然后存储在缓存中。 从上面的分析看出，插件相关的读取和执行在大部分时间里是完全不会去读数据库的，所以性能损失并不会大。 错误处理Kong的插件部分并没有错误处理部分，从现有代码上看错误处理分两个部分: 一种方式是responses.lua， 如果是在 Kong 的 Lua 代码部分检查出来的错误一般使用类似responses.send(500)这样的方式来向客户端返回错误码。 第二种是通过 kong_error_handler。 这种错误可能是执行了 ngx.exit(500) 之类的代码或者是 Nginx 内部触发的。 这在某些情况下对用户不友好，我们不能只简单地返回一个错误信息，有的时候我们需要展示一个漂亮些的错误页面或者是把请求转到别的降级站点，对于这个需求我做了一个分支来扩展错误处理。 目前实现还未完整，不过已经可以定制化错误页面了。 这里增加了一个 ngx.var.api_id，这个变量的初始化也在 core.access 阶段。因为存储在 ngx.ctx 里的这些信息在执行了 ngx.exit 之后已经释放了，所以我需要一个 ngx.var 级别的变量存储 api_id，然后使用这个变量来判断 error-handler 插件是否启用。","tags":[{"name":"Lua","slug":"Lua","permalink":"http://chenyukang.github.io/tags/Lua/"}]},{"title":"Kong源码分析: 启动","date":"2017-07-07T11:43:00.000Z","path":"2017/07/07/kong-intro-2.html","text":"Kong的初始化过程安装好Kong之后我们是用命令sudo ./bin/kong start -c kong.conf -vv来启动。其中kong.conf为配置文件，-vv选项打印出一些重要信息展示出来，方便发现问题。 可以看到./bin/kong是一个脚本，是用的#!/usr/local/openresty/bin/resty程序来执行，而resty是OpenResty的一个Perl可执行脚本。kong的内容很简单，就是一个入口函数调用：require(&quot;kong.cmd.init&quot;)(arg) 所以我们可以从cmd/init.lua这个文件开始入手看启动过程。一翻开init.lua这个文件，发现其实不过是个wrapper，解析了args之后就是调用start，stop，quit等命令。然后我们顺藤摸瓜找cmd/start.lua文件，整个启动过程就在这里了： local conf = assert(conf_loader(args.conf, &#123; prefix = args.prefix&#125;))local errlocal dao = assert(DAOFactory.new(conf))xpcall(function() assert(prefix_handler.prepare_prefix(conf, args.nginx_conf)) assert(dao:run_migrations()) assert(serf_signals.start(conf, dao)) assert(nginx_signals.start(conf)) log(\"Kong started\")end, function(e) err = e -- cannot throw from this functionend) 从代码上来看很直观，首先conf_loader载入配置文件，DAOFactory构建数据库连接层，prefix_handler.prepare_prefix是准备一些由程序生成的配置文件。dao:run_migrations是迁移表结构到数据库，类似其他 Web 框架。serf_signals是启动serf程序，nginx_signals是启动nginx进程。 读取配置文件conf_loaderconf_loader读取的当然是命令行里面传入的kong.conf文件，打开conf_loader.lua看了看，是是用一个lua第三方库来做文件解析的。local pl_config = require &quot;pl.config&quot;，最开始不太知道这个pl是什么，经过搜索后才知道是这里定义的，在kong.rockspec里面有定义了该库的依赖&quot;penlight == 1.4.1&quot;。读取配置的整个过程比较琐碎，最后回构建一个解析好的conf表。这里学到了Lua里面的setmetatable设置元表的方法，table作为Lua里面的最基本数据结构，setmetatable可以方便的绑定一个key和其对应的方法。看起来也像是面向对象的风格，在conf_loader的最后部分是: return setmetatable(&#123; load = load, add_default_path = function(path) DEFAULT_PATHS[#DEFAULT_PATHS+1] = path end, ......&#125;, &#123; __call = function(_, ...) return load(...) end&#125;) 这样其他地方调用的时候local conf, err, errors = conf_loader(args.conf)自然就把args.conf传入load，返回解析后的结果。 prepare_prefix动态生成Nginx和serf的配置prefix_handler.lua这个文件主要在准备一些Nginx的配置文件和serf的配置文件。prepare_prefix函数前半部分在创建各个子目录，logs、serf、pids、以及各个日志文件。关于Kong的config部分需要参考一下这里。这个函数比较长，重要的部分是生成Nginx的配置文件。可以看到compile_kong_conf函数其实是是用kong/templates目录下的nginx_kong.lua和nginx.lua分别生成两个文件，其中nginx_kong.lua里面包含了嵌入Kong的Lua代码的逻辑。 init_by_lua_block &#123; require 'luarocks.loader' require 'resty.core' kong = require 'kong' kong.init()&#125;location / &#123; rewrite_by_lua_block &#123; kong.rewrite() &#125; access_by_lua_block &#123; kong.access() &#125; header_filter_by_lua_block &#123; kong.header_filter() &#125; body_filter_by_lua_block &#123; kong.body_filter() &#125; log_by_lua_block &#123; kong.log() &#125;&#125; 因此我们可以知道Kong每次reload或者启动的时候会生成新的Nginx配置文件，所以我们如果要加入自己的配置可以直接修改nginx_kong.lua文件。另外我在使用的时候发现一个小问题，Kong把serf的node_id存在一个文件里，如果我们把之前跑过Kong的机器做了镜像，然后再启动一个新的实例时，这个node_id文件既然存在则没有重新生成，最终导致两台kong实例并没有相互通信形成一个集群。我认为这里其实可以再检查一下node_id的文件和本机的ip是否一致，如果不一致则重新生成。 dao:run_migrations()初始化过程的下一步则是执行数据库操作，Kong目前只支持cassandra和Postgres，个人认为应该增加Redis的支持。 serf_signals.start之前提到过serf是用来保证kong instance之间的通信的，启动的时候的一个很重要参数是--event-handler，参数的内容是一个可执行脚本(通常叫做serf_event.sh)，文件的内容是前面生成配置文件的时候写入的。默认情况下serf会监听在7946端口，如果多台server需要形成一个集群，这个端口之间需要能相互通信。这里就有一个问题，在一个新的server刚启动的时候，该server是如何发现其他节点的呢？我们可以看到serf_signals.lua里的start函数调用了serf:autojoin()函数，跟踪到autojoin里面看代码，其实是从数据库里读取出其他nodes的信息，然后依次告诉对方新同志加入了，然后把自己的节点信息写入到数据库里。自然如果要退出也需要把自己的信息从数据库里删掉。 nginx_signals.start启动的最后一步即是Nginx的启动，其实最终执行的命令就是: /usr/local/openresty/nginx/sbin/nginx -p /usr/local/kong -c nginx.conf 总结通过上面的分析，可以总结Kong的启动过程即是：解析输入参数，验证参数合法性并生成必要的目录和配置文件，执行数据库操作，启动serf，启动Nginx。最终其实就是一个OpenResty启动过程，嵌入Kong里面的core部分的Lua代码。后面继续分析其可扩展的插件机制。","tags":[{"name":"Lua","slug":"Lua","permalink":"http://chenyukang.github.io/tags/Lua/"}]},{"title":"Kong源码分析","date":"2017-07-02T11:43:00.000Z","path":"2017/07/02/kong-intro.html","text":"缘由最近在工作上接触了Kong这个开源项目，因为我们内部做微服务化重构，所以导致系统相互间通信比较复杂，如果想做一些涉及各个系统的功能就很困难。比如我们前段时间实现的灰度系统就把人折腾得很惨。因为我们的设计中有一些http header 需要在各个系统之间传递。每个项目的 Nginx 里面都用了 Lua 写一些授权逻辑，最终这些逻辑分散在各个项目的 Nginx 层，维护困难。除了灰度，其他的一些比较基础的Nginx层功能也是各自为政。所以我们的教训是: 在做微服务化之前，需要统一的、可扩张的API网关。我们希望网关性能好，并且扩张性足够好。使用OpenResty是很自然的选择，我们希望有一层 Nginx 是所有请求都会经过的，这层 Nginx 会负责做一些基础操作，当然最重要的是做流量转发。 调研了一阵子之后，我们所面临的是两条路，一是自己写一个类似于京东JEN的系统，在调研一圈之后我们发现 Kong 是比较适合自身业务需求的。二是在 Kong 的基础上做一些插件开发，然后集群部署Kong即可。 我之前稍微看了一下介绍，认为 Kong 可能对我们来说太重了些。后来又仔细看了一阵源码，自己认为代码质量挺好，而且模块化和可扩张性做得很好，因此决定采用。 Kong简介Kong 项目的目的是这样一幅图kong-intro： 可以看到这正是我们要做的事情。使用Kong的优势在于： 可扩展性，Kong依赖一个数据库来实现配置存储，依赖 serf 来实现 instance 之间的通信。任何一个节点修改了其他节点会收到通知并重新reload配置。 模块化，Kong 可以方便地增加新的插件，并且插件可以通过 Restful API 进行管理 主要代码模块Kong的使用方法这里不做介绍，这里有非常详细的文档和示例。我主要分析一下其源码和原理。 core目录里面是一些基础框架代码，包括hooks，事件，插件基础 plugins目录包括所有kong自带的插件，kong的插件扩展有一套自己的规范，按照规范来非常容易地就能扩展kong dao是数据库抽象层，目前kong自带支持数据库postgresql和cassandra。 tools为一些工具函数，需要注意的是cache。因为所有配置（包括插件的配置）都会是用cache来缓存，为了减少读取数据库次数。 api Kong会提供一个系列接口来更新配置 我觉得Kong的代码质量很好，另外依照带着问题来学习新东西感觉非常有收获，这几个部分我都是从一个主题问题逐个分析，这几个问题解决了之后自然对代码就熟悉了很多，并且有信心在生产环境使用。后续我会陆续继续写一些Kong相关原理分析，顺便更深入熟悉一下Lua。主要涉及到Kong的初始化部分、缓存如何更新、插件机制如何实现等。","tags":[{"name":"Lua","slug":"Lua","permalink":"http://chenyukang.github.io/tags/Lua/"}]},{"title":"小说推荐","date":"2017-06-27T11:43:00.000Z","path":"2017/06/27/recent-reading-list.html","text":"之前我用过一段时间 Kindle，因为没有使用保护套导致在书包里面被压坏。而后一两年用 IPad 看了一些电子书，始终觉得稍微有些笨重，而且看久了眼睛不舒服。前段时间在 z.cn 上瞎逛又有了买个 Kindle 的欲望，拿到手后又好好找了一些电子书比较多的网站。目前使用最舒服的还是 http://readfree.me。 我已经在上面免费同步了好多本书。 最近用 Kindle 看了不少书，重新燃起了自己看小说的兴趣，当然也不全是小说。印象比较深书的有下面这些： 《历史转折中的邓小平》 小说口吻讲述近代历史人物略显奇怪，不过还是可以看看。其中恢复高考那段印象深刻。值此香港回归20周年时，感谢邓小平的远见和智慧。 《褚时健传》强烈推荐的一部传记。特别敬佩褚时健解决问题的精神和执行力。褚时健一生的坎坷经历令人感叹。没几个人能做到，不管在哪个年龄段，都全心全意的做事解决问题，80多岁的年龄还能种出一大片果林。人生经历当得上『传奇』二字。 《牛鬼蛇神录》 王小凯在牢房里的各种见闻，以前还是禁书来着？看看还是有所收获。 《围城》 之前看过一次，而这次再重新读的时候才有所感触。有时候既然能在方鸿渐身上看到自己的影子，哈哈。总得来说挺幽默，女人吵架套路很固定。婚姻的不幸很多是来自两个家庭的矛盾，大多如此。 《檀香刑》 莫言的小说，最初是在知乎的一个回答上看到的行刑的那段描写，让人窒息，所以一定要找来看完这本。值得一看，看来莫言的其他基本小说也不能放过了。 《白鹿原》 这本书只看了一半，个人觉得一般。可能是因为我之前看了电影，大致的情节都知道了，所以觉得书稍显太慢，好长篇幅。 《约翰·克利斯朵夫》一个大部头小说，我应该是花了好两周的业余时间看完。最初想看这本书据说傅雷翻译得特别好，然而我下单的时候却买的是韩沪麟版本，在我看来也翻译得挺好。这本大部头叙述了一个音乐家一生的故事，前半部分情节更好。特别是描述小孩的友谊和爱情部分很吸引人。不少部分写的是对音乐的理解，只能怪自己音乐素养不够，浅尝辄止罢了。 大部分人在二三十岁上就死去了，因为过了这个年龄，他们只是自己的影子，此后的余生则是在模仿自己中度过，日复一日，更机械，更装腔作势地重复他们在有生之年的所作所为，所思所想，所爱所恨。 所谓英雄，就是干了自己力所能及的事情的人，而常人还做不到这一点。 毛姆系列 据说毛姆文笔优美，我便开始找他的小说看。最开始是看了比较流行的《月亮和六便士》，看完后真是大呼过瘾，震撼。据说月亮是头顶上的理想，六便士是脚下的现实。小说里主人公斯特里克兰德为什么突然放下家庭，完全投入到画画中文中并没有交代清楚，像是命中注定了的，他必须画画，冷酷地完全舍弃其他。一个人完全沉浸在自己的追求中，现实看起来就微不足道了，道德也不会是约束。天才有时候是一种伟大的不幸，比如主人公，而绝大部分人过的是平庸的幸福，比如施特略夫。施特略夫这个觉得有些可爱，而遭遇有些悲惨。 然后看了《在中国的屏风上》，是毛姆游历中国的随笔，记录的比较杂。这本粗略看了看。 而后继续看《刀锋》，感觉和六便士有点点类似，都是讲一个完全追求精神生活的『圣人』，最后在印度看似有所悟。比较喜欢这女主个角色，诚实地知道自己所要并决心取舍，虽然她的小心机使得儿时的女伴完全堕落。 最后粗略看了《毛姆读书心得》，讲了一些读小说的事情，推荐品论了不少小说。 《霍乱时期的爱情》 这部小说被拍成了电影(我还没看)，大家都说写尽了人间的爱情。这本书我非常喜欢，从拿起就不能停了。故事吸引人，并且文笔有些幽默。比如抓鹦鹉的那段，前面花了大篇幅来描述鹦鹉的来历，而后突然鹦鹉就把医生给弄死。还有男主和女主的各种书信，在那样嘈杂热闹的环境下女主一回头突然崩溃。男主作为纯情男孩，突然被夺了童贞，后面又心安理得地穿梭于各个寡妇之间，并倔强、默默地继续爱女主五十年。妙的是，小说里详细的叙述，让我觉得这也并不矛盾，人性以及爱情就是这么复杂，不乏欺骗和隐瞒。婚姻里到处是妥协和不满。 结尾也非常好，让他们在『霍乱的船』上一直飘荡下去。 《树上的男爵》 经同事推荐看的。故事和海上钢琴师类似，讲一个公爵小男孩因为一次偶然的被罚，爬上了树！又因为对一个女孩的承诺，他打算一辈子不下树了。一个很好的故事，结尾也来得有想象力。","tags":[]},{"title":"OpenResty使用总结","date":"2017-05-22T11:43:00.000Z","path":"2017/05/22/try-on-openresty.html","text":"OpenResty最近用OpenResty比较多，除了一些业务逻辑的实现也做了AB组灰度相关的实现。OpenResty是在Nginx基础上做的扩展，应该算是国人开源项目中很成功的一个。在做的过程中写了不少Lua代码，写Lua代码的体验就是库好少，语言好简单。 OpenResty lua编程相关参考 OpenResty最佳实践 OpenResty Readme 其中Readme要看完，大概会有一个全局的了解。最佳实践辅助看看。理解Nginx处理的几个阶段： http://www.nginxguts.com/2011/01/phases/ 处理Response Body在我们的实现中有一步需要给后端返回的结果里面加一段水印(也就是一段JS代码)，这步可以在body_filter这个里面做。不过需要注意body_filter是按流式方式处理的，需要把各个buffer存下来然后拼接起来。而且后端返回的结果可能是zip压缩过的，所以需要解压，然后才能做替换或者拼接的操作。 local chunk, eof = ngx.arg[1], ngx.arg[2] local buffered = ngx.ctx.buffered if not buffered then buffered = &#123;&#125; -- XXX we can use table.new here ngx.ctx.buffered = buffered endif chunk ~= \"\" then buffered[#buffered + 1] = chunk ngx.arg[1] = nil endif eof then local whole = table.concat(buffered) ngx.ctx.buffered = nil -- try to unzip local status, debody = pcall(com.decode, whole) if status then whole = debody end -- try to add or replace response body local js_code = .... whole = whole .. js_code ngx.arg[1] = whole end 最后因为修改了response body，所以需要修改header filter里面的部分:ngx.header.content_length = nilngx.header.content_encoding = nil 容易出现的bug 尽量使用local变量： 具体的解释，我在实践的过程中出现过变量乱窜的情况，结果发现是没有是用local。 ngx.ctx 比 ngx.var 性能要好很多，但是在执行了ngx.exec后在子请求里ctx不一样，在我们的项目里大部分是用的是ngx.var。使用ngx.var需要注意的是需要在Nginx配置文件里面提前声明。另外ngx.ctx在使用的时候也有需要注意的地方 不同阶段共享变量 不要使用错误码来做内部跳转，使用ngx.exec很方便。 是用推荐的方法来实现module","tags":[]},{"title":"rubytt 续","date":"2017-04-09T11:43:00.000Z","path":"2017/04/09/rubytt-cont.html","text":"前段时间继续做了 rubytt 这个小项目，遇到一些问题。 我想做一个自动检测未定义变量的功能，发现如果只是做静态分析，是很难做出来的。还有涉及到各种 gem 包的分析，这些工作量较大。可以看出在这个PR里我甚至用上了一些硬编码。 然后我想做一个自动分析代码复杂度的功能，比如某些函数太长，或者逻辑太多之类的。这个我实现起来很快，也是比较简单的遍历语法树，递归统计逻辑操作和幅值操作的总数之类的。不过这些在 rubocop 里面都实现了，其中Cyclomatic complexity可用来衡量代码的复杂度。我仔细看了看 rubocop 的内容，这个项目里面做的检查还挺全的，不过很多都是风格类的检查。在我下一个项目一开始我就引入了 rubocop ，对于保证代码质量还是挺有帮助的。对于之前老的项目，如果不是一开始就保持代码风格和静态分析的检查，后面要追加就非常耗时了，往往大家也没有时间来做各种重构。 rubytt 暂时告一段落，作为一个业余项目还是花费了些时间，造轮子的过程中收获不少。","tags":[]},{"title":"程序员病","date":"2017-01-24T11:43:00.000Z","path":"2017/01/24/disease-of-programmer.html","text":"最近看费曼的书《发现的乐趣》，里面有一段描述非常好玩: 好，弗兰克先生开始实施他的计划了，与此同时，他也得了一种病——『计算机病』。现在每个使用计算机的人都知道这个毛病，那种病非常厉害，会干扰整个工作。这是我们面临的一个严重问题。所谓『计算机病』就是你一『玩』上计算机，就会上瘾。计算机真的非常奇妙，你手上操作着那些 x 转换开关，这样弄得到某个偶数，那样弄得到某个奇数。如果你够聪明，很快你就能在一台机器上做越来越复杂的计算。只不过，没多久，整个系统就瘫痪了。 他对工作不再上心了，也不再管理手下，整个系统运转得很慢很慢。但是，真正麻烦的是，他一直坐在一间办公室里，琢磨怎么让制表机自动打印出反正切值，然后机器就开始打印，成排成排地打印，扑哧，扑哧，扑哧，一边打印一边还自动用积分计算反正切值，整张表都是方正切值计算结果。 其实，这毫无意义，因为我们人手一份反正切表。不过，如果你用过计算机，你就会理解他为什么得这种病。计算机能让你知道自己究竟能做多少事情，这也是一种乐趣。他第一次接触这机器，就染上了这种病，这个可怜的家伙——整个项目都是他发起的，可他却得了这种病。 其实很多程序员都有这种病，可以概括为一句话『沉迷于工具』，计算机也是工具，这位弗兰克先生还未解决眼前的问题时就丢掉了方向。好奇心是程序员必不可少的东西，而如果管不住自己的好奇心就会耽误事。对于非程序员来说，这件事情看起来就是『某个杀猪佬，拿到了一把新刀，他觉得这么刀真他妈锋利，然后磨磨刀，再磨磨刀，反正猪是不会杀的』。 程序员经常会『磨刀』，学习算法，是磨练自己的头脑和思维。学习语言，是为了多拥有一个工具或者也可说是锻炼自己的思维(不改变自己思维习惯的语言不足以学之?)。学习操作系统的原理和细节，也可以理解为加深对工具的认识和理解。在学校的学习方法大多数从基本原理和经典书籍学起，顺便找一些小项目练练手。在步职业阶段后，从实用的角度，我们是否应该直面问题，带着问题找工具，学用工具，理解工具，这个过程中更可以锻炼自己的能力。从个人体验来说，这种方式优于『先锻炼自己的能力，先学会某个工具，然后再找个问题来解决』。举例来说，其实做一些 ACM 之类的题也挺有乐趣的，但我理解为刷题也是在『磨刀』。更让自己有成就感的是，在工作中碰到一个解决不了的算法问题，通过学习和思考相关的东西解决了，这样的方式理解更深。其实如果是步入职场，很多程序员也没多少时间来广泛学习，带着问题来『磨刀』也是必然且更有效的选择。 再多扯一点，不少程序员有一些类似于强迫症的症状(在很多情况下这是一个好的特点)。而在计算机这个领域里有太多东西容易沉溺，比如编辑器，编程语言，操作系统，框架， 范式等。这类工具都有可能让程序员走向某个极端，形成『偏见』。我也有类似的体验，只是现在回想起来觉得挺傻缺、傻气的。大多数程序员都不够拥有开阔的心态来面对这些工具，我们会觉得自己的选择是更好的，能解决一切问题的银弹。这副图能说明这个道理。 我现在会注意避免自己陷入这些『疾病』中。比如一个工具，不管是框架也好，语言也好，不要在还没摸清楚门路的时候，花大片时间去学习。而是最好带着一个需要解决的问题，边做边摸索。 发现自己的傻缺，就是成长，对吧！","tags":[{"name":"Books","slug":"Books","permalink":"http://chenyukang.github.io/tags/Books/"}]},{"title":"Ruby 程序的静态分析: rubytt","date":"2016-12-27T11:43:00.000Z","path":"2016/12/27/rubytt.html","text":"rubytt是一个 Ruby 程序的静态分析器，这个项目从16年年初一直到年底，断断续续持续了近一年。这里稍微总结一下自己的开发过程。 0. 缘由14年开始，从我进入 DJI 之后开始接触 Rails 开发。Ruby 之前也接触过，不过都是写一些小脚本之类的东西。我们几乎用 Rails 写各种系统，开发的效率很快。对于经常变动的 Web 开发 rails 还是挺好的。在我经历过的一个对正确性要求很高的项目里，有一次系统出现一个致命的问题。我们6个开发人员在小黑屋里面足足找了一个下午。最后却发现不过是一个 type 错误引入的，导致后台任务一直执行错误。后来稍微多想了想，这样的类型错误应该是在开发阶段就及时发现的。 Rails 项目没有测试是不行的，所以我们后续补充了更多单元测试。另外我所使用过的静态语言几乎都能及早避免这样的错误，特别是在使用过 OCaml 这样的强类型语言后，我对类型有了更强的偏好。于是想我能不能做一个自动检测出类似 bug 的工具。据我所知王垠的rubysonar 可以做类型分析，于是我 checkout 出来看了看代码。Java代码不是特别复杂，也发现了两个问题并提交了 PR。然后觉得这个东西还是比较好玩，干脆就自己另起一个项目来玩玩。 1. rubytt 的开发首先得给这个坑起一个名字，想了想就 rubytt 吧，其实就是”ruby to type” 的意思吧。然后语言还是用了最近业余使用得比较多的 OCaml。这可能对后期其他开发参与进来不利，不过也无所谓了，业余的项目先依自己的偏好吧。 parser首先面临的问题是 parser。rubysonar 的parser 也是依靠 Ruby 自己的ripper。主要是 parser 太过繁琐，如果从头开始写整个坑估计是填不完了。所以我也就直接拿来了 rubysonar 的dump_ruby.rb。 dump_ruby 把 ruby 源文件作为输入，输出一个 json 文件作为后端分析器的输入。这里我做了一些改动，rubysonar 里面是起来一个进程，把 dump_ruby 启动起来，用管道的方式一个个 parse 源程序。这样做的目的是避免 ruby 解释器频繁启动，避免整个速度会被拖慢。 我觉得还不如让dump_ruby 一次接收多个源程序，甚至可以是用 parallel 这个库来做并行。这样的结果是 parsing 的速度确实快了很多，一般大点的项目在10s 以内可以完成。这样项目的大概流程如下: type annoation我想做自动的类型错误检查，所以需要类型分析。dump_ruby 出来的结果里面是带一些基本类型的，类型分析过程 rubysonar 里面有一个基本过程了。然后对于 Rails 项目来说，我们很多类型都可以在 db/schema.rb 里面可以分析出来，所以如果我把 schema.rb 文件也扫描分析一边，就可以为这些 model 加上不少类型。结果做出来还可以，至少目前可以分析出来很多 rubysonar 没有的类型。运行rubytt -s source_dir -t type -o res把结果输出到 res 目录。这里还有不少东西未做，比如函数的分析还是很复杂，目前做了一个初步。类型错误报出可以做一些了，但是还未来得及实现。因为我突然想到另外一个有趣的东西。 visualize rails project我既在 traverse 整个 AST，可以做很多好玩的事啊。比如把类之间的继承关系找出来，做一个类的继承关系图。于是就有了类似这样的结果(看大图)： 既然我能解析 schema.rb，也可以把数据模型给展示出来，然后再通过 model 文件里面分析模型之间的关系(has_one, has_many 等)， 于是就有了这样的结果： 不过做了一些之后我发现这两个 feature 有点鸡肋。特别是第一个，要找出 ruby 程序内部对象之间的继承关系其实很简单，比如我之前写过的一篇文章。第二个模型的关系图还好，不过项目稍微大一些的时候这些图看起来很复杂。 variable bug finder在做完上面两个蛋疼的 feature 之后，碰巧碰到了项目里面另外一个 bug。是因为重构的时候不小心引入了一个 copy &amp; paste bug。类似代码如下： event = (order.status == 'success') ? 'success' : 'fail'Job.send(['Worker'], &#123;'order_id' =&gt; order.id, 'event' =&gt; 'success'&#125;) 可以看到这个 event 本来应该使用的，结果却因为重构的时候 copy 了代码忘记把&#39;event&#39; =&gt; &#39;success&#39;改成&#39;event&#39; =&gt; event。event这个变量是未使用的变量，对于编译型语言来说这样的问题是可以在编译的时候发出报警的。因为一个变量未使用必然意味这要么是冗余代码，要么是 bug。那我可否通过 rubytt 给出类似报警？然后我就继续写了这么一个 checker，去检查ruby 程序中各种没使用的变量。最后还真能找出项目中一些其他的类似问题，比如： result = &#123;&#125;trans = self.transactions.where(..blah...)trans.each do |tran| result[:amount] = trans.amount_cent &lt;------- bug: `trans` is typo of 'tran' ...blah...end 当然还是能找到函数中未使用的参数等问题。修复的办法是如果确定这些变量是不被使用的，就在前面加_，这样rubytt 这样的 lint 类检查工具就跳过。后续我也正在做未定义变量的检查。 2. OCaml的程序发布在做完上面的几个 feature 之后，我觉得可以尝试着把这个项目推广一下给同事们玩玩。如果让从来没接触过 OCaml 的朋友从头开始编译安装会显得很麻烦。所以我就尝试着把 rubytt 合并到 OCaml 的包管理仓库。于是在经过几次和 travis CI 的斗争后，终于发布了rubytt.0.1 。 安装方法如下： gem install parallel ruby-progressbarsudo apt-get install --force-yes ocaml ocaml-native-compilers camlp4-extra opam// brew install opam (MacOS)eval `opam config env`opam install rubytt OCaml 的圈子比较小众，不过其实很多工具还是挺好用的，比如这个 OPAM 包管理器。 3. 其他心得做这个程序这么久，除了好玩还是收获不少。 OOP 和 FP 哪个好？通过这个项目的实践，我好好体会了一把 FP 写稍微大些的程序的感觉。说不上哪个好，我倒认为 type 确实很重要，rubytt 的过程中自动类型推导帮我发现了好多代码错误。编程语言应该让程序员能够精确无误地表达自己，尽量地避免人为引入的错误。 构建测试脚手架，这也是第一份工作带给我的习惯。把每一个 feature 或者 bug 都写测试来覆盖。每次提交的时候都 review 一下测试用例的改动，这样才能不断保持质量。 希望来年能继续保持对这个程序的热情。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Ruby","slug":"Ruby","permalink":"http://chenyukang.github.io/tags/Ruby/"},{"name":"OCaml","slug":"OCaml","permalink":"http://chenyukang.github.io/tags/OCaml/"}]},{"title":"读《饥饿的盛世》","date":"2016-12-11T11:43:00.000Z","path":"2016/12/11/qianlong-history.html","text":"最近又读了本张宏杰的书《饥饿的盛势》。张宏杰的书今年看了好几本，讲述历史都挺生动，特别是对人物内心的剖析很到位。很多时候作者是站在历史人物的角度去分析，书里所展现的历史人物特别鲜活。很多历史人物都被脸谱化或者自带几个标签，这人不是好的则是坏的。可是人都是复杂的、多面的，真实的历史事件又会有各种偶然因素。这本书看完后，对乾隆印象具体了很多。乾隆盛世的背后，隐藏着这位皇帝仁慈和残暴、宽容和计较。乾隆作为为数不多的自律而有头脑的皇帝，几乎是创记录地维持帝国专制统治近60年。 雍正仓促去世，乾隆在25岁的盛年继位，继位过程光明正大，水到渠成。上任之后就改变了帝国的航向。乾隆把被雍正折腾得要死的各种皇室宗族放出，给予产业和爵位，一下子扫除皇室王宫对雍正乾隆一族的怨恨。为了争取官僚集团对自己的效忠，他仿效祖父，宽大待下，从实际角度考虑问题，解决困难。对农民也采取了仁政，停捐纳，重视农业，赢取农民的爱戴。乾隆精通驭臣之术，虽然初征的时候执行仁政，他对于权利的集中却丝毫没有松懈过，时刻警惕名称、后宫、宦官等一切可能干扰权利的因素。 张廷玉是雍正时的老臣，对大清可谓鞠躬尽瘁，雍正点名其可配太庙。而乾隆因为各种鸡毛蒜皮的小事和张廷玉斗，最后把人弄得晚节不保。这章读起来真的是好生动啊，这个宇宙第一的皇帝心眼小得夸张！ 原配皇后富察氏的两个皇子的相继去世、富察氏后来也病死，这对乾隆影响很大。皇帝权利再大也抵不过生老病死。终于，乾隆13年时，借皇后富察氏去世，乾隆刮起政坛风暴，重回雍正时期刚猛、狠戾、阴险的政治风格。无数人被无辜定罪，包括自己的儿子们。原配妻子的死是乾隆一生的怨念。 在200多年前，乾隆为了留给后人一个『安全』的帝国，在内蒙古做了人类历史上一次惨绝人寰的灭族！纯朴的牧民们、归降的地人们一律被杀。 从驯身到驯心，集权统治的最后一步是驯心，就是所谓的『大清精神文明建设』。从书的描述看来，乾隆缔造了中国历史上最严酷的文字狱。无数书籍被烧，文人不敢写字发声。中国的帝王所要的向来是服服帖帖、老老实实的子民，这些子民除了基本的生存权，就不应该有其他诉求了。朱元璋洪武年间甚至规定了子民怎么穿鞋、怎么着衣。乾隆对于越级上访一律惩罚，民间的异说也是不能放任的，疯子在朱元璋手下还能逃脱，乾隆可是能杀则杀。 “千古第一全人”，乾隆年老后一直喜欢把自己和历史上的君王们比较，对自己所缔造的盛世甚为满意。甚至做到了历史上少有的权利的平稳交接，把自己的皇冠带在了嘉庆皇帝头上。不过晚年还是不得安稳，花了三年直到自己死时白莲教都没被压下。乾隆的60年统治中，中国的人口和版图都达到了峰值，而这又有什么用呢。自己培养出来的嘉庆守旧胆小，西方列强经过工业革命的洗礼已经远远超越大清。二十世纪初开始大清已经摇摇欲坠。甚至乾隆的坟墓都被炸开，真的是『千古第一全人』的巨大讽刺。","tags":[{"name":"Books","slug":"Books","permalink":"http://chenyukang.github.io/tags/Books/"}]},{"title":"Nginx限流","date":"2016-11-30T11:43:00.000Z","path":"2016/11/30/nginx-traffic-limit.html","text":"Nginx 限流可以通过几种方式实现： 1. Nginx自带的流量控制模块ngx_http_limit_req 根据特定的key(通常为IP) 控制访问频率 ngx_http_limit_req_module 控制连接数 通过修改Nginx的配置文件，然后reload。这种方式配置比较简单，然而 reload 对于当前访问量比较大的服务器开销也有一些。 根据新浪的经验，每一次的 reload 对 Nginx 的 QPS 与耗时的影响通常会持续 8~10s，考虑到一次扩容会有频繁的变更，这对在线业务来说是不堪承受之重。因此，要避免对 Nginx 进行 reload。 2. 使用lua-resty-limit-traffic 流量控制代码和文档。这个库分为limit_conn 和 limit_req模块，limit_req限制某个 ip 或者 server 的访问频率，limit_conn 限制连接数。lua-resty-limit-traffic 的原理是使用 Nginx 的 shared_dict，建立一个 hashtable，根据目前连接数或者访问请求记录相关信息。对于每一个Nginx请求都有一系列执行阶段，每个阶段可以增加 hook，access_by_lua是处理前调用的hook, log_by_lua 是处理完成后调用的 hook。进入的时候通过 ip 作为 key 找到share_dict 里面的连接数，增加1。处理完之后找到连接数， 减去1。 通俗的理解就是顾客进入试衣间前持一个牌子，出来后归还牌子。当前的正在使用的牌子数目可以配置，以达到限流目的。 依据系统状态动态改变限流的配置，可以考虑两种方案： a. limit_conn 和 limit_delay 存放在 Redis内，在 access_by_lua_block 的部分去取出当前限制，这个方案的弊端在于对每个 request 多了一次 redis 请求。 b. limit_conn存放在 Nginx 的 shared_dict内，通过 Nginx 的配置增加一个 location，专门用来请求来修改其值，任何一个 Nginx worker 修改成功后，其他 worker 都可见。 3. 使用nginx-upsync-modulenginx-upsync-module是新浪的开源库，也是依赖 openresty 的。 这套工具可以修改 backend 的各种属性，weight, max_fails等。为了避免 reload，可以使用Consul或者Etcd 进行动态配置。 其他为了做一些自动限流，可以考虑分析 nginx 日志，或者系统负载信息。系统负载分析工具，ruby gem 包usagewatch可以获取系统目前的 CPU 使用率，Memory使用率，系统 load 等相关信息，日志分析工具https://github.com/allinurl/goaccess，使用goaccess，可以实时分析rails app日志。","tags":[]},{"title":"菊与刀","date":"2016-08-09T11:43:00.000Z","path":"2016/08/09/dao-yu-ju.html","text":"前些天在家偶然翻到一部日本电影《黄昏的清兵卫》，看完后觉得非常符合个人口味。顺着同类型的电影又看了《隐剑鬼爪》。两部电影都是由山田洋次导演，主要故事都是围绕德川幕府末期的武士展开。剧情其实有些类似，一个武士，一个柔弱女主，甚至是同一个仆从，在“义务”和“义理”的冲突下来一场厮杀。武士爱着女主，却因为种种“理”而不能靠近。突出武士阶层的隐忍和不可避免的没落。 看完电影后，又顺着看了多人推荐的《菊与刀》。二战后美国急需了解日本，特别是日本人民的习俗和心理特征，因为日本在西方人看来太过特别，他们在战争中所体现的凶残程度也是前所未有的。《菊与刀》正是在这样的历史背景下由本尼迪克所写。据说作者本人并没有去过日本，而是通过书籍和调研来完成。这本书也许有的方面写得有所夸张。 看完这本书后，对上面两部电影有了更深些的理解。日本崇尚秩序，上级对下级的命令是无法抗拒的。这也解释了为什么二战时日本士兵凶暴残忍得像禽兽一般，而当天皇下诏投降书后，日本人绝大部分立马放弃抵抗，站在街头服服贴贴迎接盟军。在《隐剑鬼爪》中，藩府上级要求片桐出卖朋友交出叛党名单，片桐出于“义”而拒绝。但藩府换成“命令”的时候，他还是会去执行。“义务”和“义理”发生冲突的题材是很多日本故事和电影的基础。剧中人为履行义务忍受了一切，无论不幸、遗弃、疾病还是死亡，都未能使他们偏离。他们认为。所谓强者恰恰在于敢于抛弃个人幸福而去履行义务。他们认为，“性格的坚强不是表现为反抗，而是表现为顺从”，“真正的尊严在于各安其分，不卑不亢，自王子以至农夫，皆可以此自许”。 总的来说，日本呈现出了复杂的矛盾： 日本人好斗而又温和；黩武而又爱美；自尊自傲而又彬彬有礼； 顽固而又善变；驯服而又不愿 受人摆布；忠心而又易于叛变； 勇敢而又怯懦；保守而又欢迎革新。 他们十分介意别人对自己行为的看法，但当别人对其劣迹毫无所知时，又怡然自得。 关于个人欲望：日本人并不谴责满足私欲。他们不是清教徒。他们认为享乐是件好事，是值得培养的。他们追求享乐，尊重享乐，但享乐必须恰如其分，不能妨碍人生重大事务。 日本是比较讲究专注精神修炼，在他们看来，培养“一心”和“无我”对任何事业都是有好处的。 这本书算是我看过的翻译书籍里面很流畅的一本，甚至基本看不出来是翻译的。这和《自私的基因》比起来好多了，后者的这个版本基本没法看。 两部电影中，相对来说我更喜欢《隐剑鬼爪》。 －－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－ 最后，两部电影的女主角都挺好，宫泽理惠和松隆子。","tags":[]},{"title":"Add syntax check for Capistrano","date":"2016-07-22T11:43:00.000Z","path":"2016/07/22/capistrano-syntax-check-for-rails.html","text":"In an normal release, Rails app’s unit testing will avoid most errors. But for the urgent code publishing, we have got several time of typo error. Code syntax error may cause server crash for a little while(Passenger web server and we using ./tmp/restart.txt to restart). We use Capistrano to publish code, so I plan to add a syntax checking before publishing code.The method is writing a task to bundle exec rails runner, this will report most ruby syntax error(except the undef variables in some functions, runner will load .rb files). namespace :app do desc \"check all the ruby code\" task :check =&gt; :environment do res = `RAILS_ENV=#&#123;Rails.env&#125; bundle exec rails runner \"\" 2&gt;&amp;1` raise res if res.size &gt; 0 endend then add this in the deploy.rb (Capistrano 3.1): namespace :deploy do task :run_code_check do on roles(:all) do within release_path do with rails_env: fetch(:rails_env) do execute :rake, 'app:check' end end end end before \"deploy:updated\", \"deploy:run_code_check\"end This is not a tricky part, but please pay attention to the line: res = `RAILS_ENV=#&#123;Rails.env&#125; bundle exec rails runner \"\" 2&gt;&amp;1` This line of code cost me some time, I forget the 2&gt;&amp;1. so res will just got the stdout, not the stderr output, which causes the exception is not raised, and Capistrano flow is not stopped.","tags":[{"name":"Rails","slug":"Rails","permalink":"http://chenyukang.github.io/tags/Rails/"}]},{"title":"刷刷算法和 OJ","date":"2016-07-08T11:43:00.000Z","path":"2016/07/08/fun-on-hackerrank.html","text":"最近我们部门内部组成了一个算法读书小组，每周大家轮流分享自己的学习心得。为了方便学习我还写了一个小的 内部OJ，看起来还挺还好玩的。界面风格学习了青岛大学的 OJ，后台使用 Docker 来做沙盒跑测试输出结果。顺便学习了实际使用Docker。唯一麻烦点的是选了一个阿里的主机，最开始更新起来比较慢。还是用亚马逊的比较好。讨论形式还在摸索，我们现在每周选择一两个主题，会有两个分享人主讲，另外在 OJ 上弄几道题目大家做。总的来说还是可以提高一些东西，算法方面的知识，比如分享、表达的技巧。 等 OJ 完善得差不多了再分享出来。 另外业务时间也在 HackerRank 上做了一些题目，刚开始是为了熟悉 OCaml，专门用 OCaml写FP 方面的题目。 最近两周也顺便参加了一些比赛。这些比赛有的是和一些公司合办的，有的是各个主题的。比如有周赛，从周一到周五每天一个问题。个人觉得这个比较适合已经工作了的程序员，因为可以在空闲时间慢慢思考。等比赛结束之后也可以看其他人的解法和代码。我最近写得比较多，又找到了在学校时写程序的乐趣了。而且熟悉了之后用 OCaml实现算法还是挺快的。我的一些代码放在了这里，感兴趣的可以参考。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"}]},{"title":"Tiny Interpreters","date":"2015-09-29T11:43:00.000Z","path":"2015/09/29/programming-language-and-interpreters.html","text":"After reading the first simple Scheme interpreter of bootstrap-scheme, I have some interests on studying various programming languages and interpreters. It’s really fun to implement tiny programming languages. For learning a new programming language, a simple Scheme interpreter is a good starting project. Because in this small project we need to know some core aspects of a new programming language, including the basic I/O operations, abstraction methods for expression representation, recursive for eval, and unit testing. Also mini Scheme is so easy for parsing, we can focus on data representation and eval. Two programming language are best suited to implementing interpreter, The first one is Scheme, which used in many famous PL books, such as EOPL, SICP, etc. Another good language in OCaml,which is a sweet spot in language design space: strict, type system and type-inferer, functional. It’s very convenient to implement a parser, and also because of the pattern matching and algebraic data types, it is nature for building AST and traverse on it. For your references, I have these small projects during my studying of languages(to be continued): eopl, hundreds of interpreters written in Scheme, trying to solve most of the EOPL exercises. rust-scm, which is a Scheme interpreter written in Rust GoScheme, yet another Scheme interpreter written in Go ocaml-scheme, yet another Scheme interpreter written in OCaml toy-compilers, still they are interpreters, but not compilers, with js_of_ocaml we can compile OCaml code to Javascript, then run it on web browsers!","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"}]},{"title":"最近读的一些杂书","date":"2015-08-09T11:43:00.000Z","path":"2015/08/09/reading-notes.html","text":"最近看了几本书，大多都是觉得有些意思就从亚马逊上买了。自从我的Kindle坏了之后，我就基本只买纸质书了。虽然纸质书携带不够方便，看起来更够味。 别逗了，费曼先生! (5*)这是我最推荐的一本，断断续续看了两遍。这本书虽然是翻译的，但是质量很够水准，费曼聪明的坏教授形象跃然纸上。费曼作为物理学家也挺逗的，从小喜欢发明各种东西、恶作剧，折腾电子器件，好玩。青年时期开始折腾物理，在暑假期间顺便当了一段时间『化学家』。后面又对破解密码锁、画画、打鼓、学习外语产生浓厚兴趣，并极其投入。贯穿其中最让人敬佩的是费曼的好奇心好韧性。整本书都是在用一种诙谐平叙事写法，不过突然怀念自己的妻子那段特别感人，他的妻子去世那段时间正是在研发原子弹期间： 当我返回的时候他们都来问我发生了什么事儿， “她死了，工作进行的怎么样？” 他们立刻明白了，我不想为此终日哀伤。我显然要做些安慰心理的事：现实是重要的。我一定要理解，从生理学上说，阿琳究竟是怎么了； 我没哭，直到几个月之后。当时我在橡树岭，我正走过一家百货商店的橱窗，里头挂着女士服装，我想阿琳或许喜欢其中一件。此时此刻，我不盛悲戚。 他谢绝芝加哥大学高薪聘请的那段挺逗： “我将有能力做我一直想做的事 ——- 找个迷人的情妇，为她买一座漂亮的房子，给她买好东西……用你们给的这份薪水，我必定真的会这么做，我知道那会是什么结果，我会为她操心，挂念她在干什么，我们会吵架。我回家的时候，又会如何如何。这些闹心的事儿，会让我寝食不安，会让我心情不快。我搞物理也搞不好了，一切都将是一团糟！……因此，我已经决定，我不能接受你们的好意。” 费曼的理念是一个东西都可以用更通俗的说法来解释，但必须是建立的自己理解的基础上。 在巴西的教学过程中，费曼对填鸭式教学进行了思考和批判，里面所描述的场景和国内的教学何其相似！学生只是背诵，根本不理解那些科学概念背后的生动的东西。 最后，我认为判断人是否老了的一个标准就是其是否还对新鲜东西保持好奇心，有好奇心的人竟然这么好玩！ 鱼羊野史 (4*)一直比较喜欢高晓松，他的一些老歌都挺好听的。在深圳的时候听过一次他的演唱会，观众大多都是一些30岁以上的中年人。高晓松家庭显赫，一直都随性游荡，涉猎广泛，吹起牛来根本停不下来。有一段时间我也会在上班路上听他的小松奇谈，东南西北特别能侃。小松奇谈里面我最喜欢的故事是其二叔的爱情故事《文革时期的何以笙箫默》，是真是假无从考证，不过这还真是个能拍成电影的好故事。偶然在网上看到高晓松的这三本书，空闲时间把这些都看完了。总得来说不如听小松奇谈来劲，而且很多篇都是比较八卦，比如李宇春、齐秦生日之类的。这些还活着的明星们八卦怎么说也不能算作历史吧，即使是野史。另外就是三本的内容竟然有不少是重合的！ 李光耀观天下 (4*)中国的改革开放从新加坡借鉴了，中国相关的篇章还挺直接的。对邓小平和老毛的描述比较多，其他人就呵呵了。 成大事者不纠结 (3*）逻辑思维的公众号更新很勤快，内容也不错。不过这本书倒是没什么太多内容，李鸿章和曾国藩的章节都是在逻辑思维里面讲过的。更让我不爽的是书的封装，居然带了一打微信推广号。 从0到1 (3*)这本书挺有名的，不过看完后并没产生多少共鸣。可能是因为我现在对创业这个词有些抵触，创业现在动不动就是改变人类、情怀。这个词被玩坏了。在互联网这个行业，创业看起来有点类似大跃进。大家都吹牛，比如前段时间被扒皮的云视链就属于吹牛吹破了的。真正从0到1创造出新事物的公司太少。","tags":[{"name":"Life|Notes","slug":"Life-Notes","permalink":"http://chenyukang.github.io/tags/Life-Notes/"}]},{"title":"惰性求值和流","date":"2015-04-26T11:43:00.000Z","path":"2015/04/26/lazy-eval-and-stream.html","text":"什么是惰性求值惰性在函数式编程语言中很常见，他的通俗解释就是一个变量或者表达式，不到必要的时候不会被eval。比如函数在传递参数的时候，参数的值可以不确定。 这种方式叫做call-by-name, 首先很明显这可能会造成一部分performance差异，如果一个表达式没有用到，那么计算出其结果是毫无意义的。而惰性求值是memoized的call-by-name, 叫做call-by-need。从技术实现上来说，一个表达式在计算其结果之前其状态是Deferred或者Delayed的，在计算之后将其结果存储下来并修改状态为Value，之后再取就没有必要重新去计算。用一些OCaml代码来说明： # let v = lazy (print_string \"performing lazy computation\\n\"; sqrt 16.);;val v : float lazy_t = &lt;lazy&gt;# Lazy.force v;;performing lazy computation- : float = 4.# Lazy.force v;; - : float = 4. 关键字lazy表示延迟计算这个表达式， Lazy.force表示求值。可以看到第一次force的时候会打印出performing…信息，后面的force就直接返回了value。 为了更好的理解这个概念，我们可以实现一把Lazy。首先定义一个lazy_state: # type 'a lazy_state =| Delayed of (unit -&gt; 'a)| Value of 'a| Exn of exn;;# let create_lazy f = ref (Delayed f);; 这个lazy_state有三种状态，第一种就是dealyed，’a表示任何类型的value。Value表示被eval过了，并且保存下来他的值。Exn表示错误或者异常的状态。那么create_lazy就表示创建一个lazy_expression,这里的参数f可以是任何类型的函数(函数的参数类型和返回类型都可以不确定)，ref是OCaml里面的类似指针的概念。 上面例子就可以这样来写了: # let v = create_lazy (print_string \"performing lazy computation\\n\"; sqrt 16.);; 然后实现核心的force:# let force v = match !v with | Value x -&gt; x (* 如果已经求值就直接返回value *) | Exn e -&gt; raise e (* 如果发生错误，raise错误*) | Delayed f -&gt; try let x = f () in (* 如果还未求值，eval保存下来的f *) v := Value x; (* 并把结果保存下来 *) x with exn -&gt; v := Exn exn; (* 如果发生错误，保存下来 *) raise exn ;; 这里的!v就是取这个引用里面的值(类比C语言里面的*pointer)。然后pattern match这个lazy_state，注释里面写了每一行的操作。这里的代码很简短，最核心的意思是我们能把一个函数或者代码块保存下来，在真正需要的时候去运行这个代码块。在函数式编程里面这很常见，函数和变量一样可以自由传递。虽然看起来好不起眼，不过这会给编程带来一些深刻的影响。 Memoization通过上面对laziness的解释，我们可以发现这个概念的核心思想类似算法设计里面的memoization，这样在计算过程中把重复计算的过程省略掉。比如这段代码有些好玩: let memoize f = let table = Hashtbl.Poly.create () in (fun x -&gt; match Hashtbl.find table x with | Some y -&gt; y | None -&gt; let y = f x in Hashtbl.add_exn table ~key:x ~data:y; y );; 这个函数接收任何类型的函数f，他会像一个wrapper一样给你包装一下: 给你一个table用来存储这个函数的结果，键值是你的参数x，如果发现参数是x的结果还没计算的时候，把结果算出来并存储在table里面。这里我们又能看到函数式编程带来的好处，f是任何类型的函数(这里暂且还没处理递归)，这类问题在算法设计里面挺多的比如fibnacci，edit-distance。 在递归情况下如何处理可以看看这，这是我看过的排版最好的技术类博客Type OCaml:Recursive Memoize &amp; Untying the Recursive Knot Stream有了lazy的概念之后，我们可以在编程里面表示一些看起来很数学的概念，比如一个表示所有整数的流: type 'a stream_t = Nil | Cons of 'a * (unit -&gt; 'a stream_t)let rec from i = Cons (i, fun() -&gt; from (i+1))let hd = function | Nil -&gt; failwith \"hd\" | Cons (v, _) -&gt; vlet tl = function | Nil -&gt; failwith \"tl\" | Cons (_, g) -&gt; g()let rec take n = function | Nil -&gt; [] | Cons (_, _) when n = 0 -&gt; [] | Cons (hd, g) -&gt; hd::take (n-1) (g()) Cons是把两个元素组成链表，递归函数from做的事情就是把i和一个匿名函数fun() -&gt; from(i+1)链起来，当然匿名函数又在做类似的事情。那么(from 1)就可以表示从1开始的所有整数了，hd是取一个流的头部，tl是取流的尾部(除头部剩下的)，take是从一个流里面取前n个元素。这可是非常的方便，还有更方便的： let rec filter f = function | Nil -&gt; Nil | Cons (hd, g) -&gt; if f hd then Cons (hd, fun() -&gt; filter f (g())) else filter f (g()) 我们虽然只知道有这么一个流，但还是可以加一个筛选条件给他，filter函数接收筛选函数f和一个流，返回的结果就是被筛选后的流！ (* delete multiples of p from a stream *)let sift p = filter (fun n -&gt; n mod p &lt;&gt; 0)(* sieve of Eratosthenes *)let rec sieve = function | Nil -&gt; Nil | Cons (p, g) -&gt; let next = sift p (g()) in Cons (p, fun () -&gt; sieve next)(* primes *)let primes = sieve (from 2) 所有素数就可以这么来写了，有了这个流之后要取多少就取多少。 其他Haskell是纯函数式纯Lazy的实现，OCaml有imperative的部分，而且运行时不是Lazy的。相对来说我更喜欢OCaml的语法以及设计原则，FP有其好处，但imperative programming也有其益处。Lazy有其好处，但还是在用户明确需要的时候能提供就好。 部分代码引用Real World OCaml","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"OCaml","slug":"OCaml","permalink":"http://chenyukang.github.io/tags/OCaml/"},{"name":"PL","slug":"PL","permalink":"http://chenyukang.github.io/tags/PL/"}]},{"title":"Types and Programming Languages (2)","date":"2015-03-07T11:43:00.000Z","path":"2015/03/07/types-and-programming-languages-2.html","text":"ReferencesSide effect In particular, besides just yielding results, evaluation of terms in these languages may assign to mutable variables (reference cells, arrays, mutable record fields, etc.), perform input and output to files, displays, or network connections, make non-local transfers of control via exceptions, jumps, or continuations, engage in inter-process synchronization and communication, and so on. In the literature on programming languages, such “side effects” of computation are more generally referred to as computational effects. 引用指向的对象可以是基本类型、组合类型，甚至是函数，把指向函数的ref放进对应的record，就变成一个简单的object，OOP的原型就出来了。 update = λa:NatArray. λm:Nat. λv:Nat. a := (λn:Nat. if equal m n then v else (!a) n); 通过这个习题的例子可以看出ref引进的副作用。 Garbage CollectionGC or not This is not just a question of taste in language design: it is extremely difficult to achieve type safety in the presence of an explicit deallocation operation. The reason for this is the familiar dangling reference problem: we allocate a cell holding a number, save a reference to it in some data structure, use it for a while, then deallocate it and allocate a new cell holding a boolean, possibly reusing the same storage. Now we can have two names for the same storage cell—one with type Ref Nat and the other with type Ref Bool. Pointer Pointer arithmetic is occasionally very useful (especially for implementing low-level components of run-time systems, such as garbage collectors), it cannot be tracked by most type systems: knowing that location n in the store contains a Float doesn’t tell us anything useful about the type of location n + 4. In C, pointer arithmetic is a notorious source of type safety violations. Store typings: 引入引用后类型系统需要处理Cyclic reference structures，比如double linked list。Store typings就是一个locations到typings的映射。 实现fullref： 引用部分的实现非常简单， | TmRef(fi,t1) -&gt; TyRef(typeof ctx t1)| TmLoc(fi,l) -&gt; error fi \"locations are not supposed to occur in source programs!\"| TmDeref(fi,t1) -&gt; (match simplifyty ctx (typeof ctx t1) with TyRef(tyT1) -&gt; tyT1 | TyBot -&gt; TyBot | TySource(tyT1) -&gt; tyT1 | _ -&gt; error fi \"argument of ! is not a Ref or Source\")","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"OCaml","slug":"OCaml","permalink":"http://chenyukang.github.io/tags/OCaml/"},{"name":"PL","slug":"PL","permalink":"http://chenyukang.github.io/tags/PL/"}]},{"title":"Types and Programming Languages (3)","date":"2015-03-07T11:43:00.000Z","path":"2015/03/07/types-and-programming-languages-3.html","text":"Subtypingsubtyping解决的问题是多态，OO的一个基本要素。 we say that S is a subtype of T, written S &lt;: T, to mean that any term of type S can safely be used in a context where a term of type T is expected. This view of subtyping is often called the principle of safe substitution. 这章只是以record来作为例子说明，直白的所一个类型S是另外一个类型的T的子类型，意思是任何使用T的context，我们可以安全的使用S。对于record类型来说，field数量多的是field数量少的子类型，因为这样任何从T要取得的field都可以从子类型里面取到。 对于函数类型来说，如果S1-&gt;S2, T1-&gt;T2, S1是T1的子类型，S2是T2的子类行，那么S1-&gt;S2是T1-&gt;T2的子类型。 引入Top类型，是所有类型的父类，对应很多编程语言里面的Object(OOP里面常见的伎俩)，Go里面我就这样定义： type Object interface&#123;&#125; 引入Bottom类型似乎就没什么大用处了，还增加了typecheker的复杂度。 Ascription and Casting类型的强制转换，分为up-cast和down-cast。up-cast对于类型检查来说要简单一些，比如类型Animal -&gt; Dog, Animal -&gt; Cat，由Cat到Animal的类型转换为up-cast。在很多语言里面是当做一种抽象方法。 down-cast要复杂一些，而且也可能会导致类型系统的不安全，比如： f = λ(x:Top) (x as &#123;a:Nat&#125;).a; 这个函数接收任何类型的参数，但是隐含一个假设，必须是一个有成员变量为数字类型的a，如果传递一个错误的参数typechecker也不报错，但运行的时候就会有错误了。所以含有down-cast的类型系统应该遵循： trust, but verify，编译的时候不报错，但是留着运行的时候检查。为了避免down-cast引起的复杂问题，ML等语言选择的是down-cast with type tags。 channels: The key observation is that, from the point of view of typing, a communication channel behaves exactly like a reference cell: it can be used for both reading and writing, and, since it is difficult to determine statically which reads correspond to which writes, the only simple way to ensure type safety is to require that all the values passed along the channel must belong to the same type. subtyping的引入导致分支多的情况下类型检查麻烦，因此引入了Join和Meet的概念，实现可参考代码里面的: let rec join ctx tyS tyT = if subtype ctx tyS tyT then tyT else if subtype ctx tyT tyS then tyS else let tyS = simplifyty ctx tyS in let tyT = simplifyty ctx tyT in match (tyS,tyT) with (TyArr(tyS1,tyS2),TyArr(tyT1,tyT2)) -&gt; TyArr(meet ctx tyS1 tyT1, join ctx tyS2 tyT2) | _ -&gt; TyTopand meet ctx tyS tyT = ....... Case Study: Imperative Objects不考虑实现效率和语法简洁的条件下，目前为止学到的语言特性已经足够来模拟实现OOP。最简单的例子就是一个counter: c = let x = ref 1 in &#123;get = λ_:Unit. !x, inc = λ_:Unit. x:=succ(!x)&#125;; OOP作为一种抽象手段，可以让通过接口来隐藏实现，客户端的代码只通过同一个接口才操作各种子类的对象。这里的例子一个子类只是比父类多接口而已。 newResetCounter = λ_:Unit. let x = ref 1 in &#123;get = λ_:Unit. !x, inc = λ_:Unit. x:=succ(!x), reset = λ_:Unit. x:=1&#125;; self的简单是现实需要动态找到对应的method，更高效的实现当然是对象创建好后method table建好。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"OCaml","slug":"OCaml","permalink":"http://chenyukang.github.io/tags/OCaml/"},{"name":"PL","slug":"PL","permalink":"http://chenyukang.github.io/tags/PL/"}]},{"title":"Types and Programming Languages (1)","date":"2015-03-01T11:43:00.000Z","path":"2015/03/01/types-and-programming-languages.html","text":"最近掉进另外一个PL的坑里面，就是想读一下这本书，顺便继续熟悉一下Ocaml。下面的记录是阅读过程中的一些摘录和理解。 1-2章是数学预备部分，理论部分有些地方比较难懂，主要是一些数学符号看久了眼花。解释器的实现大多只用看syntax.ml和core.ml，就是语法和具体eval，typeof函数。 Untyped Systemsarith是一个无类型的解释器，是后面所有章节的基础。printtm_Term用了Format模块来格式化打印。 The Untyped Lambda-Calculus浅显易懂的Lambda-Calculus解释，同时列举了一些lambda calculus扩展其他语言部分的例子。 An ML Implementation of the Lambda-Calculusshifting和substitution的实现挺难看懂的，本质上是把context里面的变量用index来替换，处理变量查找的一种实现而已。eval部分是非常地简洁，我觉得ML系的语法看起来比Scheme都舒服紧凑。 Just because you’ve implemented something doesn’t mean you understand it.​ —Brian Cantwell Smith 说起来全是泪，用这种函数式的编程语言来解释自己确实比较简单，但现实往往不是这样。语言能比较容易地实现自己至少可以表明语言的内核挺小，一个语言能实现bootstrap是成熟的一个表现。Rust的实现最初是用Ocaml写的，然后编译出一个Rust的编译器，然后用上一版本的Rust再重新实现Rust编译器。 Typed Arithmetic Expressionstyarith是最简单的带类型的解释器，有bool和Nat类型。 Progress: A well-typed term is not stuck (either it is a value or it can take a step according to the evaluation rules).Preservation: If a well-typed term takes a step of evaluation, then the resulting term is also well typed These properties together tell us that a well-typed term can never reach a stuck state during evaluation. Safety = Progress + Preservation Simply Typed Lambda-Calculus In general, languages in which type annotations in terms are used to help guide the typechecker are called explicitly typed. Languages in which we ask the typechecker to infer or reconstruct this information are called implicitly typed. Well-typed programs cannot “go wrong.” —Robin Milner (1978) An ML Implementation of Simple Typessimplebool是一个只有bool类型的解释器，但是加上了函数。typeof挺简单，主要是函数这里注意处理形参和实参: | TmAbs(fi,x,tyT1,t2) -&gt; let ctx' = addbinding ctx x (VarBind(tyT1)) in let tyT2 = typeof ctx' t2 in TyArr(tyT1, tyT2)| TmApp(fi,t1,t2) -&gt; let tyT1 = typeof ctx t1 in let tyT2 = typeof ctx t2 in (match tyT1 with TyArr(tyT11, tyT12) -&gt; if (=) tyT2 tyT11 then tyT12 else error fi \"parameter type mismatch\" | _ -&gt; error fi \"arrow type expected\") if的判断部分必须为bool，而且两个分支必须为同一类型: | TmIf(fi,t1,t2,t3) -&gt; if (=) (typeof ctx t1) TyBool then let tyT2 = typeof ctx t2 in if (=) tyT2 (typeof ctx t3) then tyT2 else error fi \"arms of conditional have different types\" else error fi \"guard of conditional not a boolean\" Simple Extensions在上一章的基础上，加上各种Drived Form。 Sequencing: 是多个表达式串，这在有副作用的语言里面很常见。另外也可以把t1;t2理解为(λx:Unit.t2) t1。 Wildcards: 如何翻译好，意思就是无用形参可以不指定名字。 Ascription 是指类型缩写(或者昵名)，C++里面的typedef，和Rust里面的usize as U都是。这个的好处在于文档和接口更清晰，如果函数的参数可以是函数，类型加进以后语法看起来就比较繁琐了，用类型缩写更清晰。typechecker的时候当然需要展开来进行。ascription和casting也有一定关系。 增加各种简单的基础类型，比如String，还有Pairs，Tuple，Record， Sum，Enum，List。支持一种类型除了一个新类型名字外，其evaluation rules和type rules也要明确。这里的datatypes是按照Ocaml的语法来说明的。 因为加上了好多种类型，fullsimple这个解释器复杂多了。 Type DynamicEven in statically typed languages, there is often the need to deal with data whose type cannot be determined at compile time. This occurs in particular when the lifetime of the data spans multiple machines or many runs of the compiler—when, for example, the data is stored in an external file system or database, or communicated across a network. To handle such situations safely, many languages offer facilities for inspecting the types of values at run time. General Recursiontyped lambda-calculus加上fix combinator就是一门极小的但是是full abstraction的语言。Ocaml里面的letrec可以用来定义递归函数。fix point的概念需要继续理解。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"OCaml","slug":"OCaml","permalink":"http://chenyukang.github.io/tags/OCaml/"},{"name":"PL","slug":"PL","permalink":"http://chenyukang.github.io/tags/PL/"}]},{"title":"Understanding Computation","date":"2015-02-10T11:43:00.000Z","path":"2015/02/10/understanding-computation.html","text":"前些天花了一些时间读这本书《计算的本质：深入剖析程序和计算机》。总的来说这本书非常不错。虽然讲述的是一些看似理论的东西，里面有不少短小的Ruby程序，读起来还是非常有趣的。回想当年大学的时候有一门课程叫做形式语言与自动机，当时觉得这门课真是太没劲了。理论的东西终究需要一些实践才能掌握，早早读到这样的书就好了。 首先第一部分介绍了一些基本Ruby语法，十来页的介绍就够了。Ruby的语法真的是非常直观，人性化的。两年前我被Ruby吸引，现在我每天大部分时间都敲着Ruby代码，用Ruby很省事！对Ruby来说数据也是程序是很常见的，这本书使用Ruby来做示例是很好的选择。 什么是程序？这是一个可以从各个角度深入的问题，程序是程序员表达自己脑海中的思想的形式。我们需要从编程语言开始，语言的语法和语义完整地定义了一门编程语言。这本书开始以小步语义来解释一个简单的语言，这样就得到一个的解释器程序。小步语义提供了一种轻松的方式来模拟计算的中间过程。随后介绍了大步语义，我觉得这两者之间的关联有些像自顶向下和自底向上。然后介绍了treetop这个工具，自定义grammar来实现一个简单的语法解释器。 第三章开始介绍自动机，从最简单的确定性有限自动机开始(DFA)，然后是非确定性自动机(NFA)和正则表达式。我原来上学的时候大多在手动画这些状态图，远没这些简单的代码好玩。有输入，有状态，有输出，这些状态机就是最简单的机器了。而NFA虽然看起来比DFA有更多的特性，但本质上它可以转化为DFA。为了增加计算能力，为自动机加上一些外部存储。用自带栈的确定性有限状态机(DPDA)能识别出平衡字符串。 第五章介绍图灵机，图灵机本质上是有外部存储的状态机。我之前看过图灵传记，图灵对密码学非常感兴趣，而且在二战中破译了大量德军密电。图灵机的概念很简单，而计算的本质就是如此简单直接的描述。模拟图灵机的过程倒并没什么大的乐趣。 第六章开始lambda演算，lambda演算是从另外一个角度去理解计算。这一章非常好玩，这里只是用了Ruby的三个特性： 对变量的引用，创建proc，调用proc来实现一个极小的编程语言。lambda演算的基本元素就是这三个： &lt;exp&gt; ::= &lt;var&gt; :变量引用 | (lambda (&lt;var&gt;) &lt;exp&gt;) :创建proc | (&lt;exp&gt; &lt;exp&gt;) :调用proc 从这些简单的元素构建出语言的各种特性非常好玩，最终一个简单的gcd被解释成充满了proc的Ruby程序，然后就能运行了。 后面几章继续简述了可计算行问题。停机问题表明我们无法拥有能力不受限制的编程语言，淡淡的忧伤。 这位作者Tom Stuart的博客非常有料，他在自己的网站上用幽默了一把I Have No Idea What I’m Doing，这本书是这么写出来的。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Books","slug":"Books","permalink":"http://chenyukang.github.io/tags/Books/"}]},{"title":"广告","date":"2015-01-19T11:43:00.000Z","path":"2015/01/19/refer.html","text":"我到了一个做无人机的公司工作，叫做大疆创新(DJI)。最近内部有一些推广活动，有感兴趣的朋友了解一下。 大疆精灵 这页面我隔壁小伙子做的，看起来还不错 :) Phantom系列是公司卖得最好的一款产品，市场主要在欧美。 这个东西挺好，比如能拍出这样的照片：stacy-s-breathless-moment。 https://www.skypixel.com/#/photos这里是大量用户上传的航拍照片。从不同的视角来欣赏地球，自有另一番风景。 当然如果以后还能做得更好，或许可以这样自拍了: DJI 云拍 Inspire是下半年出的产品，这个还是挺惊艳的。设计很前卫，4k镜头，操作灵敏且稳定性极佳。不过价格也不便宜，接近2w了。 “悟” INSPIRE PHILIP BLOOM DJI Inspire 1 – “Soar” This is the most amazing drone we’ve seen yet 顺便，再分享一个好东西给大家。大家都知道我们外面有个墙，红杏出墙就是个梯子。 我用了一段时间了，挺方便的。 所以在这里推荐一下，可以用这个链接注册。","tags":[]},{"title":"Rust coming to 1.0","date":"2015-01-10T11:43:00.000Z","path":"2015/01/10/rust-10-alpha.html","text":"Again, one article just for writing practice. :) Rust-lang release alpha 1.0 today. Rust aims to be a systems level programming language to replace C and C++. I hit Rust-lang about two month ago, and found it’s a funny language. Then I read some Rust code and also wrote a hobby project with it. There are several feature attract me: Write low-level code with safety guaranteesRust have the concept of onwership. For the resource in computation(this is usually refer to memory, file handler etc), the should be an owner. Rust try to solve the common errors caused by pointers in C/C++, such like dangling pointer, unfree pointer, double free issues. The borrow checker in compiler will keep the resource onwership move correctly with some rules. for more details please refer to offical guide. So as a newbie, writing code in Rust code seems always fighting with compiler. We can not just write code and then fix the memory later, the compiler refuses to accept anything which maybe unsafe, but this also make me think more about the code and design.By the way, the error hints from compiler is very helpful, this is not like C++(specially templates got in). There are some comparisons between Go and Rust, Gc is optional in Rust, compare Rust with Go is not sensible. Recent changes of removing runtime make Rust lower level. There are even some hobby projects writting OS with Rust, refer to this and this. High level abstraction for system programmingAs a modern system programming, Rust is surprisingly expressive. I like the Ruby syntax, Rust has the same similarly mind-blowing effect. Rust carry some functional programming concepts, these make code looks just simple and elegant. Let’s have some trivial code snippet: // construct array with 0 3 6 ...let v = (0..10us).map(|x| x * 3).collect::&lt;Vec&lt;_&gt;&gt;();for i in v.into_iter() &#123; println!(\"&#123;&#125;\", i); &#125; // construct array with random valuesuse std::rand;let v = Vec::from_fn(10, |_| rand::random::&lt;uint&gt;()); Pattern match is so elegant:match number &#123; 1 =&gt; println!(\"One!\"), 2 | 3 | 5 | 7 | 11 =&gt; println!(\"This is a prime\"), 13...19 =&gt; println!(\"A teen\"), _ =&gt; println!(\"Ain't special\"), &#125; Colsures, reminds me with Ruby’s block:fn main() &#123; let captured_value = 7u; let closure = |&amp;:argument| &#123; println!(\"I captured this: &#123;&#125;\", captured_value); println!(\"Argument passed was: &#123;&#125;\", argument); true &#125;; println!(\"Closure returned: &#123;&#125;\", closure(\"a string\"));&#125; Almost every statement is an expression, this means that the statement returns a value. Blocks are also expression. This is good thing, we may write less “return”! Mixing with pattern match ends with a better sugar. Of course, nice syntax doesn’t really mean real expresiveness, There are more abstraction tools in Rust, like traits, macro definiation, generic types etc. I have tried some macros for testing in rust-scm. High SpeedI have found my favorite interpeter language, it’s Ruby. But in real world, we need to write some code need critical time performance. For this kind of task, Rust maybe a good choice. Benchmarks show Rust is almost as fast as C++. CommunityThe Rust have a small, but exciting, openly community. The language have been evolving several years, most design discussion are open source. The core team seems nice. Have a try for Rust.","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Rust","slug":"Rust","permalink":"http://chenyukang.github.io/tags/Rust/"}]},{"title":"lcc阅读记录","date":"2014-09-14T11:43:00.000Z","path":"2014/09/14/a-retargetable-c-compiler-design-and-implementation.html","text":"之前看EOPL感觉收获挺大，最近又花业余时间看了看编译相关的东西，这是我看lcc的时候顺手记下的一些自己的理解。这本书《A Retargetable C Compiler》还挺大头的。lcc代码量不是特别大，更复杂的是tinyCC，tinyCC甚至可以直接运行C代码。 alloc.c为了尽量的少调用系统调用，在alloc基础上封装了一下。 sym.c用来存储symbol，注意scope的表示方法。 input.c为了减少读取文件的开销，用一个buffer来缓存源文件内容。cp表示当前读取出来的字符位置，limit表示缓存的结尾字符位置，如果fillbuf一次以后仍然cp == limit则表示读取文件到EOF了。 注意这里的fread读取的时候是通过stdin的，但是在main.c/main_init函数的时候通过freopen将源文件重定向到了stdin。 fillbuf其实读取的时候是永远先把内容读取到buffer[MAXLINE+1]的位置，如果发现cp &lt; limit就把前面剩下的内容往前移动，这样永远保证buffer足够下一次预读取,这里有点巧妙。 比较复杂的部分是处理resynch，input处理的内容是经过C语言预处理器的，这部分没有包含在这个编译器内。 lex.c一个完全是手写的C语言Parser，虽然只是兼容C99，但手写还是比较复杂的。码农约架比写Parser是个体现实力的比赛。 getchr逐个字符读取，cp就是input.c里面的当前字符。跳过BLANK，如果碰到NEWLINE则调用input.c读取下一行。 token.h看起来有很多列，这个文件被多个地方用到。是用宏来生成一些Enum里面的代码。比如token type和expr type。 gettok顾名思义在lex运行的时候不断提供一个一个的token，这主要是通过cp匹配map来判断，条件分支很多(依据当前的第一个字符)。register unsigned char* rpc存储当前字符。register作为一个对编译器的提示，尽量用register来存储变量。事实上现在的编译器很多都能做auto register allocation，有的时候编译器的选择可能比人的选择更好。register在老的C代码里面可能更为常见。 这个函数里面很多地方都用到了goto，主要是在匹配关键字的时候区分identifier。主要几大类是: number, keyword, identifier, string。 icon处理数字的前缀，fcon处理浮点数。 Lexical analyzer基本理论是自动状态机，没一个token可以根据相应的正则表达式来表示。有一些工具可以用来自动生成这些繁琐的代码，比如LEX，更新一些的有Flex和re2c。 error.c终于来到Parser部分了，lcc使用的是recursive-descent，很多商业的编译器都是用的这种直观的算法，事实上对于大部分语言都足够了。recursive-descent是自上而下的递归的，依据当前的token匹配语法结构。一个重要的问题是如何在处理的过程中给出适当的错误信息。error.c里面的函数test和expect用来测试下一个token是否是预期的,expect可以打印出错误信息。 tree.c最重要的数据结构struct tree，AST中的基本节点，包含子节点，和operator类型(比如AND，OR，NOT等）。在构建AST的时候root函数经常被用到。 expr.c enode.cparser的一部分，用来识别表达式。代码好复杂，和paresr有些类似，整个过程是构建AST。编译器的前端最重要的事情就是这了，后面的操作都是在这个基础上做的。为什么Scheme/Lisp的front部分比较简单，因为这货代码就和AST有些类似了，括号把一个一个的节点组合了起来。初看起来很难看，其实习惯了还好。 上面说的是语法的识别，在构建AST的过程中另外一个事情就是语意的分析。包括类型检查，类型的转换，操作符优先级等，这些也在构建AST的时候顺便做了。比如在遇到expr1 ? expr2 : expr3的时候，expr1的值最后被cast成一个bool。指针之间的隐式转换也比较复杂。function call比较复杂，这里还做了函数参数的写法是否是老的风格，类型说明放在函数头的最后。assignments和binary operator的分析相对来说简单一些，需要做各种cast。 前些天稍微看了一些Erlang，发现里面的类型推导比较好玩，甚至可以发现一些代码里面的逻辑错误： 比如： fact(0) -&gt; 1;fact(N) -&gt; N * fact(N-1).test() -&gt; fact(-5). 不用运行Erlang的dialyzer就可以发现这里面的死循环，因为可以通过上面的定义推断出fact的参数是non_neg_integer,而-5是不符合的，所以报出来一个错误： fact(-5) will never return。 stmt.ccodelist为双向列表，遇到新的执行块就加到这个列表上。在处理control-flow的过程中有的死代码块是可以被编译器发现的，只是我们平时都被忽略了。 比如C代码:int loop() &#123; Loop: goto Loop; return -1;&#125;int main() &#123; printf(\"loop: %d\\n\", loop()); return 0;&#125; loop永远不会返回，Gcc选项-Wsuggest-attribute=noreturn可以报出一个warning。 decl.c声明是C语言中最难解析的部分，原因是声明涉及到变量和类型，而从C声明中弄出类型信息还是挺复杂的。另外声明还分局部，全局，其中还涉及到函数参数，结构体等。decl.c可能是最复杂的文件了，1100多行代码，里面的函数之间又相互调用。finalize()函数最后检查是否有重复定义的变量。 dag.clcc的intermediate code是用listnodes把前面parser的tree转换为DAG，最终整个程序会经过转换变成由多个DAG组合成的森林。listnodes还负责把一些公共的sub-expression简化。 接口为gencode,emitcode。后面每一个代码生成的后端都是一个Interface结构，在function函数里面调用这两个函数生成汇编代码，其中还包含一个Xinterface成员，这是平台相关的接口。 小结到现在我只是大概看了了前端和中间层，后面lcc跨平台的指令生成还没来得及研究，这本书的电子版不是很清晰，还是买个中文版来再稍微看看。总的来说，lcc是的Parsing和语义分析是同时进行的，就是所谓的one-pass方法。现在很多编译器所用的方法是先建立AST，后面可能要多次遍历整个AST进行分析，LLVM好像就是采用的这种方案。另外代码的优化是一个trade-off，作为教学用途的lcc没有过多做代码优化，这样lcc代码还是可以花不多的时间来一个大概的学习。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Compiler","slug":"Compiler","permalink":"http://chenyukang.github.io/tags/Compiler/"}]},{"title":"折腾服务器","date":"2014-08-01T11:43:00.000Z","path":"2014/08/01/install-server.html","text":"最近花了一些时间研究机器的部署，主要是实践了网络安装服务器和OpenStack部署。 网络安装Ubuntu如果有多台服务器，网络安装似乎是唯一的选择。基本原理就是在局域网里面配置一个host，里面配置好一个HDCP服务和TFTP服务，用Apache弄一个系统镜像供服务器下载。当然这里面有许多许多的坑，一个一个爬出来感觉还是挺好的。我把一些记录在了这个Gist里面。Kickstart用来自动化安装过程，这样安装过程中就不会弹出等待用户输入的对话款。总的来说就是： dhcp + tftp + web服务器 + ubuntu镜像 + kickstart : 局域网自动部署 弄这些似乎有点回到从前的感觉，我在05年左右大二的时候开始折腾系统。那时候Ubuntu正在作推广，在校学生可以免费申请光盘。因此，从4.04开始所有的Ubuntu盘我都有一份，经常乐此不疲地安装。当然也安装过各种Linux其他发行版。有时候出现问题还会找一些学长来帮忙弄。现在想来挺浪费时间的，应该花时间来多学些基础的东西。 弄完这网络安装以后我就想，如果当年整个男生宿舍弄这么一个安装系统的服务器，那可是能节省很多同学的时间啊！ OpenStack 安装部署OpenStack号称下一个Linux，分为很多独立的部件组成，看起来是一套很复杂的系统。我们主要是想利用OpenStack来构建私有云。OpenStack的安装涉及到非常多的包，过程和配置都稍微有些复杂。所幸这里有一个比较成熟的安装脚本OpenStackGeek。是一些比较简单的shell脚本，我们在这个基础上自己做了一些默认配置，这样基本能够做到一键安装OpenStack。 其他运维做的事情虽然很杂，不过中间还是能学到不少东西，比如我在这些折腾过程中学到了一些网络知识。虚拟化技术真是很好玩，『云』这个东西其实并不只是一个大家炒作的概念，即使公司现在只是用OpenStack来弄个私有云，这其中的便利真是让人感叹。有了这一套机器资源真是挥之即来，用完即丢。每个服务独立跑一个虚拟机上，相互独立。","tags":[]},{"title":"Automatically cleanup the buffer for Eshell","date":"2014-07-29T11:43:00.000Z","path":"2014/07/29/buffer-size-limit-for-eshell.html","text":"Keep writing some simple thing in English, for I will have less chance for writing English words in daily working. I will always run eshell for shell tasks, because this is really like the normal buffer in Emacs, so all the command for Emacs will keep working for this buffer. This is convenient for some actions. The problem annoying me is that if the size of buffer for eshell is too big, Emacs will gets more and more slow. Emacs essentially is a sole process program. So I have some digg and written a trivial elisp code like this solved the problem. (defun clear-and-send-input() (interactive) (if (&gt; (count-lines 1 (point)) 800) (let ((inhibit-read-only t)) (message \"Clear the eshell now !\") (erase-buffer))) (eshell-send-input))(add-hook 'eshell-mode-hook (lambda () (local-set-key (kbd \"&lt;return&gt;\") 'clear-and-send-input))) clear-and-send-input is a wrapper for eshell-send-input, I set the maximal number of eshell buffer to 800, and I bind this function to , so every time if the buffer size is too big, this wrapper will automatically clean up the buffer. And yesterday I found this article Mastering Emacs in one year guideis really thought-provoking, Hope this may help you.","tags":[{"name":"Emacs","slug":"Emacs","permalink":"http://chenyukang.github.io/tags/Emacs/"},{"name":"shell","slug":"shell","permalink":"http://chenyukang.github.io/tags/shell/"}]},{"title":"A mini Scheme interpreter written in Go","date":"2014-06-28T11:43:00.000Z","path":"2014/06/28/scheme-go.html","text":"Scheme-Brained Hare 在我学Go的时候开始了一个自己的业余小项目，就是这个GoScheme，打算用Go来写一个Scheme解释器，因为重写轮子是学习新东西的好手段。现在基本完成了，当然只是一些基本的语法支持，没有宏。 我只是用这个项目来熟悉Go的语法，Go来做这种项目没有特别大的优势，这个项目用C来实现代码量会更少一些。比如这里个里面的基本数据对象包括各种类型，boolean, symbol, fixnum, proc等等，又都是一个Object类型。如果是C可以用union类型来表示，然后通过Object*实现接口上的统一操作各种数据，类似的代码像这样子： typedef struct object &#123; object_type type; union &#123; struct &#123; char value; &#125; boolean; struct &#123; char *value; &#125; symbol; struct &#123; struct object *car; struct object *cdr; &#125; pair; // .......... &#125; data;&#125; object; Go里面没有Union这种类型，所以我用了reflect来实现这些东西，看起来还不是那么简洁。Go的自带的一些toolset还可以，比如testing，format，coverage等，可以减少一些琐碎的事。 另外，以后项目里配一下travis-CI可以做集成测试。 Go更适合做一些需要并发的任务，比如服务端的事情。","tags":[{"name":"Scheme","slug":"Scheme","permalink":"http://chenyukang.github.io/tags/Scheme/"},{"name":"Go","slug":"Go","permalink":"http://chenyukang.github.io/tags/Go/"}]},{"title":"最近在用Go","date":"2014-06-22T11:43:00.000Z","path":"2014/06/22/go-dev.html","text":"最近一直在用Go做开发，我们打算整一套和Rails对应的Go开发框架。一些代码在我们的Github小组里有。这里的几个项目都用到了代码生成的方法，生成Go文件，最后的整个web程序被编译成一个可执行文件。我们正在用一个项目来验证这个想法。其中： 1. xuanwu(玄武)根据thrift文件产生对应MVC里面的Model。生成的go文件里面，一个thrift类型对应一个go里面的type struct，生成的代码中包含一些基本的方法，比如FindByID等等，这都是根据thrift文件定义的对象属性自动生成的。这里用到了ptsd来解析thrift文件，自己定义模板来生成Go代码。我后来加了crud.py和crud.tmpl来生成Controller的代码，这样MVC里面Model和Controller就都有了。不过对于Go这样的静态语言，生成代码这套方案有个难解决的问题就是如何在生成的代码基础上实现用户自定义。我们现在的解决办法是另外写一个对应的fix文件，在里面写入自己要重写的函数，另外写一个程序根据gen文件和fix文件来做一个基于函数定义的diff，如果用户定义了就忽略自动生成的函数。好绕的方法，不过因为Go库里面自带的的parser和AST，做这么一个diff程序还挺简单的。 2. gorazor(白虎)功能是MVC里面的view engine，从C#里面的razor模仿而来，具体为什么要这么做这个详细的中文文档里面说了。有了这个东西我们可以混着html写Go代码了。我是从这个项目开始正式学习Go的，整个开发过程还是比较顺利的。刚开始lexer大量使用了正则表达式，后来发现速度有些受影响就手动写了一部分。parser部分现在还有些难看，后面继续重构一下。Debug一直都是Println，很多时候已经够用了。 3. web在web.go的基础上做了一些自己的修改。 再说一下使用Go的一些感受，大部分时候是很爽的。对于喜欢C和Python的人来说上手Go是很容易的事情。Go更像是一个更现代化的C(而不是C++)，因为简洁是其一个重要特性。和Python相似的地方是提倡一种事有一种解决方法，而不像Ruby那样有各种魔法写法，所以看别人的代码容易一些。Go对代码的格式化有一些强制约定，但是缩进并不是语法的一部分，而是通过gofmt工具来自动纠正格式，这太方便了。再加上goimport这样的工具来自动加上或者移除不必要的import，我现在写Go代码的时候基本不需要关心格式和import这些琐事，绑定Emacs快捷键保存文件以后基本都解决了。 Go的编译速度很快，我的机器上这里20w行左右的Go代码基本编译在13s左右，这和C++比起来要快很多很多。 其他我是这么配置Emacs的Go相关的东西的 其中go-autocomplete是来自动补全的，对于内置的库函数补全还是很好的。有的自定义的补全不出来。 goimports修正import的。 gocover是我自己写的一个程序，看到同事写在Vim里写Go代码的时候一个快捷键就跑相关的pkg的testing，并把结果打印出来。对于Go的这么快的编译速度，真的可以边写代码迅速按下快捷键测试的结果就出来了(还包括coverage噢)。于是我也写了个程序分析出当前编辑文件对应的package名字，设定好GOPATH，然后去tmp目录跑测试。这个程序就是gocover，我绑定到C-x g，太方便了。 Vim和Emacs的可扩展，是我们这群装逼党依然坚持用这些老古董的原因。因为可扩展意味着将来要面对新的编程语言和环境时候，我们可以做出自己改变来适应。 好的Go上手教程: Go by Example","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Go","slug":"Go","permalink":"http://chenyukang.github.io/tags/Go/"}]},{"title":"Visualize Git Projects with Ubigraph","date":"2014-04-18T11:43:00.000Z","path":"2014/04/18/visualize-git-proj.html","text":"一个比较大的项目一般都由一群人协作开发，开发人员可能活动于各个模块之间。前两天突然想起如果把一个工程的所有commit数据提取出来，然后按时间顺序动态演示出来可能会比较好玩。从这个过程中我们可以看到一个项目是如何进化的，各个开发者到底在折腾哪些模块。比如这是一个多个开发者参与的一个项目展示图，其实是3D动态的。 我写了两个脚本来做这件事情，代码放在这里了。第一个脚本是Ruby写的gitstat.rb，用来提取git的commit数据，这些信息包括：提交者名字，日期，增加的行数，删减的行数，相关的模块。所有这些数据都按照提交的时间排序，然后输出到一个文本文件里。使用方法是: $./gitstat.rb -l eventmachine,tinyrb -o log.txt -l后面是模块名字列表，如果不加-l脚本会自己检测出当前文件夹下所有的.git，每一个目录当做一个模块。log.txt的格式看起来像这个样子： Francis 2008-07-28T16:57:15+00:00 1 1 eventmachineFrancis 2008-07-28T17:03:46+00:00 2 0 eventmachineFrancis 2008-07-29T23:34:53+00:00 3 1 eventmachineMacournoyer 2008-07-31T23:34:52+00:00 13 47 tinyrbMacournoyer 2008-08-01T00:36:27+00:00 32 0 tinyrb 另外一个脚本就是gitshow.py用来从文件中读取数据，然后发送给Ubigraph渲染。 Ubigraph可以从官方网站上下载，解压后会看到一个example目录，里面有几种语言的示例。使用方式是： $./bin/ubigraph_server [在Ubigraph目录启动服务端]$./gitshow.py log.txt 这里开发者用圆球表示，模块用多边形球表示，并且颜色加以区分。另外加入了一点效果就是当开发者有提交的时候，其颜色闪红一下，同时开发者和模块之间加上一条虚线。并且开发者和模块的体积会随着代码改变量而增大，这样也能看出哪些模块工作量比较大(当然用行数来衡量工作量本身并没有多大参考价值，只是为了效果)。 对于一个多人参与的项目也可以看出一些好玩的信息来，如果一个开发者贡献大其体积越大，而且离项目的节点越近，比如eventmachine的演示图如下： 有一个类似的开源的C++项目叫做: Gource，效果做得很漂亮。","tags":[{"name":"Tools","slug":"Tools","permalink":"http://chenyukang.github.io/tags/Tools/"}]},{"title":"Heartbleed简单分析","date":"2014-04-11T11:43:00.000Z","path":"2014/04/11/heartbleed.html","text":"这几天不断听到一个词“心血漏洞”，近年来影响最严重的互联网漏洞。今天小小地研究了一把，顺便把引起一些思考记录下来。 到底是什么样的代码有一些C语言和开发经验的朋友看看这个Fix就能了解些具体细节了。在网络传输中有一个叫做心跳的概念，简单来讲就是客户端发送一个简单的心跳包给服务端，服务端又返回给客户端，然后客户端检查传回来的内容是否是预期，这样就知道了当前的TLS通信是否正常。这个Bug不是协议的问题，而是具体实现的时候的遗漏了相关的逻辑。 这个函数dtls1_process_heartbeat就是处理这块代码的，先读出长度和包类型，然后申请一段内存空间做一个memcpy，其中长度为write_length, 而这里遗漏的就是这个长度的合法性检查。 /* Read type and payload length first */ hbtype = *p++; n2s(p, payload); pl = p; unsigned char *buffer, *bp;unsigned int write_length = 1 + 2 + payload + padding;buffer = OPENSSL_malloc(write_length);bp = buffer;/* Enter response type, length and copy payload */*bp++ = TLS1_HB_RESPONSE;s2n(payload, bp);memcpy(bp, pl, payload);bp += payload;/* Random padding */RAND_pseudo_bytes(bp, padding);r = dtls1_write_bytes(s, TLS1_RT_HEARTBEAT, buffer, write_length); 可以想象如果客户端发送一个长度为很大的数，而实际给的内容还是在符合范围内的长度，而memcpy仍旧拷贝了一个比较大范围的内存空间(因为申明的包长度类型这里最大为64K)。而这个临近的内存空间存的是些什么东西就不确定了，偶尔可能包含一些敏感信息，比如用户密码等等，这些数据有一定特征，是可以通过一定手段检测出来的。这个Bug的名字很形象，就像是血从服务器这个身体里慢慢渗出来一样。 这个简单的长度检查遗漏照理来说应该会被发现，因为内存如果越界了可能会引起SegmentFault。但是OpenSSL有一个自己的内存分配器。可以想象OpenSSL先开辟一大块内存，后面的内存使用再自行分配。这样memcpy即使超出了预订的范围也没有造成问题。 影响有多大OpenSSL作为一个基础设施，世界上大量现存的网络相关的软件都在使用，特别是一些服务器。光Apache和nginx就占了Web server的66%，甚至还包括Email服务器(SMTP,POP, IMAP协议等)，VPN，和一大堆的客户端软件。这些都使得大量用户的密码有可能泄露。各个互联网公司都在为自己的产品打patch来解决这个潜在的风险。用户也有可能要再修改自己的密码来规避风险。 如何避免这样的Bug这个Bug引起了一些争议，是否开源软件存在更大的风险。因为这个Bug如果是在私有软件里，可能不会一下引起这么多人的关注，整个互联网也不必整个为此patch一遍。 对于程序员来说，如何避免这样的Bug? Redis的开发者Antirez的这篇文章Using Heartbleed as a starting point 写得挺不错，公司应该投入更多的资金在这种关键的涉及到安全的代码上，OpenSSL每年接收到的资助为2000美金。系统程序员和测试人员应该使用一些静态代码分析器，另外动态检测器(比如Valgrind)也很有帮助。因为C是一个贴近硬件的语言，可以在C上再增加一个抽象层来保护关键信息。Random测试有可能发现很多软件中潜在的问题，单元测试有可能测不到这种情况。我现在工作的公司对于测试这块还是做得挺不错(这也与我的产品特性有关，测试相对容易一些)，我们每天晚上除了跑单元测试，还需要跑Valgrind来检测内存问题，还有大量极端的random case可以发现很多Bug。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Bug","slug":"Bug","permalink":"http://chenyukang.github.io/tags/Bug/"}]},{"title":"另一本魔法书: EOPL","date":"2014-03-29T11:43:00.000Z","path":"2014/03/29/eopl.html","text":"概述很多学习计算机的同学都知道有一本号称魔法书的经典教材叫作《SICP》，《计算机程序的构造和解释》，MIT的计算机入门课程用的教程。这本书内容广泛而深邃，从出版几十年来影响了很多程序员。今天介绍另外一本我认为也是魔法书的教材，叫做《Essential of Programming Language》，简称EOPL，当然能获得简称的书都是不简单的。这本书虽然也年代久远，但是知名度不如SICP高。其作者是Dan Friedman，就是那位王垠同学的导师。这位程序语言领域的大牛写过很多Scheme相关的书籍，比如《The Little Scheme》系列，这个系列广受好评，可能很多人都读过。 我读的是EOPL3，据说这个版本稍微有点冗长，不过我还没读过前面的版本，所以对此不好评价。EOPL主要关注程序语言的方方面面，一共分为9章。这本书的讲解方式是先稍微概述主题，然后会有相关语法的定义，然后是关键代码的实现。这里同样采用了Scheme来讲解。用Scheme的好处的我们可以站在一个更抽象的角度来编写程序(Scheme如此强大，可以定义自己的语法，比如这里面的define-datatype和sllgen)。你可以看到这本书在反复折腾各种解释器，里面都是在往一个简单的解释器添加各种特性。 预备基础阅读这本需要一些简单的Scheme基础，不过对于有一些编程经验的人来说不难。我推荐这本Teach Yourself Scheme in Fixnum Days。Scheme的基本元素很少、内核简单（用Scheme写一个能自身的元解释器非常容易），这和象棋有些像：规则简单，组合变化多。至少需要了解以下Scheme的基本内容 递归思想递归不只是理解程序的一种方式，同样也是写程序的一种方式。在EOPL中到处都是递归，解释器执行的过程是递归，里面的Checker也是递归。递归无处不在。 高阶函数在函数式编程语言中，函数和变量一样也是一等公民。在Scheme里函数可以接收函数作为参数，可以把函数作为返回值。在EOPL中的envrioment可以用函数来表示。 代码即数据 数据即代码抛开效率不说，用List可以表示很多数据结构。用Scheme的一个好处，就是代码和数据几乎没有界限，比如Parser部分，因为书里自带的sllgen如此强大，要修改语法的定义是如此的简单。而Parser出来的结果就是语法树，这语法树同样是个层层嵌套的表，解释器把这个作为输入就行了。 各章内容Abstraction前两章都是基础准备，介绍了如何用递归来做抽象，包括定义和相关数据结构的实现。比如Enviroment，这不过是在一个小的envrioment上添加一个新的绑定。仔细思考那种用高阶函数的表示方法，这在以前的语言中不常见。 Expression基本的解释器，但这个解释器是后面章节的基础。到这里这个简单的语言已经可以支持递归了。 State实现了一个简单的store，用来映射variable到value。接着讲述call-by-value, call-by-reference。到这里你可以看到程序语言中指针到底是个什么东西，以及这到底是如何实现的。 CPSCPS内容比较难理解，但是CPS也是一个很有用的概念。可以看到使用CPS使得程序的空间固定，如何使用CPS来实现多线程。后面一章也是关于CPS的，实现了一个通用算法来进行CPS转换。 Type System为语言添加类型的好处，类型推倒如何实现，用替换法来做的一个简单的Type Checker。 Module如何从语言层面支持Module，以及面向接口编程。 OO面向对象和接口是如何实现的，在这里OO的实现看起来是有点繁杂，通过实现OO来看清楚本质。 习题这本书有很多习题，每一个题目都有相应的星号标示难度，三颗星的习题大部分还是需要很多思考。这里大部分习题都是需要coding，在解释器里添加一些新的特性，往往需要一些简单的代码修改即可。 我做了大部分习题，https://github.com/chenyukang/eopl，不敢保证全是正确的代码，可供参考。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"}]},{"title":"关于随机数","date":"2014-03-06T11:43:00.000Z","path":"2014/03/06/random-number.html","text":"随机数代表着不确定性，其在计算机中广泛使用，比如用作加密的key、密码的生成、模拟，扑克游戏中，还有一些经典的算法(比如Monte Carlo)依赖随机数的产生。以下是一些随机数相关的问题简单总结。 随机数产生，真随机数和伪随机数生成器随机数的产生是一个很有趣的问题。我们希望只通过计算机来产生随机数的时候会有一些困难，计算机擅长做确定的事情，按照制定的指令去依次执行。有两种产生随机数的方法，真随机数和伪随机数，这两种有各自的优点和缺点。 伪随机数生成器(PRNG)，顾名思义产生的不是严格意义上的随机数，一般是通过一些数学公式(或者计算好的表)来产生。比如简单的Linear congruential generator，可以用来产生伪随机数。伪随机数的行为是可被预测的，但是在统计意义上来说是随机的。因为这个特点其所以使用范围有限，比如一些模拟程序。而且伪随机数有可能出现固定的周期，比如下面这两幅图分别是通过真正的随机数产生器和Windows下面的PHP的伪随机数生成器产生的Bitmap，可以清楚地看到右边的那副图有规律可循。 另外如Borland随机数生成器Random的实现:long long RandSeed = #### ;unsigned long Random(long max)&#123; long long x ; double i ; unsigned long final ; x = 0xffffffff; x += 1 ; RandSeed *= ((long long)134775813); RandSeed += 1 ; RandSeed = RandSeed % x ; i = ((double)RandSeed) / (double)0xffffffff ; final = (long) (max * i) ; return (unsigned long)final;&#125; 可以看到Random的最初一个随机数依赖于seed，后一个随机数依赖前一个随机数。 真随机数生成器(RNG)，通过向计算机中引入一些不可预测的物理信息，比如键盘敲击和鼠标移动等。所以真随机数才是很难预测的或者根本来说不可预测。每个操作系统的实现有各自的区别，比如Linux中产生随机数引入了物理噪音作为输入，比如mac地址可以用来初始化entropy pool，随机源可以加入中断时间，硬盘的寻址时间等等。接口是/dev/random、/dev/urandom、get_random_bytes()，其中get_random_bytes在内核中使用。/dev/random和/dev/urandom的区别是/dev/random强度更大并且是阻塞的，因为要收集更多熵。 随机数的使用涉及到随机数的程序要特别小心。比如一个很简单的程序，我们知道C语言中的rand()产生的随机数是有范围的，0～32767，如果我要生成范围在0～10的随机数如何做？可能你会简单认为rand()%10可以得到(惭愧我以前也这样用的)，但是这真的是随机的吗？如果你把0～32767的所有数字依次%10，统计一下可以发现有的数出现的次数要大一些，因此最后出现某些数的概率相应的要大一些。 另外一个思考题，给一个rand()可以产生[1, 5]之间的随机整数，利用这个rand产生[1, 7]之间的随机整数？ 另写一个抽奖程序，从30w个用户中随机抽取10w个中奖用户？ 写个好的洗牌程序不容易 写一个对的洗牌程序看起来很容易，其实不然。Robert Sedgewick说过： &quot;That&apos;s a pretty tough thing to have happen if you&apos;re implementing online poker. You might want to make sure that if you&apos;re advertising that you&apos;re doing a random shuffle that you go ahead and do so.&quot; —Robert Sedgewick, Professor of Computer Science, Princeton 比如ASF Software在多年前写的一个流行的网上扑克游戏，其中的洗牌程序是这段Pascal代码： procedure TDeck.Shuffle;var ctr: Byte; tmp: Byte; random_number: Byte;begin &#123; Fill the deck with unique cards &#125; for ctr := 1 to 52 do Card[ctr] := ctr; &#123; Generate a new seed based on the system clock &#125; randomize; &#123; Randomly rearrange each card &#125; for ctr := 1 to 52 do begin random_number := random(51)+1; tmp := card[random_number]; card[random_number] := card[ctr]; card[ctr] := tmp; end; CurrentCard := 1; JustShuffled := True;end; 可以分析一下这里的好几处问题，这里的洗牌算法也有问题，52!个排列出现的概率不一样。拿三张牌来作为例子就明白了。 for (i is 1 to N) Swap i with random position between 1 and N 可以看出231, 213, 132出现的次数要多一些，因此相对应的概率也大。 正确的洗牌程序算法是： for (i is 1 to N) Swap i with random position between i+1 and N 一个32位的数作为seed，对于伪随机长生器是有问题的，因为如果给定seed伪随机产生器的行为是可以预测的。32的seed的所有可能值的个数为2^32个，这相比52!(8.0658 * 10 ^ 67)小得很多。所以对于32位的seed，甚至可以用蛮力法来攻破。 其他摘自&lt;&lt;思考的乐趣&gt;&gt;10个人坐在一起谈天，突然他们想知道他们的平均年薪是多少，但每个人都不愿意透露自己的工资数额，有没有什么办法让他们能够得到答案，并不用担心自己的年薪被曝光？一个简单的协议模型，当然与随机数有点关系。 参考： Wiki: Random number generation。 How We Learned to Cheat at Online Poker: A Study in Software Security。 顾森, 思考的乐趣。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Algorithms","slug":"Algorithms","permalink":"http://chenyukang.github.io/tags/Algorithms/"}]},{"title":"LeetCode: anagrams","date":"2014-01-14T11:43:00.000Z","path":"2014/01/14/leetcode-anagrams.html","text":"LeetCode这个题目想出来一个好办法，题目的意思是输入一组字符串，把他们按照Anagrams归组出来，Anagrams的意思是字母相同，排列不同的两个字符串。 比如：aabcbaaccbaa 这些都是anagrams的。如果两个字符串是满足这种关系的，那么把字符串排序后的结果一定相同。因此想到用一个map去存来。 class Solution &#123;public: vector&lt;string&gt; anagrams(vector&lt;string&gt; &amp;strs) &#123; typedef map&lt;string, vector&lt;string&gt; &gt; Dict; vector&lt;string&gt; res; Dict S; for(int i=0; i&lt;strs.size(); i++) &#123; string tmp = strs[i]; sort(tmp.begin(), tmp.end()); if(S.find(tmp) == S.end()) &#123; S[tmp] = vector&lt;string&gt;(1, strs[i]); &#125; else &#123; S[tmp].push_back(strs[i]); &#125; &#125; for(Dict::iterator it = S.begin(); it != S.end(); ++it) &#123; vector&lt;string&gt;&amp; vec = it-&gt;second; if(vec.size() &lt;= 1) continue; res.insert(res.begin(), vec.begin(), vec.end()); &#125; return res; &#125;&#125;;","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Algorithms","slug":"Algorithms","permalink":"http://chenyukang.github.io/tags/Algorithms/"}]},{"title":"正则表达式匹配和NFA/DFA","date":"2014-01-04T11:43:00.000Z","path":"2014/01/04/regular-expression-matching-dfa.html","text":"正则表达式匹配是一个经典问题，这里有一个问题。实现isMatch，其中.表示任意一个字符，*表示0个或者任一个前面的字符： isMatch(\"aa\",\"a\") → falseisMatch(\"aa\",\"aa\") → trueisMatch(\"aaa\",\"aa\") → falseisMatch(\"aa\", \"a*\") → trueisMatch(\"aa\", \".*\") → trueisMatch(\"ab\", \".*\") → trueisMatch(\"aab\", \"c*a*b\") → true 这是一个正则表达式问题的简化版本只有.和*，可以用递归来解决。正则表达式涉及到自动机理论，顺便再复习一下当年没好好学的东西。查找一番后发现了这篇Russ Cox写的文章非常好(这家伙写了不少文章，xv6里也有他的代码，现在在为Go项目工作)。于是我也尝试着用DFA来解决这个问题。 DFA和NFA的概念首先对于没一个正则表达式都有一个对应的DFA可以来表示, DFA是Deterministic Finite Automaton的简称，还有NFA(Non-deterministic Finite Automata)。NFA对于一个字符的输入有可能存在多个以上的状态转移，而DFA对于没一个输入只存在一个选择。所以每一个NFA都可以转化为一个DFA，但是一个DFA可以转化为多个NFA。我们来看一个例子: 对于正则表达(a|b)*abb的NFA和DFA分别表示为： DFA的状态数目和NFA一样，但是一般实践过程中DFA的状态转移要多，所以DFA相对来说要难构造一些，同时DFA比NFA需要的内存空间更大。正因为在NFA中一个状态可能向多个状态转移，在极端的情况下其效率比不过DFA。更多关于正则分类可以参考正则表达式引擎及其分类。 对于NFA不同的实现效率会不一样，这也是Russ的文章里所说的。Russ的文章里面介绍了Thompson NFA算法实现(没错就是发明C的那神)，一些老的Unix工具是用的这个算法，比如Awk，Tcl，GNU grep等，而一些更通用的编程语言用的是基于回溯的一种NFA实现，比如Perl/Python。通过数据比较，在最坏的情况下用Thompson NFA实现的awk表现比匹配回溯的NFA要好很多倍。最坏情况下的复杂度不一样，回溯NFA是O(2^N)，而Thompson的复杂度是O(N^2)。文中的代码可以号好看看，非常简洁的C实现。 一个尝试实现对上面那个问题我尝试着实现了一个程序构建DFA来解决，提交上去完成439个测试用例只用了28ms，相对于递归版本的需要104ms。也可能LeetCode上面的测试数据太少，比较的意义不大。代码长度当然要比递归的长不少。定义State： enum OpType &#123; ZERO_PLUS_ONE, ANY_ONE, MUST_ONE&#125;;struct State &#123; OpType type; int id; char value; bool end; State* prev; vector&lt;State*&gt; next; State(OpType t, int i, char v, State *p) : type(t), id(i), value(v), end(false), prev(p) &#123; if(type == ZERO_PLUS_ONE) next.push_back(this); //匹配任意个 next加上自己 if(p == NULL) prev = this; &#125; void add(State* n) &#123; next.push_back(n); if(type == ZERO_PLUS_ONE &amp;&amp; prev != NULL) //匹配任意，前驱加上当前需要添加的状态 prev-&gt;add(n); &#125;&#125;; 构建DFA的过程如下，注释的部分需要注意： State* construct_dfa(const char* pattern) &#123; if(pattern == NULL) return NULL; const char* p = pattern; State* start = new State(ANY_ONE, Num, '.', NULL); State* cur = start; State* next = NULL; char prev = '.'; Num = 1; while(*p &amp;&amp; *p != '\\0') &#123; if(*(p+1) != '*') &#123; OpType type; char value; if(*p == '*') &#123; type = ZERO_PLUS_ONE; //匹配0个或者多个 value = prev; &#125; else &#123; value = *p; type = *p == '.'? ANY_ONE : MUST_ONE; //匹配任意一个. 或者指定的字符 &#125; next = new State(type, Num, value, cur); prev = *p, p++; &#125; else &#123; next = new State(ZERO_PLUS_ONE, Num, *p, cur); prev = '*', p+=2; &#125; cur-&gt;add(next); cur = next; Num++; &#125; cur-&gt;end = true; // 例如 ab*a*c* 对于 \"a\"， 即使后面几个*, \"a\"也算是一个end， while(cur-&gt;type == ZERO_PLUS_ONE) &#123; cur = cur-&gt;prev; cur-&gt;end = true; &#125; return start;&#125; 匹配的过程就是一个搜索的过程，需要注意避免重复访问，另外如果下一层要访问的为空就可以退出整个搜索过程了，整个代码看这个Gist。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Algorithms","slug":"Algorithms","permalink":"http://chenyukang.github.io/tags/Algorithms/"}]},{"title":"Kernel analysis: Defunct Process","date":"2013-11-23T11:43:00.000Z","path":"2013/11/23/kernel-analysis-process-defunct.html","text":"我发现带着问题去看内核代码比较容易理解。如果一个父进程显示的设置SIGCHLD为Ignore，子进程将自己清理自己。 #include &lt;signal.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;int main() &#123; struct sigaction sa; memset(&amp;sa, 0, sizeof(sa)); sa.sa_handler = SIG_IGN; sigaction(SIGCHLD, &amp;sa, NULL); int pid = fork(); if(pid &gt; 0) &#123; printf(\"parent:%d\\n\", getpid()); sleep(30); &#125; else &#123; printf(\"child:%d\\n\", getpid()); sleep(4); &#125; printf(\"finished\\n\"); return 0;&#125; 我们可以顺便看看内核里面是怎么写的， linux/kernel/exit.c里面这部分是负责进程退出的，我截取了相关的代码： /* * Send signals to all our closest relatives so that they know * to properly mourn us.. */static void exit_notify(struct task_struct *tsk, int group_dead)&#123; bool autoreap; forget_original_parent(tsk); write_lock_irq(&amp;tasklist_lock); /* .... */ &#125; else if (thread_group_leader(tsk)) &#123; autoreap = thread_group_empty(tsk) &amp;&amp; do_notify_parent(tsk, tsk-&gt;exit_signal); &#125; else &#123; autoreap = true; &#125; tsk-&gt;exit_state = autoreap ? EXIT_DEAD : EXIT_ZOMBIE; /*..... */ /* If the process is dead, release it - nobody will wait for it */ if (autoreap) release_task(tsk);&#125; 其中有一段是判断是否autoreap，我们继续可以看看linux/kernel/signal.c里面的do_notify_parent函数: bool do_notify_parent(struct task_struct *tsk, int sig)&#123; struct siginfo info; unsigned long flags; struct sighand_struct *psig; bool autoreap = false; /* .... */ if (!tsk-&gt;ptrace &amp;&amp; sig == SIGCHLD &amp;&amp; (psig-&gt;action[SIGCHLD-1].sa.sa_handler == SIG_IGN || (psig-&gt;action[SIGCHLD-1].sa.sa_flags &amp; SA_NOCLDWAIT))) &#123; /* * We are exiting and our parent doesn't care. POSIX.1 * defines special semantics for setting SIGCHLD to SIG_IGN * or setting the SA_NOCLDWAIT flag: we should be reaped * automatically and not left for our parent's wait4 call. * Rather than having the parent do it as a magic kind of * signal handler, we just set this to tell do_exit that we * can be cleaned up without becoming a zombie. Note that * we still call __wake_up_parent in this case, because a * blocked sys_wait4 might now return -ECHILD. * * Whether we send SIGCHLD or not for SA_NOCLDWAIT * is implementation-defined: we do (if you don't want * it, just use SIG_IGN instead). */ autoreap = true; if (psig-&gt;action[SIGCHLD-1].sa.sa_handler == SIG_IGN) sig = 0; &#125; if (valid_signal(sig) &amp;&amp; sig) __group_send_sig_info(sig, &amp;info, tsk-&gt;parent); __wake_up_parent(tsk, tsk-&gt;parent); return autoreap;&#125; 可以看到如果父进程对子进程的生死不关心，那么设置autoreap为TRUE，甚至这个信号也可以不发送了。","tags":[{"name":"Linux","slug":"Linux","permalink":"http://chenyukang.github.io/tags/Linux/"},{"name":"Kernel","slug":"Kernel","permalink":"http://chenyukang.github.io/tags/Kernel/"}]},{"title":"拓扑排序","date":"2013-11-20T11:43:00.000Z","path":"2013/11/20/topological-sort.html","text":"最近在看一些图算法，发现拓扑排序频繁出现，这里写一下自己的一些总结。 拓扑排序是对于有向无环图而言的(DAG)，就是对于这个图所有的点(V1, V2, … Vn)找到一个点序列使得任意边(u, v)， u出现在v的前面。很容易证明，如果一个有向图中有环那么不存在拓扑排序。 现实中的问题首先来看现实中哪些问题需要拓扑排序的，课程排序，编译依赖问题，类似的凡是涉及到相关顺序的时间安排，比如Rails里面的初始化调用了库Tsort来进行排序。Unix中有个命令也叫tsort)，在有的makefile里面还直接使用了这个命令来解决依赖问题。 O(V+E)的算法 拓扑排序的基本算法是用DFS，我们希望把有出度的点尽量排在前面，所以这里需要注意和DFS的区别。比如上面图中的一个DFS访问顺序是: 5 2 3 1 0 4, 但是这不是一个拓扑排序，4需要排在0的前面，5, 4, 0, 2, 3, 1。拓扑排序中需要等迭代完节点的连接邻点后再把当前点压入栈。 #include &lt;iostream&gt;#include &lt;stdio.h&gt;#include &lt;list&gt;#include &lt;stack&gt;using namespace std;class Graph &#123; int V; list&lt;int&gt;* adj; void _topological_sort(int v, bool visited[], stack&lt;int&gt;&amp; stack);public: Graph(int v); ~Graph(); void addEdge(int v, int w); void Topological_sort();&#125;;Graph::Graph(int v):V(v) &#123; adj = new list&lt;int&gt;[V];&#125;Graph::~Graph() &#123; delete [] adj;&#125;void Graph::addEdge(int v, int w) &#123; adj[v].push_back(w);&#125;void Graph::_topological_sort(int v, bool visited[], stack&lt;int&gt;&amp; stack) &#123; visited[v] = true; for(list&lt;int&gt;::iterator it = adj[v].begin(); it != adj[v].end(); ++it) &#123; int u = *it; if(visited[u] == false) _topological_sort(u, visited, stack); &#125; stack.push(v);&#125;void Graph::Topological_sort() &#123; bool visited[V]; stack&lt;int&gt; stack; for(int i=0; i&lt;V; i++) visited[i] = false; for(int i=V-1; i&gt;=0; i--) &#123; if(visited[i] == false) &#123; _topological_sort(i, visited, stack); &#125; &#125; while(!stack.empty()) &#123; int v = stack.top(); stack.pop(); std::cout &lt;&lt; \" \" &lt;&lt; v &lt;&lt; \" \"; &#125; std::cout &lt;&lt; std::endl;&#125;int main() &#123; Graph g(6); g.addEdge(5, 2); g.addEdge(5, 0); g.addEdge(4, 0); g.addEdge(4, 1); g.addEdge(2, 3); g.addEdge(3, 1); cout &lt;&lt; \"Following is topological sort result: \\n\"; g.Topological_sort(); return 0;&#125; 唯一性如果一个DAG的拓扑排序中任意连续的两点都是可连通的，那么这个序列也就是DAG的Hamiltonian路径，而且如果DAG图的Hamiltonian路径存在，那么拓扑排序就是唯一的。否则如果一个拓扑排序结果不是Hamiltonian路径，那么就存在多个拓扑排序结果。 其他图算法的预处理 DAG的强连通分支问题先得到拓扑排序，形成逆向图(所有边与原来方向相反)，然后根据拓扑排序依次再进行DFS。 DAG的最短路径问题，这可以在O(V+E)复杂度解决最短路径问题。同样类似的算法适用与DAG的最长路径问题，给定一个点求DAG中的各个点与给定点之间的最长路径。最长路径问题要比最短路径问题难，因为最长路径问题没有最优子结构，对于通用的图的最长路径算法还是NP难的问题。","tags":[{"name":"Algorithms","slug":"Algorithms","permalink":"http://chenyukang.github.io/tags/Algorithms/"}]},{"title":"Do Presentation like a Geek","date":"2013-10-05T11:43:00.000Z","path":"2013/10/05/do-presentation-like-a-geek.html","text":"很多程序员不喜欢做PPT之类的东西，我也不喜欢。这有另外的原因是一直没找到一个合适的工具，Linux下PPT是个悲剧，Latex学习成本又大了点。上次在公司分享的时候偶然找到了这个叫做showoff的工具，熟悉了大概半个小时就上手了，迅速把自己的PPT完成。 showoff是Ruby写的一个适合程序员写PPT的工具，你可以用类似Markdown的语法编辑文本文件，同时在terminal下开一个服务，浏览器访问localhost:9090可以预览的成果。这个过程非常类似用Jekyll来写博客。当然最后可以导出成PDF格式的，或者直接在浏览器上展示。 安装Showoff安装非常简单: $ gem install showoff$ git clone (ppt-repo)$ cd (ppt-repo)$ showoff serve 使用我觉得showoff一些特别好的特点是: 纯文本编辑 (对程序员有吸引力) 嵌入代码方便，高亮代码 嵌入图片方便 可执行内嵌Javascript，Coffeescript 或者Ruby代码，并显示结果。(对程序员来说很不错) 一些显示特效 赶快看看example目录吧，你就能上手了。","tags":[{"name":"Tools","slug":"Tools","permalink":"http://chenyukang.github.io/tags/Tools/"},{"name":"Ruby","slug":"Ruby","permalink":"http://chenyukang.github.io/tags/Ruby/"}]},{"title":"初到美国","date":"2013-09-26T11:43:00.000Z","path":"2013/09/26/gotous.html","text":"很久没有更新了，这段时间挺忙的。公司让在美国待一段时间，所以7月份开始办理相关签证，由于自己粗心大意导致跑签证馆好几次。第一次是因为没有填写完教育信息，签证馆挂着个牌子写着 The main difference between a cat and a lie is that a cat only has nine lives. - Mark Twain 我这还不算撒谎吧，他们还算通情达理给我个纸条让回来重新填写表。 终于费劲周折前两天到了湾区，我穿着沙滩裤下了飞机，一时特别的困。这边温度19度左右，风又特别的大，感觉有点冷。 当地时间上午11点到的，为了倒时差那天就不能睡觉，所以吃了午饭我和同事骑车到处逛了逛。 这边风景不错，最让人羡慕的是各种树比较多，而且高大茂盛。树上有果子，天上有老鹰。 作为土鳖虽然以前在电视和Google街景上看过美国的房子，不过亲眼来看看还是忍不住羡慕嫉妒，可恶的美帝，这让我们这些省吃俭用买个小笼子的共产主义奋斗者情何以堪。 这边亚洲人多，华人占的比例应该也很大。跑去大华超市附近买东西，那一片和上海没什么区别。 在这边待到11月中旬回去，打算周末再出去溜达一下，主要是自己还不会开车，在这边没车就基本残废。 我前一两个月开始看本书《Essentials of Programming Languages》，顺便做做里面的练习，写了不少Scheme代码，这些习题基本都是往一个解释器里面添加一些东西。总得来说挺好玩的，做到第五章了。代码在Github上：https://github.com/chenyukang/eopl。","tags":[]},{"title":"Metaprogramming Ruby","date":"2013-08-24T11:43:00.000Z","path":"2013/08/24/meta-programming-ruby.html","text":"『Metaprogramming Ruby』这本书看了两遍，从这本书里获取了一些乐趣。技术书籍就应该这样简明扼要，寓理于事。通过一个显示中的例子引入问题，展示元编程的解决办法， 顺带介绍一下用到相关技术的gems。 下面这些不是书评，只是我在看第二遍的时候的一些简单的择要，用于自己的记忆和检索。 Introduction Meteprogramming is writing code that writes code 鬼城和集市，很多语言的运行环境在执行的时候已经固定，一片死寂。而支持Metaprogramming的语言的执行环境是充满活力的集市。很好的比喻。 动态元编程和静态元编程，C++的template属于静态元编程。 The Ruby Object Model Class定义永远是开放的，你能重新定义任何类或者给类加上一些新的东西。注意MonkeyPatch可能导致的Bug。 分清楚instance_method和class_method， Class也是对象。与C#/Java的Class不一样的地方，Ruby允许在代码运行期间操作类相关的信息，比如增加method或者重新定义method。 Methods static type checking, for example, if you call simple_talk() on Layer object that has no such method, the compiler protests loudly. call method dynamic using send(). define_method generates instance method dynamically, to_s vs to_sym. Ghost method, method_missing. 过多是用会不会拖慢执行效率，要顺着继承链一直查找method。 注意method_missing可能导致的死循环调用。 和继承过来的method之间的冲突， undef_method解决。 Blocks class, module, and def change scope. Flat Scope. instacen_eval/instance_exec create block : lambda/proc/Proc.new lambda vs Proc return in Proc also return from the scope. lambda’s argument checking is more strict. A event DSL, a elegent example for blocks. Class Definitions A Ruby class definition is actually regular code that runs. class_eval vs instance_eval class_eval both changes self and current class Eigenclass, the metaclass of a object three way to define class method Around alias Code writes code The powerful weapon: eval A good example: add_attribute Three ways to express this idea Active record Validations alias_method_chain Dynamic attributes, define read/write/question Dynamic Methods for all the columns in databases, for performance. Lesson learned, performance/complexity/readable trade-offs. Metaprogramming safely Defusing Monkeypatches, make it explicit with module, check it before patche, add warning messages.","tags":[]},{"title":"Learning Ruby with Ruby Warrior","date":"2013-07-14T11:43:00.000Z","path":"2013/07/14/ruby-warrior.html","text":"Ruby上总有好玩的东西，偶然看到这个RubyWarrior，玩了一把感觉还有些意思。这个有些像我原来介绍的RubyRobot,不过更像之前的Wumpus，看来我对这种游戏有些兴趣。 Ruby新手边玩边熟悉了语言。需要代码的可以clone下来看看，如果只是玩可以gem装上，然后运行rubywarrior就开始练级了。 gem install rubywarrior 我现在只是完成了初学者模式，这里的AI还比较简单，主要实现一个函数就行了。分为两种模式，第一种只用对付当前的场景，第二种为epic(史诗?)模式，要从1~9连续闯关。 我的平均成绩是C，所有级的代码放在Github上了。 Level Score: 27Time Bonus: 18Level Grade: FTotal Score: 374 + 45 = 419Your average grade for this tower is: CLevel 1: SLevel 2: CLevel 3: BLevel 4: BLevel 5: DLevel 6: FLevel 7: BLevel 8: FLevel 9: F 中级模式是二维的地图，所以更有挑战。 这里有一个前端，不过我还没用过。 这还有人用神经网络的方法来做的，可以学习一下，:)。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"}]},{"title":"初学Rails","date":"2013-07-06T11:43:00.000Z","path":"2013/07/06/studying-rails.html","text":"我在2012年左右开始关注Ruby，平时有的时候会用Ruby写一些脚本。这是一个很活跃的社区，Ruby火起来也不是最近的事。可贵的这里总是有一些新的东西出来，比如我现在的这个博客是基于jekyll和Github的。Ruby的迅速崛起更多的还是因为Rails，所以学习Rails也是了解Ruby的一个好方法。 最近为公司内部所配置的GitLab是Rails开发的。另外我自己也在公司做一些Web程序，其实是很简单的东西，就是把每天晚上跑的程序各种测试结果展示出来(nightly/weekly/coverage等等)。我选用Rails来开发，果然一个最初的版本很快就做出来了。在初学Rails的过程中让我体会到了一些web开发的乐趣。 Rails适合小团队的快速开发，其中的一些理念是： Encourage Agility –鼓励敏捷开发 Convention Over Configuration –约定高于配置 DRY –不要重复自己 Less Code –更短小的代码 正是这些开发原则使得Rails开发如此简单明了(当然前提是你按照Rails约定的方式来)。我原来做过一些web开发服务器方面的工作，在那种模式下开发需要每个人各司其责。但是Rails不同，在ActiveRecord这样的抽象层基础上你需要关注的数据库方面的东西少了，明确的MVC模式把你需要关注的撤离开来，这种复杂程度一个人完全能掌控下来。当然这种高度的抽象是以牺牲一部分效率为前提的，但其实在很多时候开发效率的优先级是高于实现效率的，这也是Ruby所选择的一个理念。 学习Rails的过程中这些资料是非常好的，这几本书都面向初学者，写得非常详细： Ruby On Rails教程 Begining Rails 3 Agile Web Development with Rails 当我熟悉了一些基本概念的时候，我就可以看Github上各种Rails的代码了，约定高于配置的另外一个优点就是所有Rails开发的东西结构看起来是一样的，便于不同开发者之间的交流。 Rails的一个比较突出的问题是版本之间的兼容性比较差。 比如Begining Rails里面Plugin那章的那个例子，在Rails3.1系列开始已经不支持那种方式的plugin了，其中用到的class_inheritable_accessor也变成了class_attribute。这种问题非常多，另外据说最新的Rails4.0改动也很大。 这是一个老问题，在早起的版本就有人在这上面都发生过争吵。一些人说变化太频繁，不容易学习。其中这篇“WTH is happening to Rails?” I’ll tell you解释了一下Rails如此的原因，并称这种改变位『成长』。 学习Rails的路还比较长，后面继续。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Rails","slug":"Rails","permalink":"http://chenyukang.github.io/tags/Rails/"}]},{"title":"高效的Crit-bit Tree","date":"2013-05-18T11:43:00.000Z","path":"2013/05/18/critbit.html","text":"最近了解到有这么一种数据结构，想拿来在工作中做一些事情，结果效果不好。原来我的理解有一些不对。在这里记录一下。 Crit-bit tree是一种特别的树结构，一般用于存放字符串。Critbit tree是一种BitWise tries，其树的深度为O(longest-length)，有点像二叉树，不过对于字符串做分支检测的时候代价很小。 Crit-bit快速高效的支持下面的一些操作： 插入一个字符串 测试一个字符串是否在树里 删除一个字符串 查找出树中所有以某个字符串开始的所有字符串 和hash有点像，不过hash对于第四点没这么方便。我做了一些性能对比，测试数据是/usr/share/dict/words里面的所有单词，同时做插入和查询的操作。具体测试代码看这里，结果是： critbit 11.6MB 23.34 set 21.6 MB 45.85s trie 332.3 MB 17.84s 从中可以看到trie树的内存消耗是比较大的，但是查找速度最好。critbit的内存消耗真的非常小，如果只是把这里所有的单词存下来都要4MB的内存，其查找的速度虽然和trie树比起来差一些，但还是相当不错。 好好的研读了crit-bit的实现和这篇文章，里面技巧挺多的。critbit的结构很简单: typedef struct&#123; void* child[2]; uint32 byte; uint8 otherbits;&#125;critbit0_node;typedef struct&#123; void* root;&#125;critbit0_tree; 其中child是void*指针，对于树的内部节点其指向的是子节点，对于叶子节点其指向的是字符串。byte用来表示当前节点匹配的长度，otherbits是一个mask，可以用来快速的取得不同最高位，在查询的过程中用这个来做branch。 具体的代码分析这里比较少，最复杂的函数是critbit0_insert。在插入过程中需要记录下来byte和otherbits,并且更新前面的父节点。​ 然后再继续插入后的结构变化是: 下面记录一下其中的几个技巧。 align指针最后一位用来做标志树的结构需要一个标志变量来表示是否是内部节点或者是叶子节点。这个变量如何能省掉？看上面的void root和void child, 都是即可以用来指向字符串又可以指向节点，一般申请过来的指针变量都是align好的，所以最低位为0，这是可以拿来用的。因此对于内部节点我们可以在这个位上设置为1，只是要注意在通过这个指针取值的时候需要减回去。 a = (posix_memalign((void**)&amp;x, sizeof(void*), ulen+1)) posix_memalign在这里用的是sizeof(void*)，其实就和malloc一样了，因为一般Linux上编译器和C库已经处理了对齐问题。 因此在查找的这段代码里是这样的： int critbit0_contains(critbit0_tree*t, const char* u) &#123; const uint8* ubytes= (void*)u; const size_t ulen= strlen(u); uint8* p= t-&gt;root; if(!p) return 0; while( 1 &amp; (intptr_t)p )&#123; //内部节点? critbit0_node* q = (void*)(p-1); //取得真正的指针 uint8 c = 0; if(q-&gt;byte &lt; ulen) c = ubytes[q-&gt;byte]; const int direction= (1+(q-&gt;otherbits|c))&gt;&gt;8; p = q-&gt;child[direction]; &#125; //叶子节点 return 0 == strcmp(u, (const char*)p);&#125; 取最高位的非0bit在插入过程中计算最高位的不同位。 newotherbits = p[newbyte]^ubytes[newbyte]; 其实也可以用一个for循环来计算，不过这里是这样实现的: newotherbits |= newotherbits&gt;&gt;1;newotherbits |= newotherbits&gt;&gt;2;newotherbits |= newotherbits&gt;&gt;4; 这相当于是计算不小于它的2的整数次幂，对于32bit的代码可以看看这里的next_pow_of_2。 文章和代码，其中那篇文章有详细分析。 我的测试代码,trie/set等。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Critbit","slug":"Critbit","permalink":"http://chenyukang.github.io/tags/Critbit/"}]},{"title":"迁移到Git","date":"2013-05-09T11:43:00.000Z","path":"2013/05/09/git-command.html","text":"公司这群人终于打算从CVS迁徙到Git上了，CVS这套公司用了六年。CVS这是90年代的东西，我们不能因为年代久远而嫌弃这，只是CVS这东西对于一个比较大的项目来说创建分支是相当漫长，大多数程序员都没有耐心的。迁徙计划虽然纸上谈兵了很长时间，直到现在才终于打算行动。 上午把Git在服务器上搭建好，主要卡在一个Git的命令上，因为一些权限问题。 git init --bare --shared=group ; --shared=group forget this Git的web接口是用的是ViewGit，自己做了一些修改，加上GeShi来高亮代码，并使用了GitStats来做代码统计。GitStats统计的项目非常多，看起来很直观。 稍微记录一下常用的一些git命令。 这里有一个最直观的Git学习的地方leanGitBranch。 检出仓库 git clone repo 更新 git pull 提交到远程 git push提交到本地 git commit -am”log message” 创建branch git branch branch_name切换branch git checkout branch_name合并branch git merge branch_name图形界面 gitk解决冲突 git mergetool撤销上一次commit git revert HEAD撤销上上次commit git revert HEAD^ 撤销上一次的merge git reset –hard HEAD^","tags":[{"name":"Tools","slug":"Tools","permalink":"http://chenyukang.github.io/tags/Tools/"}]},{"title":"一些包管理命令","date":"2013-04-17T11:43:00.000Z","path":"2013/04/17/apt-usage.html","text":"包管理器是Linux上一个经常用的东西，我觉得下面这几个命令是非常有用的，便于查询包的状态，或者搜索我该安装哪些包。 apt-cache用来根据名字查询软件包，比如apt-cache search vim查询vim相关的。 apt-file用来根据某个文件查询软件包，这在编译程序的时候非常有用，可以通过所需要的头文件去查询要安装的东西，可以避免去Google了。注意使用之前需要安装并update。 sudo apt-get install apt-file sudo apt-file update 比如我在编译某个软件的时候找不到&lt;readline/readline.h&gt;，使用下面的命令来查询一下： sudo apt-file readline.h 结果中有这么一行，那么我就知道继续安装libreadline5-dev库就行了。 dpkgapt是基于dpkg开发的，dpkg是更古老更底层的一套工具，Debian系统管理器的基础。 dpkg -l 列出所有已经安装的包 dpkg -s vim 列出包vim的状态 dpkg -L vim 列出本地所有vim相关联系的文件 dpkg -S vim 搜索所属包的内容 brewMac下推荐Brew来替代apt，大部分的开源包都有对应的地址源了。我没使用过MacPorts，无法比较这两套的差别。不过我个人很喜欢的一点是brew所有安装的东西都在brew -prefix/Cellar这个统一目录下， brew相关的命令： brew list — 列出已安装的软件 brew update — 更新Homebrew brew home — 用浏览器打开 brew info — 显示软件内容信息 brew deps - 显示包依赖","tags":[{"name":"工具","slug":"工具","permalink":"http://chenyukang.github.io/tags/工具/"}]},{"title":"巧妙的XOR Link List","date":"2013-04-11T11:43:00.000Z","path":"2013/04/11/xor_link_list.html","text":"XOR Link List, 只用一个附加的变量来实现双向链表。首先xor本身是个稍微有点难理解的操作。xor有下面的一些特性: A ^ 0 = A A ^ A = 0 A ^ B = B ^ A (A ^ B) ^ A = B (B ^ A) ^ B = A 注意最后两条，这是XOR Link List的关键，这也是通过xor操作来实现swap的关键。 void xorSwap (int *x, int *y) &#123; if (x != y) &#123; *x ^= *y; *y ^= *x; *x ^= *y; &#125; &#125; 这里注意需要判断x!=y，否则如果传入的是相同的指针，最后所指向的变量被设置为0了。 通过最后两条联想到双向链表中的两个指针的实现，一般如下图所示： ... A B C D E ... –&gt; next –&gt; next –&gt; next –&gt; &lt;– prev &lt;– prev &lt;– prev &lt;– 如果把next和prev用一个变量替换还能实现前向和后向遍历，那就节省了一个变量的空间。 ... A B C D E ... &lt;–&gt; A⊕C &lt;-&gt; B⊕D &lt;-&gt; C⊕E &lt;-&gt; 比如当前在B节点，其pointer变量为A⊕C，如果前面的A地址保存下来然后做运算(A⊕C)⊕A -&gt; C，这样就得到下一个节点指针，反向遍历同样如此。当然其缺点是逻辑复杂了，删除其中的某一个节点也不方便(删除头和尾要好点)，遍历的时候需要保存上一个节点。这样看来为了省一点点空间这样实现似乎有点不值，在大部分情况下这样的一个pointer的节省并没什么用，不过这其中的细节有趣、巧妙。 同样上面的xorSwap对于现代的CPU来说也没什么优化，这样的代码只是更加不便于编译器来实现指令级别的优化。这种类型trick的东西还是要避免使用才好。 自己稍微写了一下，代码在这个Gist。","tags":[{"name":"C/C++","slug":"C-C","permalink":"http://chenyukang.github.io/tags/C-C/"},{"name":"XorLinkList","slug":"XorLinkList","permalink":"http://chenyukang.github.io/tags/XorLinkList/"}]},{"title":"Jekyll使用MathJax来显示数学式","date":"2013-03-03T11:43:00.000Z","path":"2013/03/03/try-mathjax.html","text":"使用Jekyll写作文章的时候有可能需要内嵌一些数学公式, MathJax就是用来干这个的，试用了一下感觉非常方便。步骤如下: 修改html头部。 在每个页面开头加上这么一句，在Jekyll下可以通过修改default.html加上。 &lt;script type=\"text/javascript\" src=\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\"&gt;&lt;/script&gt; 本地安装kramdown。 因为rdiscount和默认的markdown在解析带公式文件的时候都会出现一些问题，所以最简单办法还是安装kramdown。$ gem install kramdown 修改_config.yml，把markdown选项修改为: markdown: kramdown 然后在发布的时候就可以使用$$来把需要显示的数学式子扩起来。像这样： $$a^2 + b^2 = c^2$$ 发布出来就是漂亮的公式了。 $$a^2 + b^2 = c^2$$ $$x^my + a^2 + b^2 = c^2$$ $$x_\\mu$$ 一些更酷的例子： $$ J_\\alpha(x) = \\sum\\limits_{m=0}^\\infty \\frac{(-1)^m}{m! \\, \\Gamma(m + \\alpha + 1)}{\\left({\\frac{x}{2}}\\right)}^{2 m + \\alpha} $$ $$ \\frac{1}{\\Bigl(\\sqrt{\\phi \\sqrt{5}}-\\phi\\Bigr) e^{\\frac25 \\pi}} =1+\\frac{e^{-2\\pi}} {1+\\frac{e^{-4\\pi}} {1+\\frac{e^{-6\\pi}}{1+\\frac{e^{-8\\pi}} {1+\\ldots} } } } $$ $$ \\left( \\sum_{k=1}^n a_k b_k \\right)^2 \\leq \\left( \\sum_{k=1}^n a_k^2 \\right) \\left( \\sum_{k=1}^n b_k^2 \\right)$$ $$\\begin{aligned}\\nabla \\times \\vec{\\mathbf{B}} -\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{E}}}{\\partial t} = \\frac{4\\pi}{c}\\vec{\\mathbf{j}} \\ \\nabla \\cdot \\vec{\\mathbf{E}} = 4 \\pi \\rho \\\\nabla \\times \\vec{\\mathbf{E}}\\, +\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{B}}}{\\partial t} = \\vec{\\mathbf{0}} \\\\nabla \\cdot \\vec{\\mathbf{B}} = 0 \\end{aligned}$$ 不过我可能永远用不到这么复杂的表达式 :). 另外今天找了一个markdown-mode.el，在Emacs下编辑Markdown文件又方便了不少。 Mac下的Markdown编辑器Mou也是非常不错的。","tags":[{"name":"Jekyll","slug":"Jekyll","permalink":"http://chenyukang.github.io/tags/Jekyll/"}]},{"title":"读bootstrap scheme","date":"2013-02-15T11:43:00.000Z","path":"2013/02/15/reading-bootstrap-scheme.html","text":"For a List in Lisp, Car is the First, Cdr is the Rest, and Lisp means List-Proccessing. 前段时间偶然在网上看到这个bootstrap scheme这个开源程序，读来简洁明了，十分有趣。我对scheme有一点了解，毕竟以前看过一段时间SICP，自己做练习的代码也是scheme写的。scheme本身属于Lisp方言，语法也极其简单，学习起来非常快的。 看看这个简单的scheme实现，不禁再次感叹递归的优美。Lisp这样的语言直接使用语法树结构来表示程序，不仅使得表示出来的程序异常简洁，就是用C语言来实现这种语言的解释器代码也看起来非常优美。在这里区区2000行的C语言代码，当然没有完整地实现scheme所有的内容，甚至只支持了整数。但是包含scheme的基本语法层面的东西，还有lambda。抛开实现的效率不说，递归是易于编写和理解代码的一种方式，这里语法是递归的，parser是递归的，eval也是递归的。在这里所有的东西都是object，没有显示的列表结构，但是嵌套的pair里蕴含着列表和树的关系。在parse阶段建立好一个以object为基本元素的树结构，做eval的时候顺着往下走就是了。 推荐对语言实现感兴趣的同学阅读一下这个代码，如果对scheme不了解也没关系，用一个小时看几个scheme程序基本就了解了。再看这个解释器，你就懂了代码是如何被运行的。 参考scheme-from-scratch-introduction 图片来自Draperg’s cartoons","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Lisp","slug":"Lisp","permalink":"http://chenyukang.github.io/tags/Lisp/"}]},{"title":"Emacs会说话","date":"2013-01-27T11:43:00.000Z","path":"2013/01/27/emacs-speaking-now.html","text":"出来工作之前我从来没认真考虑过我的英语口语问题，大学时候的四级口语考试C级也没让我意识到自己的发音比较烂。学了好多年哑巴英语，又因为本人生性有点害羞经常不好意思开口说英语，悲剧早就注定。其实我的英语阅读能力还是可以的，不过工作之后同事们都嘲笑我口语听起来像印度人，据说发音极其古怪。 在Mac下有一个叫做say的命令行程序，我有时候会用来听单词单词发音。这个程序加上-f参数也可以用来朗读整个文件。 say hello wrold say -f demo.txt 前几天突然觉得如果写个Emacs Minor Mode，能在边写单词的时候Emacs就把你写的朗读一遍就好了，Emacs号称能煮咖啡，这点小事当然不在话下。其实除了在公司我也很少写英文，不过这个想法看起来比较好玩，于是动手做了一下。预想的基本功能是实现了，我把它叫做EmacSay-mode，意为在Emacs+Mac+Say下实现的，所以这东西可能不能在Linux下运行。 这也是我第一次学着写一个minor mode，实现起来也很简单。整个不到100行elisp代码。 基本思路就是如果当前输入的字符是空白(或者其他非字母字符)，寻找前面一个字符串，格式化成一个命令行，用start-process或者shell-command来调用。注意start-process会fork出来一个子进程来执行命令，在书写过程中最好还是使用start-process来调用命令，因为say可能要待个一两秒才返回，如果使用shell-command来调用会造成输入有迟钝的感觉。 绑定的快捷键有这些，其中eamcsay-say-buffer是用来朗读当前的整个buffer，如果你想在其中中断朗读使用emacsay-say-stop。 (defvar emacsay-mode-map nil &quot;Keymap for emacsay minor mode&quot;)(unless emacsay-mode-map (let ((map (make-sparse-keymap))) (define-key map &quot;\\C-cs&quot; &apos;emacsay-say-current-string) (define-key map &quot;\\C-cp&quot; &apos;emacsay-say-buffer) (define-key map &quot;\\C-ct&quot; &apos;emacsay-say-stop) (setq emacsay-mode-map map))) 还可以有一些小的改进，比如阅读时候闪烁单词，或者say声音的选择等等。 所有代码在GitHub: emacSay-mode。","tags":[{"name":"Emacs","slug":"Emacs","permalink":"http://chenyukang.github.io/tags/Emacs/"}]},{"title":"迟到的POJ 500","date":"2013-01-22T11:43:00.000Z","path":"2013/01/22/poj-500.html","text":"我发现自己有了很重的拖延症，一个表现就是在2011年3月定下的目标POJ 500最近才完成。 这一页500道题耗费了我很多时间和精力，同样也带给了我很多知识和乐趣。 当然工作后毕竟还是没有学校的时间充足了，现在还花时间来做题似乎显得很悠闲，这500题最后十个是在元旦的几天假期里完成的。我是从2010年的4月份开始在Poj上做题，那天偶然发现自己原来2006年还注册过账号，于是做了两题试试，没想到后面就竟然沉迷其中，一直到自己从学校毕业出来。这两年强度还不算大，平时还是要在实验室做做项目的。我没参加过专业队的训练，不过参加过一次学校的比赛，和王骆驼两个人一个下午做出来五道，比较悲剧的是差一道没进决赛。不过当时还是挺欣慰的，毕竟自己还是不算专业选手啊。这一年多静下心来写程序收获很多，因为体会到了写程序的乐趣，有时候在睡觉的时候脑袋也在不知不觉地想问题。有时候我选择按不同的数据结构或者算法思想来选题做，有时候就在线上泡着看排我前面的人在做什么，然后自己也跟着做，这真写的是寂寞啊。不过现在回想起来这一两年算是最自由、最充实的写程序的日子了。 像ACM题这些东西最好还是大学开始接触，在开始学习基本算法和数据结构的时候就开始进行训练是最好的。当然如果大学能进专业队训练就更不错了，如果只是业余拿来练练手也是大有裨益的。也许我们做不到专业队哪些人写代码就像秀肌肉一样，体会到其中的乐趣就够了。在我开始做POJ之前我还是对算法充满了恐惧，感觉太高深。经过这些渐进的学习和训练，现在至少说有点入门的感受，面对一个问题多多少少会有一些思路和想法。也许平时项目和工作并没用到多少纯粹的算法部分，只是这有了这基本功还是能让你迅速上手其他东西。 《黑客和画家》里写到学习写程序和学习绘画的诸多相同点，这都是一门技能，除了多写、多看、多思考之外没有其他捷径可走。折腾多了自然就会有一点感觉。学习绘画的另外一个途径就是观摩经典的杰作，同样对应地看开源项目是另外一个很好的学习编程的途径。 幸好GitHub又被解封了。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"POJ","slug":"POJ","permalink":"http://chenyukang.github.io/tags/POJ/"}]},{"title":"获取挂掉程序的栈信息","date":"2013-01-04T11:43:00.000Z","path":"2013/01/04/print-stack-before-exiting.html","text":"在程序挂掉的时候最好还是留点有用的遗言，特别是对于一些比较难重现的Bug，也许这些信息会成为解决问题的关键。 下面这个技巧可以让程挂掉的时候打印出来栈信息。这个办法来自这里, 我觉得把SIGABRT、SIGBUS信号加进去也挺好的，在此做了点修改。曾经尝也试过glibc的backtrace函数，，但是给的信息不全(没有行号)，对此做得最好的还是gdb。 在终端可以用gdb获取某个进程的当前栈： $ gdb -p 5595 -batch -ex bt 0xb7fb4410 in __kernel_vsyscall () #0 0xb7fb4410 in __kernel_vsyscall () #1 0xb7dc2d50 in nanosleep () from /lib/tls/i686/cmov/libc.so.6 #2 0xb7dc2b87 in sleep () from /lib/tls/i686/cmov/libc.so.6 #3 0x0804874f in main () at print_stack.cc:64 那么一个好的办法就是在程序开始的时候设置好信号，绑定SIGSEGV和SIGABRT到DumpBackTrace()函数，DumpBackTrace函数fork出来一个新进程，运行上面的命令来获取调用栈。 #include &lt;stdlib.h&gt;#include &lt;signal.h&gt;#include &lt;stdio.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;#include &lt;unistd.h&gt;#include &lt;assert.h&gt;void DumpBacktrace(int) &#123; pid_t dying_pid = getpid(); pid_t child_pid = fork(); if (child_pid &lt; 0) &#123; perror(\"fork() while collecting backtrace:\"); &#125; else if (child_pid == 0) &#123; char buf[1024]; sprintf(buf, \"gdb -p %d -batch -ex bt 2&gt;/dev/null | \" \"sed '0,/&lt;signal handler/d'\", dying_pid); const char* argv[] = &#123;\"sh\", \"-c\", buf, NULL&#125;; execve(\"/bin/sh\", (char**)argv, NULL); _exit(1); &#125; else &#123; waitpid(child_pid, NULL, 0); &#125; _exit(1);&#125;void BacktraceOnSegv() &#123; struct sigaction action = &#123;&#125;; action.sa_handler = DumpBacktrace; if (sigaction(SIGSEGV, &amp;action, NULL) &lt; 0) &#123; perror(\"sigaction(SEGV)\"); &#125; if (sigaction(SIGABRT, &amp;action, NULL) &lt; 0) &#123; perror(\"sigaction(SEGV)\"); &#125;&#125;void test() &#123; //assert(0); int* p = 0; *p = 0;&#125;int main() &#123; BacktraceOnSegv(); test();&#125; 另外前段时间看到这篇文章Solving vs. Fixing写得不错，在面对一个bug的时候，先不要急于立马上gdb调试，根据现有的信息好好思考为什么会出现这个情况。Reddit上的一个得分最高的回复： The ability to reason about code is probably the most important skill. But it is sadly rare, and doesn&apos;t seem to be taught much, if at all. Some things are simple, others take some more thought: * Under what conditions will this branch get taken? * What could cause this API to fail? * Are all these parameters even valid? * What sequence of events could lead to this situation? * What assumptions does this code make? * What side-effects does this code have? * What contract is this code making (or breaking)? The most talented engineer I know, when presented with a bug, does nothing but read the code and think about the code and how it could fail. Most of the time, he just figures it out in his head and fixes it. Sometimes he will insert some strategic printfs and narrow it down like that. I don&apos;t think I have ever seen him use a debugger, even on the most complex of problems.","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"C/C++","slug":"C-C","permalink":"http://chenyukang.github.io/tags/C-C/"}]},{"title":"Browser objs and class hierarchy  in Ruby","date":"2012-12-26T11:43:00.000Z","path":"2012/12/26/browser-objs-in-ruby.html","text":"Ruby里一切都是对象，如何能看到Ruby内建的对象模型呢。这里有个小程序来查看Ruby内部构建好的的对象和类。ObjectSpace可以迭代所有对象。 set = Set.new() ObjectSpace.each_object do |x| set.add(x.class) endset.each do |x| puts xend 下面这段就能根据对象，取得class对象，建立起类的继承图。 # Creates or updates a klass_tree.# When updating no classes or objects are removeddef object_browser(classtree = ClassTreeNode.new(Kernel)) ObjectSpace.each_object do | x | classnode = classtree x.class.ancestors.reverse[1..-1] \\ .inject(classtree)&#123; | classnode, klass | classnode.add_class(klass) &#125;.add_object(x) end classtreeend use this command to get image: $ruby prog.rb &gt; class.dot; dot -Tpng class.dot -o class.png 结果看起来像这样，所有对象都画出来比较多，看大图还稍微能看到一些。完整的代码在这里。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Ruby","slug":"Ruby","permalink":"http://chenyukang.github.io/tags/Ruby/"}]},{"title":"Clang is Making Emacs Smarter","date":"2012-12-16T11:43:00.000Z","path":"2012/12/16/use-clang-autocomplete-mode.html","text":"在Emacs下自动补全总是个问题，对于同一个buffer内的基于symbol补全auto-complete-mode做得非常好了，但是因为没有进行代码的分析，所以像结构体的成员变量或者类的成员函数的补全是不可能的。当然你可能试过这个号称最智能的GCCSence,但是我觉得这个东西够复杂的，在使用之前还需要用户手动运行一个命令来用Gcc处理一遍，它还会把一些东西放在sqlite数据库里面。这大概是因为Gcc不编译做静态分析工具造成的，在这里、这里、这里有讨论，Google的一个静态分析的项目从Gcc迁移到LLVM，重点是这: The gcc version has been difficult to support and maintain, due mainly to the fact that the GIMPLE intermediate language was never designed for static analysis. The abstract syntax tree provided by Clang is an easier data structure to work with for front-end analyses of this kind. 这个thread挺好玩的，后面变成了一大群人争论functional programming和Imperative Programming。这篇The Downfall of Imperative Programming再好好看看。 回到正题，我最近切换到Mac下。因为在Mac OS X下编译器变成了Clang， Clang是基于LLVM的。LLVM对于分析代码是有比较方便的支持，所以基于LLVM有各种分析源程序的工具了，Xcode下的一些辅助开发的工具还是很舒服的。前些天突然想到那么会不会有个东西来作为Emacs的自动补全的后端，一搜果然有了这个auto-complete-clang，使用了一下非常的方便。其实看看其代码是在后面调用Clang的，比如在main.cc源文件里面写一些代码: #include &lt;string&gt;#include &lt;vector&gt;using namespace std;class Demo&#123;public: void print(); void test();private: int value;&#125;;int main() &#123; std::string s; Demo demo; demo.&#125; 结果还是非常精准的，不想截图了。后端运行的命令其实是:cmd: clang -cc1 main.cc -fsyntax-only -code-completion-at main.cc:18:10 所得到的结果是:COMPLETION: Demo : Demo::COMPLETION: operator= : [#Demo &amp;#]operator=(&lt;#const Demo &amp;#&gt;)COMPLETION: print : [#void#]print()COMPLETION: test : [#void#]test()COMPLETION: value : [#int#]valueCOMPLETION: ~Demo : [#void#]~Demo() auto-complete-clang做的事情就是把这个结果再展示出来，其实这条命令也做了语法检查的，所以加上一个语法检查的功能应该也是可以的。一搜果然还是有了，看这个Realtime syntax checking with emacs，需要翻墙，不过代码在Github上。其实其后端运行的命令是： cmd: clang -fsyntax-only -fno-exceptions main.cc 最近用这个插件，基本代码都会是一遍编译通过啊，哈哈。Clang错误提示也人性化一点，比如在Xcode下会提示你想的是不是”XXX”之类的。","tags":[{"name":"Emacs","slug":"Emacs","permalink":"http://chenyukang.github.io/tags/Emacs/"},{"name":"LLVM","slug":"LLVM","permalink":"http://chenyukang.github.io/tags/LLVM/"},{"name":"Gcc","slug":"Gcc","permalink":"http://chenyukang.github.io/tags/Gcc/"}]},{"title":"Have a try on Ninja","date":"2012-12-13T11:43:00.000Z","path":"2012/12/13/have-a-try-for-ninja.html","text":"什么是Ninja 在Unix/Linux下通常使用Makefile来控制代码的编译，但是Makefile对于比较大的项目有时候会比较慢，看看上面那副漫画，代码在编译都变成了程序员放松的借口了。所以这个Google的程序员在开发Chrome的时候因为忍受不了Makefile的速度，自己重新开发出来一套新的控制编译的工具叫作Ninja，Ninja相对于Makefile这套工具更注重于编译速度。除了Chrome现在还有一些其他的比较大的项目也在开始使用Ninja，比如LLVM。我试用了一下感觉还是不错，比如编译Cmake时间大概是原来的1/4。Ninja试用C++实现，其支持的语法非常简单，作者在这里说明了为了控制复杂度。 代码如何编译其实对于C/C++和很多其他程序的编译都是一个道理，就是把一些源代码文件编译成目标文件，或者有的目标文件再编译到一个库里，然后再链接起来。所以Ninja的配置文件分为两个部分，rule和文件依赖关系。看个简单的例子: cc=gcccflags= -g -crule cc command = $cc $cflags $in -o $outrule link command = $cc $in -o $outrule cleanup command = rm -rf *.exe *.obuild func.o : cc func.cbuild main.o : cc main.cbuild app.exe : link main.o func.obuild all: phony || app.exebuild clean: cleanup 非常易懂，编译的可执行未见叫做app.exe, 其中有三条rule: cc, link, cleanup。看看这个官方的试用手册，还有一些附加参数可以加在rule的下面，比如description用来在编译的时候显示出来。Ninja还有个比较好玩的功能就是Ninja -t graph all命令，这可以用来生成编译时候的依赖关系，可以用dot来生成图片等。Ninja的实现也可以大概推测到，根据用户给的依赖关系图，_并行_ 地编译各个文件。 使用Ninja的一个问题就是需要生成这个build.ninja文件，对于大型项目来说这样一条一条地写配置文件是不可能的。幸好我们可以使用Cmake来生成这个配置文件，Cmake对应的是automake这样的东西。在Cmake的最新版本中已经支持参数Camke -G Ninja，Cmake会根据用户给定的CMakeLists.txt来生成build.ninja文件。而CmakeLists文件相对来说要简单一些，只要写清楚编译的可执行文件的名字，和其依赖的包含main函数的源文件。把我的迷宫小项目来举个例子,在项目文件夹下写配置文件CMakeLists.txt: cmake_minimum_required(VERSION 2.8)project (Maze)add_library(maze A_star.cpp Algorithm.cpp DFS_L.cpp DFS_R.cpp DisjSets.cpp Maze.cpp)add_executable(Maze.exe main.cpp)target_link_libraries(Maze.exe maze) add_library写明了生成一个叫做maze.a的库文件，然后和main.cpp编译出来的main.o生成可执行文件，写好CmakeList.txt后运行Cmake -G Ninja, 然后运行ninja all就能编译这个工程。具体的Cmake语法参考这里，对于不少项目来说Cmake已经足够使用，只是我觉得Cmake还是稍微复杂了一点。 我这样来使用 整个Ninja是使用C++写的开源项目，如果我们想增加一些自己的feature可以hack一下，不过作者估计不会接受增加语法支持的patch。我准备做一个小的hack来自动分析我当前的源码，自动生成build.ninja文件，不要求处理所有的复杂情况，只是分析.cc和.c，自动检测main函数文件。最后用户只用配置链接参数就可以了。我觉得这样用起来就非常方便了，待完成中，顺便看看Ninja的内部实现。","tags":[{"name":"Ninja","slug":"Ninja","permalink":"http://chenyukang.github.io/tags/Ninja/"},{"name":"makefile","slug":"makefile","permalink":"http://chenyukang.github.io/tags/makefile/"}]},{"title":"Ruby Robot AI","date":"2012-11-22T11:43:00.000Z","path":"2012/11/22/ruby-robot-ai.html","text":"最近看到一个RRobot，这是一个用Ruby来实现的坦克对战平台。感觉挺好玩的，周三在公司也顺带和同事分享了一下。有时间的同学可以尝试尝试，用Ruby来写坦克的AI。另外这个不到1000行的程序也比较好读，这种Robot AI平台以前也有C++/Java版本的，不过都要比这个实现得复杂一点吧。 每个你控制的robot的api是这些，注意雷达扫描到的目标只包含距离信息，没有x和y，如果雷达扫描得越快所得到的目标位置准确率越低。自己摸索着写，找一些别人写好的策略来对战一把吧。 battlefield_height #the height of the battlefield battlefield_width #the width of the battlefield energy #your remaining energy (if this drops below 0 you are dead) gun_heading #the heading of your gun, 0 pointing east, 90 pointing #north, 180 pointing west, 270 pointing south gun_heat #your gun heat, if this is above 0 you can&apos;t shoot heading #your robots heading, 0 pointing east, 90 pointing north, #180 pointing west, 270 pointing south size #your robots radius, if x &lt;= size you hit the left wall radar_heading #the heading of your radar, 0 pointing east, #90 pointing north, 180 pointing west, 270 pointing south time #ticks since match start speed #your speed (-8/8) x #your x coordinate, 0...battlefield_width y #your y coordinate, 0...battlefield_height accelerate(param) #accelerate (max speed is 8, max accelerate is 1/-1, #negativ speed means moving backwards) stop #accelerates negativ if moving forward (and vice versa), #may take 8 ticks to stop (and you have to call it every tick) fire(power) #fires a bullet in the direction of your gun, #power is 0.1 - 3, this power will heat your gun turn(degrees) #turns the robot (and the gun and the radar), #max 10 degrees per tick turn_gun(degrees) #turns the gun (and the radar), max 30 degrees per tick turn_radar(degrees) #turns the radar, max 60 degrees per tick dead #true if you are dead say(msg) #shows msg above the robot on screen broadcast(msg) #broadcasts msg to all bots (they recieve &apos;broadcasts&apos; #events with the msg and rough direction) 最近关注Ruby比较多，平时工作中也会用Ruby来写一些脚本(渐渐代替了Python)。有两个原因，Ruby的语法更符合口味(不喜欢用Python的indent约束),Ruby也更Lisp化，Ruby的开源气氛非常好。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Ruby","slug":"Ruby","permalink":"http://chenyukang.github.io/tags/Ruby/"}]},{"title":"Ruby's Block and Proc","date":"2012-11-14T11:43:00.000Z","path":"2012/11/14/ruby_block_proc.html","text":"Callable objects在Ruby当中一切都是对象，但是有一个例外，那就是block。Block和Proc类似，但是还是有稍有差别的，Block更常用一些。最近在看《Metaprogramming Ruby》，在这节中有个例子是这样的。 require 'highline' hl = HighLine.new friends = hl.ask(\"Friends?\" , lambda {|s| s.split(',' ) }) puts \"You're friends with: #{friends.inspect}\" ⇒ Friends? Bill,Mirella,Luca You're friends with: [\"Bill\", \"Mirella\", \"Luca\"] 这里看起来hl.ask把Proc当作参数来传递，而不是接受了一个block，接受Block是另外一种使用模式： require 'highline' hl = HighLine.new new_pass = hl.ask(\"password: \") { |prompt| prompt.echo = false } 在highline代码可以看到相应的处理方式，第一种方式lambda构造成的Proc其实传递给了answer_type，而yield来处理block。 def initialize( question, answer_type ) # initialize instance data @question = question @answer_type = answer_type # allow block to override settings yield self if block_given? Proc, Lambda, Block有三种方式转化Block为Proc, Proc.new、Lambda、&amp;Operator。但是在使用过程中Block还是比Proc要常见，在给一个函数传递这种callable objcts的时候，可以隐式或者显示传递，像这样： def foo(*args) yield(args.join(' ')) end foo('Yukang', 'Chen'){|name| puts \"Hello #{name}\"} # => \"Hello Yukang Chen\" def foo(*args, &blk) blk.call(args.join(' ')) end foo('Yukang', 'Chen'){|name| puts \"Hello #{name}\"} # => \"Hello Yukang Chen\" 隐式传递要比显式传递performance要好一些。这很早就有讨论，具体原因是根据Ruby的实现一个Block在yield的时候并没有转换为Proc或者其他对象，所以少了一些开销。Ruby中的函数块是高阶函数的一种特殊形式的语法，Matz在设计块的时候考虑到： (1)在高阶函数中，这种只有一个函数参数非常常见，在实际使用中几乎没有必要在一个地方使用多个函数参数，(2)外观和形式上更直观，Enumerable利用块写的代码简洁易懂。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Ruby","slug":"Ruby","permalink":"http://chenyukang.github.io/tags/Ruby/"}]},{"title":"丽江印象","date":"2012-11-08T11:43:00.000Z","path":"2012/11/08/lijiang.html","text":"上周我们公司一行九个人去丽江开会、游玩了四天。我去之前心里还没什么期望的，不过在那边待了一段时间后对丽江的印象还是挺好的。其实像这种古镇以前也逛过不少，成都的和江浙一带的都去过，大多商业化比较严重。不过丽江的古镇确实是我见过的最大的，虽然说也是商业化，还是存在不少原生态的东西。我们去的时间也刚好还算是合适，避开了人流的高峰期，也还有暖暖的阳光。 关于住宿因为前面两天要讨论一些技术问题，所以刚到丽江住的是宾馆。在丽江古城的边缘地带，价格比较贵。如果是个人去旅游，坚决不要住宾馆，找个靠谱的客栈吧，比如我们后来一天所住的泡沫之夏就非常实惠，老板人也挺好。丽江古城的客栈非常多，而且据我观察不少看起来非常干净，有的还可以跟着客栈主人一起吃饭，价钱也便宜。当地人给人印象还算是朴实，也很容易和游客乐成一片。 关于吃饭第一天我们因为旅途劳累所以随便选择了一个古城边缘的饭店吃饭，气氛不错，就是有点小贵。其实丽江吃饭便宜又好吃的地方挺多的，找那些当地的特色馆子，我们去过的唠叨妈私房菜是个很好的馆子，里面有个唠叨妹特别好玩，唠叨妈开馆子不是为了多赚钱，价钱实惠份量又足。在人多的时候他们准备收拾收拾为自家做饭了，要不是我们人多都不会被接待。 关于艳遇在丽江到处都写着艳遇，艳遇乃丽江的另一个代名词。丽江的酒吧非常多，各种风格的都有，这歌声和酒精为所谓艳遇创造了条件。在丽江玩的人大多都比较放松，在那种环境下人的隔阂也会少一些，问问几个哲学基本问题搭讪基本没问题的。但我觉得大部分人都是普通旅客，所谓”艳遇”也不过是交个陌生朋友，谈谈旅行见闻而已。当然也有不少是单独在那边待着“疗伤”的，如果恰好能碰上聊得来的也算是缘分了。去酒吧泡着是丽江夜生活的常态，我们去了几个比较有名气的酒吧，其中江湖酒吧感觉是最好的，乐队的现场表演非常吸引人。我在丽江等你音乐要要轻一些。Bamboo很有名因为小倩那首《一瞬间》是丽江今年的街歌，不过现场表演的效果不如江湖酒吧。后街2号就没有时间去了。 一点照片丽江的狗挺多，大多都还看起来很干净，无聊地天天在那里晒太阳。 江湖酒吧，小松的嗓音极好。 茶马古道上面那座山，因为时间紧张，所以我们没爬到山顶，遗憾。 拉市海附近非常漂亮，蓝天碧水。 拉市海旁边老太太的玉米，我所吃过的最好吃的玉米。 云南玩的地方还真是非常多，丽江附近可去的还有泸沽湖、玉龙雪山、香格里拉等等。有机会再去一次把这些地方看一看，最好能稍微多住一段时间。","tags":[{"name":"旅行","slug":"旅行","permalink":"http://chenyukang.github.io/tags/旅行/"}]},{"title":"Emacs iedit/occur 插件","date":"2012-11-05T11:43:00.000Z","path":"2012/11/05/emacs-symbol-util.html","text":"今天看到Mastering Emacs上介绍iedit插件的一篇文章。对于程序员来说，经常要重命名一个变量，之前我在Emacs下面使用替换命令来完成的，而Iedit可以编辑当前buffer里面多处相同的一个单词，编辑一处其他地方相同的symbol会自动被修改，这对于这样的操作是非常地直观有效，看下面这样的效果，图片来自Mastering Emacs。 最开始看到这个功能是在比较新的编辑器Sublime上，算是编辑器里一个很好的小创新吧。 另外在buffer中查找一个symbol也是经常需要的一个操作，我基本会用 (global-set-key [f3] 'highlight-symbol-next) (global-set-key [(shift f3)] 'highlight-symbol-prev) 来快速地在相同的symbol之间切换，这是来自highlight-symbol.el里面的。 同样的操作也可以用occur-mode来实现，occur的好处在于可以在另外一个窗口列出所找到结果大纲，这样更方便快速跳到相应的位置，这对于任何类型的文件都可以使用，而不止是可能需要静态分析后生成tags的程序。在Mastering Emacs后面有一段代码使得occur-mode可以在当前所有打开的buffer里找关键字。","tags":[{"name":"Emacs","slug":"Emacs","permalink":"http://chenyukang.github.io/tags/Emacs/"}]},{"title":"调优的小工具RunLim","date":"2012-10-29T11:43:00.000Z","path":"2012/10/29/runlim.html","text":"在公司有同事用这个小程序RunLim来调试程序的内存问题。刚开始以为是我们上海的一个同事写的，就弄来看了看。后来发现是公司一个早期同事Armin Biere写的，还开源了，debian的源里有这个东西。我在公司维护的一部分代码是这个人写的，据说厉害的程序员，他现在在学术圈里。 用这个小程序来测试程序跑的时间和内存，用法很简单: ./runlim prog.exe 比如： kang@ubuntu:~/download/runlim-1.7$ ./runlim sleep 1 [runlim] version: 1.7 [runlim] time limit: 311040000 seconds [runlim] real time limit: 311040000 seconds [runlim] space limit: 4294966090 MB [runlim] argv[0]: sleep [runlim] argv[1]: 1 [runlim] start: Tue Oct 30 00:02:52 2012 [runlim] main pid: 22546 [runlim] end: Tue Oct 30 00:02:53 2012 [runlim] status: ok [runlim] result: 0 [runlim] children: 0 [runlim] real: 1.63 seconds [runlim] time: 0.00 seconds [runlim] space: 0.5 MB [runlim] samples: 10 查看help，这个工具还可以指定time limit和space limit,在指定的时间和内存限制内强制退出程序，其功能很像那些Online Judge，只是没有检测结果输出是否正确。 发现代码里有一个小小的Bug，根据源代码如果没有指定space limit， space limit那栏应该是当前的空闲内存大小，但是看我上面运行的命令，显示的4294966090 MB明显偏大，是其中的一个获取系统内存大小的函数溢出了。这里应该是这样： static unsigned get_physical_mb () { unsigned long long mem; mem = (unsigned long long)sysconf(_SC_PAGE_SIZE)* (unsigned long long)sysconf(_SC_PHYS_PAGES); return mem >>= 20; } sysconf获取页大小和页数目，具体看这里How to get information about the memory subsystem?。 这个小工具还是查询/proc下的进程统计信息的，根据fork出来的子进程pid，递归地查询统计信息。 时间的统计可能会稍显粗略，如果需要更精确的时间统计该如何实现。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"RunLim","slug":"RunLim","permalink":"http://chenyukang.github.io/tags/RunLim/"}]},{"title":"Ruby vs C++ for delegation","date":"2012-10-16T11:43:00.000Z","path":"2012/10/16/delegate_ruby_cpp.html","text":"下班之前同事BigBird给我show他的一段C++代码，对于我等拿C++当作C来用的未入门者实看起来实在是炫丽。虽然比较冗长晦涩，不过还是能看懂个大概，然后觉得这对于动态语言是非常容易实现的。 于是晚上回来用Ruby来搞搞，弄出下面这么段代码。 C++版本在这里https://gist.github.com/3900077。可见动态语言和编译型语言实现起来效率还是好太多了，同时代码也好理解。再次我讨厌C++类型推导，^_^。 Ruby实现这个方式很多，另外Ruby的库包含SimpleDelegator的，将调用的方法直接传递到其他对象。 #!/usr/bin/rubyclass Delegate attr_reader :proc_list def initialize() @proc_list = [] end def add(*proc) proc_list.push(proc) end def eval(obj) for e in proc_list: if obj.respond_to?(e[0]) if e.size == 1 obj.__send__(e[0]) else obj.__send__(e[0], e[1]) end else printf \"ERROR:%s is not defined\\n\", e[0] end end endendclass Demo attr_writer :valuepublic def print() printf \"value:%d\\n\", @value end def hello() printf \"Hello world!\\n\" end def set(val) @value = val endenddelegate = Delegate.new()delegate.add(\"print\")delegate.add(\"set\", 1)delegate.add(\"print\")delegate.add(\"hello\")delegate.add(\"nodefine\")d = Demo.new()delegate.eval(d)","tags":[{"name":"Ruby","slug":"Ruby","permalink":"http://chenyukang.github.io/tags/Ruby/"},{"name":"C++","slug":"C","permalink":"http://chenyukang.github.io/tags/C/"},{"name":"delegator","slug":"delegator","permalink":"http://chenyukang.github.io/tags/delegator/"}]},{"title":"UbiGraph动态显示Python函数调用","date":"2012-09-27T11:43:00.000Z","path":"2012/09/27/3d-python-call-path.html","text":"UbiGraph显示环境 UbiGraph是一个显示平台，可以非常方便地使用Python/C/Ruby来控制渲染，只需要制定节点和边还有其他相关属性，其余的都不用管了。其使用XML-RPC服务于客户端，所以甚至可以在一台机器上开server，在另外一台机器上用渲染代码控制，这个环境对于算法和数据的可视化很有用。 比如： import ubigraphU = ubigraph.Ubigraph()U.clear()x = U.newVertex(shape=\"sphere\", color=\"#ffff00\")smallRed = U.newVertexStyle(shape=\"sphere\", color=\"#ff0000\", size=\"0.2\")previous_r = Nonefor i in range(0,10): r = U.newVertex(style=smallRed, label=str(i)) U.newEdge(x,r,arrow=True) if previous_r != None: U.newEdge(r,previous_r,spline=True,stroke=\"dashed\") previous_r = r 显示效果如下： 只是这个软件是免费的但不是开源的，另外还没有支持Windows平台。 使用Ubigraph显示Python函数调用这是在这里看到的，貌似需要翻墙。代码比较简单，在点击查看prof3d.py。 使用方法是先启动Ubigraph的server，然后运行下面的代码： import prof3ddef run_main(): # your codeif __name__ == \"__main__\": prof3d.profile_me() run_main() 这段Python的代码函数调用关系就显示出来了，而且还是动态的。 效果如下：","tags":[{"name":"Python","slug":"Python","permalink":"http://chenyukang.github.io/tags/Python/"},{"name":"Tools","slug":"Tools","permalink":"http://chenyukang.github.io/tags/Tools/"}]},{"title":"A*算法解决kth-shortest路径问题(2)","date":"2012-09-18T11:43:00.000Z","path":"2012/09/18/a-start-k-shortest.html","text":"我之前写过一篇图文并茂的文章来介绍这个算法，有好几次有朋友反馈说对自己有帮助，深感荣幸。这次再次写这个也是因为帮忙于一个朋友解决这类问题，这里再成一篇，稍显罗嗦。 问题描述无向图G，需要求出S-&gt;T点的前k短路径，要求路径中没有环。(所有的边的权值不为负) A*算法求解kth-shortest问题A*算法已经被广泛运用于路径规划问题中，同时A*算法作为一种启发式算法的框架，可用于多种搜索问题，还是先回顾一下A*的基本符号： f(s)=g(s)+h(s)，其中h(s)&lt;=h*(s)，h*(s)是某点到终点的真实代价，h(s)是估计代价，并且对s的任意后继t有：h(t)+w(s,t)&gt;=h(s)，其中w(s,t)是从s转移到t的代价，符合这条件的评估函数f(s)可以得到正确的最短路径。 而这里评估函数f(s)是A*算法的关键，其效率都取决于此,退化的A*算法就是宽度搜索(即启发函数h(s)为常数)。另外A*算法的最优性证明在这篇论文里有阐述。 所以如果能确切的计算出来h*(s)，那么评估函数f(s)将是s点的最短路径，这可算是一个最优的启发函数。可以利用Dijkstra算法来求解出各个点到T点的最短路径，假设第i个节点到T的最短路径计为Dist_T(i)，Dist_T(i)作为A*函数中的启发函数h(s)，从S开始搜索，因此算法描述如下： int Astar()&#123; if(dist[S]==INF) return -1; priority_queue&lt;Node&gt; Q; //极小堆，定点为f(s)=g(s)+h(s)最小的节点 Q.push(Node(S,0)); //源点S加入堆，估计代价为0 while(!Q.empty())&#123; int len=Q.top().len; int u=Q.top().v; Q.pop(); cnt[u]++; //节点u访问一次 if(cnt[T]==K) return len; //第K次从队列弹出的值为kth-shortest的值 if(cnt[u]&gt;K) continue; for(int i=0;i&lt;Adj[u].size();i++) &#123;//取v节点的临接节点计算评估函数并加入优先队列 int v = Adj[u][i].v; int eval = len + Dist(u,v) + Dist_T(v); Q.push(Node(v, eval)); &#125; &#125; return -1;&#125; 因为没有标识哪些节点访问过哪些节点没有访问过，所以这种方法计算出来的结果路径可能含有环，即可能出现1-&gt;2-&gt;3-&gt;2-&gt;5，为了避免这样的情况可以在每个扩张Node里面增加当前路径已经访问过的点，在进行下一次扩张的时候可以避免访问这些已经在路径中的节点。但是这样所需要的空间复杂度是巨大的，所以需要再次用一些剪枝办法来避免过多的扩展。 一个优化A*算法在扩展节点的时候，如果我们能筛除掉更多无用的节点，那么都可以利于减少搜索的空间复杂度和时间复杂度。当k取值较小的时候，即当我们并不需要知道所有路径长度和其排序，而只需要知道前k(假设k&lt;=10)段的路径，这里加上一个剪枝会有很大的优化。 假设我们事前知道kth-shortest的最大值，就能在扩张的时候加入这个限制，避免大部分的无用的节点扩张。 for(int i=0;i&lt;Adj[u].size();i++) &#123;//取v节点的临接节点计算评估函数并加入优先队列 int v = Adj[u][i].v; int eval = len + Dist(u,v) + Dist_T(v); if(eval &gt; max_dist) continue; else Q.push(Node(v, eval));&#125; 如何知道kth-shortest的最大值这个临界点呢？ 假设我们知道某条经过点v的S-&gt;T路径的最短长度，即对于所有的点v1,v2,v3,….vn,有dist(v1)为S-&gt;…-&gt;v1-&gt; …-&gt;路径的长度，一共n个dist，把这n个dist排序以后，取第k小的dist(v_kth_smallest)即为kth-shortest。如何计算出dist(v)，通过Dijkstra(T)可以计算出v到T的最短路径，同样可以通过Dijkstra(S)可以计算出S到v的最短路径Dist_S(v)，这里有如下定理： 对于任意最短路径S-&gt;K中，假设经过点v，则必有: min(S-&gt;v)和min(v-&gt;T)。因此要计算经过v的从S-&gt;K的最短路径可以用: min_dist(v) = Dist_S(v) + Dist_T(v) 因此如果我们用这种方法计算出Dist(v)，那么最后第k小的dist(v_kth_smallest) &gt;= kth-shortest。这对于A*算法的最后结果没有影响，但是同样可以作为一个条件来删除掉大部分不符合条件的节点，因此得到一个很好的优化方案。这个优化可以用于k&lt;N时的kth最短路径问题，可以预见k越小剪枝效果越好。 据我实现在18600个节点的图上，这个算法比Yen’s算法快了很多倍，甚至在我的PC(3G内存)机上，后者在算到k=3的时候内存就支持不住了。 算法复杂度分析假设图G有m条边和n个节点，Dijkstra算法的复杂度为((m+n)log n)(二叉树实现的优先队列)。A*算法的时间复杂度取决于启发函数，事实我还不清楚如何分析这样的算法的时间复杂度和空间复杂度，根据这篇文章来说是O(delta*V^2*(lgV+lg(delta)))的。 如果哪位知道如何分析A*算法的复杂度，劳烦请教。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Algorithms","slug":"Algorithms","permalink":"http://chenyukang.github.io/tags/Algorithms/"}]},{"title":"换域名了cyukang.com","date":"2012-09-13T11:43:00.000Z","path":"2012/09/13/change-domain-name.html","text":"昨天晚上突然发现自己的域名moorekang.com不能用了，上午问了一下域名提供商Bloghost，原来因为双方沟通上的问题导致我的域名没及时续费，甚至进入了赎回期，在这个时候只有这么几种选择： 换一个域名 赎回自己原来的域名，价格不太便宜，国际域名和国内域名也有差别，我的需要150美金 等域名过了赎回期再重新购买，期间需要等待40来天左右 所以，血的教训啊，及早续费自己的域名，免得面临这么一个窘境。无奈，我选择了换域名，虽然原来那个稍显长的域名已经用了近两年多。稍微找了一下，觉得这个域名cyukang.com还比较短，于是就申请了下来。国际域名不用各种备案，所以几分钟就下来了。另外对于Jekyll和GitPage这样的组合，换域名是多么的简单，几分钟就搞定了，所以这次折腾也没花多少时间。 另外我觉得twitter这个主题已经够简洁了，今天稍微做了一下改动，用我仅有的一点css知识让顶部的导航栏固定下来。 有我链接的麻烦换一下，呃，其实也没几个人用我做友链:)，不过还是得喊一声的。 –","tags":[]},{"title":"OS dev的Bochs调试","date":"2012-08-19T11:43:00.000Z","path":"2012/08/19/os-dev-debug.html","text":"最近在弄一个自己的hobby OS，作为菜鸟在调试时候积累一些经验，记录一下。 Bochs调试Bochs自带调试功能，但是如果你是apt装上的是不行的，下源码来自己编译，编译选项为： ./configure --enable-debugger --enable-disasm 这个我只是尝试过，在OS的loader阶段可能会用到，当如果进入C语言实现部分的代码如何调试?我希望看到C的源码级别调试，而不是汇编的。 Bochs + gdb调试同样需要在编译的时候加上选项，这个选项必须注意，否则在gdb调试的时候会出现”Cannot find bounds of current function”之类的问题。 ./configure --enable-debugger --enable-disasm --enable-gdb-stub 诡异的是这个–enable-gdb-stub选项和上面的 –enable-debugger选项只能二选一。也行，编译出来后重命名吧。编译完成后在Bochs的配置文件.bashrc中加上这么一行: gdbstub: enabled=1, port=1234, text_base=0, data_base=0, bss_base=0 另外注意kernel的代码也需要加入-g编译选项。最后在编译完成后的文件是带调试信息的，但是我们在用Bochs启动的img文件不需要这些，现在比如kernel.elf是带编译信息的kernel文件，用下面的这个步骤去掉调试信息，据说也可以用strip来。 cmd=&quot;objcopy -R .pdr -R .comment -R .note -S -O binary kernel.elf kernel.bin&quot; cat boot.bin setup.bin kernel.bin &gt; ../a.img; Bochs 使用的是这个a.img文件， gdb载入的是kernel.elf文件。 启动Bochs后会等待gdb连进来(其实Qemu也可以这样进行调试的)，查资料过程中发现还可在调试的目录加上.gdbinit，这样每次启动gdb就不那么麻烦了： file ./objs/kernel.elf target remote localhost:1234 set disassembly-flavor intel b kmain 一些有用tipsOS的代码中经常会有内联汇编，有的时候一条内联过去就崩溃了，所以在gdb里需要查看反汇编语句和registers。下面这些gdb指令比较有用： (gdb) info line main.c:26 (查看main.c:26行在目标文件中的位置，为0x1cbc) Line 26 of &quot;./kernel/main.c&quot; starts at address 0x1cbc &lt;kmain&gt; and ends at 0x1cc2 &lt;kmain+6&gt;. (gdb) info line *0x1cbc (上面的反操作) Line 26 of &quot;./kernel/main.c&quot; starts at address 0x1cbc &lt;kmain&gt; and ends at 0x1cc2 &lt;kmain+6&gt;. (反汇编kmain函数，箭头指向的是当前运行的汇编代码) (gdb) disas kmain Dump of assembler code for function kmain: =&gt; 0x00001cbc &lt;+0&gt;: push ebp 0x00001cbd &lt;+1&gt;: mov ebp,esp 0x00001cbf &lt;+3&gt;: sub esp,0x28 0x00001cc2 &lt;+6&gt;: mov eax,DWORD PTR [ebp+0x8] 0x00001cc5 &lt;+9&gt;: mov ds:0x5ccc,eax 0x00001cca &lt;+14&gt;: call 0x2a29 &lt;init_video&gt; 0x00001ccf &lt;+19&gt;: mov DWORD PTR [esp+0x4],0xb 0x00001cd7 &lt;+27&gt;: mov DWORD PTR [esp],0x4777 0x00001cde &lt;+34&gt;: call 0x2a40 &lt;puts_color_str&gt; 0x00001ce3 &lt;+39&gt;: mov DWORD PTR [esp+0x4],0xa 0x00001ceb &lt;+47&gt;: mov DWORD PTR [esp],0x478d 0x00001cf2 &lt;+54&gt;: call 0x2a40 &lt;puts_color_str&gt; 0x00001cf7 &lt;+59&gt;: cli 0x00001cf8 &lt;+60&gt;: call 0x3876 &lt;time_init&gt; 0x00001cfd &lt;+65&gt;: call 0xc13 &lt;gdt_init&gt; 要正确的看到反汇编最好设置好gdb里面的汇编指令集，对于Nasm设置”set disassembly-flavor intel”,在.gdbinit里面弄好就行。 最后info registers查看cpu寄存器内容，info registers %eax只查看eax内容，而info all-registers会把cpu的所有寄存器内容显示出来，不过cr0,cr3这些貌似没有 :(。看看这里GDB参考。","tags":[{"name":"debug","slug":"debug","permalink":"http://chenyukang.github.io/tags/debug/"},{"name":"bochs","slug":"bochs","permalink":"http://chenyukang.github.io/tags/bochs/"},{"name":"OS","slug":"OS","permalink":"http://chenyukang.github.io/tags/OS/"}]},{"title":"Linux下快捷切换屏幕","date":"2012-08-09T11:43:00.000Z","path":"2012/08/09/switch-screen.html","text":"在办公室工作的时候一般面对两个显示器，大部分时候左边用来看代码，右边用来写程序。双显示屏还是有助于提高工作效率的。有一点困扰我的是如果要切换屏幕一般得用鼠标，这对于Emacs党是有些不能忍受的，右手离开键盘总是得停顿一下的感觉。今天找到一个解决办法。 最终找到的是这个号称Linux下键盘精灵的一个程序:xdotool，下载下来编译安装。这个东西可以模拟鼠标和键盘的行为： 比如： xdotool search \"Mozilla Firefox\" windowactivate --sync key --clearmodifiers ctrl+l (快速切换倒firefox,并focus在地址输入栏)xdotool getmouselocation --shell (获取当前鼠标位置等信息)X=880Y=443SCREEN=0WINDOW=16777250xdotool getactivewindow windowmove 100 100 # Moves to 100,100xdotool getactivewindow windowmove x 100 # Moves to x,100xdotool getactivewindow windowmove 100 y # Moves to 100,yxdotool getactivewindow windowmove 100 y # Moves to 100,yxdotool mousemove --screen 0 100 100 # Moves to screen 0 pos at 100,100 有了上面windowmove命令，屏幕的切换就好实现了。写个丑陋的python脚本来保存当前的位置，切换到另外一个屏幕，再次调用的时候返回到原来的位置，保存为mouse.py。 #!/usr/bin/pythonimport osimport sysimport commandsdata_f = \"/tmp/window_data\"now_info = commands.getoutput(\"xdotool getmouselocation --shell\").split('\\n')x = (now_info[1])[2:]y = (now_info[2])[2:]screen = (now_info[3])[7:]window = (now_info[4])[7:]def do_store(): data = open(data_f, \"w+\") content = screen+\"\\n\"+x+\"\\n\"+y+\"\\n\"+window data.write(content) data.close() def do_update(): if screen == \"1\": new_sc = \"0\" else: new_sc = \"1\" cmd = \"xdotool mousemove --screen \" + new_sc + \" 0 0\" commands.getoutput(cmd)if os.path.exists(data_f): data = open(data_f, \"r+\") content = data.readlines() data.close() screen = content[0][0:-1] old_x = content[1][0:-1] old_y = content[2][0:-1] old_window = content[3] if old_window != window: cmd = \"xdotool mousemove -w \" + old_window + \" \" + old_x + \" \" + old_y commands.getoutput(cmd) do_store() else: do_store() do_update()else: do_store() do_update() 最后，通过Emacs下绑定快捷键来调用这个脚本即可实现两个屏幕之间的切换，又可以远离鼠标了。哈哈。 (defun switch-screen() (interactive) (start-process \"mouse.py\" nil \"bash\" \"-c\" \"/home/yukang/apps/bin/mouse.py\")) (global-set-key (kbd \"C-x q\") 'switch-screen) Jekyll下写点东西快多了。","tags":[{"name":"Tools","slug":"Tools","permalink":"http://chenyukang.github.io/tags/Tools/"},{"name":"Linux","slug":"Linux","permalink":"http://chenyukang.github.io/tags/Linux/"}]},{"title":"分支预测优化","date":"2012-07-11T11:43:00.000Z","path":"2012/07/11/branch_prediction.html","text":"问题Stack_overflow上有这么一个帖子:为什么排序后会快很多，说是下面这段代码比较诡异，引发了比较多的回复，一起来看看。 #include &lt;algorithm&gt;#include &lt;ctime&gt;#include &lt;iostream&gt;int main()&#123; // generate data const unsigned arraySize = 32768; int data[arraySize]; for (unsigned c = 0; c &lt; arraySize; ++c) data[c] = std::rand() % 256; std::sort(data, data + arraySize); //排序这行不注释掉下面的for循环会快得多 // test clock_t start = clock(); long long sum = 0; for (unsigned i = 0; i &lt; 100000; ++i) &#123; // primary loop for (unsigned c = 0; c &lt; arraySize; ++c) &#123; if (data[c] &gt;= 128) sum += data[c]; &#125; &#125; double elapsedTime = static_cast&lt;double&gt;(clock() - start) / CLOCKS_PER_SEC; std::cout &lt;&lt; elapsedTime &lt;&lt; std::endl; std::cout &lt;&lt; \"sum = \" &lt;&lt; sum &lt;&lt; std::endl;&#125; 如果把std::sort(data, data + arraySize);注释掉，下面那段for循环所花费的时间是11.54秒。 如果不注释掉，即排序后下面那段所用的时间是1.93秒。 相差比较大。那个for循环总是要执行完的，为什么排序后会快不少? 分支预测 下面的获得票数最多的回复质量非常高，很生动细致地说明了cpu的分支预测技术。 看上面这情形，如果在没有通讯设备的年代，如果你是这个火车枢纽的操作人员，是不是要让火车驾驶员把车停下来，然后告诉你他需要往哪个方向行驶，等你完成转向操作的时候再继续行驶火车呢。也许有一些更好的办法，你可以猜测火车要往哪边行驶。 如果你猜对了，那么节省了不少时间。 如果猜错了，火车停下来，等你撤销刚才的操作，再往前走，这会比较耗费时间。 同样在执行指令的时候，cpu也能做这样类似的工作。现代cpu都采用 指令流水线技术 ，即处理器会预取下面要执行的一些指令，如果下面的指令正是需要被执行的那就节省了时间，如果在概率上大部分能猜对下面要运行的指令，那就提高了cpu的运行效率。更详细的图文介绍可以参考wiki。简单的说明就是cpu会根据前面所执行的指令的历史，归纳出相应的模式，把预测的指令预取进来，然后继续沿着预测的指令执行。如果发现预测错误，则倒过来重新初始化预测表、刷新指令管道然后继续执行。所以看上面的例子： T = branch takenN = branch not takendata[] = 0, 1, 2, 3, 4, ... 126, 127, 128, 129, 130, ... 250, 251, 252, ...branch = N N N N N ... N N T T T ... T T T ... = NNNNNNNNNNNN ... NNNNNNNTTTTTTTTT ... TTTTTTTTTT (easy to predict) 后面作者又加了一条hack，把这段代码重新改写一下： if (data[c] &gt;= 128) ====&gt; int t = (data[c] - 128) &gt;&gt; 31; sum += data[c]; ====&gt; sum += ~t &amp; data[c]; 那么前面是否排序就对这段代码效率没有影响了，同样是2秒多。 这和编译器的优化非常相关，不同的编译器的结果不一样，4.6.1 GCC 加上-O3或者-ftree-vectorize编译选项可以对这种情况进行优化，所以排序与否没有关系，而VC++2010却不能进行类似优化(GCC果然强大)。 一个优化例子 在Linux kernel里面会看到类似likely和unlikely这样的代码，从其名字就很直观的解释了其意义。看其定义为两个宏。 include/linux/compiler.h#define likely(x) __builtin_expect (!!(x), 1)#define unlikely(x) __builtin_expect (!!(x), 0) Linux内核开发者使用这两个宏来通过编译器提示cpu：某一段代码很可能会执行，应该被预测，而有的情况出现的概率比较小，不必预测。类似这样的代码： if(likely(some_cond)) &#123; //this is often happen! /* Do something */&#125;if (unlikely(some_cond)) &#123; //this is rare! /* Do something */&#125; 关于这个方面，在这篇论文What every Programmer should know about Memory里面有更详细的讲述。分支预测在现代cpu上如此通用，竟然还有人利用这个来尝试破解RSA的，看这个On the Power of Simple Branch Prediction Analysis。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"优化","slug":"优化","permalink":"http://chenyukang.github.io/tags/优化/"},{"name":"分支预测","slug":"分支预测","permalink":"http://chenyukang.github.io/tags/分支预测/"}]},{"title":"GDB调试动态链接库","date":"2012-06-25T11:43:00.000Z","path":"2012/06/25/gdb-with-libso.html","text":"今天解决了一个长期会碰到的问题，就是用GDB如何来调试动态链接库。我这个问题的难点是我的需要调试代码是在动态链接库里面，但是启动的不是普通的可以调试的二进制文件，换句话说这不是我所能控制的代码所编译出来的，甚至可能是由脚本程序来控制启动的。这个问题时不时地困扰着我，总结一下尝试过几种调试方式： 1 使用print来打印log，有时候有用，不好的地方是有时候定位出问题的代码位置还是稍显麻烦。很常用的会定义一对宏，进入函数和退出某个函数的时候都相应调用。 #define APP_LOG(X) \\ fprintf(stderr, \"log: %s %d %s %s\\n\", \\ __FILE__, __LINE__, __FUNCTION__, X); \\#define LOG_ENTER \\ APP_LOG(\"enter\") #define LOG_LEAVE \\ APP_LOG(\"leave\") 2 对于crash掉的bug，打印出来调用栈是非常有用的。使用libc提供的Backtraces函数来获取调用栈。这是在不能提供GDB环境下拿到调用栈的不错方法。不过经过我的实验这对于动态链接库有一定的问题。 3 最后就是今天试用的比较通用办法。 我们不管是如何调用到动态链接库文件的，但是肯定会调用进来。所以需要想办法让代码在库代码处停下来，然后把找机会把GDB弄进去。于是乎有这么一个变态的办法，在动态链接库入口处来这么一段，就是执行到这里停住，等待GDB attach这个进程，然后在GDB里设置一个断点，touch创建当前文件夹debug文件就跳出死循环，接下来就是一切在GDB控制下了。 void wait_attach() &#123; fprintf(stderr, \"Waiting attach pid: %d\\n\", getpid()); while(1) &#123; if((access(\"./debug\", F_OK)) != -1) &#123; break; &#125; else ; &#125;&#125; 这是一个stupid and work的方法，不过我总觉得还有更好的办法来在这种情况下调试。 在查找资料的过程中有点意外收获，顺便推荐GDB一个选项，gdb -tui, 以texture gui方式启动GDB，这是非常方便的文字界面。如果不用这个选项也可以在运行GDB以后按下快捷键盘C-x C-a(怎么这么像Emacs快捷键)来进行gui和非gui的切换。CLI爱好者可以试用一下，DDD什么的可以放下了，嘿嘿。 另外一些有用的GDB命令： rbreak: break on function matching regular expressionwhere: Line number currently being executedtbreak: Break once, and then remove the breakpointwatch: Suspend the process when a certain condition is metfinish: Continue till end of functioninfo locals: View all local variablesbacktrace full: Complete backtrace with local variablesup, down, frame: Move through framesset print pretty on: Prints out prettily formatted C source codeset print array on: Pretty array printingenable and disable: Enable/disable breakpointsset logging on: Log debugging session to show to others for support","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"gdb","slug":"gdb","permalink":"http://chenyukang.github.io/tags/gdb/"},{"name":"debug","slug":"debug","permalink":"http://chenyukang.github.io/tags/debug/"}]},{"title":"bsfl指令和Bitmap的一个优化","date":"2012-06-20T11:43:00.000Z","path":"2012/06/20/bsfl-bitmap.html","text":"如何找出int中第一个1对于这个问题我们可以从最原始的做法开始，如果没找到1返回0，如果第一位为1返回1。所以代码很简单如下： static int first_onebit(int x)&#123; if(!x) return 0; else&#123; int idx = 0; if(x%2 != 0) return 1; while( x%2 == 0 ) &#123; x&gt;&gt;=1; idx++; &#125; return idx+1; &#125;&#125; 如何能做到更好呢?这里有一个trick使用一条指令来完成这个工作，具体可以参考Linux Kernel里面这个ffs的代码。我来简化一下就是这么一个函数: /* ffs: if ret == 0 : no one bit found return index is begin with 1 */static int first_onebit(int x)&#123; if (!x) &#123; return -1; &#125; else &#123; int ret; __asm__(\"bsfl %1, %0; incl %0\" : \"=r\" (ret) : \"r\" (x)); return ret; &#125;&#125; 这里的bsfl是一条intel汇编指令，它的用法是bsfl op1,op2:顺向位扫描从右向左（从位0–&gt;位15或位31）扫描单节字或双字节操作数op2中第一个含”1”的位，并把扫描到的第一个含’1’的位的位号送操作数op1中。所以就是一条指令完成了这个计算过程。 这里真的会有多大的差别么，我们可以用程序来计算一下，测试如下: int main()&#123; int x; for(x=0; x&lt;=1000000000; x++)&#123; first_onebit(x); &#125; return 0;&#125; 第一个版本花费时间15.685s，第二个版本花费时间5.960s,而其实如果只是循环1000000000次什么也不做也好花费3.091s,所以第二个版本快到如此程度。 bitmap的优化bitmap是一种常用的数据结构，在编程珠玑有详细介绍，应用也比较广泛比如可以用来做操作系统当中的地址索引查询。对于bitmap中我们常常需要一个操作来找一个空位的bit来做set操作。既然我们知道了第一个1是如何快速查找的，第一0也就好办了，先取反，然后再找第一个1就行了。 #define first_zerobit(x) (first_onebit(~(x))) 继续bitmap的first_empty就优化成这样了: u32 first_empty()&#123; u32 idx; for(idx=0; idx&lt;max_idx; idx++)&#123; if(arr[idx] == 0xFFFFFFFF) //full continue; u32 v = arr[index]; return 32*idx + first_zerobit(v) - 1; &#125; return -1;&#125; 注意这样的用汇编指令来优化可能会有平台差异，所以你最好清楚自己的平台是否适用。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"bitmap","slug":"bitmap","permalink":"http://chenyukang.github.io/tags/bitmap/"}]},{"title":"使用Jekyll和Github搭建博客","date":"2012-06-13T11:43:00.000Z","path":"2012/06/13/try-jekyll-git.html","text":"为什么要折腾折腾了几次终于把博客从wordpress搬到Github了，迁徙这事本来是够麻烦的，而且也比较无聊。不过最终还是抑制不住诱惑，这有下面几点点好处。 编辑方便，专注写作 在线下编辑，可以随便选择自己喜欢的编辑器。当然wordpress也有离线编辑工具，不过Linux下我还没找到合适的，我平常是用Muse生成html，然后再粘贴到站上。其实还好，就是插入图片不方便。使用Github和Jekyll是完全的离线，你甚至都不需要离开终端就可以发布文章，一切都只是简单的git push而已。写的过程中还可以用jekyll –server预览最终排版。 可以使用Github进行版本管理 像写程序一样写日志，这对程序员吸引很大。我用这个小脚本来完成发布: #!/bin/shdo_commit() &#123; cmd=\"git commit -a -m\\\"$log\\\"\" echo $cmd git add .; git commit -a -m\"$log\" git push;&#125;while [ $# -gt 0 ]do case $1 in -commit |-u) shift; log=$1; do_commit; exit 0;; esac shiftdone 简洁 我喜欢这套是因为感觉一切都很简单,在_post目录下写markdown格式的文章，生成网页、push上去就发布了。页面也非常整洁，这对于一个以文字和代码为主要内容的站点来说最合适不过了。而且因为生成的全是静态网页，所以打开的速度也非常快。 折腾过程 这套工具适合程序员，因为一切都可以在本机上操作，你可以自己写程序来批量处理文档。我是自己写了一点Python小程序转移图片。 迁徙的过程中也会碰上一些问题，不过如果你懂一点Ruby，这些都还是比较好解决的。基本步骤为： 申请GitHub，这个不少程序员有，直接跳过。 安装Jekyll 在本地，可能会遇上ruby版本的问题，我的机子上是1.8.7，需要1.9.2，使用rvm来解决，具体参考这里。具体使用下面一些命令: sudo apt-get install gems curlgem install rvmrvm get latest rvm reloadrvm install 1.9.2rvm use 1.9.2ruby -v #(use 1.9.2)gem install directory_watcher liquid open4 maruku classifier jekyll 再建立yourname.github.com项目，git clone jekyll bootstrap到自己的代码库。 从wordpress迁徙，我使用wordpress.xml这个方法，最后修改域名解析就大功告成了。修改域名的时候在Git上建立CNAME为demo.com，在DNS处设置demo.com的A记录到Github的地址(207.97.227.245)，同时为了使得www.demo.com也指向GitHub,设定www的A记录到这个地址。这是我设置的时候出错了的地方。 整个流程非常简单，你甚至可以在三分钟内完成Github的博客搭建，更相详细可以参考这里这里。","tags":[{"name":"jekyll","slug":"jekyll","permalink":"http://chenyukang.github.io/tags/jekyll/"},{"name":"git","slug":"git","permalink":"http://chenyukang.github.io/tags/git/"}]},{"title":"Find duplicated Number and Cycle detection","date":"2012-04-11T11:43:00.000Z","path":"2012/04/11/find-duplicated-cycle-detection.html","text":"一个有趣的问题，据说这个题目耗费了Don Knuth 24小时解决。一起来看看。 You are given an array of integers of length n, where each element ranges from 0 to n - 2, inclusive. Prove that at least one duplicate element must exist, and give an O(n)-time, O(1)-space algorithm for finding some duplicated element. You must not modify the array elements during this process. 这有几个重要的约束，O(n)，O(1)的复杂度，不能修改这个数组。可能有多个数重复了，但至少有一个数重复了。首先第一个证明问题，等价于n个鸽子，n-1个笼子，那么至少有一个笼子里面有2个鸽子，就是鸽笼原理(抽屉原理), 反证法可以证明。难的是第二个问题，假设a[0, n], 值都在0,1, …, n-2 范围内。如果扫描这个数组，重复的会出现第二次(废话,囧)，关键是只能用O(1)的空间，否则用空间记录出现过的就行了。如果把数组看成一个映射，i -&gt; f(i) = a[i]， 那么这个问题可以转换成更抽象的模型。 举个例子： n = 6index: 0 1 2 3 4 5value: 1 4 0 0 3 2 其index对应value映射为为0-&gt;1, 1-&gt;4, 2-&gt;0等等，那么把这个图画出来就是这样： &nbsp; 这个问题转换为求图中环开始的点，因为出现环说明某个点重复出现了。从5开始遍历这个图会在0处发现环，为什么选取5，因为5肯定为一个起点，并且不在0~N-2内。其实只要选取不孤立的那个点当作起点就可以检测环，极端情况比如： n = 6index: 0 1 2 3 4 5value: 0 1 2 4 5 3 选择index=5还是可以发现环，如果选取0就发现不了3和4,5之间的那个环。 [Cycle detection]是一个经典的计算机问题。经典的算法是Floyd’s cycle-finding algorithm，这个算法简单而优美。严格的数学证明当然可以，也能更明显的从现实经验得出结论。如果一个赛道中间出现某个环(分两种情况，赛道本身是环、赛道前面有一段没环而中间出现一个环9字形)，求这个环的周长C。让两位运动员同时出发，并且P1的速度是P2的两倍，当他们第一重新相遇的时候，一定是在环的某个点上，并且其路程之差为这个环的周长的K倍(K&gt;=1)，这解决了一部分问题，我们知道了KC的值，如果K==1，则得出结果，说明两人刚好是在环开始点相遇。否则就是在环内其余点相遇，可以得知现在P2的路程为KC(P1的路程为2KC), 如果让P3以和P2同样的速度从起点开始，P2继续从相遇点开始跑，那么P2和P3肯定还会相遇，并且相遇的点一定为环开始点! 回到这个问题，这个index的值就是重复的值。代码描述如下： int detectCycle(int* seq， int Num)&#123; int slow = Num -1; int fast = Num -1; while(1) &#123; slow = seq[slow]; fast = seq[seq[fast]]; if(slow == fast) break; &#125; int finder = Num - 1; while(1) &#123; slow = seq[slow]; finder = seq[finder]; if(slow == finder) break; &#125; return finder;&#125; 算法描述很简单，但其中思维的却很有乐趣。以前同样有一个问题，检测一个链表是否有环，这是由此出来的一个特例，因为对于一个链表的每个节点除了头节点都有一个前节点和后节点(无环则末节点指向空)，而图是一个更通用的模型。 bool hasCycle(ListNode *head) &#123; ListNode* slow = head; ListNode* fast = head; while(fast &amp;&amp; fast-&gt;next) &#123; slow = slow-&gt;next; fast = fast-&gt;next-&gt;next; if(slow == fast) return true; &#125; return false;&#125;","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Algorithms","slug":"Algorithms","permalink":"http://chenyukang.github.io/tags/Algorithms/"}]},{"title":"eproject","date":"2012-03-08T11:43:00.000Z","path":"2012/03/08/eproject.html","text":"我之前一直用的是project-mode.el来管理项目，在碰上代码很多的工程时还是有点不方便，源文件太多速度有点慢。快速检索文件还是可以，需要指定代码目录，可以增加目录。工程的概念还是不太直观，主要用来快速查找文件。 以前看有同学推荐过eproject, 当时没仔细看。这会儿想自己写一个，而今天偶尔试用了一下这个eproject.el这才是真正需要的好东西啊。 一个工程包含的是经常需要访问的文件，另一个重要的地方是可以自己绑定Make, clean, run, configure等命令。 一组常用命令加文件检索，非常方便。看下面的配置文件很清楚，make绑定到了一组命令。 (setq prj-tools &apos;((&quot;Make&quot; &quot;cd ~/source/Panda/; ./run.sh -c;&quot; &quot;f9&quot;) (&quot;Clean&quot; &quot;cd ~/source/Panda/; ./run.sh -x;&quot; &quot;C-f9&quot;) (&quot;Run&quot; &quot;cd ~/source/Panda/; bochs;&quot; &quot;f8&quot;) (&quot;Stop&quot; &quot;-e eproject-killtool&quot; &quot;C-f8&quot;) (&quot;Configure&quot; &quot;./configure&quot; nil） (&quot;Explore Project&quot; &quot;nautilus --browser `pwd` &amp;&quot; nil) (&quot;XTerm In Project&quot; &quot;xterm &amp;&quot; nil)) 另外再推荐一个扩展viewer.el, 这个可以模拟vi里面的快捷键，其实我不是觉得vi的快捷键好，而是vi分为几个模式，编辑模式、浏览模式。这对emacs有些用，因为往往我打开一个文件只是看看，编辑的时候少，有时候按错了键使得文件内容不经意就改变了。所以通过这个扩展，默认打开一个文件都是浏览模式，还可以设置和vi一样的移动光标的快捷键，当需要进行编辑操作的时候按下i键进入编辑模式。状态栏可以显示当前所处的模式。 (add-hook ‘find-file-hook ‘view-exist-file) (global-set-key (kbd “C-o”) ‘view-mode)","tags":[]},{"title":"A Emacs func","date":"2011-12-21T11:43:00.000Z","path":"2011/12/21/a-emacs-func.html","text":"这个操作好像经常要用到，拷贝当前光标连续的一段字符串(除了空白和换行), 写了个小函数来实现。 (defun get-continue-string () (interactive) (skip-chars-backward &quot;^ \\n&quot;) (setq low (point)) (skip-chars-forward &quot;^ \\n&quot;) (setq high (point)) (copy-region-as-kill low high) (message (buffer-substring low high)))(global-set-key (kbd &quot;C-x y&quot;) &apos;get-continue-string)","tags":[{"name":"Emacs","slug":"Emacs","permalink":"http://chenyukang.github.io/tags/Emacs/"},{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"}]},{"title":"A Basket-Ball Demo","date":"2011-10-20T11:43:00.000Z","path":"2011/10/20/basketball.html","text":"最近闲暇时间用C++写了个小Demo，一个小小的篮球模拟。在学校的时候看过《人工智能编程精粹》，里面有个足球模拟，看起来还比较逼真。我这个篮球模拟是比较类似的，主要好玩的地方是在于状态机。图形方面做得很简单，还是用OpenGL来实现的，另外用了一个库glui，这个东西很好，把GUI方面琐碎的事情就简化了。整个效果图如下，这可是湖人对火箭噢。 调试状态机是个很有趣的过程，每一个球队有自己的状态机，分为进攻状态、防守状态、准备发球状态，每个球员也有自己的状态机，如下图所示。这里使用的是状态模式，把复杂的转移逻辑分散到各个状态节点，这正是状态模式的精华啊。现在这个还只是个粗糙的版本，虽然看得出来有那么点意思，规则都出来了，但是每个球员的跑位不逼真，没有多少智能的感觉。当篮球碰到边界的时候自动反弹，这点有点假，不过这也简化了不少比较繁琐的捡球和发球动作。当然现在的规则都比较简单，连三分和两分都没有分出来，罚球也没有，哈哈。现在的状态机看起来大部分时间还可以，很少的时候会出现一些比较反常规的现象。把每个状态转移过程在画面中显示出来能比较直观的去调试。下面这个是球员的状态转移图，也就是FieldPlayerStates.cpp实现的。球队的状态机要简单一些，只有三个。 程序在这里GitHub:BasketBall，感兴趣的可以看一下，也有7000行的代码了，也有点乱:). 后面有时间再调试一下，慢慢细化，球员的站位和防守动作做到更智能些。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"C","slug":"C","permalink":"http://chenyukang.github.io/tags/C/"},{"name":"Game","slug":"Game","permalink":"http://chenyukang.github.io/tags/Game/"}]},{"title":"姓氏的消失","date":"2011-09-25T11:43:00.000Z","path":"2011/09/25/xingshi.html","text":"前些天看到一篇文章有点意思。假设，人口的数目不变，儿子的姓氏随着父亲，那么随着时间的推移一代一代的演化，最后所有的人都只有一个姓了。具体用个例子描述就是：100个父亲，按照上面的假设会有100个儿子，也就是平均每个父亲在下一代会有一个儿子，假设某个父亲姓”王”，并且王在父亲这一代所占的比例是7%，那么概率上来说这个儿子姓”王”的概率为7%。你不能说我姓王，我儿子肯定随我姓呐，概率上的说法都是放在一个大的数目下。上面那句话的意思就是，平均来说占7%姓”王”的父亲在下一代能产出7%姓”王”的儿子，这是合理的吧。那么最后人们只剩下一个姓氏了么？对于这么简化的模型是很好模拟的，比如下面这段python的代码： def run(populationSize): generations = 0 cur = [x for x in range(1, populationSize+1)] count = 0 while max(cur) != min(cur): count = count + 1 next_generation = [] most_occur_name(cur) for x in range(0, populationSize): son = cur[random.randint(0, populationSize-1)] next_generation.append(son) cur = next_generation print \"finished through %d generations, last name is %d\"%(count,cur[0]) 初始化每种姓氏都有一个，最后只剩下一个姓氏，具体是哪个不确定，要花费多少代的演化也不确定，这一切都是随机的。那可以从上面的模型看出，如果在某个代中某个姓氏所占的比例相对而言比较大，那这个姓成为最后剩下的那个的概率也更大，我觉得这是个合理的结论。就我国目前的姓氏分布来说，这一个结论看起来是被验证了， 据统计我国大小姓的悬殊是十分明显的，这种悬殊还在有逐步增大的趋势，其发展的结果可能是大姓人口越来越多，很多小姓越来越少甚至被淘汰。我国目前使用着3000多个姓氏，但经常使用的仅有500个左右，占人口总数87％以上的人只使用100个姓氏，”王”姓最多占了7.25%，”张”占了6.7%。原来和同学讨论这个问题，对方一副自己将会儿孙满堂的模样”我们姓’王’”的是最多的，这看来是有依据的，而且很有可能会有更多。 继续想想，这也是进化的一个简单模型吧。不论进化论到底是真是假(进化论本身也只是个假说而已)，事实中会有这么一个现象：基数大的物种在下一代会有增大的趋势。而且姓氏看来比其他东西遗传得更坚固，对于单个人而言，后代随着父亲姓的概率应该远远大于身高随着父亲的概率吧，所以理论上看来姓氏的消失应该是比较快的。那到底是哪个姓氏会坚持到最后呢？这个不确定，而且也许在多少年内这都不会发生。我国目前的姓氏分布有地域关系，比如湖南可能姓陈的比例比较大，北方姓王的比例很大，这种不是完全随机的分布可以延缓姓氏的消失吧。张学友有首歌叫做《你的名字我的姓氏》里面的歌词是“可用你的名字和我姓氏 ，成就这故事，从此以后无忧无求”，可见，男人对于自己的姓氏留下来的愿望是多么强烈！哈哈，一点浪漫感都没了。","tags":[{"name":"Backup","slug":"Backup","permalink":"http://chenyukang.github.io/tags/Backup/"}]},{"title":"在外漂着","date":"2011-08-18T11:43:00.000Z","path":"2011/08/18/life_in_shangha.html","text":"来上海有一段时间了，在这段时间里一切都还好。 刚来这边一切都感觉比较新鲜，现在慢慢习惯了。在这边的生活比较规律，每天早上八点四十起来，洗刷完毕，早饭是面包片和同事磨的豆浆。这近两个月早餐都是这样，我觉得挺好的，一点都还没感觉到腻，带黑芝麻或者葡萄干的面包片真的很好吃！每天的九点钟开始出发上班，坐上两路地铁到张江一般整好10点左右。因为比较晚，所以不会赶上地铁的高峰。中午在公司附近的食堂，吃了一个月后觉得有点味觉疲劳了，主要是太清淡，和成都没法比啊。中午还会躺着休息一段，下午的精力才是最好的。公司前辈们都挺好，相处得不错，会耐心教我一些，自己在工作上面还有不少需要自己弄明白的。晚饭在公司吃，我这种刚来从学校出来的饭量是最大的，汗，我以前总觉得自己饭量不行。因此，在上海长胖了一些。在公司比较囧的事是中文式的英文，这个我觉得不太make sense啊，这个actually我不是很understand啊，anyway我想要撞墙，^_^。 另外最近喜欢打乒乓球，每周二下午公司一起活动，一般是乒乓球和羽毛球，我们几个打得都比较菜，过了几周后我觉得自己还是提高了一些。 来上海之前，不少在上海待过的朋友警告我，在上海的各种压力、排斥外地人，好像我要入火海似的。通过这两个月的生活来看，这些还没遇到。可能我在环境比较小，又相对单纯。只是在一个月左右的时候，某天早上我爬起床来，觉得有些不对劲，总感觉少了些什么。再仔细想想，原来我已经很久没和女生说过话了，自从成都到上海后一个师姐接过，之后这么常时间内我没和女生说过话！因为公司一个女生也没有，而我在上海的也没有的生活圈里的女生。嗯，这是个问题，长此以往会是个问题:)。倒也好，最近认识一些朋友和老乡，周末也可以找人耍耍了。上周去了人民广场，没见过世面的迷路了，还时不时没见过世面地感叹一把上海的楼高。周日去了华师大，因为看了“深度游上海”系列，说夏季最美校园为华师大，据说是“爱在华师大”，于是约上一个豆瓣好友一起去。传说中的美女没看到，一群男生暑假没回家在球场上耗费体力。不过荷花池附近还可以看看的。回来的时候坐的四号线地铁，很大一部分是在外面，看了一下觉得很多地方和成都差不多呃，浦东也就是陆家嘴那块要繁华些。问了好几个同事，说上海附近哪里风景比较好人又比较少的，都是得到鄙夷的答案，你看上海都开发成这样了，哪里还有人少的地方。我是个比较恋旧的人，还是会怀念成都，学生时代的无忧无虑，周末骑车乱逛，一群人三国杀。我的一个室友在北京，说成都的手机号多用两个月，保持一点回忆。我之前总说该出来看看外面的世界，少不入川，在成都待久了不好。所以出来感受一段时间后，我更觉得自己以后应该还是会回成都或者回家乡的小镇，“我见过的异地越多，就越怀念我的故乡”，成都算是第二故乡，第一故乡不好找工作。另外，这里 送一本书，因为是在豆瓣上未曾谋面的人送给我的，叫做 《自由在高处》，看完了觉得还不错。现在这本书还是全新的，放在我这里也浪费了，既然我是白白得来的也该白白送出去。如果有人想要的邮件给我你的地址，我邮寄给你，你付快递费(顺丰之类的是可以收货人付款的)。今天看到一些很美的画，然后就把这弄上博客头了，原图是这张。这里还有不少：）","tags":[{"name":"Notes","slug":"Notes","permalink":"http://chenyukang.github.io/tags/Notes/"}]},{"title":"C的面向对象风格代码","date":"2011-08-16T11:43:00.000Z","path":"2011/08/16/ooc_in_python.html","text":"OO是一种编程范型，而不只是特定语言的特定支持，所以用C来实现也是可行的。最近碰到的一部分代码都是用C实现的面向对象风格，可能是参考了Python里面的实现，Python内部实现的基本对象这块也全是这样的代码。在这里做一个小小的总结。 C语言里面没有语言层面的面向对象支持，那OO中的三个基本要素封装、继承、多态如何实现？C里面最强大的东西是指针，指针中最神奇的是void指针，这是一切的基本。首先来看封装，如何通过实例来调用方法，而对内部数据进行隐藏。完全可以写一些struct，然后写对应的函数来针对这个struct来操作，我们需要更进一步，把数据和方法绑定起来。这样写初看起来并没什么好处，后面会发现，通过函数指针去找对应的函数是多态的关键。 //object.htypedef struct _obj&#123; char name[MAXLEN]; int ref_cnt; int value; void (destructor) (void thiz); void (print) (const void thiz); int (equal) (const void thiz, const void* other);&#125; Obj;//object.c destruct,print,equal定义为staticObj Obj_new(int value)&#123; Obj o = malloc(sizeof(Obj)); strcpy(o-&gt;name,“baseobj”); o-&gt;ref_cnt = 1; o-&gt;value = value; o-&gt;destructor = &amp;destruct; o-&gt;print = &amp;print; o-&gt;equal = &amp;equal; assert(o); return o;&#125;//使用方法 &#123; Obj first = Obj_new(1); Obj other = Obj_new(2); first-&gt;print(); other-&gt;print(); first-&gt;equal(first, other); Obj_drop(first); Obj_drop(other); return 0;&#125; 对于继承C当然也没原生的支持，可以在子类的定义中写入父类中的成员变量和成员函数，这里如果父类中定义的时候就是宏，直接拿过来就是。所以把父类的定义重新改写一下，分为DATA类型和TYPE类型，在Python里面就是这样，PyObject和PyVarObject是一切其他对象都包含有的。下面是一个例子People继承Object,Student继承People。 #define PEOPLE_DATA \\ OBJ_DATA \\ int age;\\ char fullname[100]; //OBJ_DATA必须放在子类新的数据成员前面，只有这样才能把子类的指针强制转换成父类指针 或者转化为Object指针 #define PEOPLE_TYPE \\ OBJ_TYPE \\ void (sleep)(void thiz); typedef struct _People_Type&#123; PEOPLE_TYPE&#125; People_Type;extern const Object_Type Object_type;extern const People_Type People_type;typedef struct _People&#123; const People_Type* methods; PEOPLE_DATA&#125;People; 这里sleep为新增加的子类方法，fullname为新增加的成员变量。注释部分为特别注意的，只有在保证内存的里面数据的分布前面部分都是一样的(一个methods指针和obj_data部分)才能进行指针之间的强制转换时候不出问题。例子里面的Student类也是类似的继承People类，这里可以看到sleep这个方法不好弄，因为在People那里申明为static了，这里想复用就麻烦，所以只有再自己写一个(即使实现是一样的)，这也是C++内部帮用户做好的。可以看到通过type里面的函数指针的不同，不同对象相同的方法实现就不同了，因此实现了多态。 最后我们可以写一个基于计数的指针管理，在持有一个指针的时候调用Obj_pick,用完以后执行Obj_drop。 void Obj_pick(const void thiz)&#123; assert(thiz); Object o = (Object*)thiz; o-&gt;ref_cnt++;&#125;void Obj_drop(const void thiz)&#123; Object o = (Object)thiz; const Object_Type p; if( –o-&gt;ref_cnt &lt;= 0)&#123; for( p = o-&gt;methods; p; p=p-&gt;father)&#123; if(p-&gt;destructor) p-&gt;destructor(o); &#125; &#125; free(o);&#125; 按照这种OO的风格的C代码感觉要清晰一些，至少我习惯了。不过还是看个人品位吧，这样的代码风格是我另外一个同事所鄙视的。关于用C实现OO风格，还有一本比较好的书叫做Object-oriented Programming with ANSI-C，感兴趣可以看看。 上面的代码在这里下载：https://github.com/chenyukang/ooc。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Backup","slug":"Backup","permalink":"http://chenyukang.github.io/tags/Backup/"}]},{"title":"一种更快的字符串匹配算法-源自Python2.5","date":"2011-07-30T11:43:00.000Z","path":"2011/07/30/fastsearch-in-python2.html","text":"Python2.5的实现中有一个字符串匹配算法，在s中查找p是否存在，s的长度为n，p的长度为m。这个算法符合以下要求： 任何情况下都要比brute-force算法快 O(1)的空间，O(m)的初始化复杂度 O(n/m)的查找复杂度 最坏情况下不能比O(nm)时间复杂度差 实现简单，对于实际中的查找大部分表现良好，最坏情况出现概率小 标准的字符串查找算法不满足这些要求，KMP的时间复杂度为O(m+n)(初始化O(m)加第二部分O(n)， Boyer-Moore和其变形要求额外的空间，Python2.5里面增加了这个结合了Boyer-Moore和Sunday的思想的变形实现。来看看这是怎么个神奇的算法，KMP的思想是在每一次不匹配的情况下尽量的向右边移动，所以计算一个Next的移动下标数组。如果不匹配，最理想的情况下是向右边移动多长?应该是m，这样就能尽量减少对比的次数。所以每次比较的时候先比较p的最后一个字符，比如s=”aaaaaaad”，p=”aae”，如果从s的开头查找，只要发现第3个和p的第三个不一样，移动指标，移动多少？如果发现没有e，最长能移动p的长度，就是3。如果最后一个不匹配并且s[i+m]不是p中的字符就移动m，否则移动1。这里有两个问题： 如何知道s中的某一个字符是否是p中的一部分?如何尽量移动m而不出现少找的情况? 第一个问题，可以用某个存储空间存下是否有p中的某个字符出现过，方便以后查找。Hash的思想，但是这里字符串查找里面再弄个Hash太无语了吧。一个简单的Bloom-filter，这里是这样实现的。 /*计算mask*/ mlast = m-1;for (mask = i = 0; i &lt;= mlast; i++) &#123; mask |= (1 &lt;&lt; (p[i] &amp; 0x1F));&#125;/*判断s[i]不是p中的一个字符串*/ if(!(mask &amp; (1 &lt;&lt; (s[i] &amp; 0x1F)))) printf(\"s[i] is not in pattern\");else printf(\"s[i] is in pattern\"); 其实我们是要判断一个s中的一个字符串没有出现在p中，取低5位不是可能产生冲突么？产生冲突也没问题，就像一个Hash只要一个元素算出来的Key指定的slot没元素不就能确定这个元素不在里面了么。 第二个问题，有些巧妙。上面那个例子是因为s的最后一个字符没被匹配，所以能移动m的长度。如果这个例子s=”aaacaaaacaa”，p=”aacaa”，第5个位置都为a，最后一个匹配，但是s里面前几个其实不为aacaa，所以需要移动，但是移动多少呢?如果移动p的长度，那从第2个位置开始的aacaa就没被检查到。所以需要一个变量记录在每次最后一个字母匹配的情况下向右移动的合理偏移量，在这里为skip，初始化的时候计算出来，这最偏移量其实是计算的最小偏移量，就是移动skip个位置到第一个s[m-1]的位置。 整个实现既节省空间又速度快，强大。 具体实现如下： //如果mode为FAST_COUNT，则查找pattern出现的次数#define FAST_COUNT 1int fastsearch(const char* s, size_t n, const char* p, size_t m, int mode)&#123; long mask; size_t skip, count = 0; size_t i, j, mlast, w; w = n - m; if (w &lt; 0) return -1; /* 如果m=1，特例，扫描一遍解决*/ if (m &lt;= 1) &#123; if (m &lt;= 0) return -1; if (mode == FAST_COUNT) &#123; for (i = 0; i &lt; n; i++) if (s[i] == p[0]) count++; return count; &#125; else &#123; for (i = 0; i &lt; n; i++) if (s[i] == p[0]) return i; &#125; return -1; &#125; mlast = m - 1; skip = mlast - 1; /*计算mask*/ for (mask = i = 0; i &lt; mlast; i++) &#123; mask |= (1 &lt;&lt; (p[i] &amp; 0x1F)); if (p[i] == p[mlast]) skip = mlast - i - 1; &#125; mask |= (1 &lt;&lt; (p[mlast] &amp; 0x1F)); for (i = 0; i &lt;= w; i++) &#123; if (s[i+m-1] == p[m-1]) &#123;//pattern末尾匹配 /* candidate match */ for (j = 0; j &lt; mlast; j++) if (s[i+j] != p[j]) break; if (j == mlast) &#123;//一个匹配成功 if (mode != FAST_COUNT) return i; count++; i = i + mlast; continue; &#125; /*移动多少?,根据mask*/ if (!(mask &amp; (1 &lt;&lt; (s[i+m] &amp; 0x1F)))) i = i + m; else i = i + skip; &#125; else &#123; /* skip: check if next character is part of pattern */ if (!(mask &amp; (1 &lt;&lt; (s[i+m] &amp; 0x1F)))) i = i + m; &#125; &#125; if (mode != FAST_COUNT) return -1; return count;&#125;","tags":[{"name":"Python","slug":"Python","permalink":"http://chenyukang.github.io/tags/Python/"},{"name":"Algorithms","slug":"Algorithms","permalink":"http://chenyukang.github.io/tags/Algorithms/"},{"name":"C","slug":"C","permalink":"http://chenyukang.github.io/tags/C/"}]},{"title":"让Emacs提醒睡觉","date":"2011-07-24T11:43:00.000Z","path":"2011/07/24/emacssleep.html","text":"最近都睡的比较晚，对身体不好啊。写了几行恶趣味的elisp，晚上10点40开始提醒提醒我准备睡觉，如果10点50还没动，我的上下移动键就不能用了，下面会有一条提示：太晚了，该睡觉了。不过这时可以用方向键盘来移动。但过十分钟后快捷键又恢复正常，因为过了11点表示我确实要再待晚点，下个小时40分钟继续提醒，50分锁死快捷键盘。12点过后emacs彻底对我无语了。真是egg hurt… (defun is-late-now() \"Check if it is now late, emmm, go to sleep\" (let ((hr (nth 2 (decode-time (current-time)))) (minute (nth 1 (decode-time (current-time))))) (and (and (&gt;= hr 22) (&gt;= minute 40) (message \"prepare sleep now....\")) (&gt;= minute 50)))) (defun my-next-line() (interactive) (if (is-late-now) (message \"late now, go to sleep ... baby!\") (next-line))) (defun my-prev-line() (interactive) (if (is-late-now) (message \"late now, go to sleep ... baby!\") (previous-line))) (global-set-key (kbd \"C-n\") 'my-next-line) (global-set-key (kbd \"C-p\") 'my-prev-line) 这样写不好看，更好的办法是用defadvice，那就不用重新绑定C-n和C-p了，defadvice可以直接在运行next-line和previous-line之前检查一下。 (defadvice previous-line (before check-is-later) (if (is-late-now) (progn (message “late now”) (sleep-for 1)))) ;;just sleep 1 second (ad-activate ‘previous-line)这样后只要执行previous-line这个函数之前都会执行我这个defadvice定义的代码，但是这样连方向键也不能移动了，因为向上这个按钮是绑定的previous-line这个函数。","tags":[{"name":"Life|Notes","slug":"Life-Notes","permalink":"http://chenyukang.github.io/tags/Life-Notes/"}]},{"title":"到上海了","date":"2011-07-23T11:43:00.000Z","path":"2011/07/23/toshanghia.html","text":"很久没写咯，我已经在上海了，房子刚好弄好。 毕业之前去了青海湖，我和一个同事本来打算三天环青海湖骑行一圈的，第一天骑车148公里，第二天一早就走错了路（环行的居然走错了路），结果骑过了橡皮山，发现是已经骑了20公里左右。幸好在路上等了个回去的卡车，把我们带回黑马河。重新出发，环湖西路的路况非常好，车也很少。继续骑了120公里到达刚察，到刚察之前的最后一段感觉是最累的。第三天早上我刚出门过了个大坡，下来的时候不小心摔了一下，于是最后那一段就没骑了，真是遗憾啊。在西海镇继续住了一晚，221骑吧的店主人很好，看我摔了下巴，晚上给我做粥喝。牦牛肉粥非常好喝，嗯，非常感谢！也非常感谢同行的同事，一路给了我很多鼓励和帮助。青海一行虽然有些意外，但是也还是觉得挺不错的，那边人和风景都可以。 更多照片在豆瓣上面，照得不好，实景更漂亮，如果七月份去会更好。在从青海回成都的火车上，躺在铺上看《瓦尔登湖》，以前总没好好静下心来看完这本书，那天慢慢翻着有些入味了。“你们要尽可能长久地生活得自由，生活得并不执着才好。执迷于一座田园，和关在县政府的监狱之中，简直没有分别。” 如何生活得简单、自由，是我所难于学会的。 从青海回成都后，在学校办了一些手续，然后直接到上海了。国庆看有没有时间再回家一趟吧。在成都，走之前还和不少朋友没有聚，先记下吧，我觉得我会回成都的:) 在上海待了已经有几天了，说不上适应不适应，至少还没融入，只是一个旁观者。至少楼比成都高多了，交通比较方便也稍微有点贵。房子基本没找，有同事的一个二室一厅的，租下来就行了吧，认识的人住在一起也好些。工作上面还在适应，不少东西要好好学习一下噢。新的开始，努力一把。","tags":[{"name":"Life|Notes","slug":"Life-Notes","permalink":"http://chenyukang.github.io/tags/Life-Notes/"}]},{"title":"Wumpus and 《Land of Lisp》","date":"2011-07-22T11:43:00.000Z","path":"2011/07/22/wumpus-and-2.html","text":"最近在看一本书《Land OF Lisp》，看了大部分。离前一次看Lisp方面的书刚好三年，用Emacs也有四年了，这期间接触的多是简单的Elisp。总得来说，Lisp的书看起来是比较有趣的，这本也不错，稍微比《Practical Lisp》简单。竟然有个第6.5章，Lambda这么重要，怎么说也要占一章！第八章实现了一个小游戏。Wumpus(Hunt the wumpus)是个古老的游戏，那个年代还没有绚丽画面，只有文字界面。这里游戏的规则是： 1. 地图为一个无向图，玩家控制一个人物在图中行走，目的是寻找潜伏在节点中的一个怪兽。其中要边走边推理，得出怪兽在哪个节点。 2. 还有其他角色，有的节点隐藏着超级蝙蝠，它能把你扔到图的任何位置。节点之间的边可能有警察。 3. 如果你推测出怪兽的位置，向那里射箭，如果射中则胜利，否则输掉。如果你不小心从有警察的边通过了，也死掉。 4. 在怪兽的附近两个距离范围内，会有血气。如果一个点的某条边有警察，这个点会有光晕。 说起来复杂，来看副图。有点像挖地雷那种小游戏。有？符号的为没访问过的点，*为当前点，从14到15遇到警察死掉了。上周末玩了好几个小时，还挺难胜，主要还是图比较大，游戏一开是整个地图是已经生成了的，要偷懒可以看看。来看看如何用Lisp代码来实现这个程序，程序比较短。首先是如何生成图，需要生成一个随机的连通图。设定节点数目和边的数目，以编号代表节点。random-node:随机地选一个节点。edge-pair:连接两个点表示边。make-edge-list: 重复N次，生成N条边的集合。这个随机图可能不是连通的，下面的代码找出孤立的点集，用一些边连接起来这些孤立的点集，随机图产生完成。第二步向某些点之间加警察，随机的。这其中用了各种mapcar和Lambda，这样的效果使得Lisp程序看起来全是括号。mapcar的意思就是我要在这个列表上面所有的元素上都执行这个Lambda函数。visited列表保存已经访问过的节点，know-city-nodes更新(不是纯函数式编程的风格)，know-city-edges根据访问的节点，生成已知的路径，当前已知的用dot画出来。graphviz是个好东西，最近也在学习用这个来画一些流程图，效果挺好的。 乱说说Common Lisp，看了一些这方面的资料，这语言不管有多少牛逼人士簇拥(最近Paul Grahamd的书被翻译了)，使用的人还是太少还是有一定的历史原因，早期的实现效率是一个问题，而当实现和硬件都不错了的时候C/C++已经成大局了。另一个很重要的原因是，文档不是很好，我想找个处理图片方面的库，见到一个README文件跟救命稻草似的，打开一看”Do you really need DOCS?”。Lisp的哲学是语言不能给太多限制，甚至做到代码就是数据、数据就是代码，你可以轻而地为语言添加特性，你还可以用宏来写出生成代码的代码。Lisp给了程序员最大的自由来挑战语言的限制，所以会出现如此多种的方言。好的一面是面对特定的问题或许能得到优美而高效率的解决方法，而这个代码对于另外一个程序员来说太难读懂(特别是夹杂了宏的代码)，继而难于流传。这里有篇经典的Lisp:Good news,Bad news，作者为早期用Lisp作为开发语言开公司的。以后看看Haskell吧，这个比较有前途。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Books","slug":"Books","permalink":"http://chenyukang.github.io/tags/Books/"},{"name":"Lisp","slug":"Lisp","permalink":"http://chenyukang.github.io/tags/Lisp/"},{"name":"wumpus","slug":"wumpus","permalink":"http://chenyukang.github.io/tags/wumpus/"}]},{"title":"《Advanced linux progamming》笔记","date":"2011-06-14T11:43:00.000Z","path":"2011/06/14/advanced-linux-porg-notes.html","text":"Writing and using Libraries 链接分为动态链接和静态链接。 Archives archive(静态链接)为目标文件的集合，linker从archive文件中找到obj文件进行链接。 % ar cr libtest.a test1.o test2.o 创建库文件libtest.a(类似windows下test.lib)，当linker处理archive文件的时候，将在库文件中查找当前已经处理但是还没定义的symbols。所以库文件应该出现在命令的最后。 % gcc -o app app.o -L. -ltest Shared Library Shared lib和archive的两个区别： 1，当进行的是动态链接，最后得到的可执行程序中不包含实际库中的执行代码，只是一个对库的引用。所以动态链接最后得到的可执行程序要小一些。 2 多个程序可以共享动态链接库，动态链接库不只是obj文件的集合，其中是单一的一个obj文件，包含了库中所有的信息，所以一个程序动态加载shared lib的时候是把库中所有的东西都加载了，而不是所引用的那部分。 % gcc -c -fPIC test1.c % gcc -shared - fPIC libtest.so test1.o test2.o -fPIC选项指编译为位置独立的执行代码，这样可以动态加载，产生libtest.so文件。 默认的库文件寻找路径变量：LD_LIBRARY_PATH 库文件之间的依赖关系：如果是动态链接，链接库会自动寻找到自己所依赖的其他库文件，如果是静态链接，必须为linker提供所有依赖的库文件名称。 % gcc -static -o tifftest tifftest.c -ltiff -ljpeg -lz -lm 上面例子中tiff依赖jpeg库，因为是-static链接，必须指明所有依赖的库文件。 Pros and Cons 动态链接的优势：可以减少可执行文件的size，如果库文件进行升级，原程序可以不用重新链接。如果是静态链接，库文件改变了程序要重新进行link。 也有一些特殊情况必须使用static link。 动态加载和卸载库 void* handle = dlopen (&#8220;libtest.so&#8221;, RTLD_LAZY); void (*test)() = dlsym (handle, &#8220;my_function&#8221;); (*test)(); dlclose (handle); 上面例子中打开libtest.so动态链接库，找到my_function定义，执行，然后卸载库文件。 进程 创建进程 using system #include &lt;stdlib.h&gt; int main () { int return_value; return_value = system (\"ls -l /\"); return return_value; } system将执行/bin/sh,然后执行命令，因为不同系统中/bin/sh所链接的shell不同，所以会导致执行差异，同时这种方式存在安全隐患。 using fork and exec fork创建一个子进程，fork的返回值用来区别父进程和子进程。子进程将和拷贝父进程一些信息，更详细的东西在这本书内没说明。 exec函数家族，fork创建一个子进程，用exec在子进程中执行命令。 process scheduling nice命令可以调节process的优先权值。 niceness value越大，进程的优先权越低，越小进程的优先权越高。一般进程的niceness value为0。只有root的进程可以减少一个进程的niceness value。 signal signal is asynchronous:进程收到信号的时候会立即处理信号，处理信号的一般方式分为几类：忽略，执行默认处理，执行特定的处理程序。 因为信号处理是异步的，所以在信号处理程序中尽量不要执行IO，或者调用库函数。信号处理函数应该作最少量的工作，尽快返回到主流程中，或者干脆结束掉程序。一般只是设置变量表明某个信号发生了，主程序定时检查变量再处理。SIGTERM和SIGKILL区别，前一个可能被忽略，后一个不能被忽略。 改变sig_atomic_t的值的操作是原子性的。 process exit exit(int return_value)函数退出一个进程，并把exit_code告诉父进车。kill(pid_t,KILL_TYPE)向某个进程发送相应的退出信号。 wait函数家族，让父进程等待某个子进程的结束。WIFEXITED宏判断子进程是否正常退出或者是由于其他原因意外退出。 zombie process(僵死进程)为一个进程已经退出，但是没有进行善后处理。一个父进程有责任处理子进程的善后处理，wait函数即为此用，父进程调用wait一直被阻塞(当子进程没有退出的时候),子进程退出后wait函数返回。如果父进程没有为已经退出的子进程处理善后，子进程将变为init的子进程，然后被处理删除。 一种更好的处理方法是当子进程退出的时候发信号通知父进程，有几种方式可以实现(进程间通信),其中一种比较方便的方式是父进程处理SIGCHLD信号。 Threads 线程作为亲量级进程，切换引起的开销更小，一个进程的多个子线程共享进程的资源。 create thread 创建线程：pthread_create (&amp;thread_id, NULL(pointer_to_thread_info), &amp;thread_func, NULL(argument)) 线程的执行顺序是异步的，不能假设其执行顺序。 向thread传递数据：可以通过pthread_create的地四个参数，传递一个void* 的指针，指针指向一个数据结构体。注意在多线程中的数据空间的销毁。 More about thread_id: if (!pthread_equal (pthread_self (), other_thread)) pthread_join (other_thread, NULL); Thread Attributes,为了设定线程的某些属性，detach线程退出后自动回首资源，joinable则等到另一个线程调用pthread_jion获得其返回值。 Thread-specific data:每个线程都有一份自己的拷贝，修改自己的数据不会影响到其他线程。 Cleanup Handlers:使用pthread_cleanup_push(function,param)和pthread_cleanup_pop(int)在线程退出的时候自动调用清理函数，释放资源。 多线程程序可能出现的问题：竞争，需要使用atomic操作。 互斥锁 只有一个线程能够拥有，此时其他线程访问互斥锁将被阻塞。 pthread_mutex_t mutex; pthread_mutex_init(&amp;mutex,NULL); //&#25110;&#32773;pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; //&#32447;&#31243;&#20013;&#20351;&#29992;pthread_mutex_lock&#21644;pthread_mutex_unlock&#26469;&#38145;&#20303;&#21644;&#35299;&#38145;&#20114;&#26021;&#38145;&#65292; Semaphores for Threads sem_t 可以作为一个share counter 来使用， sem_t job_queue_count; //initialize sem_init(&amp;job_queue_count,0,0); //wait for sem_wait(&amp;job_queue_count); //lock mutext //and do somethting //unlock //new job sem_post(&amp;job_queue_count) Threads VS Process Guidelines: 1，所有线程所执行的指令必须是在一个可执行文件里面，而多进程可以执行多个命令。 2，因为多个线程共享相同的虚拟内存地址，所以一个线程的错误可能会影响到其他线程，而多进程程序中一个进程的错误不会影响到其他进程。 3，为新进程拷贝内存将增加开销，但是只有在新进程写其内存的时候才会进行拷贝(写拷贝)。 4，多线程适用于多个相似的执行任务，而多进程可以执行不同类型的任务。 5，多个线程中共享数据要容一些，但是也会产生相关问题(条件竞争，死锁)，多个进程共享数据难一些，使用IPC机制，虽然实现要难一些，但是不容易出现并发bug。 Interprocess Communication Share Memory share Memeory 是最简单的进程间共享数据的方式。 Allocation shmget函数创建或者访问一个已经存在的share mem。 int segment_id = shmget (shm_key, getpagesize (), IPC_CREAT | S_IRUSR | S_IWUSER); Attachment and Detachment 函数shmat(SHMID,pointer to address,flag)使得一个进程attach到一个共享内存。进程通过fork创建的子进程也将继承这一共享内存。函数shmdt(address)将detach共享内存。 int segment_size; const int shared_segment_size=0x6400; //allocate a shared mem segment_id=shmget(IPC_PRIVATE,shared_segment_size, IPC_CREAT|IPC_EXCL|S_IRUSR|S_IWUSR); //atach the share mem share_memory = (char*)shmat(segment_id,0,0); printf(\"share memory attached at addreass %p\\n\",share_memory); Control share mem 函数调用exit或者exec 可以detach一个共享内存，但是并没有释放它。必须调用shmctl去释放其空间。ipcs -m 命令可以查看系统中当前的share mem的信息，如果没有删除遗留的shared mem，其nattch为0。可以使用ipcrm shm segment_id删除。 Process Semaphores semaphore和shared memory的使用方式类似，可以通过semget,shmctl创建和删除，提供的参数表明要创建semaphore。没详细说，查看其他书。 Mapped memory Mapped memory是不同进程可以通过一个公用的共享文件进行交流。Mapped mem在进程是进程和文件的一个桥梁，linux通过把文件映射到虚拟内存，这样进程可以像访问普通内存一样访问该文件。void* mmap(address,LENGTH,prot_option,option,file_rp,pos) //将一个文件映射到address，如果不提供系统将映射到合适的地址munmap(file_memory,FILE_LENGTH);// 释放memory设置了MAP_SHARED,多个进程可以通过同一文件访问该内存区。 管道 pipe int pipe_fds[2]; int read_fd; int write_fd; pipe (pipe_fds); read_fd = pipe_fds[0]; write_fd = pipe_fds[1]; pipe_fds[0] 为reading file desc,pipe_fds1为writing file desc。 Pipe只能用于同一个进程的子进程之间。 dup2重定向标准输入输出符。 popen,pclose很方便，FILE* stream=popen(&quot;progam&quot;,&quot;w&quot;)向program发送。pclose(stream)关闭。 FIFO 为有名字的pipe，任何不相关的两个进程可以通过fifo来进行数据传递。mkfifo函数创建FIFO。 Socket 系统调用: socket-- Creates a socket close -- Destroys a socket connect -- Creates a connection between two sockets bind -- Labels a server socket with an address listen -- Configures a socket to accept conditions accept -- Accepts a connection and creates a new socket for the connection Unix-domain sockets能用于同一机器上的进程通信。Internet-domain sockets用于不同机子上的通信。struct sockaddr_in addr类型变量为其地址结构。addr.sin_family=AF_INETaddr.sin_addr 存储一个32bit的IP地址。 只是给了两个程序例子，详细内容看网络编程相关书籍。 Mastering Linux Device 分为字符设备和块设备，块设备可一随机访问，字符设备提供流。一般应用程序不会直接访问块设备，而是通过系统调用来使用块设备。设备号，主设备号是根据设备类型分的，从设备号根据具体设备分。cat /proc/devices 查看设备类型和主设备号。 Device Entry 只有root的进程可以通过mknod创建新的Device Entry。mknod name b/c 主设备号 从设备号 linux目录/dev 下面是系统所支持的Device Entry。字符设备可以像一般文件一样访问，甚至可以用重定向去访问。 cat somefile &gt; /dev/audio 可以发出声音了 特殊设备：/dev/null /dev/zero /dev/full /dev/random /dev/urandomLoopback Devices:环回设备，在文件系统上新建一个普通文件，可用于模拟特定设备，比如软盘。也可把实际设备中的内容拷贝到其中，比如把光盘中的内容拷贝到新建的一个cdrom-image中。 /proc mount命令可以看到一行输出：proc on /proc type proc (rw,noexec,nosuid,nodev)/proc包含系统的一些配置信息，不和任何设备相关联。 $cat /proc/version 查看内核版本 $cat /proc/cpuinfo 查看cpu信息 /proc目录下同时包含系统中当前的进程信息，由于权限设置，有的只能由进程本身访问。可以通过访问文件获取系统中进程的相关信息，比如参数，运行环境,内存使用信息等等。 Linux system call system call和一般的C库函数的区别：系统调用一般通过门陷入实现，是系统内核和用户程序的接口，运行过程中会进入系统内核。C库函数一般和普通的函数没有区别。 strace:该命令可以追踪一个程序执行过程中的调用的system call。access:测试进程对于一个文件的权限。 int access(path,bit_flag),注意返回值和errno。fcntl:锁住文件和控制文件操作。fsync,fdatasync:flush disk buffer。getrlimit,setrlimit:资源限制设置。getusage:获取进程的统计信息。gettimeofday:获取wall_clock time。mlock:锁住一段物理内存，使得该内存不能因为swap换出，一些速度要求很高的和安全性要求很高的代码会使用这个功能。 mlock(address,mem_length)mprotect:设置内存的权限。nanosleep:高分辨率睡眠函数。readlink:read symbolic links。sendfile:Fast file Transfer。setitimer:定时器。sysinfo:获取系统统计信息。uname:获取系统版本信息和硬件信息。 Inline Assembly Code /usr/include/asm/io.h 定义了汇编代码中能够直接访问的端口。/usr/src/linux/include/asm and /usr/src/linux/include/asm-i386 linux内核中汇编代码头文件/usr/src/linux/arch/i386/ and /usr/src/linux/drivers/ 汇编代码当使用特定平台的汇编代码时使用宏和函数来简化兼容问题。 Security 用户组 文件 进程权限 用户和组的概念超级用户 无穷权力proccess user id和proccess group id。进程开始的时候其id和启动该程序的用户信息相同。文件权限 chmod stat(filename,&amp;(struct stat))program without Execution Permissions: a security hole。 其他用户能够拷贝该文件，然后修改其权限。Sticky bit:用于文件夹，当一个文件夹的sticky bit设置了后，要删除该文件夹下的一个文件必须拥有对该文件的拥有权，即使已经拥有该文件夹访问权。Linux下的/tmp设置了sticky bit。Real and Effective ID::EID代表进程所具有的系统权限，如果是非root用户，EID=RID；只有root用户可以改变它的EID为任何有效的用户ID。su命令：是一个setuid程序，当程序执行的时候其EID是文件的拥有者，而不是启动程序的用户号。chmod a+s使得文件有这个属性。 缓冲区漏洞 如果栈中有固定长度的输入区，则会含有缓冲区漏洞。最通常的形式： char username[32];/ Prompt the user for the username. /printf (&#8220;Enter your username: &#8220;); / Read a line of input. /gets (username);/ Do other things here… /攻击者可以故意使得缓冲区读满，然后在超出的区域植入想执行的代码段，获得控制权。 Race Conditions in /tmp 攻击者先创建一个链接，如果应用程序在/tmp下创建打开一个相同名称的文件，所有写入的数据将传送到链接所指向的文件里。解决方法：在文件名称内使用Random，open函数使用O_EXCL参数，如果文件存在则失败，打开一个文件后用lstat查看是否是链接文件，检查文件的所有者是否和进程所有者一样。/tmp文件不能挂载在NFS下，因为O_EXCL不能在NFS文件系统下使用。 system ,popen函数的危险 替代使用exec族函数。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Linux","slug":"Linux","permalink":"http://chenyukang.github.io/tags/Linux/"}]},{"title":"从豆瓣FM下载喜欢的音乐","date":"2011-06-07T11:43:00.000Z","path":"2011/06/07/554.html","text":"我是豆瓣FM的忠实用户，用这个东西已经有一年多了吧，累计收听了不少歌曲(316首喜欢的,45首不再播放的,7352首播放过)。通过这个东西发现不少符合自己口味的音乐。这316首是我喜欢的类型，所以想把这个列表弄下来，然后把这些歌曲下载到电脑上。 看了一下豆瓣是有自己开放的API的，不过还是够麻烦的。于是折腾了一个Python程序，输入你的豆瓣用户名和密码，模拟登录豆瓣并记录cookie，自动地到FM的页面去取下这个音乐列表。这个程序在处理HTML文件的时候有点笨拙，正则表达式不够强嗄。需要另一个库python-beautifulsoup。 通过歌曲名，自动下载这个应该是已经有人做了的，于是发现这个getsong.py，是通过Baidu音乐自动下载的，使用了一下速度和成功率都不错，于是在这个上面做了一些修改，直接从上面的程序生成的列表中取歌曲名字，下载下来。如果网速可以一般能在500k左右的下载速度，挺不错的。这个程序有可能会抛出一些异常，我没做仔细的检查，如果一首歌下载不下来就pass掉。 上面的程序都放在GitHub上了，Git/GitHub可个是真好东西。需要的朋友们从这个地址弄下代码:https://github.com/chenyukang/fmmusic 使用方法： 1 修改fm_get_music.py，在里面填入自己的豆瓣用户名和密码。 2 运行这个程序，会在当前目录生成一个歌曲列表：songlist.txt。 3 运行getsong.py程序， python getsong.py -x，就是通过songlist.txt逐个通过百度搜索自动下载，存在当前目录。","tags":[{"name":"Python","slug":"Python","permalink":"http://chenyukang.github.io/tags/Python/"},{"name":"mp3","slug":"mp3","permalink":"http://chenyukang.github.io/tags/mp3/"},{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"豆瓣","slug":"豆瓣","permalink":"http://chenyukang.github.io/tags/豆瓣/"}]},{"title":"读memcached","date":"2011-05-22T11:43:00.000Z","path":"2011/05/22/memcached.html","text":"最近在看memcached的源代码，边看边随手记录了一下。 assoc.c: 记录一个item是否存在于缓存中，这里使用了power 2扩展，primary_hashtable,和old_hashtable分别存新申请的hashtable和旧的hashtable。这里起了个线程来做拷贝的工作，当需要扩展hashtable的时候就触发assoc_expand函数，但是这个函数做的工作是备份primary_hashtable，即old_hashtable=primary_hashtable；然后申请新的空间，标识expanding为true，如果申请空间失败则交换回来。通过条件信号量，assoc_maintenance_thread把old_hashtable的数据逐步拷贝到新的hashtable中，当拷贝完了后释放old_hashtable的空间。耗时的操作用另外一个线程逐步来处理，不过查询和插入都要注意是否是在扩展状态，判断是去old还是primary里面去操作。 cache.c: 在malloc和free的基础上封装了一层，多线程安全的。维持了一个指针列表，释放的时候并没有一下就把内存还给系统，而是在列表中保存了下来，申请时如果列表中有没用的指针就直接返回给出来。能这么因为这个cache模块只是负责申请和释放size相同的内存块。 thread.c: 维持连接列表相关的内容。为一个队列，cq_push、cq_pop，维持一个LRU机制。cqi_new函数返回一个新的CQ_ITEM指针，同样维持了一个cqi_freelist，当有空闲指针的时候直接返回，当没有空闲的时候申请一个列表，从第二个开始连结成链表形式，返回第一个元素的指针。create_worker，创建一个处理线程。Item为memcached中处理的主要对象，item_alloc、item_get、item_link、item_unlink、item_remove方法，处理的时候都要锁住cache_lock。threadlocal_stats_reset、threadlocal_stats_aggregate：统计信息相关。slab_stats_aggregate：统计一个线程使用的slab信息。threadlocal_stats_reset：清空统计信息。 thread_init：主程序中调用的创建多线程函数，包括初始化互斥锁(cache_lock,stats_lock)，条件锁，空闲连接列表等。nthreads为初始化的线程数目，继续调用setup_thread启动每一个线程，调用create_worker创建处理线程。 stats.c:负责统计信息，记录get、set、delete、hits的数目。以前缀作为key。 slabs.c：负责管理内存申请和释放，slabs主要是为了避免内存碎片问题，同时提高申请内存的速度，其基本原理是大块地申请内存，根据不同的slabclass块大小分给slabclass，申请内存的时候根据地址选择最适合的slabclass，从中去下内存返回指针，释放的时候只是放在其空闲指针列表中(不少地方都用到这样的方式)。slab_list没什么用，因为释放的指针放在了slots里面啊！slabs贪婪地使用内存，整个这东西的作用就是用内存空间来换时间效率的。 memcached.c：主程序，分析设置参数默认值，分析参数根据参数修改配置参数。初始化stats，assoc，conn，slabs等。thread_init启动线程，每一个线程都有自己的struct event_base，setup_thread函数初始化这些，最重要的设置thread_libevent_process来处理新的连接。一直到： / Create threads after we’ve done all the libevent setup. / for (i = 0; i &lt; nthreads; i++) { create_worker(worker_libevent, &amp;threads[i]); }每个线程进入自己的event_loop。 当请求来临的时候对于每一个连接，增加一个事件来调用处理函数event_handler。每个连接的处理过程是一个状态机，drive_machine(conn* c)来处理，由even_handler来调用，状态转移这部分代码比较复杂，conn_listening —&gt; conn_new_cmd —&gt; conn_parse_cmd —&gt; conn_mwrite —&gt; conn_closing。process_command来处理各种命令。","tags":[{"name":"Linux","slug":"Linux","permalink":"http://chenyukang.github.io/tags/Linux/"},{"name":"C","slug":"C","permalink":"http://chenyukang.github.io/tags/C/"},{"name":"Backup","slug":"Backup","permalink":"http://chenyukang.github.io/tags/Backup/"},{"name":"memcached","slug":"memcached","permalink":"http://chenyukang.github.io/tags/memcached/"}]},{"title":"valgrind","date":"2011-05-06T11:43:00.000Z","path":"2011/05/06/valgrind.html","text":"纪念一下跑测试跑了几天才找出的一个内存泄漏，这个函数源于UNP，还以为UNP有bug呢，找到原书当getaddreinfo失败或者res==NULL的时候直接退出了。但是写这个代码的同学当然不想连接不上直接退出，于是忘记了freeaddrinfo调用直接返回，那个struct addrinfo就没释放。很多错误都是这种，涉及到库函数的时候更加难查。 int tcp_connect(const char host, const char serv)&#123; int sockfd, n; struct addrinfo hints, res, ressave; bzero(&amp;hints, sizeof(struct addrinfo)); hints.ai_family = AF_UNSPEC; hints.ai_socktype = SOCK_STREAM; if ( (n = getaddrinfo(host, serv, &amp;hints, &amp;res)) != 0) &#123; log_sprintf(“tcp_connect error for %s, %s: %s”, host, serv, gai_strerror(n)); freeaddrinfo(res); //oops: memory leak return -1; &#125; ressave = res; do &#123; sockfd = socket(res-&gt;ai_family, res-&gt;ai_socktype, res-&gt;ai_protocol); if (sockfd &lt; 0) continue; / ignore this one / if (connect(sockfd, res-&gt;ai_addr, res-&gt;ai_addrlen) == 0) break; / success / close(sockfd); / ignore this one / &#125; while ( (res = res-&gt;ai_next) != NULL); if (res == NULL) / errno set from final connect() / &#123; log_sprintf(“tcp_connect error for %s, %s”, host, serv); freeaddrinfo(ressave); //oops: memory leak return -1; &#125; freeaddrinfo(ressave); return(sockfd);&#125; 上一篇博文中说到自己包装的内存检测方法，这还有个问题当时没发现，就是那个包装malloc之类的方法对于库函数中的内存申请调用没法记录，所以是不会发现上面这个bug的。这个Memwatch倒是把原生的malloc都重定义了，但是最好的Linux下检测内存泄漏的工具还是valgrind，这真是个神器，在代码上不用做一点修改，这东西甚至能测试程序的cache命中率。看了一下valgrind的相关论文，对于检测方法都是一种称之为shadow value的方法，也就是用信息来记录每一个byte内存的使用情况。这种方式的一个缺点都是会拖慢速度，前面提到的那种稍微包装了一下的方式可能还好(因为使用的是静态数组), Memwatch里面使用了不少链表也会拖慢速度。再看看valgrind的实现，以后工作可能会碰上类似的。 更多valgrind 更多Memwatch","tags":[{"name":"Tools","slug":"Tools","permalink":"http://chenyukang.github.io/tags/Tools/"}]},{"title":"内存又泄漏:(","date":"2011-04-25T11:43:00.000Z","path":"2011/04/25/memleak2.html","text":"内存泄漏 上一次以为内存泄露查完了，发现服务器跑了比较长时间后又占用太多内存。刚好这段时间加了一些新的模块，又该查查了。整个服务器模块分的还行，但是中间经过几个人一起写，所以看起来就麻烦了。要解决问题还是必须找到泄露的代码段。在C/C++中，只要用了指针这东西，很多逻辑上的问题也会产生内存泄露。在线下用上次封装malloc和free的方法测试，找不到产生内存泄露的样例，grep了一下没有用原来的malloc之类的东西啊，那就应该是测试数量太少的问题。没法，从线上的log中导入一些天的访问记录，其中包含了一天的访问url。试着用Python写个小程序把一天中所有的url依次往线下的服务器发送，这应该有几万条数据了。Python中这相关的库够多的,可以用的httplib,或者webbrowser模块中的webbrowser.open(“url_address”,1),不过这得打开系统的默认的浏览器，并且好像还没关掉一个tab的接口。最合适这个简单任务的是urllib这个模块，下面这样就行了，往线下的服务器狂发请求吧: for rec in alllogs: urlstr = rec[0] #print urlstr line=line+1 print line,allnum,allnum-line,urlstr try: u = urllib.urlopen(urlstr) except IOError,e: print ‘connect refused’,e except UnicodeError,e: print ‘UnicodeError’,e res = u.read() ##print u.info() print “read %d data”%(len(res)) ##time.sleep(0.01) 调试方式 Linux下有一些内存调试工具，不过感觉要么过于复杂要么对代码改动太多，对于在后台这种长时间运行的程序不是很适用。上次提到的封装malloc,calloc,free这些函数的检测方法本来是挺好的，但是有两个问题： 1.用于存储内存信息的空间是用数组的，其大小运行时候就固定。2.不适合多线程程序。 如果用上面所有的url向服务器发送完毕后，再来检查输出文件不可行，因为运行中超过了数组的最大记录数后面的检测就没办法记录下来了。对于第二个问题，这个服务器模型是一种简单的多线程并发，启动时设定其启动线程的数目，多个线程排队，一个线程处理一个请求所以之间并无过多的交互。如果保证一个线程运行过程中不会出现内存泄漏，那应该就没问题了。调试的时候在每一个线程开始跑的时候就启动清空上面的记录内存申请和释放的数组，如果某个一个url请求产生了泄漏就停下来查看生成的meminfo.xls。这样跑完几万个url后，发现一些代码问题。这些bug要是通过人来审查代码不可能查出来，所以测试还是非常重要。其中一部分代码错误是使用了C写了一些基本的数据结构，这些里面有的使用了malloc来动态调整空间大小，用起来倒是比较方便，但是用完后必须显式地释放掉。这和指针的问题是一样的:何时何地释放。调试后会在代码中加入了很多语句，打印信息、脚手架位置等等，这可以用下面这些命令来替换成空白或者注释。 grep debug_str -rl ./*.c | xargs sed -i “s/debug_str/substr/g”","tags":[{"name":"Python","slug":"Python","permalink":"http://chenyukang.github.io/tags/Python/"},{"name":"C","slug":"C","permalink":"http://chenyukang.github.io/tags/C/"},{"name":"Backup","slug":"Backup","permalink":"http://chenyukang.github.io/tags/Backup/"}]},{"title":"论文吐槽","date":"2011-03-27T11:43:00.000Z","path":"2011/03/27/fuckpaper.html","text":"前些天在写毕业论文，开题弄了个什么神经网络什么数据融合，至今没搞懂过，真是没话说，但是又不得不硬着头皮写，废话连篇，说来说去就那么几句。做的东西本来挺简单的，没用到那么高深的理论，不过为了装装深度，硬要往上面套，希望最好别出什么问题吧。写论文的时候我就想嗄，写代码好玩多了，异常怀念那段天天在poj上写程序的日子。这两天交完初稿，继续做做题，一是玩玩，二是为了原来定下的一个小目标：毕业前水到500题，还差20。两个比较好玩也折腾得比较久的题目。 poj 2050 这题折腾了很久很久，刚开始误以为每个文件的最大行数为1500，最后因为输出格式问题。代码也比较长330行，954ms。使用数组作为hash，使用位图记录文件中存在的单词，idx为由单词转化得到的该单词在hash表中的index。 unsigned int docs_flag[MAXDOC][(MAXWORDS+31)/32]; //记录某个文件中是否存在某个单词void set_docflag(int doc[], unsigned int idx)&#123; doc[idx&gt;&gt;5] |= (1&lt;&lt;(idx&amp;0x1f));&#125;int get_docflag(int doc[],unsigned int idx)&#123; return doc[idx&gt;&gt;5] &amp; (1&lt;&lt;(idx&amp;0x1f));&#125; poj 2518 这个好玩，一个44的方格，里面分别放四个A,B,C,D，初始状态从输入获取，先随便选取一个字母，然后能进行很多次操作。每次能交换两个相邻的方格，到任何一个小的22的方格中全部都是所选的字母就获胜。对于每一个输入，求最少多少次交换就能达到胜利状态，以及有多少方案可以达到这个目的。例如：AABBABABCDCDCCDD output ==&gt; 1 4 (选择A或者B 交换BA 选择C或者D 交换DC)ACABCBBDADADDCBC output ==&gt; 4 96首先想到还是搜索，用bit来减少空间。求最少次数，BFS搜索也许太慢，毕竟每次状态转移会有16个选择。对于每一个输入，先枚举A,B,C,D进行搜索。对于每一个字母，比如A，用一个整数表示其在方格的位置(最大数字到1&lt;&lt;16)， AABBABABCDCDCCDD state ==&gt; 1100 1010 0000 0000 胜利的状态有9个，可以先枚举出来，1100110000000000等等。胜利状态比较多，照一般的BFS写下去代码肯定比较复杂，时间和空间肯定也都要求比较多。考虑可以从胜利状态反着向初始状态搜，先把9个胜利状态放入数组，求到初始状态最少的步数，同时可以算出有多少种走法。这样做了还是超时，看有人说线上输入有很多组数据。 看来每次计算调用了四次BFS确实比较要时间，看提示打表，对于每一个输入先查查看以前计算过没有，计算过则直接输出结果，否则照上面的枚举字母，调用BFS。提交还是超时。 再想想，每次输入可能A的分布是一样的，其他字母分布不一样，照上面那样做对于A还是BFS搜索了一次。从16个位置选择4个位置给A的总分布数目是C(16,4)=1820，不是很大的。很开心，把A的状态记录下来，对于每个输入先看看A这种布局以前算过了没有，如果算过则不用算了，其他字母都是一样处理。结果还是超时，无语了。 正要崩溃时，发现自己还是没看到本质，对于A的每一个布局，B不是一样么，是A还是B没关系的啊。所以，打表不用分字母需要1820*4这么大的表，只要一个1820的表就行了。对于每个输入，分字母获取四个分布状态，看这个状态以前是否算过了，如果算过直接拿那个结果，如果没算过算了存下来。再提交，终于AC了，：）这一步步够辛苦的。","tags":[{"name":"Backup","slug":"Backup","permalink":"http://chenyukang.github.io/tags/Backup/"},{"name":"ACM","slug":"ACM","permalink":"http://chenyukang.github.io/tags/ACM/"},{"name":"POJ","slug":"POJ","permalink":"http://chenyukang.github.io/tags/POJ/"}]},{"title":"近期","date":"2011-03-27T11:43:00.000Z","path":"2011/03/27/guitar.html","text":"1 学吉他 我终于开始学吉他了，五音不全双手不灵活不识谱的我居然开始学吉他了。跟某些朋友说我要学吉他，对方往往有几种反应：1.头被墙夹了 2.要改变风格了？装文艺小青年了？ 3.要追哪个女生么？其实弹吉他还是符合本人闷骚这一特质的。说来惭愧，很早就想学点乐器了，小时候爸想让我学二胡来着，幸好没学，一听那声音就觉得悲催啊。在我高中毕业那会，会憧憬着大学应该能拿个吉他在湖边，身边还有个妹子坐着。这个画面在沙河少林寺和清水河少林寺连实现的欲望都没有。所以，这么个小愿望到现在才付诸实践。前些天买了个民谣吉他，目前还只上了一堂课，右手拨弦有点感觉了，左手按着很痛，这要靠长期练习，慢慢来吧。等我学会了对某个女生来这么首歌-黑眼睛的姑娘。[audio:http://www.moorekang.com/wp-content/uploads/2011/03/20.mp3|titles=黑眼睛的姑娘] 2 到处逛了一趟 从上学期开始实习并找工作以来就没怎么出门玩过，这段时间刚好论文写完，可以出去耍耍。刚好王聪同学从北京解放后开始到处游荡，打算在成都待一周，所以一起找个地方玩。本来计划去海螺沟的，出发前一天晚上被某失恋男说服去碧峰峡。提前假期一天出发，到了雨城雅安。上里古镇没什么好玩的，就是一条河，半个多小时逛完了。立马往碧峰峡赶，下午三点多才到，已经不卖门票了。在山上的旅馆住了一夜，晚上三个大男人在旅馆看成都电视台的特色节目《今天我相亲》，真实得很喜感。第二天从碧峰峡动物园开始逛，因为学生证没带，我买了全票，看完后真是觉得不值啊！！下午逛植物园，在票上看到一个雅女园。话说雅安三大特色：雅雨、雅鱼、雅女，这雅女园莫非有什么非同寻常的东西:)。沿着碧峰峡逛了一圈，中途发现三个mm，其中两个算是美女双胞胎，于是我们三个后面一直处于两种状态，等mm追上我们，在后面追mm。到最后最后，除了王同学搭讪了一句并且没下文，我们都只是有胆看没胆搭讪，很失败。逛完大概耗时三个多小时，急忙忙看完熊猫就得赶车回成都了，前面一直满怀期望的雅女园都没来得及逛，不过肯定是没雅女在里面的，哈哈。总得来说，这碧峰峡是不值我那两张全票的价格的，风景算一般吧。 回成都第二天去了石象湖，在我印象中石象湖应该是不错的，有几个人向我推荐过此处。于是叫上那失恋男饭量同学三个人一起前往。快出成都上高速的时候才发现出来的不是时候啊，车暴多太堵塞，经过漫长的堵车后13点多才到。在门口感觉已经不好了，人太多。进去后刚开始一块还可以，全是一片一片的郁金香，美女也不少。逛进去也就没什么了，一个小湖加几个小石头象，坑啊，开发商太黑了，弄个几个别墅在这园里，卖房又卖票。三个人很失望，立马找出口。在门口等回成都的车足足等了一个多小时，在路上又堵了一个很久，这一天总共在来回路上耗费七个小时，人挤人看了一个小时！我提议的出游计划，对不住两位了。这几天玩下来还真是有点累！ 接下来该锻炼一下身体，打算去青海骑车，目前有四个人了。","tags":[{"name":"Notes","slug":"Notes","permalink":"http://chenyukang.github.io/tags/Notes/"},{"name":"Backup","slug":"Backup","permalink":"http://chenyukang.github.io/tags/Backup/"}]},{"title":"Cflow分析","date":"2011-03-09T11:43:00.000Z","path":"2011/03/09/cflow.html","text":"cflowcflow是个比较古老的程序(好像比我老一岁)，主要是用来打印C程序的函数调用关系，通过函数调用关系能大概看一下程序的流程。最近看了一下这个程序的代码，主要分为两个小程序组成。首先是prcc.c这个程序，作用是读源文件，提取出函数名称，然后生成一个函数列表。第一列是调用函数，第二列是被调用的函数名称(如果是函数声明则这两列相同)。第二个程序prcg.c是读取函数关系，里面建起一个有向无环图。根据这个图加上缩进打印出函数调用轮廓，这里有一个例子。最后是一个脚本cflow.sh，其核心代码就是。 prcc demo.c | prcg 这是典型的通过管道把小程序组起来的例子。 life is short , use Python 闲着的时候在这个程序上做了些小工作。既然有了第一个程序，那也可以用python来快速写个程序继续做些工作。首先想到的是写个程序把函数名打印出来，在有调用关系的函数之间用直线连起来。python就是容易实现。这里有一个问题，就是怎么排列函数名的位置，使得连线不怎么相交，因为相交起来就不容易看到函数之间的关系了。不好解决，还是用了以前《集体智慧编程》里面的优化函数，也就是优化问题。通用思路就是试着移动各个函数的位置，朝着相交点最少的部分移动(这里给一个解，相交点的个数为评估函数)。效果不是很好，当函数比较多的时候哪种算法都比较慢，而且交点看起来不可避免。这是一个结果。运行方法是: prcc demo.c | python drawfuncs.py 或者 find *.c | xargs prcc| python drawfuncs.py 来处理多个程序。 &lt;img src=”/images/out.jpg” alt=”screen” class=”img-center” width=”400”, height=”400” /&gt; 然后又想着可以做一个标签一样的东西，把调用深度比较潜的放大，调用深度深的缩小。不连线，位置随机画。这样一眼能看出来这个程序的主要函数是哪些。结果成这样了。 &lt;img src=”/images/out5.jpg” alt=”screen” class=”img-center” width=”400”, height=”400” /&gt; 位置随便画还是不好，可以分层。然后再相邻层之间的函数有调用关系的再用直线连起来，就变成这样了。清晰一点。既然有函数关系，其实是可以做到更好的，就像上面那个prcg.c程序，不过代码要复杂些了。 &lt;img src=”/images/out6.jpg” alt=”screen” class=”img-center” width=”400”, height=”400” /&gt; C要的是运行速度，Python实现速度快！","tags":[{"name":"Python","slug":"Python","permalink":"http://chenyukang.github.io/tags/Python/"},{"name":"Tools","slug":"Tools","permalink":"http://chenyukang.github.io/tags/Tools/"},{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Linux","slug":"Linux","permalink":"http://chenyukang.github.io/tags/Linux/"},{"name":"C","slug":"C","permalink":"http://chenyukang.github.io/tags/C/"}]},{"title":"给老婆介绍OOD(翻译)","date":"2011-03-03T11:43:00.000Z","path":"2011/03/03/ood_for_wife.html","text":"晚上看到个有趣的文章，翻译了一下，看过Head First绕过。 原文在这里。 OOD介绍 Why OOD? Single Responsibility Principle单一职责原则 Open-closed Principle 开闭原则 Liskov’s Substitution Principle 里氏可替换原则 The Interface Segregation Principle 接口分离原则 The Dependency Inversion Principle 依赖倒置原则 总结 我的妻子Farhana想重新她软件开发师的职业生涯(她以前也是个软件开发师，但是因为第一个孩子的出生而没有继续下去)。所以，这段时间我在帮助她学习一些OOD方面的东西，我是一个比较有开发经验的程序员。 从我早期的职业生涯中，我发现不管是多么复杂的技术问题，如果从普通交谈中以平常生活常见的角度去解释往往变得更容易理解。因为之前我和她有不少富有成果的交谈，我想可以和大家一起分享一下这种学习OOD的有趣方式。 下面是我们学习OOD的对话： OOD介绍 Shubho : 好，让我们开始学习OOD，你已经知道了面向对象三大特性，对吗？ Farhana: 你是指封装、继承、多态吗？是的，这些我知道。 Shubho : 好，希望你已经知道了使用对象和类，让我们今天开始学习OOD。 Farhana: 等等，知道面向对象特性还不够面向对象程序设计吗？我的意思是，我能定义类，封装成员变量和函数，我也能根据类之间的关系定义继承类。那还有什么需要学的么？ Shubho : 好问题，OOP和OOD是两码事。让我给个例子给你。当你还是小孩的时候你学会了字母表，对吧？ Farhana: 嗯 Shubho : 好，你也学会了如何用字母形成一个个有意义的单词，同时，你也学会了一些语法来造句子。比如，你要维持时态，使用介词、连接词、和其他语法来造出正确的句子。比如说一个句子像下面这样。”I” (pronoun) “want” (Verb) “to” (Preposition) “learn” (Verb) “OOD” (Noun) 你看，你要让这些单词安特定的顺序组成，你也 要选取正确的词来使得这个句子有意义。 Farhana: 呃，这是什么意思？ Shubho : 这和OOP是类似的。OOP是面向对象程序设计的基本原则和核心思想。这里，OOP对应于英语语法，这些基本语法告诉你如何用单词去构造一句有意义的话，OOP告诉你使用类，封装成员变量和方法，也告诉你在代码中使用继承关系。 Farhana: 嗯，有点懂了。那么OOD对应于什么呢？ Shubho : 你马上就知道。好，现在比如说你想要就一个论题写一些文章。你也想就一些你比较精通的方面写一些书。知道如何遣词造句还不够写一篇好文章或者好书出来，对吧？你还需要学习很多，你需要知道如何用一种好的方式去解释一个东西，这样读者才能了解你到底在说什么。 Farhana: 有点趣，继续。 Shubho : 好，现在比如说你想就OOD方面写一个本书，你需要知道如何把这个主题分为小题目。然后在这些小议题上面逐章地写，你还要写前言、简介、解释、例子，还有许多其他段落。你需要知道如何从整体上把握这本书的构造，甚至需要一些写作技巧。这才能让你的书通俗易懂。在软件设计领域，OOD同样是个更上层的角度。你需要好好的设计，使得你的类和代码可以更好地模块化、复用、灵活。使用这些设计原则可以是你少重复发明轮子。懂了吗？ Farhana: Hmm，我明白了一些，但是请继续。 Shubho : 别急，一会你就知道了。我们只管讨论就是了。Why OOD? Shuboho : 这有个很重要的问题，为什么我们需要OOD，我们明明就能很快的稀里糊涂的设计一些类，赶快完成开发然后交付？这还不够么？ Shubho : 就是，我以前也不知道OOD，我仍然能开发完成项目。那这有什么问题么？ Shuboho : 好，让我来给你一个经典的引用: “Walking on water and developing software from a specification are easy if both are frozen.” - Edward V. Berard (如果水是冰冻的在上面行走很方面，如果规格书是不变的，开发软件也很方便) Shubho : 你是说软件的需求说明书一直都在变化？ Shuboho : 正确，最普遍的真理就是”你的软件注定都要变化”,为什么？因为你的软件需要解决的是现实生活中的问题，而这些都是会变化的—永远会变。你的软件按照今天需要做的，做的足够好。但是你不设计得足够好，你的软件足够灵活来应对”变化”吗？ Shubho : 好，这样，快给我介绍什么是”设计得足够灵活的软件”! Shuboho : “一个设计的灵活的软件是容易适应变化的，它能够便于扩展和复用”。而使用一种好的”面向对象设计”方式是得到这种灵活设计的关键。但是，我们有什么标准来说明我们的代码中使用了良好的OOD？ Shubho : 呃嗯，这也是我的问题。 Shuboho : 你需要做到了下面几点: 面向对象方式 可复用 修改代价最小化 不修改现有代码的基础上扩展前人已经在这方面做了许多工作，他们已经对一些通用的场景列出了一些通用的设计准则。最基本的五点可以简称为SOLID原则(Uncle BoB)。S = Single Responsibility PrincipleO = Opened Closed PrincipleL = Liscov Substitution PrincipleI = Interface Segregation PrincipleD = Dependency Inversion Principle下面我们逐一介绍上面的几个原则。Single Responsibility Principle 单一职责原则 Shubho : 先来看幅图，很形象。你能把所有的功能都集成在一个东西上，但是真的不应该。为什么？因为这为以后增加了很多额外的管理工作。我来用OO术语解释一下,”不能有多个理由去改变一个类”,或者说”一个类有且只能有单一职责”。 Farhana: 能解释一下吗？ Shubho : 让我们来看这个继承的例子，这是从Uncle Bob书上弄来的。Rectangle类做了两件事， 计算矩形的面积 在UI上画出矩形两个程序要用这个类， 一个几何计算的程序要用来计算面积 一个图形界面程序要用来在UI上画一个矩形这就违反了SRP原则。 Farhana: 怎么？ Shubho : 你看，一个矩形类包含了两个不同的动作，一个计算面积，一个画矩形，这导致了下面的问题： 在几何计算的程序中我们要包含GUI，进而又需要包含GUI所用的图形库。 任何因为图形界面而在这个类上面所做的修改将导致几何计算程序重新编译测试，相反也是。 Farhana: 变得有趣了，所以我们应该根据其功能把这个类分开，对吧？ Shubho : 正是，那么该如何做？ Farhana: 我来试试，也许该这样，根据职责分为两个类，比如： Rectangle 这个类定义方法method() RectangleUI 这个类从Rectangle继承并定义Draw()方法 Shubho : 非常好，现在两个程序分别使用两个不同的类，我们甚至可以将两个类放在不同的Dll文件里面，这样任何一个类的改动不会影响到另外一个程序。 Farhana: 谢谢，我想我理解了SRP。一方面，SRP是一种把东西分开到一些便于复用和集中管理的小模块中。那么，我们同样也能在成员函数这一级别来使用这个原则吧？我是说，如果我写了很多很多行代码在一个函数中完成几件不同的事，这也违反了SRP原则，对吧？ Shubho : 是的，你应该把这个函数分成几个小的分别做一份特定的事。这也让你只需要很小的代价来应付变化。 Open-closed Principle 开闭原则 Shubho : 这幅图是说开闭原则的。 Shubho : 先来解释一下:软件实体(类、模块、函数等等)应该对扩展开放，对修改封闭。最基本的层次，你应该能够在不修改一个类的基础上扩展它的行为。比如，我不需要在我的身体上做什么改变，就能穿上一件衣服，哈哈。 Farhana: 有趣，你能穿不同的衣服来改变的外貌，而不需要对你的身体做改变，所以你是对扩展开放的，对吧？ Shubho : 是的，在OOD里面，对扩展开放意味着我们能够扩张模块/类，对需求的变化添加一些新的东西。 Farhana: 而你的身体对修改是关闭的，我喜欢这个例子。那么核心的类和模块在扩展的时候是不能被修改的，你能具一些例子吗? Shubho : 好，我们来看这副图，这是一个违反了开闭原则的例子。 Shubho : 你看，服务端和客户端是直接连接的，这样不管是因为什么原因，当服务端实现改变了的时候，客户端也需要改变。 Farhana: 恩，懂了点。如果一个浏览器只是针对于特定的服务器(比如IIS)，如果因为什么原因我们需要换一个服务器(比如Apache),浏览器也需要改变，这真是恐怖。 Shubho : 对，下面这个设计应该要好。 那个抽象的服务器类对修改是关闭的，而具体的子类实现对扩展是开放的。 Farhana: 恩，懂了。抽象是关键，对吧？ Shubho : 对，我们应该抽象系统中那些核心的概念，如果你抽象得好，当添加新功能的时候不需要修改。比如上面服务端是个抽象概念，如果IISServer是服务器的一种实现，现在需要扩展服务端这个概念，比如说一种新的ApacheServer实现，而这些扩展对客户端程序没有任何影响。 Liskov’s Substitution Principle 里氏可替换原则 Shubho : LSP原则听起来很难理解，其实含义很简单，看下面这副图。这个原则意思就是：子类必须能够替换其继承的基类。或者换一种说法：基类能使用的方法，子类也能使用。 &lt;p&gt;&lt;a href=&quot;/images/7.jpg&quot;&gt;&lt;img class=&quot;aligncenter size-medium wp-image-431&quot; title=&quot;7&quot; src=&quot;/images/7-300x237.jpg&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;237&quot; /&gt;&lt;/a&gt;&lt;/p&gt; &lt;li&gt;Farhana: 对不起，听起来很难懂。我认为这时OOP的基本规则，这时多态，对吗？&lt;/li&gt; &lt;li&gt;Shubho : 好问题，答案是：在基本OOP里面，&quot;继承&quot;被描述成一种&quot;is-a&quot;的关系，如果&quot;开发者&quot;是一个&quot;软件职业者&quot;,那么&quot;开发者&quot;类应该继承&quot;软件职业者&quot;,这种&quot;is-a&quot;的关系在类的设计中非常重要，但是这样非常容易导致一种错误的继承设计。LSP原则是一种保证正确使用继承的方法。让我们看个例子。&lt;/li&gt; &lt;p&gt;&lt;a href=&quot;/images/8.png&quot;&gt;&lt;img class=&quot;size-full wp-image-432 aligncenter&quot; title=&quot;8&quot; src=&quot;/images/8.png&quot; alt=&quot;&quot; width=&quot;188&quot; height=&quot;176&quot; align=&quot;center&quot;&gt;&lt;/a&gt;&lt;/p&gt; KingFishera是一种能飞的鸟，它继承Bird类没问题。但是如果下面这样： 鸵鸟是一种鸟，所以它基于鸟基类。现在能飞么？不行，所以，这个设计违反了LSP。所以，即使在真实世界中看起来很自然。但在类的设计中，鸵鸟不应该继承鸟类。应该有一种不能飞的鸟类，然后鸵鸟从这个类中继承。 Farhana: 好，我懂了LSP，让我来指出为什么LSP这么重要： 如果LSP不满足，类继承关系将会混乱，如果一个子类实例被当作参数传到一个函数，奇怪的事可能会发生。 如果LSP不满足，单元测试中基类通过而子类通不过。 Shubho : 很正确，你能吧LSP原则当作一种验证工具，来测试你的继承层次是否正确。 The Interface Segregation Principle 接口分离原则 Farhana: 这是什么意思？ Shubho : 意思如下：客户代码应该不依赖他们不使用的接口。 Farhana: 解释一下。 Shubho : 当然，其意思就是，假设你要买一台电视机，现在有两台可供选择，一台有很多转换器和按钮，大部分你都不明白是用来干什么的。另一个只有少数几个按钮和转换器，对你来说很熟悉。你选哪一个？ Farhana: 当然是第二个。 Shubho : 是的，但是为什么？ Farhana: 因为我不需要那么转换器和按钮，那些我不明白，而且对我也没什么用嗄。 Shubho : 对，类似的，假设你有一些类，你要暴露一些接口给外界，这样外面的代码才能利用这个类。如果一个类的接口太多，也暴露了很多接口，这对于外界来说是比较混乱的。而且，方法太多的接口也是不利于复用的，这种”大而全”的接口导致类之间的紧耦合。这也导致一个问题，任何使用这个接口的类都需要实现那些方法，而有些对于这个类是根本没用的。所以这么做也带来了不必要的复杂性，导致维护的困难和系统的健壮性问题。接口分离原则保证接口设计得合理，他们都有自己的职责，这样简明、方便理解、利于复用。 Farhana: 哦，我懂了。你的意识是指接口只含又那些必须的方法，而不包括冗余的? Shubho : 是的，来看个例子。下面这个例子违反了ISP原则。 注意，IBird接口包含很多鸟的行为，还有Fly()行为，现在一个Bird类(鸵鸟)实现这个接口，它必须实现Fly()行为，这对于鸵鸟来说是不行的。 正确的设计是这个。鸵鸟实现IBird接口，而可以飞的鸟实现IFlyingBird接口。 The Dependency Inversion Principle 依赖倒置原则 Shubho : 是说：高层模块不依赖底层模块，两者都依赖抽象。抽象不应该依赖于细节，细节应该依赖于抽象。 让我们来看一个现实的例子，你的车子包括很多组成部分，有引擎、轮子、空调、还有其他东西，对吧？ Farhana: 是的。 Shubho : 好，每一件东西都是严格地独立地造的，而且每一样都是可以”插拔”的，所以你的引擎或者轮子坏了，你可以修它，甚至可以换掉它，但是其他部分不需要动。你换的时候需要保证配件和车子的设计是符合的，比如这车子需要1500Cc的引擎和18英尺的轮子。同时，你的车也可以使用2000CC的引擎，任何厂家的都可以。现在，想象一下如果你的车子不设计成这种可”插拔”的，会出现什么问题？ Farhana: 那真是太糟糕了！如果车子引擎坏掉你需要修理整个车子，或者卖一辆新的。 Shubho : 是的，那么”可插拔”是如何做到的? Farhana: “抽象”是关键，对吧？ Shubho : 是的。在现实中，汽车是一种更高层次的实体，它依赖于一些第层次的实体，像引擎和轮子。而车子不依赖于具体引擎和轮子，依赖于这些概念。这样，任何符合这个概念的引擎或者轮子都能放进车子让车子跑动起来。看看下面这幅图，注意这里车子类中，有两个属性，都是接口类，而不是具体类。引擎是”可插拔”的是因为它接受任何满足这个抽象的具体实现，而不改变其他部分。 Farhana: 那么如果违反了DIP原则，将会有下面的风险。 破坏高层次的代码 当底层代码改动的时候，需要大量成本改变上层代码 代码复用不好 Shubho : 完全正确！ 总结 Shubho : 除了SOLID，还有其他很多原则。 * “Composition over Inheritance”: This says about favoring composition over inheritance. * &quot;Principle of least knowledge&quot;: This says that &quot;the less your class knows, the better&quot;. * &quot;The Common Closure principle&quot; : This says that &quot;related classes should be packaged together&quot;. * &quot;The Stable Abstractions principle&quot;: This says that &quot;the more stable a class is, the more it must consist of abstract classes.&quot;&lt;/pre&gt; 设计模式是OOD的特例，DP就像是对于特定场景的特定框架，而OOD则是说明。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Backup","slug":"Backup","permalink":"http://chenyukang.github.io/tags/Backup/"},{"name":"OOD","slug":"OOD","permalink":"http://chenyukang.github.io/tags/OOD/"}]},{"title":"在显示器前干了什么","date":"2011-02-22T11:43:00.000Z","path":"2011/02/22/workingtime.html","text":"时间啊时间 写论文头大，翻资料找到一个以前写的小东西。有段时间在实验室，一坐就是一整天，经常在网上找找资料，找着找着就从一个链接点到另一链接，从豆瓣到Hoop，再弹出个QQ，一整个上午就过去了。天天对这显示器，于是就想我整天呆在这大部分时间在干什么了，要是有个记录就好了。就想写这么一个小程序，来记录我一天在电脑前花的时间分布。 方法 怎么实现呢。要知道现在在干什么，就应该要知道我现在在活动程序，编辑或者鼠标点击的。如何知道现在活动的程序名，如果能获得当前活动的程序的可执行文件的路径就比较好办了。于是在网上找了找，在Windows下可以这样实现。 CString getProcPath(int PID)//返回pid进程的可执行程序名称{ HANDLE hModule; MODULEENTRY32* minfo=new MODULEENTRY32; minfo-&gt;dwSize=sizeof(MODULEENTRY32); hModule=CreateToolhelp32Snapshot(TH32CS_SNAPMODULE,PID);//对系统进程进行拍照 Module32First(hModule, minfo);//返回与进程相关的第一个模块信息 CString str; str=CString(minfo-&gt;szExePath); CloseHandle(hModule); if(minfo) delete minfo; &lt;span style=&quot;color: #00bfff; font-weight: bold;&quot;&gt;return&lt;/span&gt; str; } 得到了当前活动的程序名称就比较好办了，其实经常用的就是那么几个程序，稍加分析然后分类就能统计到我的时间分布。我这里分为了四类：编程、上网、看文档、QQ。用个定时器记录下来即可。实现个托盘最小化，就可以了。 void Report::Init(){ m_Programming.push_back(_T(“devenv.exe”)); m_Programming.push_back(_T(“Microsoft Visual Studio”)); m_Programming.push_back(_T(“vim”)); m_Programming.push_back(_T(“matlab”)); m_Programming.push_back(_T(“MATLAB”)); m_OnWeb.push_back(_T(“firefox”)); m_OnWeb.push_back(_T(“Chrome”)); m_OnWeb.push_back(_T(“IEXPLORE”)); m_OnWeb.push_back(_T(“opera”)); m_QQ.push_back(_T(“QQ”)); m_QQ.push_back(_T(“Tecent”)); m_Document.push_back(_T(“WINWORD”)); m_Document.push_back(_T(“Office”)); m_Document.push_back(_T(“CAJView”)); m_Document.push_back(_T(“hh.exe”)); m_Document.push_back(_T(“FOXITR”)); } 结论是个有点无聊的东西。其实可以稍微完善一下，比如加一个定时通知休息的功能、或者是上网过久的通知、便签之类的小功能也可以呵。代码 ：Workingtime ,匈牙利命名法好难看。","tags":[{"name":"Backup","slug":"Backup","permalink":"http://chenyukang.github.io/tags/Backup/"}]},{"title":"走过十年","date":"2010-12-30T11:43:00.000Z","path":"2010/12/30/tenyears.html","text":"过两天就是2011年，一到年底总会让人有些抚今追夕，免不了唏嘘感叹一番。总结一年太短了，我来好好想想这十年我记忆中还存有的一些事，断断续续的。 2000年 ，以及之前三年，那年我十四岁，初三，读了两年寄宿后已经变得弱不禁风。刚好那年也是奥运年，没电视看，只有一块小黑板摆在楼下，我不知道悉尼在哪，印象更深的是旁边的菠萝块，五毛钱一块，相当爽口。那物质贫乏的年代一个礼拜的火食费大概在八块五左右，初一到处三基本维持这水平。有一次看同学的篮球杂志，一个黑人(后来才知道是carter)举着个球把人给飞过去了，印象深刻，从此起后就经常看篮球了，并长期偏爱看这个黑人的球赛。初二时当过一年的劳动委员，当时正值学校大搞建设，我们就被叫到山上去挖草皮铺在学校广场上。这好歹也算个官，还挺霸道的，就是分配任务然后坐在那里记录没人挖了多少土和草，也许除了这次我再也没有主宰别人劳动的权利了。进那传说中的重点初中是要考试的，爸妈说我是成绩本来没上的，用关系把我送进来。现在也不知道是不是这回事，反正那时估计是心里有所愧疚，或者是因为读寄宿没动画片看了，我学习那可是相当努力，摸着良心说真是勤奋检朴、纯正无邪、天天向上的好孩子。那时多幼稚，就把排名在自己前面的同学的名字写在书上，有位我要超的同学五点半就起来了，我也要跟着起。不知道什么应试教育，什么素质教育，只知道前面有人排我前面很不爽，回想起来也挺好玩的。学习之外有个乐趣是看人打架，那时流行古惑仔什么的，总是有些同学看起来特牛逼，没人敢惹。有次据说有大规模群架，月黑风高爬到学校的小山坡上等着，结果两群人罗嗦了半天没动手，很另人失望。我虽看起来老实，也确欺负过比我更老实的同学们，就在现在还是心里有所愧疚，对不起了。到现在能记下来的初中同学的名字就那么几个了，大部分人毕业后再也没联系过。快毕业那年第一次对一位姑娘有了脸红心跳的感受，其实什么也没做，只是我向她借教室的钥匙。依然记得午后教室走廊上的风和阳光的味道，我跑得很快。 2001年 ，9月进了高中，17岁的少年很单纯、无虑，有一群人可以和你打球、彻夜瞎谈。不会想着未来会怎么样，但会觉得未来很美好很美好。高三那年经常一个人，开始觉得有压力，进而有时失眠，那个暑假我还搬到一个自己的租的小房子里住，不过没到一个月就觉得不适了，矛盾的就是想独处而又耐不住独处，然后又搬回宿舍。回忆起来三年一闪而过，现在我也会觉得高中是段最快乐的时光，有时会在梦里回到那段年少光阴。高中毕业后大概有一半多点同学上了大学，但能联系的比较少。后来和一些在高中都没说过几句话的同学聊天，有人说我是个狂人，看起来很嚣张、不怎么理人的那种。我只是对没太熟悉的人没什么话说，看起来很冷淡可有些时候还会私下来那么一下，用后来的词说是闷骚。这种性格我是知道怎么形成的，已经不好改了。其实高中能记下来的事很多，在此不一一写下。大家都天各一方，有的人和事也许永远不会忘记，但也就仅此而已。 2004年 ，来成都，第一次出远门，还是有点远。大一的印象就是国腾的天蓝色寝室和教室、冬天里弥漫的大雾、小说、篮球、村子里的网吧、PS。我们总是五个一小撮人走在一起，后来大三后就成了舍友。那时班还有个手掌大的电视机，黑白的，五点多起来看火箭的比赛。那时在学校上网还得排很长的队伍，上网也没什么事，就是那么耗着排队。现在想想真是可惜了大好时间，多多学习些其他的就好了。大二的时候就搬到市区了，感觉一下子从农村到了城市，各种方便了不少。然后下面三年就待在了万人坑里面，宅了两年，一年宅在图书馆，大学就这么过了。其中无所事事、浑浑噩噩的时间多，还有一年的精神折磨，回想起来不是很好的感受。宅起折腾的时间多，也没什么特别的收获，最多的时候就是试用各种版本Linux，结果系统倒装得挺熟，经典书籍也略看过一遍，没精髓和深度，倒也对计算机有所兴趣了。交际圈在隔壁几个寝室范围内，各种挺失败的，在风中论坛里面看热闹灌水。另外喜欢过两个女生，一个未来得及追求，一个追求未遂。毕业那会四川地震，刚好中午在十一楼我们寝室都在午睡。我以为是这栋楼坏了，吓得腿都软掉，五个人在寝室厕所趴了一会就跟着大部队跑了出去，然后是几天的不眠夜。第一次被摆放在这么大的自然灾害面前，经历后就会觉得平常在乎的什么都不那么揪心的重要了，活着是个的幸运。 2008年 ，还在成都，本校读研。读研的根本原因还是想在学校多待两年吧，另外也觉得自己大学是荒废了不少时间。这两年变成了宅在实验室，做做项目，写代码看书，周末还经常出去逛一下，生活很简单。喜欢上了骑自行车，去各种地方玩玩才对成都有个大概印象。心里比较平稳，也总会想着要抓紧时间，因为在学校的时间不多了。恋爱过一段，又是异地才4个月。现在对于恋爱这些也不是特别强求，又有那么点小愤青和理想主义，认为房子、车子和老婆、孩子没什么太大的瓜葛。过年回家小学同学孩子都能打酱油了，大学同学也有的结婚了，和我一年的同事送来请帖的时候就倍感压力。算算还真有那么点催人急了。又说不以结婚为目的的恋爱是耍流氓，但以结婚为目的的相亲也是俗，俗俗俗，“生活正在不可避免的走向庸俗”。爱情变得那么奢侈，可遇不可求，他们喜欢说缘，当找不到的时候这就是个很好的托词。 2010年 ，就现在，快结束了。这本命年过得还算安稳，努力并收获了一些。已经找完工作在实习了，基本不怎么在学校，学校里的日子很安逸，还有午觉睡。找工作是段比较重要的日子，因为不得不考虑怎么去迎合到社会中，自己想要什么，想要什么样的工作，想要在什么地方，以及自己能给别人什么能承担什么。这些也许以前都有大概的想法，但真的面对一个个切实的选择的时候还是会有很多纠结，经历过就会有另外一番感受，那就是成熟吧。简单回想一下，这一路走过的都很平凡，其中的各种滋味和大部分80后一样，这十年里面每一个时间断点处摆在我们面前的就是那么些选择，无所谓好和坏、对和错。如果要谈梦想，我小时候的梦想很好玩，湘江边总会有很多巨型的船嗡嗡作响，在我还是小孩的时候我认为那是个挖金子的机器，在船夹上可以洗用水冲洗出金子出来，就想我以后要是有那么一艘就好了，并幻想着我在船上日出而作日落而息的画面。而后稍微长大一点再在河边一看，不过是些挖沙船，破烂不已，有种被骗的感觉。被骗的会很多，生活总是在欺骗我们，以前很赞同《爱与生的苦恼》的一段，“一切生命本质上皆为痛苦，人生即抛掷在痛苦和无聊之中”，痛苦源于贫乏，无聊源于满足。太悲观了不好，还是应该轻松一些、感恩一些来面对，不管是得或失，用回忆拥抱过去，用热望迎接未来。 再见，往事。你好，新年。 快到家的路上 不是我拍的 不过很有家的感觉","tags":[{"name":"Notes","slug":"Notes","permalink":"http://chenyukang.github.io/tags/Notes/"}]},{"title":"《先知》- 纪伯伦","date":"2010-12-29T11:43:00.000Z","path":"2010/12/29/theprophet.html","text":"《先知》，纪伯伦。这本书买了一年，看了一遍，更多的时候是听其附带的朗诵，美和哲理，很让人内心平静。左上角的“憩于理性，行于热情”也是出于这。先知讲述的真理包括爱、婚姻、孩子、施与、饮食、工作、欢乐和悲哀、房子、衣服、买卖、罪与罚、法律、自由、理性和热情、痛苦、自知、教育、友谊、谈话、时间、善恶、祈祷、快乐、美、宗教、死。 为什么说是真理，当你相信的时候就是真理，不相信的时候就是建议。正如里面所说:“不能说我找到了真理，而应该说我找到了一条真理。” 这一个月里经常去参加教会的活动，得到的多是感动和宁静，虔诚的爱可以让生活变得不一样。如一位大哥所说，在这里的是新生，以前认为很重要的东西变得不重要，以前认为很不重要的东西重要起，迷途的羔羊们都弄反了。 论爱 假如你在你的疑惧中，只寻求爱的和平与逸乐， 那不如掩盖你的裸露，而躲过爱的筛打， 而走入那没有季候的世界，在那里你将欢笑，却不是尽情的笑悦；你将哭泣，却没有流干了眼泪。 爱除自身外无施与，除自身外无接受。 爱不占有，也不被占有。 因为爱在爱中满足了。 论工作 你们也听见人说，生命是黑暗的。在你疲劳之中，你附和了那疲劳的人所说的话。 我说生命的确是黑暗的，除非是有了激励； 一切的激励都是盲目的，除非是有了知识； 一切的知识都是徒然的，除非是有了工作； 一切的工作都是空虚的，除非是有了爱。 当你仁爱地工作的时候，你便与自己、与人类、与上帝连系为一。","tags":[{"name":"Books","slug":"Books","permalink":"http://chenyukang.github.io/tags/Books/"}]},{"title":"内存泄漏","date":"2010-12-22T11:43:00.000Z","path":"2010/12/22/c-mem-leak.html","text":"以前写的一些程序运行一段时间后占用的内存越来越多，估计是内存泄露了。服务端的程序要长时间的运行，内存泄露是个很严重的问题。于是再检查程序，很崩溃的是还有另外一个模块不是自己写的，看起来很麻烦。看了半小时后发现一些问题，但是还是不能保证是否完全解决了。同事让我用以前他们写的一些函数，对应的为MALLOC和FREE。仔细看了一下觉得很不错，其实就是把malloc和free函数封装了一下，用来记录申请空间的文件和代码位置，使用方法就是用MALLOC和FREE替代原来的函数。主要的数据结构是： typedef struct{ long pcode; //指针 char filename[128]; //申请空间的源文件名称 int line; //申请空间的代码所在的行 int ct; //内存状态: 0-未闭合,1-闭合,2-log/脚手架}mem_info;mem_info mem_in[MEM_SIZE]; //MEM_SIZE最大指针数目int mem_in_id; //数组中已经占有的mem_info数目int mem_check_statue; //是否进行内存泄露检查然后有两个函数，一个是初始化函数mem_check_init(),另一个为mem_check_write(),这样就能检查者两个函数之间的代码是否有内存泄露，mem_check_write()可以打印成一个表，所有申请了空间的代码的文件名称和代码所在的行数，以及运行到mem_check_write()这里的时候所有申请空间的状态，1表示已经释放，0表示申请未释放，2表示的是脚手架的位置（用来方便检查哪一小段代码是否有内存泄露）。#define MALLOC(size) ck_malloc(size,FILE__,LINE) //FILE 文件 LINE 代码所在行void __ck_malloc(int size,char file,int line){ void p=malloc(size); if (mem_check_statue) return p; if (mem_in_id&gt;=MEM_SIZE) return p; mem_in[mem_in_id].pcode=(long)p; strcpy(mem_in[mem_in_id].filename,file); mem_in[mem_in_id].line=line; mem_in[mem_in_id].ct=0; // 状态: 0-未闭合 mem_in_id++; return p;}那么FREE(p)，进行的操作就是现在数组中找到是否有这个p，如果有就改变状态，变为1表示闭合了，也就是释放掉了。CALLOC和MALLOC类似，是调用calloc，函数malloc()和函数calloc()的主要区别是前者不能初始化所分配的内存空间，而后者能。REALLOC有点不一样，调用void np=realloc(p,size)，这里要注意np和原来的p有可能不一样，有可能一样，比较一下进行相应处理。最后mem_check_write()遍历上上面的数组打印出来表，其顺序就是按照代码执行的顺序了，其中脚手架可以比较方便的定位于申请了没有释放的代码行，也就是查找两个2之间的0所对应的行。这是一个很不错的方法，今天用这个办法找到了好多处不易发现的内存泄露错误。但这也有其缺点，即使完全通过也不能保证就完全没内存泄露了，除非测试时运行代码的覆盖率要保证所有代码都运行到了，这也是正规的、高质量的测试所要做到的程度。我们现在没有时间来做足够好的测试，以后再好好规范一下。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"C","slug":"C","permalink":"http://chenyukang.github.io/tags/C/"},{"name":"内存泄漏","slug":"内存泄漏","permalink":"http://chenyukang.github.io/tags/内存泄漏/"}]},{"title":"老罗的扯淡极致","date":"2010-12-01T11:43:00.000Z","path":"2010/12/01/luopanzi.html","text":"昨晚上正准备睡觉时手贱点随便点击了个链接，然后就在这个《老罗全国巡回演讲完结篇：海淀剧场》里一直跟着欢乐到2点钟。大学时有一段经常听老罗语录，胖子嬉笑怒骂、语言犀利、愤世嫉俗、玩世不恭、理性的愤青，听来很过瘾。那时很流行的一句是：“彪悍的人生不需要解释”。时不时我们寝室几个人吃完饭就那么瞎坐在那里，放上几段经典的来笑笑。原来我电脑上是有老罗全集的，后面硬盘毁掉了。很久没这么长时间听这罗氏语调了，酣畅淋漓。 老罗在腾讯微博上很活跃，一如既往的内心强大，就中医是否伪科学和无数人争论到底，耐心相当之好。原来听过老罗语录的人应该会知道此人为什么会如此憎恨中医。这牛还出书了，《我的奋斗》，看过几章，还是挺不错的。原来听说老罗在办个英语培训学校——老罗和他的朋友们教育科技有限公司，没想到现在已成气候，每天醒来都能闻到钱的味道。这个老罗全国巡讲应该是最好的广告了。以前的一系列我都没看到，不过看了最后这个终点站的应该不用看前面的了。演讲的题目是《一个理想主义者的创业故事》，估计是演说了很多场了，这牛已经熟练到如火纯青的地步。原来还以为ppt是别人帮忙放的，后来才发现应该是自己手里握着个遥控器，期间基本很少看自己的ppt，只有在自恋的时候转身对着花痴一下。笑过后也是有所收获，老罗分享了其创业以来的一些经历和想法。稍微总结一下。 1 企业的核心产品或服务。老罗英语培训，师资是关键，这个没办法，有的事只能钱来解决，用最好的薪资待遇请最好的老师。 2 营销策略和推广，这是最长也是最有趣的部分，都是一些有趣的案例。老罗是个偏执狂，只有偏执狂才能做出那么漂亮的宣传画和广告。小小窃喜一下，那个音乐节上的广告我也想到了那么个切入点，不过看的时候还是震撼了一把，完美，太有才了。还有一些平面广告在这里。 3 待遇、企业文化、愿景，这些东西是一个公司是否能留住人的关键，实实在在做产品或者服务的公司，即使在中国这样的创业环境下，还是有生存机会。我没上过老罗的辅导班，也没那钱力，觉得关于英语学习的任何辅导班都没什么用，学英语这事得靠自己。可这老罗英语培训机构做的确实很有个性。 4 即使是老罗这么内心强大的人也有挺不住的时候，这时候他的自恋和幻觉产生作用了。看来老罗最后居然有点哽塞，果真是讲到深处了。最后在商业机构里做一个理想主义者非常难，但赚钱不等于染铜臭。而又有“偏执狂才能生存”这么一个道理，要做一个牛逼的企业，还是需要理想主义的偏执狂。","tags":[{"name":"扯淡","slug":"扯淡","permalink":"http://chenyukang.github.io/tags/扯淡/"},{"name":"老罗","slug":"老罗","permalink":"http://chenyukang.github.io/tags/老罗/"}]},{"title":"优化算法","date":"2010-11-20T11:43:00.000Z","path":"2010/11/20/gene-alg.html","text":"POJ 2714最近又在POJ上做题，碰上2714，题意是： 输入N，和N个点(x,y)，从原点开始一共可以走N步，每一步可以随机选择移动(x,y)，或者(-x,-y)。N的范围为1-100。输出最远能走到离开原点多远的地方，输出其距离。 分析一下，用迭代肯定可以，不过2^N的复杂度肯定太高了。每步有两种选择，其本质是求一个长度为N的0、1序列使得最后的值最大，为一个优化问 题。这里贪心不能求到最优解，稍微证明一下就能得出。如果不贪心，或者把贪心的范围扩大一点，求出每一步完后的凸包呢，然后再在这步的基础上继续扩展下一 些节点，再求凸包，继续如此，最后求得凸包中距离最远的。求凸包的复杂度位O(nlgn)，即最后的复杂度为O(N^2lgN)，是可以接受的。 随机搜索以前看过《集体智慧编程》这本书，这里有一章是说的优化。稍微回顾一下其中的几个算法。对于优化问题，首先得找到一个评价函数，对于其某个方案评价函数能给出某个值评估方案的优劣。至于返回值越大还是越好没有规定，对于特定的问题选择特定的评价函数。 随机搜索不是一种好的优化算法，但是却是后面的算法的根源。其基本思想是，我们随机长生一些解，看是否好，如果比当前更好，替换当前最优解，直到收敛了，或者猜测了足够的次数了。 do{ solution=rand_solution; value=eval(solution); if(value&gt;best) best=value; times++; //测试是否收敛}while(times&lt;max_iter&amp;&amp;(!limit_flag));这种盲目的猜测虽然有机会在某一次猜中最优解，但是效率肯定不怎么好。随机算法还是有一些问题可以适用，比如素数判定，如果能保证错误率很低很低也是可行的算法。 爬山法随机搜索不是一种好的优化方法，为什么？因为没有充分利用已经得出的当前最好解。对于上面这个问题，最优解可能和当前最优解有一些相近之处，可能是因为某一步当前最优解走错了，最后没有演变成最优解。其意思就是，如果把当前最优解稍微改变一下，可能会向最优解的方向靠 近。那么爬山法就是通过当前的最优解，在其附近找更好的解，知道当前没有更好的解为止。而随机搜索是跳越型的，所以没有这个优势。看下面这幅图，现实中很 多问题都会像这样，如果我们把所有解都算出来，按组合排列的顺寻作为x轴，评估函数得出的值为y轴，能得出稍微连贯的曲线。随机从某个初始点出发，沿着我们想要的方向寻找，能找到优解。 陷入局部最小 最优解为最低点 爬山法的缺点是，如过找到某个局部最优的地方，可能就被欺骗了，因为发现没有斜率了，以为是最优解。最后可能是个次优解。所以继续改进。 模拟退火爬山法总是接受当前最好解，也算是一种贪心的思想，正如贪心一样，有可能得不到最优解。如何改进呢？那就在选择的时候不止是选最好的，还要接受一些看其来不怎么好的解。模拟退火就是这样，“模拟退火”的原理也和金属退火的原理近似。其关键在于：如果新的解比当前解更优， 即换为当前最优解，如果不优，新的解仍然可能成为优解，但是要一定的概率接受。这个时候神奇的e派上用场了，这个接受的概率我们可以算 作：p=e^(-(highest-lowest)/(temprature))。刚开始的时候温度很高，所以p接近为1，后面温度开始降低，表现出来的结果就是越是到后面接受较差解的机会就越小。就是因为接受一定的较差解，模拟退火能找到最优解的概率比较大。 遗传算法换一个思路，如果我们把搜索空间中的所有解看成一个个的物种，初始化随便初始化一些物种，然后随着自然的演变，我们需要最好的最强大的最优秀的最优生命力的物种保存下来。遗传算法就是这样，符合自然规律，符合进化论。和上面几种算法一样，随机初始化。为了得出优秀的后代，需要优秀的双亲进行杂交，或者称为配对、或者交叉。别想歪了，对于简单的二进制序列，就可以选p1的一部分和p2的一部分组合成为一个新的解，当然还有其他的方式。位了避免局部最优的陷阱，我们还需要变异，正如现实中人类总是需要变异的天才一样。对于序列，简单的变异就是改变其中的某一位或者几位。然后每一轮都进行排序，选择其中%10，或者%20的优秀物种，继续上面的操作，直到解收敛或者达到一定的循环次数。这里可以改变的参数就比较多了， 最大筛选次数，生存的比率和选择的方法，变异的比率，杂交的函数选择，变异的函数选择等等。 总结上面的优化算法都是一个算法框架，如A*算法一样，最后更多的细节比如评估函数或者参数的选择对算法的效果都有影响。 另外这些优化算法最后能生效都是基于这么一个事实:很多优化问题最优解附近的解也是比较优的解，比如上面的问题，另比如旅行商问题。但有的情况，如下图，就是一个可能不被优化的问题，最优解附近并不是好的解，对于上面的算法都有随机性，也许随机优化一下能找到这个解（概率很小），也许遗传算法能产生个变异，但这都是概率问题，不能保证。 难优化的例子 最优解为最低点 说明：上面的图来自《集体智慧编程》中，这是本不错的书，在网上有代码，python写的，感兴趣的同学可以仔细看看。 我试着用遗传算法去解上面这个问题，参数调了很多次，最后还是能在一个可以接受的时间内得到所有正确的解。 代码在后面，写得很难看。gene_alg","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Algorithms","slug":"Algorithms","permalink":"http://chenyukang.github.io/tags/Algorithms/"}]},{"title":"Emacs Muse的使用","date":"2010-11-15T11:43:00.000Z","path":"2010/11/15/emacs-muse.html","text":"Muse简介 Muse的配置 Muse中源代码高亮显示 Muse 来写主页和博客 Muse简介 Muse 是由 EmacsWiki 衍生的，为emacs下的一个扩展模式，可以方便快捷的为文档生成各种格式，包括html,pdf，latex等等。Muse的编辑规则很简单，而且支持“所见即所得”的编辑方式可以让文档编辑更轻松。我使用这个工具已经快一年了，强烈推荐。这个html文件就是从Muse调用htmlize生成的。 Muse的配置 从这里下载最新版本的Muse，比较简单的安装方法是解压后直接在目录下运行make，然后把所有的文件都拷贝到emacs的一个加载目录下面(比如~/.emacs.d/muse/)。设置.emacs加入以下几行。 ;; 加载 muse (require 'muse-mode) (require 'muse-html) 然后就可以利用Muse-mode来方便地创建文档。这里有个QuickStarted，看一遍就基本掌握了编辑规则。编辑完成以后按键C-u C-c C-t即可发布该文档。 Muse中源代码高亮显示 在Muse-mode中编辑时是所见即所得样式的显示，但是有一个问题是代码不能高亮显示，要贴代码就有点不方便，解决的方法是要下载htmlize.el,而且需要1.34以后的版本才支持这个功能，在这里下载。使用方法也有说明。 Muse 来写主页和博客 很多搞学术的同学喜欢建一个看起来很严谨的静态主页，这样的主页用Muse来维护非常方便。对于wordpress的博客或者主页，一款离线撰写工具是必须的，在windows下可以用WindowsLiveWriter,Linux下也有相应工具。不过我大部分还是在自己电脑上用Muse来写完发布成html格式，然后再发布到主页上。首先我们需要建立一个主页的工程。比如我的： ;;==新建一个wiki工程 (setq muse-project-alist '((\"MainPage\" (\"~/document/blog/Home\" :default \"index\") (:base \"html\" :path \"~/document/blog/Home_Page\")) (\"Computer\" (\"~/document/blog/Home/Computer/\" :default \"index\") (:base \"html\" :path \"~/document/blog/Home_Page/Computer\")) (\"Sport\" (\"~/document/blog/Home/Sport\" :default \"index\") (:base \"html\" :path \"~/document/blog/Home_Page/Sports\")) (\"Other\" (\"~/document/blog/Home/Other\" :defualt \"index\") (:base \"html\" :path \"~/document/blog/Home_Page/Other\")))) 然后到相应目录下撰写muse文件，快捷键C-c c-p就发布了整个工程，在Home_Page相应的目录下生成了html的文件。看起来有点复杂，其实还是很方便的，代码高亮这个程序员都喜欢的功能肯定就不用操心了，同时在本机上留有个备份。这种wiki风格的网页还是很利于浏览。不过有一个弊端，图片插入虽然在撰写过程中能直接预览的，但是上传到wordpress上路径肯定会变，所以还是要再稍微编辑一下。","tags":[{"name":"Emacs","slug":"Emacs","permalink":"http://chenyukang.github.io/tags/Emacs/"},{"name":"Tools","slug":"Tools","permalink":"http://chenyukang.github.io/tags/Tools/"}]},{"title":"又是一些歌","date":"2010-11-14T11:43:00.000Z","path":"2010/11/14/damien-rice.html","text":"实验室的机子要被占，要搬出来，所以得把资料整理一下。发现一个原来研一英语课上做representation的ppt,题目是介绍一位自己喜欢的歌手。那次第一次上台做英报告，呵呵。我喜欢缓慢而伤感，有些沉重的歌。在一位同学日记上看到介绍Damien Rice的，然后喜欢上了他的歌。研一那一年骑车时候基本都是这些歌，高中时最郁闷的时候经常听的是王菲和齐秦。一段时间狂听某些歌好像已经成了习惯，然后偶尔再听到的时候当时的情景自然就浮现了，音乐也是一种好的记忆载体。 Damien Rice Damien Rice is an Irish Rock singer.Two studio albums: O in 2003, and 9 in 2006.He was born and raised in Ireland,a country which is rich in country music, poets, singers. When He was young, music and drawing attract him. Rice was a member of the rock band Juniper.Having released the singles “The World Is Dead” and “Weatherman” in Ireland during 1998. Rice left the band to pursue a solo career. His Juniper band mates later became Bell X1. Rice’s first solo album is O, which was released in 2003 and a true contender for one of the best albums of 2003, won the Shotlist Music Prize.Rice’s style is simplity. The cover of this album is a beige hand painted portraits of the two small chiledren, which was drawed by himsefl. This is am simple folk album. This album contains a large number of hollow guitar chords , easy and simple percussion, drowning, backwards vocals, and low_key accompaniment . Rice is master of what critic called “the unknown tongue” — basically the musical equivalent of the “punctum” in photos, Rice’s emtional singing brings me a sad ,clean and sophisticated intimate space. Three years later, following extensive promotion of O in Ireland and further success worldwide, Rice released his second studio album 9 in 2006. 好听的专辑： 9 1. 9 crimes the animals were gone elephant rootless tree dogs coconut skins me, my yoke and i grey room accidental babies sleep don’t weep9 crimes最好听，适合半夜失眠。MV拍得很吸引人，在这里，我当时课上放的就是这个MV，非常惊艳，课后还有同学问我要这个。另有个评论感觉写得非常不错。Cold water浮躁繁杂的时候，就来听听这样一首像诗歌般的曲子，这也是电影《偷心》的片尾插曲。木吉他很有感觉，以后有时间学学，呵呵。 还有这首The Blowers Daughter非常不错。","tags":[{"name":"Notes","slug":"Notes","permalink":"http://chenyukang.github.io/tags/Notes/"}]},{"title":"给C瓜同学吧","date":"2010-10-27T11:43:00.000Z","path":"2010/10/27/forc.html","text":"C瓜同学一直关注这个我这个小地方，下面是一些我面试中或者和同学讨论的一些不错的面试题，备份一下，也希望对你有用。 1：C++的多态是如何实现的？如果你用C如何来实现面向对象的多态？2：判断一个有向图中是否有环。上篇文章里面写的那个杯子倒水问题。给一个都是正整数的数组，和一个正整数sum，求是否存在和为sum的子数列。3：两个有大量id的集合A和B，数量上亿级，如何求出两个集合的交集，A中有的B中没有的，和B中有的A中没有的集合。4：设计实现一个管理内存的小模块，接口为void checkout(size_t size), void checkin(void ptr)。5： 设计一个数据结构，存储一副象棋子的摆放，尽量压缩空间，使得方便通过传输到另外一台机子上然后恢复棋盘。6：数组的众数问题，最长递增子序列问题。找大量数据中前k个大的数。找大量数据中第k大的数。7：一个平面中有很多点，用最快的算法找出相隔最近的两个点。8：select/poll和epoll，基本互联网公司都会提到这个东西。9：给敏感词列表，和一大段文本，考虑一个敏感词过滤的算法。10：海量数据问题，很多，一般方法就为分治、hash、位图。 很多没有标准答案，面试过程中的探讨很重要。找工作不难，找份好工作还是难的，基础知识很重要，数据结构和算法、操作系统、编程语言的掌握，数据库和网络。可以根据自己的喜好，偏向于某个方向。","tags":[{"name":"Notes","slug":"Notes","permalink":"http://chenyukang.github.io/tags/Notes/"},{"name":"工作","slug":"工作","permalink":"http://chenyukang.github.io/tags/工作/"}]},{"title":"有你的快乐","date":"2010-10-27T11:43:00.000Z","path":"2010/10/27/haveyourfun.html","text":"晚上睡在公司，这边除了晚上偶尔有施工的声音，一切都还不错。洗个热水澡，随便写写早点睡。嘈杂的音响放着这么王若琳的《有你的快乐》，标题就用这个吧，哈哈。关于工作：今年好像计算机专业的同学们还是非常好找工作，首先华为华赛来得非常早，然后就是腾讯，这几个公司就签了好多。成都很多同学都不想离开四川，所以进华为的很多。我开始找工作的时候也没有想法一定要留在这，只是周围一直有各种什么成都多好多好之类的言论，什么消费低，房价低，不排外，生活安逸之类的。渐渐地也不由自主地越发想留在这边。我找工作应该已经结束了，一共面了大概六个公司，一周三个公司，中间有一周觉得身体不是很舒服，就没怎么动。第一周面的华赛，前面已经说了很悲剧。然后腾讯，也很诡异，小概率事件发生了，面了终面没有给offer。现在还不知道原因，可能还是二面的问题吧，二面的面试官问我平时是不是都很自我，当时我还没反应过来，后来才觉得不对劲。大公司都会有自己的企业文化，可能会因为这些把人刷掉也是正确的。没收到offer心里多少会有点失落吧，深圳是除了成都之外我比较想去的地方，毕竟那边认识的人比较多，离家也比较近。过了一周后，已经是找工作的高潮时段，我也安奈不住了，所有公司都想去试试。上海纳拓软件，因为何师兄的内推这个公司暑假就已经开始联系然后笔试了，最后因为实习没去上海面试，所以等到他们的校园招聘。前面三面技术面，一面C++，两人一台电脑整程序。电工的校友大哥最后一个题目把我摧残了，模板类啊、嵌套类、友元类啊一看就紧张了。基本是他教我怎么改那个程序，从来没觉得自己C++那么差了，我以前也只是把C++当一个扩展了一点的C来用，所以当时备受打击。二面是师兄的算法，还是比较照顾我，给tips，算是探讨了。三面数理逻辑，面试官很nice，一点点教导，终于给那些最基本的文式图画出来了。纳拓的三个面试是我接触的最深的面试了，一路下来感觉很辛苦。联发科，据说要在成都建立分公司，去试试。面试官很多都是台湾人，感觉很有礼貌，他们要求也不是很高，还是吸引了不少想留成都的同学。另外当晚面了创新工场，感谢欧阳大哥的内推，还有Xiaoxiao同学的面试也很有水准，又有点受打击，后面的那个程序实在做得不尽如人意，最后还是让我进了二面。然后和Billy大概40分钟的聊天，交流了一些想法。创新工场到底怎么样我不是很了解，网上的看法是两个极端，要么是说很好的，要么是说一个空壳，但是我知道很多很强的同学在里面做得都非常有激情，非常有干劲，技术氛围也都不错，所以我也动心了。过了两天是纳拓那边的技术四面，刘大哥很和蔼，一起吃了个晚饭然后才面试。也是首先谈谈项目，没说多久就指出了我的东西是over design了，呵呵。然后交流了各自的看法，感觉很投机。纳拓软件虽然只有10个人左右，但肯定是个非常出色的团队。然后是他们老板的电话终面，他也没怎么太为难我，连老板都在问技术问题，呵呵。总是面完后感觉找到了中意的公司，所有后面也没有再去继续找了。在同一天收到创新工场和纳拓的offer，当天比较纠结。北京和上海，不知道去哪个了。真的也想去北方那边闯闯，创新工场那边应该是个不错的平台。还有欧阳大哥每周教会聚会的短息发到我手机上，我也会时不时想如果我在北京一定要去参加他们的聚会。最后综合各方面的意见，我应该还是签纳拓吧，因为对他们那边感觉很投机投缘，而且也很可能会过一年后在成都开branch。那么，两周的找工作日子算是过去了，没太努力，不过还是认为找到了适合自己的公司。实验室的同学们都找到了自己满意的工作，突然觉得我身边一个个是大牛啊，哈哈。今年的行情真的非常好了，国内的IT公司都在大规模扩招，外企倒还招得少，我们陶瓷国的IT虽然一直说做不到核心，但也确实在进步啊。 最近不知道为什么，非常淡定，也许在这边公司做得比较安稳。我喜欢这种一小群人做东西的感觉，大家一起讨论争论，努力想把一个东西做好的感觉。也可能是因为在这边受到了一些熏陶，所以找工作也想去小的公司或者创业型的公司。第一份工作工资不是主要考虑的，因为我想想即使一年赚20w(应该对应届生算不错的待遇了吧),除去平时花费一年能攒多少钱呢？多1k，2k对于生活也本质的提高，所以在能养活自己的情况下，找些觉得适合自己、能多锻炼、能让人有动力的公司挺好的。况且，如果把工作看严肃点，我应该找的是一群得整天相处的人，所以投机很重要，^^。感谢找工作这段时间所有给予我帮助的所有人，虽然你们不一定能看到，^^。熊师兄，两位何师兄，欧阳大哥。王骆驼，傅骆驼，yyl，寓于其中以及实验室的各位师兄师姐们，哈哈。","tags":[{"name":"Notes","slug":"Notes","permalink":"http://chenyukang.github.io/tags/Notes/"}]},{"title":"面试：杯子倒水","date":"2010-10-14T11:43:00.000Z","path":"2010/10/14/beizidaoshui.html","text":"前些天纳拓的面试有一道题目: 给你一个3升的杯子和一个5升的(杯子是没有刻度的)，要你取4升水来(水可以无限取)，请问该如何操作。这个题目今年面试出现了很多次,不过这次变化了一些。如何抽象出一个模型,如果写程序如何解,如果要求得杯子倒水的过程如何做? 当时并没有一下想出来,看起来有点像取石子那样的游戏,想找规律。然后被提示搜索,对,搜索问题。 搜索得确定状态的表示,状态之间的转移方式,起点和终止状态，如果这些都确定那么就基本完成了。 如果我要求最快的解法,BFS。如果要求所有的解法,递归DFS。这里状态的总数目比较少,如果用一个整数来表示,10位表示A杯子的水量,个位表示B杯子的水量,这样要的空间最大也为60个整数。再想想如果用两个整数，最多64bit，也能表示出状态，能省下空间。 很久没做题了,有些生疏了,看来还得好好补一下。 代码_下载","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"工作","slug":"工作","permalink":"http://chenyukang.github.io/tags/工作/"}]},{"title":"找工作小结","date":"2010-09-30T11:43:00.000Z","path":"2010/09/30/forjob.html","text":"又是很久没更新了，这段时间比较忙碌，各种笔试面试各种奔波，终于体会到了找工作到艰辛。而这还只是开始。国庆这些天应该要轻松一点，很多公司都是国庆后再来学校。总得来说最近这两个月还算比较充实，即将面临走出校园，还是得去考虑各种选择。另外，尝试着离开实验室后又淡定了不少，哈哈。虽然还没完全结束找工作这些事，但还是记录一下面试的感受吧，其实我面得还算少，才三个公司。 首先华赛就悲剧了，本来打算去积累点面经的，又不是特别重视，那面试官估计也看出来了，其中各种不爽，自己的交流方式也有问题，让他觉得这人有些傲吧。呵呵，本来我是个多不自信、多自我怀疑的人，硬是装作很自信的样子就出问题了。最后面试官说今天就到这里吧，你回去等通知吧。我说把我简历还给我，汗，我当时居然还说了这么句话，想起就无语呀。 TX的笔试感觉很细，做完后不怎么确定能不能有面试机会了，不过第二天就发来了短消息，笔试还是没怎么刷人。一面人山人海，岷山饭店还没个坐的地方，等了两个小时腿都酸掉了。据说王骆驼碰上个年纪比较大的，问得比较刁，自我感觉是挂掉了。最终，我碰上一个比较年轻的，一看就搞技术的，笑得很贼，哈哈。问题都中规中举，有的没答出来，不过还是说了一下自己到思路。最后讨论了前段时间自己在做到多线程的缓存，嘻嘻。这里不得不再说一下，在公司这段时间虽然比较短，但还是实在地做了一些事，对这一块至少说有一些体验，还是可以和面试官聊聊。面完后心里貌似有个底了，应该有二面机会。果然，第二天早上不到6点怎么就自然醒了，睡不着，于是就想一面时候的一个问题，觉得貌似想到了优化方法，哈哈，这时手机震动，于是下床一看果然有二面(赞一下tx的招聘人员敬业精神，早上1点半给你发短信)。二面在成都TX，第一次去了躺软件园，人挺多。TX的工作环境貌似还不错，装饰看起来比较鲜艳。走之前向何老大打听了一下，据说二面就是狂问技术，各种方面的都有，于是心里有点点发毛。等了近四十分钟，最后碰上六号面试官，很奇怪的是后面感觉一直在聊天，项目方面都是泛泛而谈，没怎么问我很深入的技术问题，气氛还可以。大概二十多分钟就结束了。等王骆驼面完一起回，他又碰上个狂刁钻的，各种效率不高，速度不行…..然后我觉得诡异了，说你机会可能更大点。 晚上去面了一下中兴移动，面C++，刚开始那年轻到面试官一副很凶很高深的样子：“学过UML吧，把你这个项目中所用到到类图和关系画出来..”。顿时很无语，在纸上边说边画，心里觉得不爽，这么累了本来是想来打打酱油的，还得慢慢回想一下那折磨了我两年的各种不感兴趣的对象。然后那人问：“你这个项目中只用了两层继承关系吗？”呃，我这正有点郁闷，突然想起哪本书说的，于是就随口说：“面向对象不是银弹，设计得好两层就够了，设计不好十层也不够”。 他居然没继续问了，原来适当地装装也能唬住人的。然后聊了聊状态模式，我说得比较清楚，因为这个模式还是有点体会的。不爽，面试过程中还换了个房间。然后再下面就是聊天了，这下感觉平等多了，聊了聊他们是做什么的，做手机终端各种底层和上层吧。然后就来了个人力资源的面试吧，比较和蔼，就说我们待遇比中兴好。完后站在电梯旁边，王骆驼要强面，两个人一副喝茶的姿势聊得很high，我在旁听了一下，觉得很无语。一个40岁左右的貌似技术人，在王骆驼各种项目忽悠了一顿后，说：“恩，UDT这个东西这么好，我在哪里找到呢？”王骆驼：“在网上下载”。然后面试官最后问了句：“在你编译的时候出现了一大堆到错误提示，你怎么解决？”，王骆驼：“我从第一个错误开始改“。面试官露出了找到知己的那种兴奋表情，最后站起来总结一番：”好，我觉得你对C语言理解很深刻，我去给你安排第二轮面试”。回来时王骆驼一副神清气爽，之前TX被问得不知所云，这会劳累全没了，反差啊，哈哈！然后第二天中兴移动就让人同学们去签就业意向了，估计很多人都不去。 继续TX，说着觉得诡异了，果然晚上王骆驼进入了三面，我就没了名字。后来想想估计还有一批，我就不相信就这么悄无声息地挂掉了，如果挂掉我真不知道原因在哪里了。晚上跑到公司睡了一觉，好久没来公司了，还有一些工作要做。另外如果还有三面，从这边过去软件园也方便。晚上9点多看到一条短信，估计是来消息了，果真自我感觉还是有点点灵验的，第二天九点三面。三面就更是聊天了，没有经历过群P，不过今天到碰上了类似的问题，例举出三个自己的缺点。呵呵，总不能继续各种老套太过追求完美吧。比较属实的三点：稍微有点害羞，作息时间不怎么好，有时候有些马虎。最后就等消息吧，感觉面试就和聊天一样，聊得好就好。另外根据王骆驼的经历，面试过程中不一定都要马上答出最好的答案，其中的讨论过程很重要，而且可能问题本来没有最好的解法，只能折中。韩sir说：“一般招人技术不是最重要的，应聘者是否是一个口味的很重要“。恩，有道理。 嗄，外面乌云一片，正考虑今天要不要回学校。","tags":[{"name":"Notes","slug":"Notes","permalink":"http://chenyukang.github.io/tags/Notes/"},{"name":"Backup","slug":"Backup","permalink":"http://chenyukang.github.io/tags/Backup/"}]},{"title":"Emacs自虐","date":"2010-08-21T11:43:00.000Z","path":"2010/08/21/emacs-for-fun.html","text":"无意中用了一下C#,发现VS下面有一个功能还是非常好的，就是每次按下回车键盘的时候，都可以把刚刚输入的那行代码自动排版一下， 看起来要清晰一些。比如 int a=0; ==&gt; int a = 0;struct Node p=&amp;node; ==&gt; struct Node p = &amp;node;a+=b; ==&gt; a += b;int p=&amp;a; ==&gt; int p = &amp;a;int a=b+c+d+f; ==&gt; int a = b + c + d + f;for(a=0,b=0;a&lt;10;a++) ==&gt; for(a = 0, b=0; a&lt; 10; a++)if(a==b) ==&gt; if(a == b)if(pbuf!=0) ==&gt; if(a != b)fwrite(buf,1,size,fp); ==&gt; fwrite(buf, 1, size, fp);printf(“%d %s\\n”,len,buf); ==&gt; printf(“%d %s\\n”, len, buf); //引号内的不变，引号外的”,”后面加空格if(p&gt;=allocbuf&amp;&amp;p&lt;buf+size) ==&gt; if(p &gt;= allocbuf &amp;&amp; p &lt; buf + size)return (b!=0)?gcd_ver2(b,a%b):a; ==&gt; return (b != 0) ? gcd_ver2(b, a % b) : a;同时要注意的情况，还有些情况下我不想让符号两边加空格： #include &lt;stdio.h&gt; //&lt; &gt; 两边不加 printf(“%d%d%d\\n”,n,m,k);//这个%两边不加 检测是否在引号内部a++; //不加空格int p; //不加空格return manip(this); //这个两边不加 找到前面或者后面是否为(strcpy(mode,“w+”); //引号里面的不变 检测是否在引号内部我以前写代码习惯都不加空格，感觉不加要写得快一些，可是这不是个很好的习惯。linux下有indent这样的工具，不过是针对于最后完成的源程序来排版。在写程序的过程中像赋值操作符两边加上空格会显得比较清晰，Emacs里面好像还没这么个插件，那我来折腾一下自己写了一个。原来还是比较复杂的。应该好好学学正则表达式，这就是一个正则匹配和替换的过程。呜，括号看得头都晕呼呼的，不过还好，最终有这么一个东西用起来比较顺手了。 首先定一个关键字和替换列表： (setq beautifly-line-list ‘( (“+” . “ + “) (“-“ . “ - “) (“=” . “ = “) (““ . “ “) (“/“ . “ / “) (“%” . “ % “) (“&lt;” . “ &lt; “) (“&gt;” . “ &gt; “) (“,” . “, “) (“+=” . “ += “) (“=” . “ = “) (“/=” . “ /= “) (“%=” . “ %= “) (“==” . “ == “)))一个用来测试dest是否为上面关键字的函数，后面用char-after来获取一个point的字符，对应的是asci码。 (defun test-valid(dest) (interactive) (if(or (equal dest 43) (equal dest 45) (equal dest 42) (equal dest 47) (equal dest 37) (equal dest 62) (equal dest 60)) ;;&lt; t nil)) ;;打印出当前位置的字符 调试用(defun print-pos-char () (interactive) (setq value (char-after (point))) (print value)) ;;从point-pos位置开始 到这一行的尾部，检测是否有”，即检测是否在” “内部(defun test-in-quote (point-pos) (interactive) (move-end-of-line 1) (setq end-pos (point)) (goto-char point-pos) (setq ret-value nil) (if (search-forward “\\”” end-pos t) (setq ret-value t) ) (goto-char point-pos) ret-value) ;;这个函数先调用我的排版函数，然后调用原来的new-line-and-indent(defun my-new-line-and-beautyfly () (interactive) (beautifly-line) (newline-and-indent)) ;;在my-c-mode-common-hook下面加上这么一句，表示把回车键绑定在上面那个函数上。 (define-key c-mode-base-map [(return)] ‘my-new-line-and-beautyfly)下面就剩下这两个函数了，写的太过复杂，可惜不会用高级一点的正则表达式，所以显得不好看。其想法比较简单，按照上面那个列表，一次查找，我要找一个两员操作符，其两边都是空格，在其两边加上空格，注意排除掉++,—操作。然后识别+=,-=,*=等符号，再两边加上空格。用起来还可以。逐渐写了些elisp，感觉特别适合自底向上的方式进行，通过一些小函数，逐步累积成一个功能，再最后只用一个上层函数来调用这个功能。每个小函数除了返回结果不改变函数外的其他变量(无副作用)。同时写一个小的函数可以马上写一个测试函数，保证其正确无误。 最后bueatifly_line的代码有点点长，不贴咯。","tags":[{"name":"Emacs","slug":"Emacs","permalink":"http://chenyukang.github.io/tags/Emacs/"},{"name":"Linux","slug":"Linux","permalink":"http://chenyukang.github.io/tags/Linux/"},{"name":"Backup","slug":"Backup","permalink":"http://chenyukang.github.io/tags/Backup/"}]},{"title":"using automake","date":"2010-08-21T11:43:00.000Z","path":"2010/08/21/using-automake.html","text":"以前都是手写makefile,没使用automake之类的工具,今天看了一些相关资料,简单地总结一下，留个备份。 使用Makefile unix/linux下面使用相当广泛,对于简单一些的程序,手写makefile还是比较容易的,只要指定清目标文件,最后可执行文件的依赖关系。使用一些高级一点的功能更方便,比如下面这个就比较好用,稍微编辑一下就可以用于常用的小工程。这个Makefile把所有.cpp的文件编译成相应的.o文件,然后链接为Targetfile文件。 CC = g++ -O2LD = g++TARGET = TargetfileSOURCES = $(wildcard *.cpp)OBJS = $(patsubst %.cpp,%.o,$(SOURCES)) %.o:%.cpp $(CC) $(CFLAGS) -c $&lt; -o $@ Targetfile:$(OBJS) $(CC) $(OBJS) -lglut -lglui -o Targetfile clean: @/bin/rm *.o 使用automake等工具 1. 首先运行autoscan,这之后会生成一个configure.scan文件,修改为configure.in，并编辑。典型的一个文件如下,AC_CONFIG_SRCDIR,AC_CONFIG_HEADER这两项还不知道干什么用的,如果不注释掉后面automake会出现错误,那就先注释掉吧。重点修改AC_INIT，AC_INIT_AUTOMAKE。AC_CHECK那些不用管,后面提示-lglui提示要注意,这是需要链接的库文件，这里链接glui这个库。 # -- Autoconf --# Process this file with autoconf to produce a configure script. AC_PREREQ(2.61)AC_INIT(TSPdemo, 1.0, moorekang@gamil.com)AM_INIT_AUTOMAKE(TSPdemo, 1.0)#AC_CONFIG_SRCDIR([Elastic_Alg.cpp])#AC_CONFIG_HEADER([config.h]) # Checks for programs.AC_PROG_CXXAC_PROG_CC # Checks for libraries.# FIXME: Replace main&lt;span style=&quot;color: #deb887;&quot;&gt;&#39; with a function in-lglui’:AC_CHECK_LIB([glui], [main])# FIXME: Replace main&lt;span style=&quot;color: #deb887;&quot;&gt;&#39; with a function in-lglut’:AC_CHECK_LIB([glut], [main]) # Checks for header files. AC_HEADER_STDCAC_CHECK_HEADERS([stdlib.h]) # Checks for typedefs, structures, and compiler characteristics.AC_HEADER_STDBOOLAC_C_CONSTAC_C_INLINEAC_TYPE_SIZE_T # Checks for library functions. AC_CHECK_FUNCS([sqrt])#AC_CONFIG_FILES([makefile])AC_OUTPUT(Makefile) 编写Makefile.am,如下面这样。和makefile一样,写上可执行文件依赖于的源文件,_LDADD是要链接的库文件名。AUTOMAKE_OPTIONS=foreignbin_PROGRAMS=TSPdemoTSPdemo_SOURCES= Elastic_Alg.cpp MyMap.cpp mathlib.cpp \\Elastic_Alg.h MyMap.h mathlib.h \\LaoMan.cpp SOM.cpp pointdef.h \\LaoMan.h SOM.h main.cppTSPdemo_LDADD = -lglut 然后执行aclocal,和autoconf，最后automake —add-missing 生成configure文件。这就完成了,下面就是unix下编译安装软件的三个步骤了,./configure，make,makeinstall等。 写得比较粗略,详细查看这个文档。","tags":[{"name":"Linux","slug":"Linux","permalink":"http://chenyukang.github.io/tags/Linux/"},{"name":"Backup","slug":"Backup","permalink":"http://chenyukang.github.io/tags/Backup/"},{"name":"makefile","slug":"makefile","permalink":"http://chenyukang.github.io/tags/makefile/"}]},{"title":"折腾记录","date":"2010-08-20T11:43:00.000Z","path":"2010/08/20/zheteng.html","text":"centos 环境变量 在配服务器web环境的时候，因为这个问题花费了不少时间。tomcat找不到java的其他开发包，开始以为是服务器是64位的问题。最后因为在/etc/profile文件里面设置为export CLASSPATH=…,这个export貌似不能少。或者是因为命令prelink -a的作用起了效果，这个命令好像只是起到加速到作用。orz，我是被ubuntu宠坏了，什么linux命令都没怎么用咯。 mysql mysql配置局域网内都能访问。 1 mysql -h localhost -u root2 mysql&gt;GRANT ALL PRIVILEGES ON . TO ‘root’@‘%’WITH GRANT OPTION3 mysql&gt;FLUSH PRIVILEGES4 mysql&gt;EXIT 这样就可以在其它任何的主机上以root登录，其他用户类似。但是连上以后速度比较慢，在my.cnf文件里面配置一下啊， 把缓存那些改大一些，加上这么一行：skip-name-resolve。 centos 双网卡路由问题 centos能ping通局域网，但是不能上外网，最后查处是因为双网卡到问题，添加一个默认的网关就可以了。使用命令： route add defualt gw 192.168.1.1netstat -nr 查看内核iP路由表。 two or more data types in declaration specifiers C编译器这个错误指向到行会不准确，有一种情况最容易出现这样的错误，那就是在你的程序里少了个”;”号，有可能在你的头文件里，也有可能在本文件中。","tags":[{"name":"Linux","slug":"Linux","permalink":"http://chenyukang.github.io/tags/Linux/"},{"name":"Backup","slug":"Backup","permalink":"http://chenyukang.github.io/tags/Backup/"}]},{"title":"《编程珠玑》：代码优化","date":"2010-08-05T11:43:00.000Z","path":"2010/08/05/programming-peal.html","text":"编程珠玑里面代码优化这一章。问题1 函数,宏，内联代码#define max(a,b) ((a)&gt;(b)? (a):(b))float max(float a,float b){ return a&gt;b? a:b;}inline float max(float a,float b){ return a&gt;b? a:b;}上面这个函数到底哪一个快一些？测试了一下。宏效率是高一点，但是对于加上编译器优化以后基本没什么区别了。 问题2 顺寻搜索 int search1(int v){ for(int i=0;i&lt;N;i++) if(vec[i]==v) return i; return -1;} int search2(int v){ vec[N]=v; int i; for(i=0; ;i++) if(vec[i] == v) break; if(i==N) return -1; return i;} int search3(int v){ vec[N]=v; int i; for(i=0; ;i+=8) { if(vec[i]==v) break; if(vec[i+1]==v) {i+=1; break;} if(vec[i+2]==v) {i+=2; break;} if(vec[i+3]==v) {i+=3; break;} if(vec[i+4]==v) {i+=4; break;} if(vec[i+5]==v) {i+=5; break;} if(vec[i+6]==v) {i+=6; break;} if(vec[i+7]==v) {i+=7; break;} } if(i==N) return -1; return i;} 这三个函数哪一个效率最好？据说第二个提高5%，第三个会提高10%~20%(对于老实计算机)。在我的机子上测试了一下，N=10000000。并不如书上说的能提高多少， 反而最原始的写法在优化后效率更高，确实是这样的数据。 问题三 二分查找 数组大小为1000。 单位ms。 确实第二个版本提高了一些，第四个版本甚至提高了一半的效率。测试是一个麻烦的事情，因为同一时间处理器调度了其他进程，但多次测试还是能给一个大概的印象。第二个例子的优化没起什么作用，也许现在的编译器优 化技术比以前更好的，得出的结果并不如书上所说。在一个算法复杂度确定的情况下改变一些写法会有一点提升，但是对于不同的输入规模也许就得不到什么提高， 而且编译器优化以后基本差别就更小了。为了那么一点效率的 提升增加了代码的复杂度得不偿失。原理那章也说了，不成熟的优化是大量编程的祸害，会危机程序的正确性、功能性、和可维护性。 王道还是改变数据结构或者算法,除非确定一个部分的代码会经常被调用很多次，在这里可以花一些功夫去优化。优化是把双刃剑，玩火者，小心自焚，哈哈。","tags":[{"name":"Books","slug":"Books","permalink":"http://chenyukang.github.io/tags/Books/"}]},{"title":"A*算法与K-shortest path问题","date":"2010-08-02T11:43:00.000Z","path":"2010/08/02/astart-k-shortest-path.html","text":"那天师兄给面试，面到一道图算法题目，求图中两个点的前K短路径。当时觉得用Dijkstra+heap应该可以，不过也没想清楚。以前看到过这个，那时还没怎么仔细看图算法所以丢一边了， 今天好好看了一下。简单一点的解法是用Dijkstra+Astar。典型的题目就是POJ 2449。 A* 算法 再谈A算法。A算法中的评估函数为f(N)=cost(N)+h(N)。其中cost(N)为从源点到N点的距离，h(N)为N点到终点的的一个评估路径长度，设h(N)为实际N点到终点的路径长度。只要满足条件： h(N)&lt;=h(N)，那么用这个评估函数找到最短路径。具体证明看这篇论文A Formal Basis for the Heuristic Determination of Minimum Cost Paths。 其优势在于在选择每个路径 上的点的时候给予了h(N)这个启发，在搜索空间中尽量选择可能最有可能产生最优解的下一个状态，使得搜索的时间都相应地减少。A算法的思想也是贪心 的，Dijkstra是A的一个特例，当h(N)=0时，A*就退化成了Dijkstra算法，那么就是盲目的扩展当前最短路径了。 来个例子，下面这是一个城市的公路图网，一共有18263个点，23874条边，视为无向图。我们知道起点和终点的坐标，现在我们要求某两点之间的最短路径。 1. 用Dijkstra算法来，其中白色的点表示搜索过程中访问了的点。可以看出Dijkstra算法有点像BFS向周围扩展,做了很多无用的搜索。当然这与图的形状也有一定关系。 [Dijkstra 访问18191个点] 2. 用A算法，设S为起点，T为终点，启发函数为F(N)=Path_Dist(S-&gt;N)+Dist(N-&gt;T)。在搜索过程中Path_Dist一直维持着S-&gt;N的路径长度，Disk(N-&gt;T)的计算可以有多钟选择，这里我选择 Dist(N-&gt;T)=sqrt(|Xn-Xt||Xn-Xt|+|Yn-Yt||Yn-Yt|),这个为两点之间的理论最短路径，肯定是满足条件h(N) &lt;= h(N)的，那么能得到最优解。可以看到搜索偏向于目标点的方向。 [A* 两点之间距离为评估函数 访问4398个点] 3. 另外(x+y)/2 &lt;= sqrt(x^2+y^2)，所以也可以选择(|Xn-Xt|+|Yn-Yt|)/2作为启发函数。但为了节省这个sqrt的操作，代价就是访问了更多的点。 [A* (x+y)/2作为启发函数 访问14374个点] 4. 可以做得更好，修改启发函数。Dist(N-&gt;T)=|Xn-Xt|+|Yn-Yt|,这为曼哈顿函数，这样就不满足条件h*(N)&lt;=h(N)了。所以得不到最优解，但是速度上会快很多，搜索的点也会减少很多。 [A* 曼哈顿距离作为启发函数 访问296个点] 大概能得到一个规律，搜索效率依赖于h(N)的启发作用，当h(N) &lt;= h(N)时候，我们能得到最优解，用第二种启发函数能也满足最优解的条件，但是因为启发用少了所以访问了更多的点。当h(N)&gt;h(N)时，得到的可能是比较优的解(非最短路径)，可以认为因为得到的启发更多(多到超出了得到最优解的条件限制)，所以能取得更快的效率。这又是一个普遍的问题，在速度、精确度两者之间经常会只能二选一，对于不同的应用从中作出折中。上面那篇论文证明了，对于刚才举例的这个问题，用两点之间的直线距离最为启发函数的A算法是所有能得到最优解的算法中访问点最少的。启发函数对于特定的问题有特定的取法，那么A*作为一个搜索的算法框架用处还是挺多的。 Dijkstra＋A* 求k短路径 当然这个算法不是我想出来的，这里只是说一下看后自己的理解。在A算法中，优先队列出来的点如果扩展到了终点，那么 就得到了最短路径。如果能得到实际的评估函数(也就是h(N))，那么第二次 从优先队列里面弹出来的就是第2段的路径，依次直到k短。如何得到h(N),就是图中各个点到T的实际最短路径距离，可以从图的反向图以T为源点进行 Dijkstra算法，最后Dist[N]就可以作为h(N)。然后以cnt[N]表示N点从优先队列里面弹出来的次数。K-shortest问题还有更快的解法，不过还没看，这里有大把论文。这里还分结果路径中是否可以有环，像现实中公路网肯定是要求无环的k-shortest path。下面这个算法是可以有环的。 完整代码如下： //7040K 282MS#include &lt;iostream&gt;#include &lt;queue&gt;#include &lt;vector&gt;#include &lt;stdio.h&gt;#include &lt;cstring&gt;using namespace std;const int MAXN=1001;const int INF=(1&lt;&lt;20);int N,M; //N个点 M条边int S,T,K; //起点和终点typedef struct _Edge&#123; int v;//边顶点 int len;//边长度&#125;Edge;int dist[MAXN];int cnt[MAXN];bool mark[MAXN];struct Node&#123; int v,len; Node() &#123;&#125;; Node(int a,int b):v(a),len(b) &#123;&#125;&#125;;bool operator &lt; (const Node&amp; a,const Node&amp; b)&#123; return (a.len+dist[a.v] &gt; b.len+dist[b.v]);&#125;vector&lt;Edge&gt; Adj[MAXN];//图的邻接表表示vector&lt;Edge&gt; Rev[MAXN];//图的逆图void Init_graph()&#123; int u,v,l; Edge edge; scanf(\"%d%d\",&amp;N,&amp;M); for(int i=0;i&lt;M;i++) &#123; scanf(\"%d%d%d\",&amp;u,&amp;v,&amp;l); edge.v=v; edge.len=l; Adj[u].push_back(edge); edge.v=u; Rev[v].push_back(edge); &#125; scanf(\"%d%d%d\",&amp;S,&amp;T,&amp;K);//计算S到T的第K短路径 if(S==T) K++;&#125;//Dijkstra 算法 找出各个点到T的最短距离void Dijkstra()&#123; memset(mark,false,sizeof(mark)); for(int i=1;i&lt;=N;i++) dist[i]=INF; dist[T]=0; int u,v,min; while(1) &#123; u=-1,min=INF; for(int i=1;i&lt;=N;i++) if(!mark[i] &amp;&amp; dist[i]&lt;min) &#123; min=dist[i]; u=i; &#125; if(u==-1) break; mark[u]=true; for(int k=0;k&lt;Rev[u].size();k++) &#123; v=Rev[u][k].v; if(!mark[v] &amp;&amp; dist[v]&gt;dist[u]+Rev[u][k].len) dist[v]=dist[u]+Rev[u][k].len; &#125; &#125;&#125;int Astar()&#123; if(dist[S]==INF) return -1; memset(cnt,0,sizeof(cnt)); priority_queue&lt;Node&gt; Q; Q.push(Node(S,0)); while(!Q.empty()) &#123; int len=Q.top().len; int v=Q.top().v; Q.pop(); cnt[v]++; if(cnt[T]==K) return len; if(cnt[v]&gt;K) continue; for(int i=0;i&lt;Adj[v].size();i++) Q.push(Node(Adj[v][i].v,len+Adj[v][i].len)); &#125; return -1;&#125;int main()&#123; Init_graph(); Dijkstra(); int ans=Astar(); printf(\"%d\\n\",ans); return 0;&#125;","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"A* k-shortest","slug":"A-k-shortest","permalink":"http://chenyukang.github.io/tags/A-k-shortest/"}]},{"title":"一个小题目","date":"2010-08-02T11:43:00.000Z","path":"2010/08/02/findsum.html","text":"前些天在班级群里看到一个笔试题： 从1到100000中任意拿掉两个数字，把剩下的99998个数顺序打乱，并且放入数组A中。要求只扫描一遍，把这两个数找出来；可以使用最多不超过5个局部变量，不能使用数组变量，并且不能改变原数组的值。也想不到什么更好的解法，原解法是顺序扫一边求得所有数的乘积(mul_res)、和(sum_res)。用(N!)/mul_res得到两个数的乘积，1到100000的和减去sum_res得到两个数之和。 解这个方程得到两个数。关键是N!太大了，C会溢出。刚开始想想乘积每次模100000，后来写了一下还是不对的，因为模100000中可能就出现了0，后面全为0了。最后想到这么一个办法，不过中间 除法和比较多。也许有更快的解法。 file:///home/heipang/document/wiki/Home_Page/Computer/笔试题.html //1到100 000 #include &lt;iostream&gt; #include &lt;math.h&gt; using namespace std; #define N 100000 typedef long long LL; LL a; LL b; LL vec[N]; int cnt; LL MAX_MUL; void Find(const LL* vec) { int sum=0; LL mul=1; LL Now=1; for(int i=0;i&lt;cnt;i++) { sum+=vec[i]; while(mul%vec[i]!=0) mul*=(++Now); mul/=vec[i]; } while(Now&lt;100000) mul*=(++Now); LL diff=((1+N)*N)/2-sum; cout&lt;&lt;diff&lt;&lt;\" \"&lt;&lt;mul&lt;&lt;endl; LL a=(diff+sqrt(diff*diff-4*mul))/2; cout&lt;&lt;a&lt;&lt;\" \"&lt;&lt;diff-a&lt;&lt;endl; } int main() { srand(time(NULL)); a=(rand()%100000)+1; b=(rand()%100000)+1; cnt=0; for(int i=1;i&lt;=N;i++) { if(i!=a&amp;&amp;i!=b) vec[cnt++]=i; } cout&lt;&lt;a&lt;&lt;\" \"&lt;&lt;b&lt;&lt;\" \"&lt;&lt;endl; cout&lt;&lt;a+b&lt;&lt;\" \"&lt;&lt;a*b&lt;&lt;endl; Find(vec); } ---------------------------------------------------------- 经熊师兄指点，上面的解法还是不对，如果vec前面刚好为比较大的素数，mul就溢出了。正确的解法应该为求x+y=B, x^2+y^2=A, 1-100000的平方和可以用double存下来，然后减去vec里面的平方和就得到x^2+y^2的值。 void Find(const LL* vec) { double sum=0; double square_sum=0; for(int i=0;i&lt;cnt;i++) { sum+=vec[i]; square_sum+=(vec[i]*vec[i]); } double diff=((1+N)*N)/2-sum; double square_sum_diff= ((double)N*(N+1)*(2*(double)N+1))/6 - square_sum; cout&lt;&lt;diff&lt;&lt;\" \"&lt;&lt;square_sum_diff&lt;&lt;endl; a=(2*(diff)+sqrt(8*square_sum_diff-4*diff*diff))/4; cout&lt;&lt;a&lt;&lt;\" \"&lt;&lt;diff-a&lt;&lt;endl; }","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"}]},{"title":"魔法书：SICP","date":"2010-07-27T11:43:00.000Z","path":"2010/07/27/sicp.html","text":"《计算机程序的构造与解释》，SICP。这本书号称魔法书，真的是本非常有趣的书。为什么要看这本书，豆瓣上面有很多推荐，书评写得都很好，在这里。我最初看的是英文版， 在网上很好找到，MIT开源课程的网站上面有很多相关资料。从80年开始MIT就是用这门课程作为计算机的入门课程的(MIT真是个神牛云集的地方,看这个神牛的博客http://blog.vgod.tw/category/divine-code/ ,神乎其乎)，不过 现在这门课程的编程语言换作Python了。所以曾经风靡一时的scheme和Lisp学的用的人就更少了。这最古老的一种编程语言之一 在慢慢要消失，不知那帮做人工智能的还用这个不？关于语言的发展参考这个牛人的一系列博文(http://blog.youxu.info/)。 这本书06年看过一点，不过那时候没怎么看懂,到前两章就没看下去了。大四的暑假进了实验室，怎么就偶然又想好好看看，学校图书馆三楼有这本英文原版的，纸张非常之好，看起来是相当舒服。有中文 版的，不过翻译有时看起来会有点点别扭。大学期间没写过很大的工程，当时也不知道这本书的内容的深度，因为之前一段时间看了Concrete Abstraction 吧，所以看起来没06年那么吃力了。 反正只是觉得好玩，正如书的前言中所说，编程应该是充满艺术性以及美感的。后来又在寝室下了MIT的课程视频，两个老师讲课都非常好，很奇怪那些老师都会用粉笔在黑板上狂写代码，或者是当时在键盘上敲代码，分析来分析去的，反正极少用ppt之类的东西。 国内的大学老师大多是不怎么用粉笔了。总之这本书的内容还是相当广泛，我花了近两个月看了四章多点，慢慢做每章后面的习题,感觉收获不少，函数、算法、面向对象、高阶函数、泛型、并发、流、惰性求值、解释器和编译器、一些编程风格和方式的解释等等。 很多高级语言里面的特性在那里都已经提及过,比如STL里面不就有高阶函数吗，现在的动态语言还支持lambda。理论支撑实现，实现很多内容看起来很高深，不过因为有具体的代码可以实现一下就比较好理解了。 当时看的时候有的地方还是没理解，后来看到一个书评说多年的编程经验才能完全理解其中的内容。虽然现在除了Elisp也很少用函数式语言，但通过看这本书和做习题来让我对编程有了更多的兴趣。以后有时间再好好看看后面两章，因为第五章还没看完。有的题目有些难， 做的时候参考了这个博客(http://eli.thegreenplace.net/)，估计这人是第一个在网上放出SICP绝大部分习题解答的吧，他用的是Lisp。下面的附件是我做习题的代码，不保证全部都正确，如果有错误或者更好的解法请给我指出来(moorekang@gmail.com)。 前面三章用的环境是PLT scheme的集成环境，后面用的是mzscheme，不过应该是没有问题的，我把一些运行结果也放到里面了。sicp(1~4)_exercise","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Books","slug":"Books","permalink":"http://chenyukang.github.io/tags/Books/"},{"name":"Lisp","slug":"Lisp","permalink":"http://chenyukang.github.io/tags/Lisp/"},{"name":"SICP","slug":"SICP","permalink":"http://chenyukang.github.io/tags/SICP/"}]},{"title":"走出迷宫-路径搜索","date":"2010-07-22T11:43:00.000Z","path":"2010/07/22/maze.html","text":"上次把那个迷宫弄出来，然后想了想解法，找了些资料。再把界面上弄了一下，右边迷宫大小，然后有一个选项percent，是代表要推倒的墙占的总百分比，如果数字越小生成的迷宫就越稀疏,有可能有多条 通路从起点到终点,数字大那么生成的迷宫就越密集，但至少有一条通路。 单迷宫解法迷宫第一定律：一般而言，只要在出发点单手摸住一面墙出发，手始终不离开墙面，总可以找到迷宫的出口。对于单迷宫而言，这一种万能的破解方法，即沿着某一面墙壁走。 或者换句话说，你在走的时候，左（右）手一直摸着左（右）边的墙壁，这种方法可能费时最长，也可能会使你走遍迷宫的每一个角落和每一条死路，但你绝不会永远困在里面。 直觉上好像是可以，实现一下也确实能找到终点的，也就是靠着墙，一直靠左或者一直靠右。实现的时候甚至都不用记录哪些点已经访问过了，哪些点还没访问过。 这也是一种人能来做的算法，毕竟人不可能像计算机一样dfs、bfs。 BFS用BFS肯定也是可以的，如果是单路径的迷宫，用BFS实在是太慢了,它会把大部分的点都遍历一边。感觉就像是一颗石子掉到水中，要找岸边的终点那得等波纹波及到岸边。 非常之慢。但如果是有多条通路的迷宫，BFS是能保证找到最短路径的。也许双向BFS会好一点，不过猜想对于单迷宫，也提高不了多少。 DFS那用DFS也是可以的。不过效率还是很差，像苍蝇一般在迷宫的各个角落转悠，直到大部分点都遍历了。稍微改变一下DFS优先搜索的方向会有一些提高，比如我这个图优先走下方或者优先走左方。 AA是一种启发式搜索算法，在这里我用点与点的曼哈顿距离来作为启发函数，效果不好，因为曼哈顿距离也就大概的告诉了搜索路径现在应该往哪个方向走比较好。不过总得来说 这么一点启发得到的效果还是要比BFS和DFS要好些。评估函数选择合适也是能找到最短路径的，曼哈顿是可以的。如果墙比较稀疏(肯定有多条路径)，那么A*算法会快得许多。 用键盘走呵呵，对于小点的迷宫用键盘来移动可以比较快解决，人是有直觉和经验的，在合适复杂度上面这种直觉给的启发可比上面好，但是如果迷宫太大了就不行咯。或者还有其他算法去走出迷宫么？","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"迷宫","slug":"迷宫","permalink":"http://chenyukang.github.io/tags/迷宫/"},{"name":"路径搜索","slug":"路径搜索","permalink":"http://chenyukang.github.io/tags/路径搜索/"}]},{"title":"《C深度探索》笔记","date":"2010-07-20T11:43:00.000Z","path":"2010/07/20/c-deep.html","text":"最名不副实的关键字 static这个关键字在C语言里面有两个作用，C++对这个关键词进行了扩展。1：修饰变量，又分为局部变量和全局变量，被修饰的变量都存储在静态的内存区域。 修饰静态变量，那么只有在这个文件内可以引用它，在其他文件里面即使使用extern也不能进行访问。所以一般是放在文件头部分。 修饰局部变量，只有在定义的函数内访问，函数外不能访问，即使是在同文件内。2：修饰函数，在函数前面添加static，那么这个函数只能在该文件内使用。这样，不同人编写的函数，如果不在同文件内，可以不用担心函数名字 相同。main.cint main()&#123; Func(); reutrn 0;&#125;Def.cstatic void Func()&#123; printf(\"Func called\\n\");&#125;编译: gcc main.c Def.c -o main 链接错误变量的命名min-length&amp;&amp;max-information低精度数据向高精度数据扩展。被冤枉的关键字 sizeof 用法：sizeof(int), sizeof(i), sizeof i;if ,else float类型值与0值比较，定义一个很小的数，在某个范围内。同时不要在一个很大的浮点数和很小的浮点数之间进行运算。循环注意点嵌套循环中，长循环放在内，短循环放在外面，这样可以减少cpu跨切循环层的次数，利用cpu cache。 循环里面的代码尽量短，一般不超过20行。如果不行就改为循环调用函数。void主要作用在于对函数参数的限定和函数返回值的限定。不能对void进行算法操作。const修饰指针的时候的记法，就近原则。 const int p ; p可变，指向的对象不可变 int const p ; p可变，指向的对象不可变 int* const p; p不可变，指向的对象可变struct 和class的区别在C++中struct关键字与class一般可以通用，一个区别就是struct的成员默认情况下是public的，而class的是private的。union一个union只配置一个足够大的空间来容纳最大的数据成员，union的作用在于压缩空间。存储的大小端：union&#123; int i; char a[2];&#125;*p,u;int main()&#123; p=&amp;amp;u; p-&amp;gt;a[0]=0x39; p-&amp;gt;a[1]=0x38; printf(\"%d\\n\",p-&amp;gt;i); PrintBinary(14393); PrintBinary(56); PrintBinary(57); if(CheckSystem()==1) printf(\"Little endian\\n\"); else printf(\"Big endian\\n\"); return 0;&#125;11100000111001111000111001Little endian 低字节存储在低地址指针，访问内存的钥匙前段时间听过一个面试题，就是如何读写某人地址，答案就是指针？#include &lt;stdio.h&gt;int main()&#123; int i=0; int pp=&amp;i; printf(\"%x\\n\",pp); int p=(int)0x12ff60; printf(\"%x\\n\",p); *p=1; printf(\"%d\\n\",i); getchar(); return 0;&#125;这段代码在vc中编译是能够运行的，但是在gcc中不行，gcc中编译后i的地址并不是固定的，这样直接给指针赋值，写指向的地址出现访问越界。a和&amp;a的区别 int main()&#123; int a[5]=&#123;1,2,3,4,5&#125;; int* ptr=(int*)(&amp;amp;a+1); int* p=(int*)(&amp;amp;a); printf(\"%x\\n\",ptr); printf(\"%x\\n\",p); printf(\"%d,%d\\n\",*(a+1),*(ptr-1)); return 0;&#125; bfeae860 bfeae84c 2,5 说明ptr和a的地址相差5*4=20个byte。 定义数组int a5; a表示的是数组中首元素的地址，&amp;a才是数组的首地址，两者的值是一样的，但是意义却不同。 数组当作函数参数传递传递的是指针，也就是数组的地址，但注意如果把指针本身传递进函数的时候进行了数组的拷贝，传递的是一个拷贝。 void func(char* p)&#123; char c=p[3]; *(p+3)='X'; printf(\"%c\\n\",c);&#125;int main()&#123; //char* p=\"abcdef\"; char p[]=\"abcdefg\"; func(p); printf(\"%s\\n\",p); return 0;&#125; 注意上面的区别，如果是char* p=”abcdef”，那么p为main函数的局部变量，”abcdef”的存储空间在静态内存中，func函数中可以通过指针p去访问其内容， 但如果改变其内容会发生访问越界。而char p[]=”abcdefg”，其数组的内容是在栈上。 内存管理静态区:保存自动全局变量和 static 变量(包括 static 全局和局部变量)。静态区的内容 在总个程序的生命周期内都存在,由编译器在编译的时候分配。 栈(堆栈):保存局部变量。栈上的内容只在函数的范围内存在,当函数运行结束,这些内容 也会自动被销毁。其特点是效率高,但空间大小有限。 堆:由 malloc 系列函数或 new 操作符分配的内存。其生命周期由 free 或 delete 决定。 在没有释放之前一直存在,直到程序结束。其特点是使用灵活,空间比较大,但容易出错。","tags":[{"name":"C","slug":"C","permalink":"http://chenyukang.github.io/tags/C/"},{"name":"Books","slug":"Books","permalink":"http://chenyukang.github.io/tags/Books/"}]},{"title":"《Concrete Abstractions》的一些解答","date":"2010-07-20T11:43:00.000Z","path":"2010/07/20/concrete-abstractions.html","text":"这本书名中文名字叫什么呢，有本《具体数学》，那么这本书“具体抽象”，矛盾了。副标题是An Introduction to Computer Science Using Scheme。可以看出这是本引论性质的计算机理论书籍。《冒号课堂》里面说过，编程中最重要的能力是抽象的能力，这本书也在培养这么一种能力，并且能代 码实现去辅助说明。这本书是美国一个大学用的一本教材(具体哪个忘记了，可以到书的主页上去看看),貌似很多大学都使用scheme作为第一门程序设计语 言，历史悠久，属于Lisp变种。像这种函数式语言虽然效率不是很高，但是语法简单，而且功能强大，支持多种程序设计方法。在这里程序就是数据，数据就是 程序，在sicp中一段不长的scheme代码就能成为一个scheme解释器。Scheme很简单，和下棋一样，人们能很快就学会其语法，这里有个很好 的教程t-y-scheme。 貌似以前美国很多大学都是用这个作为第一门程序设计语言来教学，现在用Python的更多了，函数式语言还是在渐渐被遗忘。作为引论性质的课程，广度和高 度都达到一定程度，甚至让学生站了语言设计者的角度去思考问题。其中的主线是：过程抽象，数据抽象，和状态抽象。内容涉及:递归和推导，迭代，高阶函数， 数据结构，泛型操作，实现程序设计语言，动态规划，面向对象范型等等。SICP包含这些内容，并且思想上更深入。所以先大概看看这本书对于阅读SICP(《计算机程序的构造和解释》)有很大的帮助。大学的时候看到第五章，做了其中大部分习题，有些题目很有启发。我大四的时候做的1~5章的练习题。在这里下载。不保证所有的解法都是正确并最好的，网上这本书的相关资料比较少，而SICP的解答到是有比较多可以参考。","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Scheme","slug":"Scheme","permalink":"http://chenyukang.github.io/tags/Scheme/"}]},{"title":"指针指针","date":"2010-07-20T11:43:00.000Z","path":"2010/07/20/pointerbug.html","text":"今天由一个函数加深了对指针的理解，是这么一个函数： void BST_Delete(BITREE y) //删除节点y&#123; if (y-&gt;lch==NULL &amp;&amp; y-&gt;rch==NULL &amp;&amp; y-&gt;p) &#123; if(y==(y-&gt;p)-&gt;lch) (y-&gt;p)-&gt;lch=NULL; else (y-&gt;p)-&gt;rch=NULL; &#125; else if (y-&gt;rch==NULL &amp;&amp; y-&gt;p) &#123; if(y==y-&gt;p-&gt;lch) y-&gt;p-&gt;lch=y-&gt;lch; else y-&gt;p-&gt;rch=y-&gt;lch; &#125; else if (y-&gt;lch==NULL &amp;&amp; y-&gt;p)&#123; if(y==y-&gt;p-&gt;lch) y-&gt;p-&gt;lch=y-&gt;rch; else y-&gt;p-&gt;rch=y-&gt;rch; &#125; else &#123; BITREE t=BST_Successor(y); y-&gt;data=t-&gt;data; BST_Delete(t); y=t;//y=NULL &#125; free(y);&#125; 在最后一个else内，如果二叉搜索树中有左右孩子，那么找这个删除节点的后继，把内容互换，然后删除后继 节点，因为后继节点一定只有一个孩子或者没有孩子。最后只有一个free()操作其实是为了代码简洁,可以把前面每一个else if后面加一个free， 最后不写free()操作。但是这么写运行起来会有问题，y=t,就是所指向的地址相同，但是因为是 递归操作，t指向的地址在调用BST_Delete(t)的时候已经被free掉了，所以如果再删除一次就会 出现内存错误，修改方法是y=NULL,或者修改函数参数，用指针引用的形式 void BST_Delete( BITREE&amp; y)，然后再在free(y)后面增加一句y=NULL。以前以为两次调用free(p)是不会出现问题的，free()在释放掉p指向的内存以后，会 自动将p赋值为NULL，其实没有这部分操作。 前些天还看到一个面试题目，malloc申请的空间用delete删除会有什么问题？一般来说没有问题， 内存会释放掉，而且即使是有析构函数的对象指针，用delete删除的时候同样会调用析构函数。这说明 c++的delete操作其实是在c的基础增加了一些操作，先调用析构函数，然后释放空间。良好的编程风格 就是free/malloc，new/delete一一对应，甚至不要出现一次调用，多次释放，像上面那样的因为递归 而产生的多次释放并不是很好发现","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"C","slug":"C","permalink":"http://chenyukang.github.io/tags/C/"}]},{"title":"The Game of Life","date":"2010-07-20T11:43:00.000Z","path":"2010/07/20/the-game-of-life.html","text":"简介 Game of Life是Princeton的一个数学家发明的游戏，这个不像一般的小游戏，有胜负，这只是一个规则很简单的模拟游戏， 规则很简单，但是过程和结果都很有趣，大三时看到一个同学实现过，去年无聊时也写了个实现，挺好玩的，最后形成的图案很有趣。 rule平面中的一个小方格分为生和死的状态，规则是： 如果一个死的细胞周围有三个细胞是活的，在下一轮中这个位置出现一个活的细胞。 如果一个活的细胞周围有两个或者三个活的细胞，在下一轮中或者，否则下轮中该细胞死掉。 其他情况该位置维持不变。这里的 周围 是指一个方格的周围8个位置。 规则很简单，结果也很完美，甚至是符合现实世界中生命的生死规律，一个群种只有在保持平衡的状态下才能实现良性循环。 不可能有一种初始状态使得活着的细胞数量一直增加,如果你找到一种，可以向原作者所要一笔钱，哈哈。不管初始状态如何，真个世界在经过一段时间的演变之后都会逐渐稳定下来。稳定的状态有很多中，分为静止的和“颤抖”的。 另外发现一些的简单规律：并不是初始或者的数目越多最后或者的数目就越多，测试表明初始或者的数目为总量的一半的时候活着的比较多。 还有很多规律在其主页上可以找到。 实现我这个是Linux下OpenGL实现的，红色代表死的细胞，蓝色代表活着的细胞，稳定以后世界","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"Life Game","slug":"Life-Game","permalink":"http://chenyukang.github.io/tags/Life-Game/"}]},{"title":"迷宫生成算法–并查集","date":"2010-07-20T11:43:00.000Z","path":"2010/07/20/union-set-maze.html","text":"好书好书 在看《数据结构与算法分析》这本书的时候看到后面的一个关于并查集的有趣应用，是个生成迷宫的算法，看起来非常有趣，所以就实现了一下。顺便把几种走迷宫的算法都整了 进去。八卦一下，这本书的作者是Mark Weiss,这牛写了几本数据结构和算法的书，各种语言版本(C,C++,Java)，原来是师出名门啊，在他的主页上一看，原来是Robert Sedgewick 的学生。Sedgewick更是师出名门，在Princeton跟高纳德神牛读的博士，也写了N本算法和数据结构的书。这两人写的书都还不错，对于初学者和中等水平来说很好，覆盖了一般的数据结构和算法，同时带有一定的理论分析还有特定的语言实现。 并查集 可能一般的大学教材上面没有说这个数据结构，这是个很有趣的东西。《算法导论》上面用这个来作为均摊分析的例子吧。在ACM/ICPC中这个数据结构经常出现，有可能是一个小题 （难点的就是要维护节点之间关系的那种），或者是有的图论算法中实现要用,比如实现Kruskar算法求最小生成树。并查集本身比较简单，主要是用来操作元素集合，支持的操作有： UnionSets(int root1,int root2), 用来合并两个根节点。 FindSet(int x) , 用来查找x所属的根节点。 一并一查，所以叫作并查集。实现时候可以通过按秩合并(union by rank)，和路径压缩(path compression)来增加效率，可以获得几乎与总操作数m成线性关系的运行时间。 int rank[MAXSIZE]; // 节点高度的上界int parent[MAXSIZE]; // 根节点void Init(void)&#123; memset(rank, 0, sizeof(rank)); for(int i=0; i &lt; MAXSIZE; ++i ) parent[i] = i;&#125;int FindSet(int x)&#123;// 查找+递归的路径压缩 if( x != parent[x] ) parent[x] = FindSet(parent[x]); return parent[x];&#125;​void UnionSet(int root1, int root2)&#123; int x = FindSet(root1), y = FindSet(root2); if( x == y ) return ; if( rank[x] &gt; rank[y] ) parent[y] = x; else&#123; parent[x] = y; if( rank[x] == rank[y] ) ++rank[y]; &#125;&#125; 迷宫的实现 上面那本书上的习题上给了提示，比如首先所有的墙都没有去掉，那么是一个一个的方格，每一个方格为并查集合的一个元素，已经连通的元素是在并查集的一个集合中，有相同的根节点。 随机的选择一个墙，在并查集中查询这两个元素是否已经连通，如果已经连通则另选一个墙，如果不连通，union两个节点的根节点，这样操作以后这两个方格已经连通。继续上面的操作， 直到入口和出口连通位置，那么这就形成了一个只有一条合法路径的迷宫，称为单迷宫。如下图所示。 左上角起点 右下角终点","tags":[{"name":"Programming","slug":"Programming","permalink":"http://chenyukang.github.io/tags/Programming/"},{"name":"迷宫","slug":"迷宫","permalink":"http://chenyukang.github.io/tags/迷宫/"}]},{"title":"Emacs: keyboard macros","date":"2010-07-17T11:43:00.000Z","path":"2010/07/17/emacs-keyboard-macros.html","text":"宏编辑以前知道Emacs有一个keyboard macros，不过一直没认真看一下，今天算是粗略懂了一些。宏编辑很早就有了，很多编辑器都有这种功能，word好像是有的，不过没用过，格式刷算宏编辑不？甚至Emacs 的起名有一种说法就是 Edit MACroS，最初是作为一个叫作TECO编辑器上的一套宏而编写，然后就是重写了N次，现在Emacs上还有个模拟TECO的模式：）。kbd macros就是把一系列要做的动作集合成一个，然后可以执行多次。以前有时在网上拷贝代码，但是前面都加有行好，不编辑一下不能编译，这种情况 就可以用这个kbd macro一下就解决了。 先来一个例子，比如说有这么一段文字：Newton, IsaacEinstein, AlbertMaxwell, JamesTuring, Alan…现在要变成这个样子Isaac NewtonJames MaxwellAlan Turing…在Emacs下可以执行下面一系列快捷键来处理一行。如果行数不多，那么敲几下键盘就可以了，如果是很多行呢，总不可能一直这样用手动的吧。上次遇到那个几百行的代码，每 行前面都有一个表示行数目的数字，一狠心写了个C程序来处理，囧。为了不让手指报废，定义一个kbd macro是很快速的方法。也就是在我处理的一行的之前按F3(或者”C-x (“ ),在处理第一行的时候Emacs已经在记录这即个命令，结束完一行的处理就可以按F4(或者”C-x )”。这样就已经完成了定义。使用宏 定义好以后下面的很多行都可以使用这个宏去操作，只要按C-x e就是执行上一次定义的宏，C-u 20 C-x e执行20次，甚至可以选中一个区域然后执行M-x apply-macro-to-region-lines (或者 C-x C-k r)。但这个时候宏里面别加go-to-the-next-line，因为上面这个命令就已经是逐渐移动区域的每一行，执行上面的宏，如果再加goto命 令就会跳过一些行。另外还可以手动编辑这个宏，命令M-x edit-kbd-macro，会让你选择要编辑的宏，比如说选刚才保存的那个宏，得到： ;; Keyboard Macro Editor. Press C-c C-c to finish; press C-x k RET to cancel.;; Original keys: C-a M-d 2*C-d C-e SPC C-y C-nCommand: last-kbd-macroKey: noneMacro:C-a ;; move-beginning-of-lineM-d ;; kill-word2*C-d ;; delete-charC-e ;; move-end-of-lineSPC ;; self-insert-commandC-y ;; yankC-n ;; next-line 编辑完后按C-c C-c完成。 如果这个操作经常会用到(比如清楚带行号的代码)，还可以把这个操作保存下来，以后都可以用。在.emacs或者自己的配置文件中增加: (fset &apos;foo [?\\C-a ?\\M-d delete delete ?\\C-e ? ?\\C-y ?\\C-n])","tags":[{"name":"Emacs","slug":"Emacs","permalink":"http://chenyukang.github.io/tags/Emacs/"}]},{"title":"胡乱想想","date":"2010-07-15T11:43:00.000Z","path":"2010/07/15/thinking.html","text":"哈哈，终于还是弄了独立空间，yo2还在崩溃中，没前的还没转过来。新的空间速度不错，服务也可以，可是在教育网内不能访问，算了，教育网内能访问的就那么几个。中午下了场雨，可还是很闷，下午在看《The Practice of Programming》，不错的书。两天没去实验室了，那里闷得慌。这个月还是打算在学校待着，8月份回家一趟。昨天一个校友从上海回来，大家一起聊了会，对他们那公司挺感兴趣的，准备有机会去面试一下。这些天经常睡不着，睡着也做梦。我就是这样，在生活的链接点比较焦虑，比如说升学时，这会是找工作了。一些朋友会说，你那么当心干什么，找份工作应该不难，况且你又平常又不是懒人，还是学了点东西的。呵呵，我是天生有点悲观吧，总会忍不住去想结果。这会倒比较轻松，工作有好坏之分么，适合自己的工作才是最好的吧，做自己想做的领域才会有激情，现在工作的愿望比两年前强多了。同时我也比较能看得到自己的弱点。我很清楚自己不是想搞科研，可能也不是很适合。对于写论文，我更倾向于写代码。我不适合做市场，同人打交道好像要比同机器打交道要难。我不适合做管理，尽管有时候想改变自己的一些性格特点，现在回想起来勉强自己做的那些并没什么好的效果。总之，既然想搞所谓的挨踢行业，想走技术路线，那还是好好的坚持吧，The lyf so short, the craft so long to lerne.. 在学校还能好好看看想看的书，以后就是MOP了，珍惜珍惜！控制自己的思绪和情绪是件比较重要的事情，“憩于理性，行于热情”这是我所期望的，抓紧时间好好享受这段最后的单调的校园生活。面包会有的，哼哈。","tags":[{"name":"Notes","slug":"Notes","permalink":"http://chenyukang.github.io/tags/Notes/"}]},{"title":"Hello world!","date":"2010-07-13T11:43:00.000Z","path":"2010/07/13/hello-world.html","text":"欢迎使用 WordPress 。这是系统自动生成的演示文章。编辑或者删除它，开始您的博客！","tags":[{"name":"Notes","slug":"Notes","permalink":"http://chenyukang.github.io/tags/Notes/"}]}]